var data =
[
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "sstsimulator/sst-spack",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/27a2a2325cf0fa186b65c72ddc9d538f0bb36c7d521486221b8b7adbcf3e1180/687474703a2f2f7373742d73696d756c61746f722e6f72672f696d672f7373742d6c6f676f2d736d616c6c2e706e67\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27a2a2325cf0fa186b65c72ddc9d538f0bb36c7d521486221b8b7adbcf3e1180/687474703a2f2f7373742d73696d756c61746f722e6f72672f696d672f7373742d6c6f676f2d736d616c6c2e706e67\" alt=\"SST\" data-canonical-src=\"http://sst-simulator.org/img/sst-logo-small.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eStructural Simulation Toolkit (SST) Spack Packages\u003c/h1\u003e\u003ca id=\"user-content-structural-simulation-toolkit-sst-spack-packages\" class=\"anchor\" aria-label=\"Permalink: Structural Simulation Toolkit (SST) Spack Packages\" href=\"#structural-simulation-toolkit-sst-spack-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eCopyright (c) 2009-2023, National Technology and Engineering Solutions of Sandia, LLC (NTESS)\u003c/h4\u003e\u003ca id=\"user-content-copyright-c-2009-2023-national-technology-and-engineering-solutions-of-sandia-llc-ntess\" class=\"anchor\" aria-label=\"Permalink: Copyright (c) 2009-2023, National Technology and Engineering Solutions of Sandia, LLC (NTESS)\" href=\"#copyright-c-2009-2023-national-technology-and-engineering-solutions-of-sandia-llc-ntess\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBasic Usage\u003c/h2\u003e\u003ca id=\"user-content-basic-usage\" class=\"anchor\" aria-label=\"Permalink: Basic Usage\" href=\"#basic-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMake sure you have downloaded \u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e and added it to your path.\nThe easiest way to do this is often (depending on your SHELL):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; source spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo get the most up-to-date version of the SST Spack packages, after downloading the sst-spack GitHub repository, you simply need to run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack repo add sst-spack/sst\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo validate that Spack now sees the repo with the SST packages, run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack repo list\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis should now list your newly downloaded Spack repo.\nYou can display information about how to install the individual packages with, e.g.:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack info sst-core\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will print all the information about variants and dependencies of the package.\nFor detailed instructions on how to use Spack, see the \u003ca href=\"https://spack.readthedocs.io\" rel=\"nofollow\"\u003eOwner\u0027s Manual\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eA basic installation of a package is done as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack install sst-core +pdes-mpi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewhich tells Spack to install the core with PDES support using MPI.\nFor downstream packages like sst-elements, sst-core and all dependencies will be automatically installed.\nWe can visualize this with either \u003ccode\u003espack spec\u003c/code\u003e or \u003ccode\u003espack graph\u003c/code\u003e, e.g.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack spec sst-elements +pin +hybridsim\nInput spec\n--------------------------------\nsst-elements+hybridsim+pin\n\nConcretized\n--------------------------------\nsst-elements@master%gcc@7.4.0~dramsim2~goblin~hbm+hybridsim~nvdimmsim+pin~ramulator arch=linux-centos7-haswell\n    ^autoconf@2.69%gcc@7.4.0 arch=linux-centos7-haswell\n    ^automake@1.16.1%gcc@7.4.0 arch=linux-centos7-haswell\n    ^dramsim2@2.2%gcc@7.4.0 arch=linux-centos7-haswell\n    ^hybridsim@2.0%gcc@7.4.0 patches=e266e00e3777feb1d9b3691f6a5a88d1d99c5aa0e0811fcf5461d55e0ac4a7bd arch=linux-centos7-haswell\n        ^nvdimmsim@2.0%gcc@7.4.0 arch=linux-centos7-haswell\n    ^intel-pin@2.14%gcc@7.4.0 arch=linux-centos7-haswell\n    ^libtool@2.4.6%gcc@7.4.0 arch=linux-centos7-haswell\n    ^python@2.7%gcc@7.4.0+bz2+ctypes+dbm~debug+libxml2+lzma~nis~optimizations+pic+pyexpat+pythoncmd+readline+shared+sqlite3+ssl~tix~tkinter~ucs4~uuid+zlib arch=linux-centos7-haswell\n    ^sst-core@master%gcc@7.4.0~hdf5+pdes-mpi~zlib~zoltan arch=linux-centos7-haswell\n        ^openmpi@3.1.5%gcc@7.4.0~cuda+cxx_exceptions fabrics=none ~java~legacylaunchers~memchecker~pmi schedulers=none ~sqlite3~thread_multiple+vt arch=linux-centos7-haswell\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis shows what will be installed along with the specification of all the dependencies.\nIf any of the dependencies are missing, Spack will download and install them.\nNote here that the default compiler for this Spack is GCC 7.4.\nIf we wish to use a different compiler, we can specify it as, e.g:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack install sst-elements +pin +hybridsim %clang@9.1.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo make sure your desired compiler is known to Spack, you can check:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack compiler list\n==\u0026gt; Available compilers\n-- clang centos7-x86_64 -----------------------------------------\nclang@7.0.0\n\n-- gcc centos7-x86_64 -------------------------------------------\ngcc@7.4.0  gcc@4.8.5\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAll compilers in the path are usually located by running \u003ccode\u003espack compiler find\u003c/code\u003e and automatically added.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTesting and Developing with Spack\u003c/h2\u003e\u003ca id=\"user-content-testing-and-developing-with-spack\" class=\"anchor\" aria-label=\"Permalink: Testing and Developing with Spack\" href=\"#testing-and-developing-with-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack has historically been much more suited to \u003cem\u003edeployment\u003c/em\u003e of mature packages than active testing or developing.\nHowever, recent features have improved support for development.\nFuture releases are likely to make this even easier and incorporate Git integration.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTesting\u003c/h3\u003e\u003ca id=\"user-content-testing\" class=\"anchor\" aria-label=\"Permalink: Testing\" href=\"#testing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA common pattern in testing is validating a successful build of feature branches.\nSpack provides the \u003ccode\u003edev-build\u003c/code\u003e feature for building and installing from a custom source folder.\nFor example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; git clone git@github.com:sstsimulator/sst-core.git -b devel src\n\u0026gt; spack dev-build -d src sst-core@devel +pdes-mpi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eis equivalent to just running\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack install sst-core@devel +pdes-mpi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor validating a complete build of the \"core\" packages (sst-core, sst-elements, sst-macro) with any combination of branches, one can simply run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; git clone git@github.com:sstsimulator/sst-core.git -b feature-core sst-core-src\n\u0026gt; git clone git@github.com:sstsimulator/sst-macro.git -b devel sst-macro-src\n\u0026gt; git clone git@github.com:sstsimulator/sst-elements.git -b feature-elems sst-elements-src\n\u0026gt; spack dev-build -d sst-core-src sst-core@devel core-variants... %compiler\n\u0026gt; spack dev-build -d sst-macro-src sst-macro@devel macro-variants... ^sst-core@devel core-variants... %compiler\n\u0026gt; spack dev-build -d sst-elements-src sst-elements@devel elem-variants... ^sst-core@devel core-variants... %compiler\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere \u003ccode\u003e%compiler\u003c/code\u003e is a spec like \u003ccode\u003egcc@7.4.0\u003c/code\u003e.\n\u003ccode\u003ecore-variants...\u003c/code\u003e is the desired sst-core spec like \u003ccode\u003e+pdes-mpi +zoltan\u003c/code\u003e.\nNote the the \u003ccode\u003e^\u003c/code\u003e syntax used here to ensure that sst-elements and sst-macro depend on a precise variant of sst-core.\nFor example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack dev-build -d sst-macro-src sst-macro@devel +otf2 +core ^sst-core+pdes-mpi+zoltan\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBecause we are doing feature branch testing, we use \u003ccode\u003e@devel\u003c/code\u003e to build the branches as-if they were the \u003ccode\u003edevel\u003c/code\u003e branch.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDeveloping\u003c/h3\u003e\u003ca id=\"user-content-developing\" class=\"anchor\" aria-label=\"Permalink: Developing\" href=\"#developing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe above commands will do a full build and install of the packages.\nIf doing development, you may wish to merely set up a build environment.\nThis allows you to modify the source and re-build.\nIn this case, you can stop after configuring:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; spack dev-build -d sst-core-src -u configure sst-core@devel +otf2 +core ^sst-core+pdes-mpi+zoltan\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis sets up a development environment for you in \u003ccode\u003esst-core-src\u003c/code\u003e, which you can use (Bash example shown):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; cd sst-core-src\n\u0026gt; source spack-build-env.txt\n\u0026gt; cd spack-build\n\u0026gt; make\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBefore sourcing the Spack development environment, you may wish to save your current environment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; declare -px \u0026gt; myenv.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen done with Spack, you can then restore your original environment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource myenv.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eConfiguring Default Spack Packages\u003c/h2\u003e\u003ca id=\"user-content-configuring-default-spack-packages\" class=\"anchor\" aria-label=\"Permalink: Configuring Default Spack Packages\" href=\"#configuring-default-spack-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack assumes nothing is available on your system, including even basic utilities like Perl and M4.\nThis leads to Spack \"bootstrapping\" for each new install (and each compiler!) many, many packages.\nIt is recommended to set up a \u003ccode\u003epackages.yaml\u003c/code\u003e file in a \u003ccode\u003e$HOME/.spack\u003c/code\u003e folder that identifies your default local packages.\nBelow is an example file with the most important packages for efficient SST development:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epackages:\n zlib:\n  paths:\n    zlib: /usr\n  buildable: False\n libtool:\n  paths:\n   libtool@2.4.6: /opt/local\n  buildable: False\n cmake:\n  paths:\n   cmake@3.15: /opt/local\n  buildable: False\n pkg-config:\n  paths:\n   pkg-config: /opt/local\n m4:\n  paths:\n    m4: /usr\n  buildable: False\n numactl:\n  paths:\n   numactl@2.0.12: /opt/local\n   buildable: False\n hwloc:\n  paths:\n   hwloc@2.0.2: /usr\n   hwloc@1.11: /opt/local\n   buildable: False\n python:\n  paths:\n   python@2.7: /usr\n   python@3.6: /opt/local\n  variants: +shared\n  buildable: False\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe paths would need to be updated for your system.\nIf you \u003cem\u003enever\u003c/em\u003e want Spack to re-build a library (which is often the case for C libraries like hwloc),\nyou need the \u003ccode\u003ebuildable: False\u003c/code\u003e entry.\nIn most cases a single version suffices, but you may need multiple versions to resolve conflicts (as was the caes here for Python and hwloc).\nIn other cases, you may need to identify the Spack variants supported by your local installation.\nIn this case, we had to inform Spack that our Python has shared libraries.\nWith the \u003ccode\u003epackages.yaml\u003c/code\u003e, our Spack dependency graph for \u003ccode\u003espack graph sst-core +pdes-mpi\u003c/code\u003e is:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eo  sst-core\n|\\\n| o  openmpi\n| |\\\n| | |\\\n| o | |  zlib\n|  / /\no | |  python\n / /\n o |  numactl\n  /\n  o  hwloc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn this case, the only dependency Spack will build is \u003ccode\u003eopenmpi\u003c/code\u003e (recommended due to the compiler dependence).\nWithout the \u003ccode\u003epackages.yaml\u003c/code\u003e, a huge dependency graph would be built:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eo  sst-core\n|\\\no |  python\n|\\ \\\n| |\\ \\\n| | |\\ \\\n| | | |\\ \\\n| | | | |\\ \\\n| | | | | |\\ \\\n| | | | | | |\\ \\\n| | | | | | | |\\ \\\n| | | | | | | | |\\ \\\n| | | | | | | | | |\\ \\\n| | | | | | | | | | |\\ \\\n| | o | | | | | | | | | |  sqlite\n| |/| | | | | | | | | | |\n|/| | | | | | | | | | | |\n| | |/ / / / / / / / / /\n| | | | o | | | | | | |  openssl\n| |_|_|/| | | | | | | |\n|/| | | | | | | | | | |\n| | | | | | | | | | | o  openmpi\n| |_|_|_|_|_|_|_|_|_|/|\n|/| | | | | | | | | | |\n| | | | | | | | | | | |\\\n| | | | | | | | | | | | o  hwloc\n| | | | |_|_|_|_|_|_|_|/|\n| | | |/| | | | | | | |/|\n| | | | | | | | | | | | |\\\n| | | | | | | o | | | | | |  gettext\n| | |_|_|_|_|/| | | | | | |\n| |/| | | | |/| | | | | | |\n| | | | | |/| | | | | | | |\n| | | | | | | |\\ \\ \\ \\ \\ \\ \\\n| | | | | | | | |\\ \\ \\ \\ \\ \\ \\\n| | | | | | | | | |_|_|_|_|/ /\n| | | | | | | | |/| | | | | |\n| | | | | | | | | | |/ / / /\n| | | | | | | | | |/| | | |\n| | | | | | | | o | | | | |  libxml2\n| |_|_|_|_|_|_|/| | | | | |\n|/| |_|_|_|_|_|/| | | | | |\n| |/| | |_|_|_|/| | | | | |\n| | | |/| | | | | | | | | |\no | | | | | | | | | | | | |  zlib\n / / / / / / / / / / / / /\n o | | | | | | | | | | | |  xz\n  / / / / / / / / / / / /\n  | | | | | | | | | | | o  libpciaccess\n  | | |_|_|_|_|_|_|_|_|/|\n  | |/| | | | | | | | | |\n  | | | | | | | | | | | |\\\n  | | | | | | | | | | | o |  util-macros\n  | | | | | | | | | | |  /\n  | | | | | o | | | | | |  tar\n  | | | | | |/ / / / / /\n  | | | | | | | | | o |  numactl\n  | | | | | | | | | |\\|\n  | | | | | | | | | |\\ \\\n  | | | | | | | | | | |\\ \\\n  | | | | | | | | | | o | |  automake\n  | | | |_|_|_|_|_|_|/| | |\n  | | |/| | | | | | | | | |\n  | | | | | | | | | | |/ /\n  | | | | | | | | | | o |  autoconf\n  | | | |_|_|_|_|_|_|/| |\n  | | |/| | | | | | |/ /\n  | | o | | | | | | | |  perl\n  | | | |_|_|_|/ / / /\n  | | |/| | | | | | |\n  | | o | | | | | | |  gdbm\n  | |/ / / / / / / /\n  |/| | | | | | | |\n  o | | | | | | | |  readline\n  | |/ / / / / / /\n  |/| | | | | | |\n  o | | | | | | |  ncurses\n  |/ / / / / / /\n  o | | | | | |  pkgconf\n   / / / / / /\n   | | | | | o  libtool\n   | | | | |/\n   | | | | o  m4\n   | | | | o  libsigsegv\n   | | | |\n   | | o |  bzip2\n   | | o |  diffutils\n   | |/ /\n   | o |  libiconv\n   |  /\n   o |  libffi\n    /\n    o  expat\n    o  libbsd\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 14,
    "topics": [],
    "updated_at": 1701377450.0
  },
  {
    "data_format": 2,
    "description": "A microservice (i.e., Mochi provider) for high performance bulk storage of raw data regions",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-bake",
    "latest_release": "v0.6.4",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eBake\u003c/h1\u003e\u003ca id=\"user-content-bake\" class=\"anchor\" aria-label=\"Permalink: Bake\" href=\"#bake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage of raw data regions.  Bake uses modular backends to store data\non persistent memory, conventional file systems, or other storage media.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\"\u003ehttps://www.mcs.anl.gov/research/projects/mochi/\u003c/a\u003e and\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/\u003c/a\u003e for more information about Mochi.\u003c/p\u003e\n\u003cp\u003eBake\u0027s scope is limited exclusively to data storage.  Capabilities such as\nindexing, name spaces, and sharding must be provided by other microservice\ncomponents.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe easiest way to install Bake is through spack:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install bake\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis will install BAKE and its dependencies.  Please refer to the end of the\ndocument for manual compilation instructions.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eArchitecture\u003c/h2\u003e\u003ca id=\"user-content-architecture\" class=\"anchor\" aria-label=\"Permalink: Architecture\" href=\"#architecture\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLike most Mochi services, BAKE relies on a client/provider architecture.\nA provider, identified by its \u003cem\u003eaddress\u003c/em\u003e and \u003cem\u003emultiplex id\u003c/em\u003e, manages one or more\n\u003cem\u003eBAKE targets\u003c/em\u003e, referenced externally by their \u003cem\u003etarget id\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eA target can be thought of as a storage device.  This may be (for example) a\nPMDK volume or a local file system.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSetting up a BAKE target\u003c/h2\u003e\u003ca id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" aria-label=\"Permalink: Setting up a BAKE target\" href=\"#setting-up-a-bake-target\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBAKE requires the backend storage file to be created beforehand using\n\u003ccode\u003ebake-mkpool\u003c/code\u003e. For instance:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-mkpool -s 500M /dev/shm/foo.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ecreates a 500 MB file at \u003cem\u003e/dev/shm/foo.dat\u003c/em\u003e to be used by BAKE as a target.\nBake will use the \u003ccode\u003epmem\u003c/code\u003e (persistent memory) backend by default, which means\nthat the underlying file will memory mapped for access usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as \u003ccode\u003efile:\u003c/code\u003e for the\nconventional file backend or \u003ccode\u003epmem:\u003c/code\u003e for the persistent memory backend) to\ndictate a specific target type.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStarting a daemon\u003c/h2\u003e\u003ca id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-label=\"Permalink: Starting a daemon\" href=\"#starting-a-daemon\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBAKE ships with a default daemon program that can setup providers and attach\nto storage targets. This daemon can be started as follows:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon [options] \u0026lt;listen_address\u0026gt; \u0026lt;bake_pool_1\u0026gt; \u0026lt;bake_pool_2\u0026gt; ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe program takes a set of options followed by an address at which to listen for\nincoming RPCs, and a list of\nBAKE targets already created using \u003ccode\u003ebake-mkpool\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234 /dev/shm/foo.dat /dev/shm/bar.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe following options are accepted:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-f\u003c/code\u003e provides the name of the file in which to write the address of the daemon.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m\u003c/code\u003e provides the mode (\u003cem\u003eproviders\u003c/em\u003e or \u003cem\u003etargets\u003c/em\u003e).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \u003cem\u003eproviders\u003c/em\u003e mode indicates that, if multiple BAKE targets are used (as above),\nthese targets should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... \u003cem\u003eN\u003c/em\u003e where \u003cem\u003eN\u003c/em\u003e is the number of storage targets\nto manage. The \u003cem\u003etargets\u003c/em\u003e mode indicates that a single provider should be used to\nmanage all the storage targets.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIntegrating Bake into a larger service\u003c/h2\u003e\u003ca id=\"user-content-integrating-bake-into-a-larger-service\" class=\"anchor\" aria-label=\"Permalink: Integrating Bake into a larger service\" href=\"#integrating-bake-into-a-larger-service\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBake is not intended to be a standalone user-facing service.  See\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/bedrock.html\u003c/a\u003e for guidance on how to\nintegrate it with other providers using Mochi\u0027s Bedrock capability.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eClient API example\u003c/h2\u003e\u003ca id=\"user-content-client-api-example\" class=\"anchor\" aria-label=\"Permalink: Client API example\" href=\"#client-api-example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eData is stored in \u003ccode\u003eregions\u003c/code\u003e within a \u003ccode\u003etarget\u003c/code\u003e using explicit create,\nwrite, and persist operations.  The caller cannot dictate the region id\nthat will be used to reference a region; this identifier is generated\nby Bake at creation time.  The region size must be specified at creation\ntime as well; there is no mechanism for extending the size of an existing\nregion.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e#include\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u0026lt;bake-client.h\u0026gt;\u003c/span\u003e\n\n\u003cspan class=\"pl-smi\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-smi\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eargc\u003c/span\u003e, \u003cspan class=\"pl-smi\"\u003echar\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003eargv\u003c/span\u003e)\n{\n    \u003cspan class=\"pl-smi\"\u003echar\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003esvr_addr_str\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// string address of the BAKE server\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003ehg_addr_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003esvr_addr\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// Mercury address of the BAKE server\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003emargo_instance_id\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// Margo instance id\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003ebake_client_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ebcl\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// BAKE client\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003ebake_provider_handle_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// BAKE handle to provider\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003euint8_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003emplex_id\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// multiplex id of the provider\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003euint32_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etarget_number\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// target to use\u003c/span\u003e\n    \u003cspan class=\"pl-smi\"\u003ebake_region_id_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003erid\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// BAKE region id handle\u003c/span\u003e\n\t\u003cspan class=\"pl-smi\"\u003ebake_target_id_t\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ebti\u003c/span\u003e; \u003cspan class=\"pl-c\"\u003e// array of target ids\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e/* ... setup variables ... */\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e/* Initialize Margo */\u003c/span\u003e\n\t\u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emargo_init\u003c/span\u003e(..., \u003cspan class=\"pl-c1\"\u003eMARGO_CLIENT_MODE\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e-1\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Lookup the server */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003emargo_addr_lookup\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003esvr_addr_str\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003esvr_addr\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Creates the BAKE client */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_client_init\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003ebcl\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Creates the provider handle */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_provider_handle_create\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebcl\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003esvr_addr\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003emplex_id\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Asks the provider for up to target_number target ids */\u003c/span\u003e\n\t\u003cspan class=\"pl-smi\"\u003euint32_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003enum_targets\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n\t\u003cspan class=\"pl-s1\"\u003ebti\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ecalloc\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003enum_targets\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003esizeof\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003ebti\u003c/span\u003e));\n\t\u003cspan class=\"pl-en\"\u003ebake_probe\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003etarget_number\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ebti\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003enum_targets\u003c/span\u003e);\n\t\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003enum_targets\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e\u0026lt;\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etarget_number\u003c/span\u003e) {\n\t\t\u003cspan class=\"pl-en\"\u003efprintf\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003estderr\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\"Error: provider has only %d storage targets\\n\"\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003enum_targets\u003c/span\u003e);\n\t}\n\t\u003cspan class=\"pl-c\"\u003e/* Create a region */\u003c/span\u003e\n\t\u003cspan class=\"pl-smi\"\u003esize_t\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003esize\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e ...; \u003cspan class=\"pl-c\"\u003e// size of the region to create\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_create\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ebti\u003c/span\u003e[\u003cspan class=\"pl-s1\"\u003etarget_number\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e-\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e], \u003cspan class=\"pl-s1\"\u003esize\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e\u0026amp;\u003c/span\u003e\u003cspan class=\"pl-s1\"\u003erid\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Write data into the region at offset 0 */\u003c/span\u003e\n\t\u003cspan class=\"pl-smi\"\u003echar\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ebuf\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e ...;\n\t\u003cspan class=\"pl-en\"\u003ebake_write\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003erid\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ebuf\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003esize\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Make all modifications persistent */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_persist\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003erid\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Release provider handle */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_provider_handle_release\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebph\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Release BAKE client */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003ebake_client_finalize\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ebcl\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e/* Cleanup Margo resources */\u003c/span\u003e\n\t\u003cspan class=\"pl-en\"\u003emargo_addr_free\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003esvr_addr\u003c/span\u003e);\n\t\u003cspan class=\"pl-en\"\u003emargo_finalize\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e);\n\t\u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that a \u003ccode\u003ebake_region_id_t\u003c/code\u003e object is persistent.  It can be written\n(into a file or a socket) and stored or sent to another program. These\nregion ids are what uniquely reference a region within a given target.\u003c/p\u003e\n\u003cp\u003eThe rest of the client-side API can be found in \u003ccode\u003ebake-client.h\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProvider API\u003c/h2\u003e\u003ca id=\"user-content-provider-api\" class=\"anchor\" aria-label=\"Permalink: Provider API\" href=\"#provider-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe bake-server-daemon source is a good example of how to create providers and\nattach storage targets to them. The provider-side API is located in\n\u003cem\u003ebake-server.h\u003c/em\u003e, and consists of mainly two functions:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_register\u003c/span\u003e(\u003cspan class=\"pl-smi\"\u003emargo_instance_id\u003c/span\u003e                     \u003cspan class=\"pl-s1\"\u003emid\u003c/span\u003e,\n                           \u003cspan class=\"pl-smi\"\u003euint16_t\u003c/span\u003e                              \u003cspan class=\"pl-s1\"\u003eprovider_id\u003c/span\u003e,\n                           \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-k\"\u003estruct\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003ebake_provider_init_info\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eargs\u003c/span\u003e,\n                           \u003cspan class=\"pl-smi\"\u003ebake_provider_t\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e                      \u003cspan class=\"pl-s1\"\u003eprovider\u003c/span\u003e);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis creates a provider at the given provider id using the specified margo\ninstance.  The \u003ccode\u003eargs\u003c/code\u003e parameter can be used to modify default settings,\nincluding passing in a fully specified json configuration block.  See\n\u003ccode\u003ebake-server.h\u003c/code\u003e for details.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_attach_target\u003c/span\u003e(\u003cspan class=\"pl-smi\"\u003ebake_provider_t\u003c/span\u003e   \u003cspan class=\"pl-s1\"\u003eprovider\u003c/span\u003e,\n                                \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003echar\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e       \u003cspan class=\"pl-s1\"\u003etarget_name\u003c/span\u003e,\n                                \u003cspan class=\"pl-smi\"\u003ebake_target_id_t\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e*\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etarget_id\u003c/span\u003e);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis makes the provider manage the given storage target.\u003c/p\u003e\n\u003cp\u003eOther functions are available to create and detach targets from a provider.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGeneric Bake benchmark\u003c/h2\u003e\u003ca id=\"user-content-generic-bake-benchmark\" class=\"anchor\" aria-label=\"Permalink: Generic Bake benchmark\" href=\"#generic-bake-benchmark\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBy using \u003ccode\u003e--enable-benchmark\u003c/code\u003e when compiling Bake (or \u003ccode\u003e+benchmark\u003c/code\u003e when using Spack),\nyou will build a \u003ccode\u003ebake-benchmark\u003c/code\u003e program that can be used as a configurable benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure Bake with\n\u003ccode\u003eCC=mpicc\u003c/code\u003e and \u003ccode\u003eCXX=mpicxx\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe benchmark is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a server, while non-zero ranks act as clients. The server will not create\na Bake target. The Bake target needs to be created (with \u003ccode\u003ebake-makepool\u003c/code\u003e) beforehand.\u003c/p\u003e\n\u003cp\u003eThe program takes as parameter the path to a JSON file containing the sequence\nof benchmarks to execute. An example of such a file is located in \u003ccode\u003esrc/benchmark.json\u003c/code\u003e.\nEach entry in the \u003ccode\u003ebenchmarks\u003c/code\u003e array corresponds to a benchmark. The \u003ccode\u003etype\u003c/code\u003e field indicates\nthe type of benchmark to execute. The \u003ccode\u003erepetitions\u003c/code\u003e field indicates how many times the\nbenchmark should be repeated.\u003c/p\u003e\n\u003cp\u003eThe following table describes each type of benchmark and their parameters.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003etype\u003c/th\u003e\n\u003cth\u003eparameter\u003c/th\u003e\n\u003cth\u003edefault\u003c/th\u003e\n\u003cth\u003edescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ewrite\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the input buffer for each write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to write to the same region\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the input buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epersist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eread\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to access the same region for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate-write-persist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create/write/persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer on clients for each operation\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eManual installation\u003c/h2\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-label=\"Permalink: Manual installation\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBAKE depends on the following libraries:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003euuid (install uuid-dev package on ubuntu)\u003c/li\u003e\n\u003cli\u003ePMDK (see instructions below)\u003c/li\u003e\n\u003cli\u003ejson-c\u003c/li\u003e\n\u003cli\u003emochi-abt-io\u003c/li\u003e\n\u003cli\u003emochi-margo\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBake will automatically identify these dependencies at configure time using\npkg-config. To compile BAKE:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e./prepare.sh\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emkdir build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecd build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e../configure --prefix=/home/carns/working/install\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emake\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf any dependencies are installed in a nonstandard location, then\nmodify the configure step listed above to include the following argument:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ePKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1633975151.0
  },
  {
    "data_format": 2,
    "description": "Container building infrastructure (mirror of https://eicweb.phy.anl.gov/containers/eic_container)",
    "filenames": [
      "spack-environment/prod/spack.yaml",
      "spack-environment/dbg/spack.yaml"
    ],
    "full_name": "eic/containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eEIC software environment container\u003c/h1\u003e\u003ca id=\"user-content-eic-software-environment-container\" class=\"anchor\" aria-label=\"Permalink: EIC software environment container\" href=\"#eic-software-environment-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor installation instructions of \u003ccode\u003eeic-shell\u003c/code\u003e, see \u003ca href=\"https://github.com/eic/eic-shell\"\u003ehttps://github.com/eic/eic-shell\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 47,
    "topics": [],
    "updated_at": 1711749573.0
  },
  {
    "data_format": 2,
    "description": "An agent-based epidemiological simulation code using AMReX",
    "filenames": [
      "docs/spack.yaml"
    ],
    "full_name": "AMReX-Codes/ExaEpi",
    "latest_release": null,
    "readme": "\u003cp\u003eThis is a demo for an Agent-based epidemiology code built using the AMReX framework.\u003c/p\u003e\n\u003cp\u003eFor more information about AMReX:\nwebsite: \u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003ehttps://amrex-codes.github.io/\u003c/a\u003e\ndocumentation: \u003ca href=\"https://amrex-codes.github.io/amrex/docs_html/\" rel=\"nofollow\"\u003ehttps://amrex-codes.github.io/amrex/docs_html/\u003c/a\u003e\nsource code: \u003ca href=\"https://github.com/AMReX-Codes/amrex\"\u003ehttps://github.com/AMReX-Codes/amrex\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding the code\u003c/h2\u003e\u003ca id=\"user-content-building-the-code\" class=\"anchor\" aria-label=\"Permalink: Building the code\" href=\"#building-the-code\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis demo uses CMake version 3.14 or higher. To build it:\nmkdir build\ncd build\ncmake ..\nmake -j8\u003c/p\u003e\n\u003cp\u003eTo build with GPU support, use the \u003ccode\u003e-DAMReX_GPU_BACKEND=CUDA\u003c/code\u003e CMake option.\u003c/p\u003e\n\u003cp\u003eFor convenience, a script for setting up the module environment for Perlmutter is\nprovided in etc/perlmutter_environment.sh. To use it, do:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource etc/perlmutter_environment.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning the code\u003c/h2\u003e\u003ca id=\"user-content-running-the-code\" class=\"anchor\" aria-label=\"Permalink: Running the code\" href=\"#running-the-code\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eNavigate to build/bin and run the executable using one of the \"inputs\" files in \"examples\".\u003c/p\u003e\n\u003cp\u003eFor example:\ncd build/bin\n./agent ../../examples/inputs\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLooking at the output\u003c/h2\u003e\u003ca id=\"user-content-looking-at-the-output\" class=\"anchor\" aria-label=\"Permalink: Looking at the output\" href=\"#looking-at-the-output\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRunning the code succesfully will create a number of \"plt?????\" files. You can visualize\nthese using the script at etc/plot.py. This will require the \"yt\" package to be installed:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ehttps://yt-project.org/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright Notice\u003c/h2\u003e\u003ca id=\"user-content-copyright-notice\" class=\"anchor\" aria-label=\"Permalink: Copyright Notice\" href=\"#copyright-notice\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExaEpi Copyright (c) 2022, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of\nany required approvals from the U.S. Dept. of Energy). All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Intellectual Property Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights.  As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit others to do so.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1689181940.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "berquist/spack-gha-buildcache-example",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003espack-buildcache-example\u003c/h1\u003e\u003ca id=\"user-content-spack-buildcache-example\" class=\"anchor\" aria-label=\"Permalink: spack-buildcache-example\" href=\"#spack-buildcache-example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExample of using OCI buildcaches within \u003ca href=\"https://github.com/berquist/spack-buildcache-example\"\u003eGitHub Actions\u003c/a\u003e and \u003ca href=\"https://gitlab.com/berquist/spack-buildcache-example\" rel=\"nofollow\"\u003eGitLab CI\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1703271490.0
  },
  {
    "data_format": 2,
    "description": "Support for building chipStar and related libraries via Spack",
    "filenames": [
      "Environments/ROCm/spack.yaml",
      "Environments/LevelZero/spack.yaml"
    ],
    "full_name": "CHIP-SPV/chipStar-Spack",
    "latest_release": null,
    "readme": "\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eOverview\u003c/h1\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/CHIP-SPV/chipStar\"\u003echipStar\u003c/a\u003e (formerly CHIP-SPV)\nis software that allows software written to use the\n\u003ca href=\"https://https://github.com/ROCm-Developer-Tools/HIP\" rel=\"nofollow\"\u003eHeterogeneous-compute Interface for Portability\n(HIP)\u003c/a\u003e\ninterface and kernel language to target GPUs via the\n\u003ca href=\"https://registry.khronos.org/spir\" rel=\"nofollow\"\u003eSPIR-V\u003c/a\u003e intermediate language.\nchipStar can use either the Intel Level Zero runtime or an OpenCL\nruntime as a backend.\u003c/p\u003e\n\u003cp\u003eThis repository contains support for building chipStar and its\ndependencies via the \u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package\nmanager.\u003c/p\u003e\n\u003cp\u003eNote: most development to date has been done with the Level Zero\nenvironment, and it is expected that substantial work is needed for\nthe environment targeting the OpenCL backend to work.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePrerequisites\u003c/h1\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eAn x86_64 system running a common Linux distribution.  OpenSLES 15 is\nthe best tested to date.\u003c/li\u003e\n\u003cli\u003eA working Spack installation.\u003c/li\u003e\n\u003cli\u003eA recent Clang installation that is registered with Spack as a compiler.\nVersions 15 and 16 are best tested, but 14 might work.  We suggest\ninstalling the compiler via Spack (i.e., by installing something like\n\u003ccode\u003ellvm@16.0.2\u003c/code\u003e and then using \u003ccode\u003espack compiler add\u003c/code\u003e with the llvm\npackage\u0027s install location), because the \u003ccode\u003echipstar\u003c/code\u003e package defined\nin this repository depends on the \u003ccode\u003ellvm\u003c/code\u003e package anyway.\u003c/li\u003e\n\u003cli\u003eA recent (at least version 2023.1) Intel OneAPI compiler installation\nthat is registered with Spack as a compiler.  The recommended way\nof doing this is by installing the Spack \u003ccode\u003eintel-oneapi-compilers\u003c/code\u003e\npackage, then registering the location of its compilers with Spack.\nE.g.,\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack install intel-oneapi-compilers@2023\n$ spack compiler add \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003espack location -i intel-oneapi-compilers@2023\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e/compiler/latest/linux\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUsage\u003c/h1\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col start=\"0\"\u003e\n\u003cli\u003eClone this repository to the target system.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eActivate the environment you want to build.  E.g., for the\nenvironment that just builds chipStar with Level Zero backend:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e CHIP-SPV-Spack/Environments/LevelZero\n$ spack env activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eConcretize the active environment.  (In Spack terminology,\n\"to concretize\" means to let Spack examine the package specifications\nit has been asked to build, plus the available package repositories,\nresolve dependencies and check constraints, and decide exactly which\npackages it will build, in which order, and with which configuration.)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack concretize -f -U\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe suggest examining the output from running the \u003ccode\u003espack concretize\u003c/code\u003e\ncommand to make sure that Spack\u0027s concretizer has truly decided to\nuse the configuration options and especially the compilers that you\nwant it to use.  Note that the environment and related configuration\nare purposefully not overly constrained to use the given compiler\nfor every dependency package, so even though there are some packages\nthat must be built with \u003ccode\u003e%clang\u003c/code\u003e, there are others that may be\nbuilt (or re-used from already-installed packages) using \u003ccode\u003e%gcc\u003c/code\u003e such\nas the system\u0027s GCC installation.\u003c/p\u003e\n\u003cp\u003eIf Spack\u0027s concretizer  didn\u0027t do what you want, you can re-concretize\nthe environment and be more explicit about what you want using command-line\nconfiguration options (recommended) or by editing the environment\u0027s\n\u003ccode\u003espack.yaml\u003c/code\u003e file or other configuration options that your Spack installation\nis using.  (Use \u003ccode\u003espack config blame\u003c/code\u003e to see which configuration files Spack is\nusing.)  For instance, if you have both \u003ccode\u003eclang@16.0.2\u003c/code\u003e and \u003ccode\u003eclang@15.0.7\u003c/code\u003e\ninstalled and registered as Spack compilers, and you want to build\nusing \u003ccode\u003eclang@15.0.7\u003c/code\u003e, you may have to use a concretize command like the\nfollowing:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack -c \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epackages:chipstar:require:\u0027%clang@15.0.7\u0027\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e concretize -f -U\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAs before, verify from the output of the \u003ccode\u003espack concretize\u003c/code\u003e command that it\nis using the compiler version you want, \u003ccode\u003eclang@15.0.7\u003c/code\u003e in this example.\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eBuild the environment.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSpack supports some options for controlling the build and installation,\nsuch as \u003ccode\u003e-j\u003c/code\u003e to limit the number of processes used for parallel builds,\nuseful for being a good citizen on shared systems by not allowing Spack\nto use all available cores (its default).  See the Spack documentation for\nmore information.\u003c/p\u003e\n\u003cp\u003eAssuming all goes well with the build and install, a \u003ccode\u003espack find\u003c/code\u003e\nshould show the packages that you just built.\u003c/p\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eUse the installed software.  There are several ways you might\nupdate your environment to use the software, including:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003espack load chipstar\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eActivating the environment that you used to build the software\u003c/li\u003e\n\u003cli\u003eIf your Spack configuration is such that it can generate module files\nand module files have been generated for the software you built\nvia this environment, \u003ccode\u003emodule load chipstar\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNote that you may need to modify your environment to be able to run\nprograms produced using chipStar and the H4I libraries built\nusing this Spack repository.  For instance, on some systems,\none must load the \u003ccode\u003eintel_compute_runtime\u003c/code\u003e module before being\nable to run programs that use the Intel Level Zero runtime.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eTODO\u003c/h1\u003e\u003ca id=\"user-content-todo\" class=\"anchor\" aria-label=\"Permalink: TODO\" href=\"#todo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eClean up and verify the OpenCL-based environment.\u003c/li\u003e\n\u003cli\u003eEnsure the OpenCL-based environment can use any OpenCL implementation.\u003c/li\u003e\n\u003cli\u003eIncorporate H4I HIP libraries like H4I-HipBLAS into an environments.\u003c/li\u003e\n\u003cli\u003eSupport using the software installed by the environment via\n\u003ccode\u003emodule\u003c/code\u003e command.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1687550793.0
  },
  {
    "data_format": 2,
    "description": "Mochi-based staging service for in situ analysis and visualization",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-colza",
    "latest_release": "v0.4.0",
    "readme": "",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1640788783.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "config/docker/spack.yaml"
    ],
    "full_name": "camierjs/okina-jit",
    "latest_release": null,
    "readme": "\u003cpre\u003e\u003ccode\u003e                Finite Element Discretization Library\n                               __\n                   _ __ ___   / _|  ___  _ __ ___\n                  | \u0027_ ` _ \\ | |_  / _ \\| \u0027_ ` _ \\\n                  | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_| |_| |_|\n\n                           https://mfem.org\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://mfem.org\" rel=\"nofollow\"\u003eMFEM\u003c/a\u003e is a modular parallel C++ library for finite element\nmethods. Its goal is to enable high-performance scalable finite element\ndiscretization research and application development on a wide variety of\nplatforms, ranging from laptops to supercomputers.\u003c/p\u003e\n\u003cp\u003eWe welcome contributions and feedback from the community. Please see the file\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e for additional details about our development\nprocess.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFor building instructions, see the file \u003ca href=\"INSTALL\"\u003eINSTALL\u003c/a\u003e, or type \"make help\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopyright and licensing information can be found in files \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe best starting point for new users interested in MFEM\u0027s features is to\nreview the examples and miniapps at \u003ca href=\"https://mfem.org/examples\" rel=\"nofollow\"\u003ehttps://mfem.org/examples\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstructions for learning with Docker are in \u003ca href=\"config/docker\"\u003econfig/docker\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConceptually, MFEM can be viewed as a finite element toolbox that provides the\nbuilding blocks for developing finite element algorithms in a manner similar to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\nH(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\nbilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping of various finite element discretizations, including Galerkin\nmethods, mixed finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization and Discontinuous Petrov-Galerkin (DPG) approaches.\u003c/p\u003e\n\u003cp\u003eMFEM includes classes for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral and hexahedral, as well as surface and topologically\nperiodical meshes. It has general support for mesh refinement, including local\nconforming and non-conforming (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for high-order mesh elements with curved boundaries,\nare also supported.\u003c/p\u003e\n\u003cp\u003eWhen used as a \"finite element to linear algebra translator\", MFEM can take a\nproblem described in terms of finite element-type objects, and produce the\ncorresponding linear algebra vectors and fully or partially assembled operators,\ne.g. in the form of global sparse matrices or matrix-free operators. The library\nincludes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\nwell as support for sequential sparse direct solvers from the SuiteSparse\nlibrary. Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit and implicit Runge-Kutta time integrators are also available.\u003c/p\u003e\n\u003cp\u003eMFEM supports MPI-based parallelism throughout the library, and can readily be\nused as a scalable unstructured finite element problem generator. Starting with\nversion 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal changes to switch from a serial to a highly-performant MPI-parallel\nversion of the code, where they can take advantage of the integrated linear\nsolvers from the hypre library. Comprehensive support for other external\npackages, e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional linear and nonlinear solvers, preconditioners, time integrators, etc.\u003c/p\u003e\n\u003cp\u003eFor examples of using MFEM, see the \u003ca href=\"examples\"\u003eexamples/\u003c/a\u003e and \u003ca href=\"miniapps\"\u003eminiapps/\u003c/a\u003e\ndirectories, as well as the OpenGL visualization tool GLVis which is available\nat \u003ca href=\"https://glvis.org\" rel=\"nofollow\"\u003ehttps://glvis.org\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMFEM is distributed under the terms of the BSD-3 license. All new contributions\nmust be made under this license. See \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e for\ndetails.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: BSD-3-Clause \u003cbr\u003e\nLLNL Release Number: LLNL-CODE-806117 \u003cbr\u003e\nDOI: 10.11578/dc.20171025.1248\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1689268998.0
  },
  {
    "data_format": 2,
    "description": "Spack configuration files and scripts for use on machines at NREL",
    "filenames": [
      "configs/ellis/compilers/spack.yaml",
      "configs/rhodes/utilities/spack.yaml",
      "configs/eagle/utilities/spack.yaml",
      "configs/rhodes/compilers/spack.yaml",
      "envs/exawind/spack.yaml",
      "configs/eagle/compilers/spack.yaml",
      "configs/eagle/software/spack.yaml"
    ],
    "full_name": "jrood-nrel/spack-configs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack configuration files and scripts for use on machines at NREL\u003c/h1\u003e\u003ca id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" aria-label=\"Permalink: Spack configuration files and scripts for use on machines at NREL\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThese software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in \u003ca href=\"modules.txt\"\u003emodules.txt\u003c/a\u003e. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.\u003c/li\u003e\n\u003cli\u003e\"binaries\" are generally the binary downloads of Paraview and Visit.\u003c/li\u003e\n\u003cli\u003e\"compilers\" are the latest set of compilers built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"utilities\" are the latest set of utility programs that don\u0027t rely on MPI and are built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.\u003c/p\u003e\n\u003cp\u003eCurrently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.\u003c/p\u003e\n\u003cp\u003eTo use these modules you can add the following to your \u003ccode\u003e~/.bashrc\u003c/code\u003e for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf \u003ccode\u003emodule avail\u003c/code\u003e does not show the modules on Eagle, try removing the LMOD cache with \u003ccode\u003erm -rf ~/.lmod.d/.cache\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eAlso included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have \u003ccode\u003eSPACK_ROOT\u003c/code\u003e set you can run \u003ccode\u003e/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh\u003c/code\u003e which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your \u003ccode\u003e${SPACK_ROOT}/etc\u003c/code\u003e directory manually. \u003ccode\u003espack compilers\u003c/code\u003e should then show you many available compilers. Source your Spack\u0027s \u003ccode\u003esetup-env.sh\u003c/code\u003e after you do the \u003ccode\u003emodule unuse ${MODULEPATH}\u003c/code\u003e in your \u003ccode\u003e.bashrc\u003c/code\u003e so that your Spack instance will add its own module path to MODULEPATH. Remove \u003ccode\u003e~/.spack/linux\u003c/code\u003e if it exists and \u003ccode\u003espack compilers\u003c/code\u003e doesn\u0027t show you the updated list of compilers. The \u003ccode\u003e~/.spack\u003c/code\u003e directory takes highest precendence in the Spack configuration.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1666717629.0
  },
  {
    "data_format": 2,
    "description": "testing spack\u0027s containerize command",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "js947/spack-docker-test",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg\"\u003e\u003cimg src=\"https://github.com/js947/spack-docker-test/workflows/Build%20container/badge.svg\" alt=\"Build container\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003espack-docker-test\u003c/h1\u003e\u003ca id=\"user-content-spack-docker-test\" class=\"anchor\" aria-label=\"Permalink: spack-docker-test\" href=\"#spack-docker-test\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003etesting spack\u0027s containerize command\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1606954982.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mdorier/test-ssg-cori",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eBuilding\u003c/h1\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink: Building\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSetup spack and sds-repo, clone this repository and \u003ccode\u003ecd\u003c/code\u003e in it, then:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env create ssg-test spack.yaml\nspack env activate ssg-test\nspack install\nspack env deactivate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen to build the code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport CRAYPE_LINK_TYPE=dynamic\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\nspack env activate ssg-test\nmkdir build\ncd build\ncmake ..\nmake\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eRunning\u003c/h1\u003e\u003ca id=\"user-content-running\" class=\"anchor\" aria-label=\"Permalink: Running\" href=\"#running\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFrom the \u003ccode\u003ebuild\u003c/code\u003e directory:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 128 ./test-server\n# one of the server will print \"Credential: X\", copy the X\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn another terminal window, with current working directory set to \u003ccode\u003ebuild\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 1 ./test-client X # replace X with the copied value\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1614179535.0
  },
  {
    "data_format": 2,
    "description": "Python binding to the Mochi Sonata microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-sonata",
    "latest_release": null,
    "readme": "\u003cp\u003ePy-Sonata is a Python interface for the \u003ca href=\"https://github.com/mochi-hpc/mochi-sonata\"\u003eSonata Mochi microservice\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1633975502.0
  },
  {
    "data_format": 2,
    "description": "New sets of scripts for HPX+LCI experiments based on spack and python",
    "filenames": [
      "spack_env/expanse/hpx-lcw-sc24-papi/spack.yaml",
      "spack_env/expanse/hpx-lcw-debug/spack.yaml",
      "spack_env/expanse/hpx-lcw-relDeb/spack.yaml",
      "spack_env/perlmutter/hpx-lci-master/spack.yaml",
      "spack_env/rostam/hpx-lcw-analyze/spack.yaml",
      "spack_env/rostam/hpx-lcw-openmpi-griddim2/spack.yaml",
      "spack_env/delta/hpx-lcw-sc24-cray/spack.yaml",
      "spack_env/frontera/hpx-lcw/spack.yaml",
      "spack_env/expanse/hpx-lci-ucx/spack.yaml",
      "spack_env/delta/hpx-lcw-sc24/spack.yaml",
      "spack_env/rostam/hpx-lci-analyze/spack.yaml"
    ],
    "full_name": "JiakunYan/hpx-lci_scripts",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eHPX/LCI Scripts\u003c/h1\u003e\u003ca id=\"user-content-hpxlci-scripts\" class=\"anchor\" aria-label=\"Permalink: HPX/LCI Scripts\" href=\"#hpxlci-scripts\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOverview\u003c/h3\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a scripts collection for running HPX/LCI related software on clusters.\nAll scripts are written in Python (including those that will be submitted to\nSLURM). The execution environment are managed by Spack environment.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eFile Structure\u003c/h3\u003e\u003ca id=\"user-content-file-structure\" class=\"anchor\" aria-label=\"Permalink: File Structure\" href=\"#file-structure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003einclude: common python scripts imported by others\n\u003cul\u003e\n\u003cli\u003eplatforms: platform-specific configurations.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003espack_env/\u0026lt;platform_name\u0026gt;/\u0026lt;env_name\u0026gt;: spack environment yaml file\u003c/li\u003e\n\u003cli\u003elci: Scripts to run LCI software.\u003c/li\u003e\n\u003cli\u003ehpx: Scripts to run HPX software.\u003c/li\u003e\n\u003cli\u003ehpx_pingpong: Scripts to run the HPX Ping-pong benchmark.\u003c/li\u003e\n\u003cli\u003eoctotiger: Scripts to run Octo-Tiger.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWithin the lci/hpx/hpx_pingpong_octotiger directory, there are a number of\nsubdirectories, such as \"benchmark\", \"debug\", \"perf\", serving different\npurposes. Within each subdirectory, you may find the following scripts:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003erun.py: the script that submit one or more jobs to platforms (typically\nthrough SLRUM \u003ccode\u003esbatch\u003c/code\u003e).\u003c/li\u003e\n\u003cli\u003eslurm.py: the script that \u003ccode\u003erun.py\u003c/code\u003e submit to the platforms. Users generally\nshould not run this script directly.\u003c/li\u003e\n\u003cli\u003eparse.py: the script that parse the experiment results from log file\ninto \u003ccode\u003ecsv\u003c/code\u003e file.\u003c/li\u003e\n\u003cli\u003edraw.py: the script that plot the experiment results from the \u003ccode\u003ecsv\u003c/code\u003e file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eA typical workflow\u003c/h3\u003e\u003ca id=\"user-content-a-typical-workflow\" class=\"anchor\" aria-label=\"Permalink: A typical workflow\" href=\"#a-typical-workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSuppose we are on Perlmutter and want to run Octo-Tiger benchmarks.\u003c/p\u003e\n\u003cp\u003eSetup phase:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003ccode\u003espack environment activate path/to/hpx-lci_scripts/spack_env/perlmutter/hpx-lcw\u003c/code\u003e:\nactivate the spack environment we want to use.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003espack concretize ; spack install\u003c/code\u003e: install the environment.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eExperiment phase:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003ecd path/to/hpx-lci_scripts/octotiger/benchmark\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003evim run.py\u003c/code\u003e: decide which configurations I want to run\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003erun.py 5\u003c/code\u003e: run all configurations 5 times.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eparse.py\u003c/code\u003e: (After all jobs complete) parse all SLURM output files.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003edraw.py\u003c/code\u003e: plot the results.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eImportant notes on how the scripts work\u003c/h3\u003e\u003ca id=\"user-content-important-notes-on-how-the-scripts-work\" class=\"anchor\" aria-label=\"Permalink: Important notes on how the scripts work\" href=\"#important-notes-on-how-the-scripts-work\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003ePersistent shell\u003c/h4\u003e\u003ca id=\"user-content-persistent-shell\" class=\"anchor\" aria-label=\"Permalink: Persistent shell\" href=\"#persistent-shell\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUsing python to run shell command can be difficult, because the environment\nor current path does not persist through multiple \u003ccode\u003esubprocess\u003c/code\u003e or \u003ccode\u003eos.system\u003c/code\u003e\ncalls. For example, the following python code will not work\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eos.system(\"module load openmpi\")\nos.system(\"export DEBUG_MODE=1\")\nos.system(\"cd workspace/hello_world\")\nos.system(\"mpirun -n 2 hello_world\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAs a result, all shell commands invoked by the python scripts in this project\nare all through the special \u003ca href=\"include/pshell.py\"\u003epshell\u003c/a\u003e (persistent shell) module.\nThe following python code will work\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epshell.run(\"module load openmpi\")\npshell.run(\"export DEBUG_MODE=1\")\npshell.run(\"cd workspace/hello_world\")\npshell.run(\"mpirun -n 2 hello_world\")\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1709678887.0
  },
  {
    "data_format": 2,
    "description": "rhel7 spack configuration and scripts",
    "filenames": [
      "v0.20.1/v1/spack.yaml"
    ],
    "full_name": "SCOREC/rhel7-spack-config",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003esetup on SCOREC\u003c/h1\u003e\u003ca id=\"user-content-setup-on-scorec\" class=\"anchor\" aria-label=\"Permalink: setup on SCOREC\" href=\"#setup-on-scorec\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /opt/scorec/spack/rhel7-spack-config/\nsource setupSpack.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003erhel7-spack-config\u003c/h1\u003e\u003ca id=\"user-content-rhel7-spack-config\" class=\"anchor\" aria-label=\"Permalink: rhel7-spack-config\" href=\"#rhel7-spack-config\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003erhel7 spack configuration and scripts\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003einstall.sh\u003c/code\u003e script maintained in this repo is for documentation purposes (e.g., in case we had to reinstall the entire stack from scratch) and should not be executed as it will not use all of our existing package installs.  More discussion of package installation is below.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003euseful commands\u003c/h2\u003e\u003ca id=\"user-content-useful-commands\" class=\"anchor\" aria-label=\"Permalink: useful commands\" href=\"#useful-commands\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eregenerate lmod module tree:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack module lmod refresh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003einstalling new packages\u003c/h2\u003e\u003ca id=\"user-content-installing-new-packages\" class=\"anchor\" aria-label=\"Permalink: installing new packages\" href=\"#installing-new-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOur spack repo is tracking the master spack branch.  Spack package updates could result in additional installation of packages with little or no package source code changes.  These additional installs can be avoided when installing new packages by first examining the output of the \u003ccode\u003espack spec -I\u003c/code\u003e command.  If a utility/infrastructure level package, such as cmake or mpich, is marked with a \u003ccode\u003e[+]\u003c/code\u003e symbol in the leftmost column then it means that the existing install will be used.  If spack does not default to using the existing install you can append the hash of the package to the spec command.\u003c/p\u003e\n\u003cp\u003eFor example, lets see what happens when we ask for a pumi install using gcc 7.3.0\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack spec -I pumi@develop%gcc@7.3.0\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n -       ^mpich@3.3%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n[+]          ^findutils@4.6.0%gcc@7.3.0 patches=84b916c0bf8c51b7e7b28417692f0ad3e7030d1f3c248ba77c42ede5c1c5d11e,bd9e4e5cc280f9753ae14956c4e4aa17fe7a210f55dd6c84aa60b12d106d47a2 arch=linux-rhel7-x86_64 \n[+]              ^autoconf@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^automake@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^libtool@system%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]              ^m4@1.4.16%gcc@7.3.0 patches=c0a408fbffb7255fcc75e26bd8edab116fc81d216bfd18b473668b7739a4158e +sigsegv arch=linux-rhel7-x86_64 \n[+]              ^texinfo@6.5%gcc@7.3.0 arch=linux-rhel7-x86_64\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSpack wants to install mpich 3.3, but we don\u0027t want to change to the new mpich version yet.  So, we will get the hash of the existing mpich 3.2.1 install:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack find -ldv mpich%gcc@7.3.0\n==\u0026gt; 1 installed package\n-- linux-rhel7-x86_64 / gcc@7.3.0 -------------------------------\nniuhmad    mpich@3.2.1 device=ch3 +hydra netmod=tcp +pmi+romio~verbs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ethen append the hash \u003ccode\u003eniuhmad\u003c/code\u003e to the spec for pumi using the \u003ccode\u003e^\u003c/code\u003e syntax to specify it as a dependency:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack spec -I pumi@develop%gcc@7.3.0 ^/niuhmad\nInput spec\n--------------------------------\n -   pumi@develop%gcc@7.3.0\n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\nConcretized\n--------------------------------\n -   pumi@develop%gcc@7.3.0 build_type=RelWithDebInfo ~fortran~shared simmodsuite=none ~zoltan arch=linux-rhel7-x86_64 \n[+]      ^cmake@3.13.1%gcc@7.3.0~doc+ncurses+openssl+ownlibs~qt arch=linux-rhel7-x86_64 \n[+]          ^ncurses@6.1%gcc@7.3.0~symlinks~termlib arch=linux-rhel7-x86_64 \n[+]              ^pkgconf@1.5.4%gcc@7.3.0 arch=linux-rhel7-x86_64 \n[+]          ^openssl@1.1.1%gcc@7.3.0+systemcerts arch=linux-rhel7-x86_64 \n[+]              ^perl@5.16.3%gcc@7.3.0+cpanm patches=0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac +shared+threads arch=linux-rhel7-x86_64 \n[+]              ^zlib@1.2.11%gcc@7.3.0+optimize+pic+shared arch=linux-rhel7-x86_64 \n[+]      ^mpich@3.2.1%gcc@7.3.0 device=ch3 +hydra netmod=tcp +pmi+romio~verbs arch=linux-rhel7-x86_64 \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd see that in the Concretized spec it is now using the existing mpich 3.2.1 install.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003econtents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: contents\" href=\"#contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ecompilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1683174256.0
  },
  {
    "data_format": 2,
    "description": "Spack configuration files for LUMI",
    "filenames": [
      "22.08/0.18.1/spack.yaml"
    ],
    "full_name": "Lumi-supercomputer/lumi-spack-settings",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack configuration files for LUMI\u003c/h1\u003e\u003ca id=\"user-content-spack-configuration-files-for-lumi\" class=\"anchor\" aria-label=\"Permalink: Spack configuration files for LUMI\" href=\"#spack-configuration-files-for-lumi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRepository containing configuration files for the Spack instances installed in \u003ccode\u003e/appl/lumi/spack\u003c/code\u003e on LUMI for public use. The files in this repository can be found in \u003ccode\u003e/appl/lumi/spack/etc/\u003c/code\u003e on LUMI. The folder hierarchy is determined by the Cray Programming Environment (CPE) version and Spack release version. For example, the directory\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e22.08/0.18.1/\n22.08/0.18.1-user/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003econtains the configuration files for Spack version 0.18.1 configured to use CPE 22.08. The first instance \u003ccode\u003e0.18.1\u003c/code\u003e is the upstream instance, which is maintained by the LUMI Support Team. The second instance \u003ccode\u003e0.18.1-user\u003c/code\u003e is a separate instance configured to install packages in a user-defined directory in e.g. \u003ccode\u003e/project/\u003c/code\u003e. It is chained to the upstream instance, so that already installed packages can be reused.\u003c/p\u003e\n\u003cp\u003eIf you are user of LUMI, and want to set up your own instance, you can copy the \u003ccode\u003ecompilers.yaml\u003c/code\u003eand  \u003ccode\u003epackages.yaml\u003c/code\u003e files to your instance. The \u003ccode\u003econfig.yaml\u003c/code\u003e needs to be modified if you want to use that one.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1675956191.0
  },
  {
    "data_format": 2,
    "description": "ACCESS-OM2-BGC: ACCESS Ocean-Sea Ice Model with WOMBAT Biogeochemistry",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "ACCESS-NRI/ACCESS-OM2-BGC",
    "latest_release": "2024.03.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eACCESS-OM2: ACCESS Ocean-Sea Ice Model with WOMBAT Biogeochemistry\u003c/h1\u003e\u003ca id=\"user-content-access-om2-access-ocean-sea-ice-model-with-wombat-biogeochemistry\" class=\"anchor\" aria-label=\"Permalink: ACCESS-OM2: ACCESS Ocean-Sea Ice Model with WOMBAT Biogeochemistry\" href=\"#access-om2-access-ocean-sea-ice-model-with-wombat-biogeochemistry\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAbout the model\u003c/h2\u003e\u003ca id=\"user-content-about-the-model\" class=\"anchor\" aria-label=\"Permalink: About the model\" href=\"#about-the-model\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-OM2-BGC is a global coupled ocean - sea ice model with WOMBAT biogeochemistrydeveloped by \u003ca href=\"http://www.cosima.org.au\" rel=\"nofollow\"\u003eCOSIMA\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eACCESS-OM2-BGC consists of the \u003ca href=\"https://github.com/ACCESS-NRI/MOM5\"\u003eMOM 5\u003c/a\u003e ocean model with WOMBAT Biogeochemistry, \u003ca href=\"https://github.com/ACCESS-NRI/cice5\"\u003eCICE 5\u003c/a\u003e sea ice model, and a file-based atmosphere called \u003ca href=\"https://github.com/ACCESS-NRI/libaccessom2\"\u003eYATM\u003c/a\u003e coupled together using \u003ca href=\"https://github.com/ACCESS-NRI/oasis3-mct\"\u003eOASIS3-MCT v2.0\u003c/a\u003e. ACCESS-OM2-BGC builds on the ACCESS-OM (\u003ca href=\"http://www.bom.gov.au/jshess/docs/2013/bi2_hres.pdf\" rel=\"nofollow\"\u003eBi et al., 2013\u003c/a\u003e) and AusCOM (\u003ca href=\"https://50years.acs.org.au/content/dam/acs/50-years/journals/jrpit/JRPIT39.2.137.pdf\" rel=\"nofollow\"\u003eRoberts et al., 2007\u003c/a\u003e; \u003ca href=\"https://www.cawcr.gov.au/technical-reports/CTR_027.pdf\" rel=\"nofollow\"\u003eBi and Marsland, 2010\u003c/a\u003e) models originally developed at \u003ca href=\"http://www.csiro.au\" rel=\"nofollow\"\u003eCSIRO\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe model code, configurations and performance were described in \u003ca href=\"https://doi.org/10.5194/gmd-13-401-2020\" rel=\"nofollow\"\u003eKiss et al. (2020)\u003c/a\u003e, with further details in the draft \u003ca href=\"https://github.com/COSIMA/ACCESS-OM2-1-025-010deg-report\"\u003eACCESS-OM2 technical report\u003c/a\u003e. The current code and configurations differ from this version in a number of ways (biogeochemistry, updated forcing, improvements and bug fixes), as described by \u003ca href=\"https://doi.org/10.1029/2021GL097211\" rel=\"nofollow\"\u003eSolodoch et al. (2022)\u003c/a\u003e, \u003ca href=\"https://dx.doi.org/10.1029/2023JC019697\" rel=\"nofollow\"\u003eHayashida et al. (2023)\u003c/a\u003e, \u003ca href=\"https://doi.org/10.5194/egusphere-2023-390\" rel=\"nofollow\"\u003eMenviel et al. (2023)\u003c/a\u003e and \u003ca href=\"https://doi.org/10.5194/gmd-2023-123\" rel=\"nofollow\"\u003eWang et al. (2023)\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSupport\u003c/h2\u003e\u003ca id=\"user-content-support\" class=\"anchor\" aria-label=\"Permalink: Support\" href=\"#support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://www.access-nri.org.au\" rel=\"nofollow\"\u003eACCESS-NRI\u003c/a\u003e has assumed responsibility for supporting ACCESS-OM2-BGC for the Australian Research Community. As part of this support ACCESS-NRI has developed a new build and deployment system for ACCESS-OM2-BGC to align with plans for supporting a range of Earth System Models.\u003c/p\u003e\n\u003cp\u003eAny questions about ACCESS-NRI releases of ACCESS-OM2-BGC should be done through the \u003ca href=\"https://forum.access-hive.org.au/\" rel=\"nofollow\"\u003eACCESS-Hive Forum\u003c/a\u003e. See the \u003ca href=\"https://forum.access-hive.org.au/t/access-help-and-support/908\" rel=\"nofollow\"\u003eACCESS Help and Support topic\u003c/a\u003e for details on how to do this.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild\u003c/h3\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-NRI is using \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003espack\u003c/a\u003e, a build from source package manager designed for use with high performance computing. This repository contains a \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003espack environment\u003c/a\u003e definition file (\u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/blob/main/spack.yaml\"\u003e\u003ccode\u003espack.yaml\u003c/code\u003e\u003c/a\u003e) that defines all the essential components of the ACCESS-OM2-BGC model, including exact versions.\u003c/p\u003e\n\u003cp\u003eSpack automatically builds all the components and their dependencies, producing model component executables. Spack already contains support for compiling thousands of common software packages. Spack packages for the components in ACCESS-OM2-BGC are defined in the \u003ca href=\"https://github.com/ACCESS-NRI/spack_packages/\"\u003espack packages repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eACCESS-OM2-BGC is built and deployed automatically to \u003ccode\u003egadi\u003c/code\u003e on NCI (see below). However it is possible to use spack to compile the model using the \u003ccode\u003espack.yaml\u003c/code\u003e environment file in this repository. To do so follow the \u003ca href=\"https://forum.access-hive.org.au/t/how-to-build-access-om2-on-gadi/1545\" rel=\"nofollow\"\u003einstructions on the ACCESS Forum for configuring spack on \u003ccode\u003egadi\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThen clone this repository and run the following commands on \u003ccode\u003egadi\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env create access-om2-bgc spack.yaml\nspack env activate access-om2-bgc\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eto create a spack environment called \u003ccode\u003eaccess-om2-bgc\u003c/code\u003e and build all the ACCESS-OM2-BGC components, the locations of which can be found using \u003ccode\u003espack find --paths\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIn contrast, the \u003ca href=\"https://github.com/COSIMA/access-om2\"\u003eCOSIMA ACCESS-OM2 repository\u003c/a\u003e uses \u003ca href=\"https://git-scm.com/book/en/v2/Git-Tools-Submodules\" rel=\"nofollow\"\u003esubmodules\u003c/a\u003e to bring all the code dependencies into a single repository and build all the models together.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDeployment\u003c/h3\u003e\u003ca id=\"user-content-deployment\" class=\"anchor\" aria-label=\"Permalink: Deployment\" href=\"#deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-OM2-BGC is deployed automatically when a new version of the \u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/blob/main/spack.yaml\"\u003e\u003ccode\u003espack.yaml\u003c/code\u003e\u003c/a\u003e file is committed to this repository and tagged with a new version. All the ACCESS-OM2-BGC components are built using \u003ccode\u003espack\u003c/code\u003e on \u003ccode\u003egadi\u003c/code\u003e and installed under the \u003ca href=\"https://my.nci.org.au/mancini/project/vk83\" rel=\"nofollow\"\u003e\u003ccode\u003evk83\u003c/code\u003e\u003c/a\u003e project in \u003ccode\u003e/g/data/vk83\u003c/code\u003e. It is necessary to be a member of \u003ca href=\"https://my.nci.org.au/mancini/project/vk83\" rel=\"nofollow\"\u003e\u003ccode\u003evk83\u003c/code\u003e\u003c/a\u003e project to use ACCESS-NRI deployments of ACCESS-OM2-BGC.\u003c/p\u003e\n\u003cp\u003eThe deployment process also creates a GitHub release with the same tag. All releases are available under the \u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2-BGC/releases\"\u003eReleases page\u003c/a\u003e. Each release has a changelog and meta-data with detailed information about the build and deployment, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epaths on \u003ccode\u003egadi\u003c/code\u003e to all executables built in the deployment process (\u003ccode\u003espack.location\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ea \u003ccode\u003espack.lock\u003c/code\u003e file, which is a complete build provenance document, listing all the components that were built and their dependencies, versions, compiler version, build flags and build architecture\u003c/li\u003e\n\u003cli\u003ethe environment \u003ccode\u003espack.yaml\u003c/code\u003e file used for deployment\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdditionally the deployment creates environment modulefiles, the \u003ca href=\"https://opus.nci.org.au/display/Help/Environment+Modules\" rel=\"nofollow\"\u003estandard method for deploying software on \u003ccode\u003egadi\u003c/code\u003e\u003c/a\u003e. To view available ACCESS-OM2-BGC versions:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodule use /g/data/vk83/apps/spack/0.20/release/modules/linux-rocky8-x86_64\nmodule avail access-om2-bgc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor users of ACCESS-OM2-BGC model configurations released by ACCESS-NRI the exact location of the ACCESS-OM2-BGC model executables is not required. Model configurations will be updated with new model components when necessary.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1710289078.0
  },
  {
    "data_format": 2,
    "description": "My Spack environments",
    "filenames": [
      "thetagpu/spack.yaml"
    ],
    "full_name": "thomas-bouvier/spack-envs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003espack-envs\u003c/h1\u003e\u003ca id=\"user-content-spack-envs\" class=\"anchor\" aria-label=\"Permalink: spack-envs\" href=\"#spack-envs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git ~/spack\ngit clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages\ngit clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLocally\u003c/h2\u003e\u003ca id=\"user-content-locally\" class=\"anchor\" aria-label=\"Permalink: Locally\" href=\"#locally\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUsing Fedora Asahi Remix 39, make sure that dev tools are installed on the system:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ednf group install \"Development Tools\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ednf group install \"Development Libraries\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ednf group install \"C Development Tools and Libraries\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ednf install gcc-gfortran\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eChange the default configuration is needed:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack config --scope defaults edit config\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003einstall_tree: $spack/opt/spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ebuild_stage: $spack/var/spack/stage\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eActivate the environment and install it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack env activate ~/Dev/spack-envs/local\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack install\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eLast successful installations:\u003c/h3\u003e\u003ca id=\"user-content-last-successful-installations\" class=\"anchor\" aria-label=\"Permalink: Last successful installations:\" href=\"#last-successful-installations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eDate\u003c/th\u003e\n\u003cth\u003e\n\u003ccode\u003espack-envs\u003c/code\u003e commit\u003c/th\u003e\n\u003cth\u003eSpack commit\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e2024-01-15\u003c/td\u003e\n\u003ctd\u003e``\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGrid5000\u003c/h2\u003e\u003ca id=\"user-content-grid5000\" class=\"anchor\" aria-label=\"Permalink: Grid5000\" href=\"#grid5000\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack config --scope defaults edit config\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003einstall_tree: /my-spack/spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ebuild_stage: /tmp/spack-stage\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eArgonne National Lab\u003c/h2\u003e\u003ca id=\"user-content-argonne-national-lab\" class=\"anchor\" aria-label=\"Permalink: Argonne National Lab\" href=\"#argonne-national-lab\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCopy the relevant content of \u003ccode\u003e.zshrc\u003c/code\u003e into the frontend \u003ccode\u003e.zshrc\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePolaris\u003c/h3\u003e\u003ca id=\"user-content-polaris\" class=\"anchor\" aria-label=\"Permalink: Polaris\" href=\"#polaris\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce you are logged in on a compute node, activate the environment and install it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003euse_polaris\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack env activate git/spack-envs/polaris\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack install\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [
      "grid5000",
      "alcf"
    ],
    "updated_at": 1710496903.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "eugeneswalker/exawind-containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWorking with the Docker image (ecpe4s/exawind:latest)\u003c/h2\u003e\u003ca id=\"user-content-working-with-the-docker-image-ecpe4sexawindlatest\" class=\"anchor\" aria-label=\"Permalink: Working with the Docker image (ecpe4s/exawind:latest)\" href=\"#working-with-the-docker-image-ecpe4sexawindlatest\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eBuild the Docker image\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-docker-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eLaunch a container from the image\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; docker run -it --rm ecpe4s/exawind\n\nroot@8df184bdac63:/# which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nroot@8df184bdac63:/# which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWorking with the Singularity image (exawind.sif)\u003c/h2\u003e\u003ca id=\"user-content-working-with-the-singularity-image-exawindsif\" class=\"anchor\" aria-label=\"Permalink: Working with the Singularity image (exawind.sif)\" href=\"#working-with-the-singularity-image-exawindsif\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eBuild the Docker image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-docker-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eSave the Docker image as a docker-archive\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; docker save -o exawind.tar ecpe4s/exawind:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eBuild the Singularity image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-singularity-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eRun the Singularity image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./exawind.sif\n\nExawind Singularity\u0026gt; which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nExawind Singularity\u0026gt; which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRun Selected ExaWind Regression Tests\u003c/h2\u003e\u003ca id=\"user-content-run-selected-exawind-regression-tests\" class=\"anchor\" aria-label=\"Permalink: Run Selected ExaWind Regression Tests\" href=\"#run-selected-exawind-regression-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eLaunch a container using either the Docker or Singularity image (see above)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eClone this repository in the newly launched container and run the tests (here illustrated with Singularity)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003eExawind Singularity\u0026gt; git clone https://github.com/eugeneswalker/exawind-containers ~/exawind-containers\nExawind Singularity\u0026gt; cd ~/exawind-containers/demo\n\n\nExawind Singularity\u0026gt; ./run-nonIsoEdgeOpenJet.sh\nPASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15\n\n\nExawind Singularity\u0026gt; ./run-nalu-wind-tests.sh\nPASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11\nPASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13\n...\n\n\nExawind Singularity\u0026gt; ./run-amr-wind-tests.sh\nfinished abl_bndry_output\nfinished abl_godunov\n...\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1626420401.0
  },
  {
    "data_format": 2,
    "description": "Spack environments",
    "filenames": [
      "envs/alps/sirius/cpu/spack.yaml",
      "envs/alps/dlaf/oneapi-mt/spack.yaml"
    ],
    "full_name": "RMeli/my-spack",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eMy Spack\u003c/h1\u003e\u003ca id=\"user-content-my-spack\" class=\"anchor\" aria-label=\"Permalink: My Spack\" href=\"#my-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack-related stuff for @RMeli.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePackage Repository\u003c/h2\u003e\u003ca id=\"user-content-package-repository\" class=\"anchor\" aria-label=\"Permalink: Package Repository\" href=\"#package-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/repositories.html\" rel=\"nofollow\"\u003eSpack Package Repositories\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1711377578.0
  },
  {
    "data_format": 2,
    "description": "Spack clone",
    "filenames": [
      "share/spack/gitlab/cloud_pipelines/stacks/aws-isc/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml"
    ],
    "full_name": "lezzidan/spack",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e Spack\u003c/h1\u003e\u003ca id=\"user-content--spack\" class=\"anchor\" aria-label=\"Permalink:  Spack\" href=\"#-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/spack/spack/actions\"\u003e\u003cimg src=\"https://github.com/spack/spack/workflows/linux%20tests/badge.svg\" alt=\"Unit Tests\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml\"\u003e\u003cimg src=\"https://github.com/spack/spack/actions/workflows/bootstrap.yml/badge.svg\" alt=\"Bootstrapping\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/spack/spack\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/70b0104a5a00f472f39f523bb50f576c7d5456c58b0068304f1ecd8e5054ae8c/68747470733a2f2f636f6465636f762e696f2f67682f737061636b2f737061636b2f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/spack/spack/branch/develop/graph/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/spack/spack/actions/workflows/build-containers.yml\"\u003e\u003cimg src=\"https://github.com/spack/spack/actions/workflows/build-containers.yml/badge.svg\" alt=\"Containers\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fca79013ca8059644742ad2936823670fa01342c0e60d57949ee69f693dccde3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/psf/black\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7d770c433d6198d89f8c1e2f187b904a9721d176259d0e97157337741cc8e837/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667\" alt=\"Code style: black\" data-canonical-src=\"https://img.shields.io/badge/code%20style-black-000000.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://slack.spack.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e8580758c789c07a64e14287a71a75290dcddc6fee61b8a2e64f07bf7dca1ec9/68747470733a2f2f736c61636b2e737061636b2e696f2f62616467652e737667\" alt=\"Slack\" data-canonical-src=\"https://slack.spack.io/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSpack is a multi-platform package manager that builds and installs\nmultiple versions and configurations of software. It works on Linux,\nmacOS, and many supercomputers. Spack is non-destructive: installing a\nnew version of a package does not break existing installations, so many\nconfigurations of the same package can coexist.\u003c/p\u003e\n\u003cp\u003eSpack offers a simple \"spec\" syntax that allows users to specify versions\nand configuration options. Package files are written in pure Python, and\nspecs allow package authors to write a single script for many different\nbuilds of the same package.  With Spack, you can build your software\n\u003cem\u003eall\u003c/em\u003e the ways you want to.\u003c/p\u003e\n\u003cp\u003eSee the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/features.html\" rel=\"nofollow\"\u003eFeature Overview\u003c/a\u003e\nfor examples and highlights.\u003c/p\u003e\n\u003cp\u003eTo install spack and your first package, make sure you have Python.\nThen:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone -c feature.manyFiles=true https://github.com/spack/spack.git\n$ cd spack/bin\n$ ./spack install zlib\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"\u003e\u003cstrong\u003eFull documentation\u003c/strong\u003e\u003c/a\u003e is available, or\nrun \u003ccode\u003espack help\u003c/code\u003e or \u003ccode\u003espack help --all\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor a cheat sheet on Spack syntax, run \u003ccode\u003espack help --spec\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTutorial\u003c/h2\u003e\u003ca id=\"user-content-tutorial\" class=\"anchor\" aria-label=\"Permalink: Tutorial\" href=\"#tutorial\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe maintain a\n\u003ca href=\"https://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\"\u003e\u003cstrong\u003ehands-on tutorial\u003c/strong\u003e\u003c/a\u003e.\nIt covers basic to advanced usage, packaging, developer features, and large HPC\ndeployments.  You can do all of the exercises on your own laptop using a\nDocker container.\u003c/p\u003e\n\u003cp\u003eFeel free to use these materials to teach users at your organization\nabout Spack.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCommunity\u003c/h2\u003e\u003ca id=\"user-content-community\" class=\"anchor\" aria-label=\"Permalink: Community\" href=\"#community\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is an open source project.  Questions, discussion, and\ncontributions are welcome. Contributions can be anything from new\npackages to bugfixes, documentation, or even new core features.\u003c/p\u003e\n\u003cp\u003eResources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eSlack workspace\u003c/strong\u003e: \u003ca href=\"https://spackpm.slack.com\" rel=\"nofollow\"\u003espackpm.slack.com\u003c/a\u003e.\nTo get an invitation, visit \u003ca href=\"https://slack.spack.io\" rel=\"nofollow\"\u003eslack.spack.io\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/spack/spack/discussions\"\u003e\u003cstrong\u003eGithub Discussions\u003c/strong\u003e\u003c/a\u003e: not just for discussions, also Q\u0026amp;A.\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eMailing list\u003c/strong\u003e: \u003ca href=\"https://groups.google.com/d/forum/spack\" rel=\"nofollow\"\u003egroups.google.com/d/forum/spack\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eTwitter\u003c/strong\u003e: \u003ca href=\"https://twitter.com/spackpm\" rel=\"nofollow\"\u003e@spackpm\u003c/a\u003e. Be sure to\n\u003ccode\u003e@mention\u003c/code\u003e us!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eContributing to Spack is relatively easy.  Just send us a\n\u003ca href=\"https://help.github.com/articles/using-pull-requests/\"\u003epull request\u003c/a\u003e.\nWhen you send your request, make \u003ccode\u003edevelop\u003c/code\u003e the destination branch on the\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYour PR must pass Spack\u0027s unit tests and documentation tests, and must be\n\u003ca href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"nofollow\"\u003ePEP 8\u003c/a\u003e compliant.  We enforce\nthese guidelines with our CI process. To run these tests locally, and for\nhelpful tips on git, see our\n\u003ca href=\"https://spack.readthedocs.io/en/latest/contribution_guide.html\" rel=\"nofollow\"\u003eContribution Guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSpack\u0027s \u003ccode\u003edevelop\u003c/code\u003e branch has the latest contributions. Pull requests\nshould target \u003ccode\u003edevelop\u003c/code\u003e, and users who want the latest package versions,\nfeatures, etc. can use \u003ccode\u003edevelop\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eReleases\u003c/h2\u003e\u003ca id=\"user-content-releases\" class=\"anchor\" aria-label=\"Permalink: Releases\" href=\"#releases\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor multi-user site deployments or other use cases that need very stable\nsoftware installations, we recommend using Spack\u0027s\n\u003ca href=\"https://github.com/spack/spack/releases\"\u003estable releases\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEach Spack release series also has a corresponding branch, e.g.\n\u003ccode\u003ereleases/v0.14\u003c/code\u003e has \u003ccode\u003e0.14.x\u003c/code\u003e versions of Spack, and \u003ccode\u003ereleases/v0.13\u003c/code\u003e has\n\u003ccode\u003e0.13.x\u003c/code\u003e versions. We backport important bug fixes to these branches but\nwe do not advance the package versions or make other changes that would\nchange the way Spack concretizes dependencies within a release branch.\nSo, you can base your Spack deployment on a release branch and \u003ccode\u003egit pull\u003c/code\u003e\nto get fixes, without the package churn that comes with \u003ccode\u003edevelop\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe latest release is always available with the \u003ccode\u003ereleases/latest\u003c/code\u003e tag.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"https://spack.readthedocs.io/en/latest/developer_guide.html#releases\" rel=\"nofollow\"\u003edocs on releases\u003c/a\u003e\nfor more details.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCode of Conduct\u003c/h2\u003e\u003ca id=\"user-content-code-of-conduct\" class=\"anchor\" aria-label=\"Permalink: Code of Conduct\" href=\"#code-of-conduct\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease note that Spack has a\n\u003ca href=\".github/CODE_OF_CONDUCT.md\"\u003e\u003cstrong\u003eCode of Conduct\u003c/strong\u003e\u003c/a\u003e. By participating in\nthe Spack community, you agree to abide by its rules.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMany thanks go to Spack\u0027s \u003ca href=\"https://github.com/spack/spack/graphs/contributors\"\u003econtributors\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSpack was created by Todd Gamblin, \u003ca href=\"mailto:tgamblin@llnl.gov\"\u003etgamblin@llnl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCiting Spack\u003c/h3\u003e\u003ca id=\"user-content-citing-spack\" class=\"anchor\" aria-label=\"Permalink: Citing Spack\" href=\"#citing-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you are referencing Spack in a publication, please cite the following paper:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTodd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee,\nAdam Moody, Bronis R. de Supinski, and W. Scott Futral.\n\u003ca href=\"https://www.computer.org/csdl/proceedings/sc/2015/3723/00/2807623.pdf\" rel=\"nofollow\"\u003e\u003cstrong\u003eThe Spack Package Manager: Bringing Order to HPC Software Chaos\u003c/strong\u003e\u003c/a\u003e.\nIn \u003cem\u003eSupercomputing 2015 (SC\u201915)\u003c/em\u003e, Austin, Texas, November 15-20 2015. LLNL-CONF-669890.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOn GitHub, you can copy this citation in APA or BibTeX format via the \"Cite this repository\"\nbutton. Or, see the comments in \u003ccode\u003eCITATION.cff\u003c/code\u003e for the raw BibTeX.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack/blob/develop/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1684418839.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ci/spack.yaml"
    ],
    "full_name": "rohankumardubey/libtree",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\"\u003e\u003cimg src=\"https://github.com/haampie/libtree/workflows/Test/badge.svg?branch=master\" alt=\"Test\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://aur.archlinux.org/packages/libtree/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e22cad709c40ea40e72b03313e4a660481222a373c9217b71809265e991f747e/68747470733a2f2f696d672e736869656c64732e696f2f6175722f76657273696f6e2f6c6962747265653f6c6f676f3d417263682d4c696e7578\" alt=\"AUR version\" data-canonical-src=\"https://img.shields.io/aur/version/libtree?logo=Arch-Linux\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003elibtree\u003c/h1\u003e\u003ca id=\"user-content-libtree\" class=\"anchor\" aria-label=\"Permalink: libtree\" href=\"#libtree\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA tool that:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\ud83c\udf33 turns \u003ccode\u003eldd\u003c/code\u003e into a tree\u003c/li\u003e\n\u003cli\u003e\u261d\ufe0f explains why shared libraries are found and why not\u003c/li\u003e\n\u003cli\u003e\ud83d\udce6 optionally deploys executables and dependencies into a single directory\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"doc/screenshot.png\"\u003e\u003cimg src=\"doc/screenshot.png\" alt=\"example\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDownload the \u003ca href=\"https://github.com/haampie/libtree/releases\"\u003e\u003cstrong\u003elatest release\u003c/strong\u003e\u003c/a\u003e from Github.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStatic executable\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ewget -qO libtree https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64\nchmod +x libtree\n./libtree \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich man\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eStatic executable + optional dependencies\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ewget -qO libtree.tar.gz https://github.com/haampie/libtree/releases/download/v2.0.0/libtree_x86_64.tar.gz\nmkdir libtree\ntar -xf libtree.tar.gz -C libtree\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PATH=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/libtree:\u003cspan class=\"pl-smi\"\u003e$PATH\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\nlibtree \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich man\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDeploying binaries + dependencies into a folder\u003c/h2\u003e\u003ca id=\"user-content-deploying-binaries--dependencies-into-a-folder\" class=\"anchor\" aria-label=\"Permalink: Deploying binaries + dependencies into a folder\" href=\"#deploying-binaries--dependencies-into-a-folder\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ libtree \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich man\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e -d man.bundle --chrpath --strip\nman\n\u251c\u2500\u2500 libmandb-2.9.1.so [runpath]\n\u2502   \u251c\u2500\u2500 libman-2.9.1.so [runpath]\n\u2502   \u2502   \u251c\u2500\u2500 libpipeline.so.1 [ld.so.conf]\n\u2502   \u2502   \u2514\u2500\u2500 libseccomp.so.2 [ld.so.conf]\n\u2502   \u2514\u2500\u2500 libgdbm.so.6 [ld.so.conf]\n\u251c\u2500\u2500 libman-2.9.1.so (collapsed) [runpath]\n\u2514\u2500\u2500 libpipeline.so.1 (collapsed) [ld.so.conf]\n\nDeploying to \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/bin/man\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/bin/man\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/lib/man-db/libmandb-2.9.1.so\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libmandb-2.9.1.so\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/lib/man-db/libman-2.9.1.so\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libman-2.9.1.so\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/lib/x86_64-linux-gnu/libpipeline.so.1.5.2\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libpipeline.so.1.5.2\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n  creating symlink \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libpipeline.so.1\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/lib/x86_64-linux-gnu/libseccomp.so.2.5.1\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libseccomp.so.2.5.1\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n  creating symlink \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libseccomp.so.2\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/usr/lib/x86_64-linux-gnu/libgdbm.so.6.0.0\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e =\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libgdbm.so.6.0.0\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n  creating symlink \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eman.bundle/usr/lib/libgdbm.so.6\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n$ tree man.bundle/\nman.bundle/\n\u2514\u2500\u2500 usr\n    \u251c\u2500\u2500 bin\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 man\n    \u2514\u2500\u2500 lib\n        \u251c\u2500\u2500 libgdbm.so.6 -\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e libgdbm.so.6.0.0\n        \u251c\u2500\u2500 libgdbm.so.6.0.0\n        \u251c\u2500\u2500 libman-2.9.1.so\n        \u251c\u2500\u2500 libmandb-2.9.1.so\n        \u251c\u2500\u2500 libpipeline.so.1 -\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e libpipeline.so.1.5.2\n        \u251c\u2500\u2500 libpipeline.so.1.5.2\n        \u251c\u2500\u2500 libseccomp.so.2 -\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e libseccomp.so.2.5.1\n        \u2514\u2500\u2500 libseccomp.so.2.5.1\n\n3 directories, 9 files\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVerbose output\u003c/h2\u003e\u003ca id=\"user-content-verbose-output\" class=\"anchor\" aria-label=\"Permalink: Verbose output\" href=\"#verbose-output\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBy default certain standard depenendencies are not shown. For more verbose output use\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003elibtree -v $(which man)\u003c/code\u003e to show skipped libraries without their children\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003elibtree -a $(which apt-get)\u003c/code\u003e to show the full recursive list of libraries\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUse the \u003ccode\u003e--path\u003c/code\u003e or \u003ccode\u003e-p\u003c/code\u003e flags to show paths rather than sonames:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003elibtree -p $(which tar)\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eChanging search paths\u003c/h2\u003e\u003ca id=\"user-content-changing-search-paths\" class=\"anchor\" aria-label=\"Permalink: Changing search paths\" href=\"#changing-search-paths\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003elibtree\u003c/code\u003e follows the rules of \u003ccode\u003eld.so\u003c/code\u003e to locate libraries, but does not use \u003ccode\u003eldconfig\u003c/code\u003e\u0027s\ncache. Instead it parses \u003ccode\u003e/etc/ld.so.conf\u003c/code\u003e at runtime. In fact you can change the search\npath config by setting \u003ccode\u003e--ldconf mylibs.conf\u003c/code\u003e. Search paths can be added as well via\n\u003ccode\u003eLD_LIBRARY_PATH=\"path1:path2:$LD_LIBRARY_PATH\" libtree ...\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding\u003c/h2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink: Building\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eFrom source\u003c/strong\u003e:\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/haampie/libtree.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e libtree\nmkdir build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/path/to/cxxopts;/path/to/elfio;/path/to/termcolor\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e ..\nmake -j\nmake install\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eUsing \u003ca href=\"https://github.com/spack/spack\"\u003espack\u003c/a\u003e\u003c/strong\u003e:\n\u003cpre\u003e\u003ccode\u003espack install libtree +chrpath +strip\nspack load libtree\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eKnown issues\u003c/h2\u003e\u003ca id=\"user-content-known-issues\" class=\"anchor\" aria-label=\"Permalink: Known issues\" href=\"#known-issues\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eWhen deploying libs with \u003ccode\u003elibtree app -d folder.bundle --chrpath\u003c/code\u003e, the runpaths are only\nchanged when the binaries already have an an rpath or runpath. This is a limitation of\n\u003ccode\u003echrpath\u003c/code\u003e. Another option is to use \u003ccode\u003epatchelf\u003c/code\u003e instead, but this tool is known to break\nbinaries sometimes.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1664232270.0
  },
  {
    "data_format": 2,
    "description": "Python wrapper for BAKE",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-bake",
    "latest_release": null,
    "readme": "",
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1633975348.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "oneapi/failures/spack.yaml",
      "oneapi/spack.yaml",
      "gnu/spack.yaml"
    ],
    "full_name": "eugeneswalker/noaa",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1675202595.0
  },
  {
    "data_format": 2,
    "description": "SIRIUS AppImage (using just the bare minimum)",
    "filenames": [
      "libtree/spack.yaml"
    ],
    "full_name": "haampie/sirius-appimage",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCreating an AppImage from a spack environment\u003c/h1\u003e\u003ca id=\"user-content-creating-an-appimage-from-a-spack-environment\" class=\"anchor\" aria-label=\"Permalink: Creating an AppImage from a spack environment\" href=\"#creating-an-appimage-from-a-spack-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHPC container runtimes often use squashfs as an archive to store an image, which is then mounted on compute nodes and made writeable using overlayfs where the top layer is a ramfs. This trick gives good performance particularly on shared filesystems, since the squashfs file is a single blob on the disk and has good caching behavior.\u003c/p\u003e\n\u003cp\u003eHowever, perfect isolation from the host system is not always possible, in particular when vendor optimized libraries (e.g. cuda and mpi) have to be mounted into the container, and the question is what the point of containers really is if they still depend on the host system.\u003c/p\u003e\n\u003cp\u003eInstead of using containers, one can still deploy applications as a single self-contained blob on the filesystem by using the AppImage runtime. The basic idea is to create an executable which unwraps and mounts a squashfs file baked into the binary.\u003c/p\u003e\n\u003cp\u003eThis repo shows how to do that using spack environments, where we install \u003ca href=\"https://github.com/electronic-structure/SIRIUS/\"\u003eSIRIUS\u003c/a\u003e, bundle it using \u003ca href=\"https://github.com/haampie/libtree\"\u003elibtree\u003c/a\u003e and then create a self-unwrapping binary using the \u003ca href=\"https://github.com/AppImage/AppImageKit\"\u003eAppImage runtime\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding\u003c/h2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink: Building\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e./build.sh\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning\u003c/h2\u003e\u003ca id=\"user-content-running\" class=\"anchor\" aria-label=\"Permalink: Running\" href=\"#running\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e./sirius.app sirius.scf\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eSIRIUS version : 6.5.7\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003egit hash       : https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003egit branch     : release v6.5.7\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ebuild time     : 2021-03-23 10:46:06\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003estart time     : Tue, 23 Mar 2021 12:34:25\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003enumber of MPI ranks           : 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eMPI grid                      : 1 1 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003emaximum number of OMP threads : 16\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e...\u003c/span\u003e\n\n\n$ \u003cspan class=\"pl-s1\"\u003e./sirius.app atom\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eAtom (L)APW+lo basis generation.\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eUsage: atom [options]\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eOptions:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --help     print this help and exit\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --symbol=  {string} symbol of a chemical element\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --type=    {lo1, lo2, lo3, LO1, LO2} type of local orbital basis\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --core=    {double} cutoff for core states: energy (in Ha, if \u0026lt;0), radius (in a.u. if \u0026gt;0)\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --order=   {int} order of augmentation\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --apw_enu= {double} default value for APW linearization energies\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --auto_enu allow search of APW linearization energies\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --xml      xml output for Exciting code\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  --rel      use scalar-relativistic solver\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning on piz daint\u003c/h2\u003e\u003ca id=\"user-content-running-on-piz-daint\" class=\"anchor\" aria-label=\"Permalink: Running on piz daint\" href=\"#running-on-piz-daint\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor Piz Daint I\u0027ve modified the \u003ccode\u003esirius/spack.yaml\u003c/code\u003e a bit so that it links against system libmpi.so (\u003ccode\u003e^cray-mpich\u003c/code\u003e that is):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edaint103 $ ./build.sh\n...\n\ndaint103 $ du -sh sirius.app # binary size (includes compressed squashfs)\n26M\tsirius.app\n\ndaint103 $ ./sirius.app --appimage-extract # runtime allows you to extract\nsquashfs-root/AppRun\nsquashfs-root/usr\nsquashfs-root/usr/bin\nsquashfs-root/usr/bin/atom\nsquashfs-root/usr/bin/sirius.scf\nsquashfs-root/usr/lib\nsquashfs-root/usr/lib/libAtpSigHandler.so.1\nsquashfs-root/usr/lib/libAtpSigHandler.so.1.0.1\nsquashfs-root/usr/lib/libcuda.so.1\nsquashfs-root/usr/lib/libcuda.so.450.51.05\n...\n\ndaint103 $ du -sh squashfs-root # uncompressed size\n70M\tsquashfs-root/\n\ndaint103 $ srun ... -Cmc -N1 -n2 -c2 --time=00:01:00 ./sirius.app sirius.scf # run sirius.scf with cray mpi\nsrun: job 30079568 queued and waiting for resources\nsrun: job 30079568 has been allocated resources\nSIRIUS 6.5.7, git hash: https://api.github.com/repos/electronic-structure/SIRIUS/git/ref/tags/v6.5.7\ninput file does not exist\n===========================================================================================================\n                            #         Total          %   Parent %        Median           Min           Max\n-----------------------------------------------------------------------------------------------------------\nsirius                      1       2.30 ms     100.00     100.00       2.30 ms       2.30 ms       2.30 ms\n |- sirius::initialize      1       1.40 ms      60.83      60.83       1.40 ms       1.40 ms       1.40 ms\n |- sirius::finalize        1     333.28 us      14.52      14.52     333.28 us     333.28 us     333.28 us\n\n===========================================================================================================\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1616508538.0
  },
  {
    "data_format": 2,
    "description": "SKA Spack environments related files",
    "filenames": [
      "env-bipp-izar/spack.yaml"
    ],
    "full_name": "epfl-radio-astro/ska-spack-env",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eska-spack-env\u003c/h1\u003e\u003ca id=\"user-content-ska-spack-env\" class=\"anchor\" aria-label=\"Permalink: ska-spack-env\" href=\"#ska-spack-env\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSKA Spack environments related files\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1674857920.0
  },
  {
    "data_format": 2,
    "description": "Spack Environments ",
    "filenames": [
      "cent8/envs/avx/rproject/spack.yaml",
      "cent7/library/spack.yaml",
      "cent7/library/bak/spack.yaml",
      "compilers/envs/compilers/spack.yaml"
    ],
    "full_name": "alexpacheco/spackenv",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSPACK Environments\u003c/h1\u003e\u003ca id=\"user-content-spack-environments\" class=\"anchor\" aria-label=\"Permalink: SPACK Environments\" href=\"#spack-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo contains the environment definitions to deploy site-software on Lehigh University\u0027s Research Computing resources via SPACK environments.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSoftware deployment for CentOS 8.x\u003c/h2\u003e\u003ca id=\"user-content-software-deployment-for-centos-8x\" class=\"anchor\" aria-label=\"Permalink: Software deployment for CentOS 8.x\" href=\"#software-deployment-for-centos-8x\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSoftware is deployed using two Spack installations.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFor compilers and module environments\u003c/li\u003e\n\u003cli\u003eSite software for general use\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCompilers\u003c/h3\u003e\u003ca id=\"user-content-compilers\" class=\"anchor\" aria-label=\"Permalink: Compilers\" href=\"#compilers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis spack installation provides the gcc, nvhpc and cuda compilers, and lmod software for module management. In the future, this installation will also provide intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were installed in /share/Apps/intel with older intel compilers. This installation should not be used for deploying site software nor should the software provided be made available using the module environment.\u003c/p\u003e\n\u003cp\u003eTo reproduce installation\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/alexpacheco/spackenv.git\ncd spackenv/compilers/envs/compilers\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe directory \u003ccode\u003eetc/lmod\u003c/code\u003e contains the LMOD configuration to switch between avx, avx2 and avx512 enabled \u003ccode\u003eMODULEPATHS\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eLU Software\u003c/h3\u003e\u003ca id=\"user-content-lu-software\" class=\"anchor\" aria-label=\"Permalink: LU Software\" href=\"#lu-software\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis spack installation provides the deployed site-software on Sol and Hawk.\u003c/p\u003e\n\u003cp\u003eTo reproduce this installation, you need to first copy the site configuration files from \u003ccode\u003eetc/spack\u003c/code\u003e to your spack install tree. This assumes that SLURM and the compiler environment above is already installed. Edit the \u003ccode\u003epackages.yaml\u003c/code\u003e file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel, cuda, and nvhpc. The file \u003ccode\u003erepo.yaml\u003c/code\u003e is hardwired with  location of the lubio repository and should be changed to your location. The directory \u003ccode\u003etemplates\u003c/code\u003e contains the template lua file for a few modules as defined in the \u003ccode\u003emodules.yaml\u003c/code\u003e file  and should be copied to the \u003ccode\u003eetc\u003c/code\u003e directory in your spack installation tree.\u003c/p\u003e\n\u003cp\u003eOn Sol, these files are available at \u003ccode\u003e/share/Apps/lusoft/etc/spack\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eAvailable Environments\u003c/h4\u003e\u003ca id=\"user-content-available-environments\" class=\"anchor\" aria-label=\"Permalink: Available Environments\" href=\"#available-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch5 class=\"heading-element\"\u003esolhawk\u003c/h5\u003e\u003ca id=\"user-content-solhawk\" class=\"anchor\" aria-label=\"Permalink: solhawk\" href=\"#solhawk\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis environment builds the entire software except the various python and r packages for ivybridge, haswell and skylake_avx512 architectures. This environment also builds the tcl environment modules that is not currently used. This should be build first and any new packages should be added to this environment.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/solhawk\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eavx/avx2/avx512\u003c/h4\u003e\u003ca id=\"user-content-avxavx2avx512\" class=\"anchor\" aria-label=\"Permalink: avx/avx2/avx512\" href=\"#avxavx2avx512\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThese environment builds the software stack except the various python and r packages for ivybridge/haswell/skylake_avx512 architectures. If software in the \u003ccode\u003esolhawk\u003c/code\u003e environment is already built, then these environments are only setting up the installation root for the LMOD module files \u003ccode\u003e/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}\u003c/code\u003e. The only reason these environments exist is due to SPACK\u0027s inability to built a architecture based LMOD module tree similar to the TCL module tree.\n\u003cem\u003eNote\u003c/em\u003e: If you change the path of the installation root, make sure that you change the corresponding path in \u003ccode\u003ecompilers/etc/SitePackage.lua\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx2/lusoft\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003ePython and R packages\u003c/h4\u003e\u003ca id=\"user-content-python-and-r-packages\" class=\"anchor\" aria-label=\"Permalink: Python and R packages\" href=\"#python-and-r-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRather than building module files for various python and r packages, a single module is created for a filesystem view of all python and r packages respectively. The path to the r filesystem is setup as \u003ccode\u003eR_LIBS_SITE\u003c/code\u003e so that any application such as \u003ccode\u003etrinity\u003c/code\u003e that requires many R packages only need to load the r module. If new packages added to the above environments require a dependent R package, then that dependency should be added to the rpoject environment and concretized. The python environment uses a \u003ccode\u003econcretization: together\u003c/code\u003e and may not provide the same python package as the above software environments. The filesystem views are hardwired as \u003ccode\u003e/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}\u003c/code\u003e and \u003ccode\u003e/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx/python\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx512/rproject\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003ex86_64\u003c/h4\u003e\u003ca id=\"user-content-x86_64\" class=\"anchor\" aria-label=\"Permalink: x86_64\" href=\"#x86_64\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis environment builds unoptimized software such as anaconda python, gnu parallel, scree, tmux, etc for generic x86_64 processor.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCentOS 7.x software\u003c/h2\u003e\u003ca id=\"user-content-centos-7x-software\" class=\"anchor\" aria-label=\"Permalink: CentOS 7.x software\" href=\"#centos-7x-software\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis just collects the various environments for building software before the CentOS 8.x upgrade.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1657632897.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "roblatham00/phonebook",
    "latest_release": null,
    "readme": "\u003cp\u003eYour project \"YP\" has been setup!\nEnjoy programming with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1682697472.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "robertu94/roibin-sz3-experiments",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eROIBIN-SZ Experiments\u003c/h1\u003e\u003ca id=\"user-content-roibin-sz-experiments\" class=\"anchor\" aria-label=\"Permalink: ROIBIN-SZ Experiments\" href=\"#roibin-sz-experiments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSystem Information\u003c/h2\u003e\u003ca id=\"user-content-system-information\" class=\"anchor\" aria-label=\"Permalink: System Information\" href=\"#system-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe hardware and software versions used for the performance evaluations can be found in Table I in the paper. These nodes come from Clemson University\u0027s Palmetto Cluster.\u003c/p\u003e\n\u003cp\u003eThe quality assessment was done on the PSANA system at SLAC national accelerator laboratory using PSOCAKE, PHENIX, and CCP4.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWhere is the implementation of ROIBIN-SZ3?\u003c/h2\u003e\u003ca id=\"user-content-where-is-the-implementation-of-roibin-sz3\" class=\"anchor\" aria-label=\"Permalink: Where is the implementation of ROIBIN-SZ3?\" href=\"#where-is-the-implementation-of-roibin-sz3\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains only our experimental codes and configuration files.\u003c/p\u003e\n\u003cp\u003eWe contributed the composed building blocks for ROIBIN-SZ3 into the \u003ca href=\"https://github.com/robertu94/libpressio\"\u003elibpressio\u003c/a\u003e repository specifically \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc\"\u003e\u003ccode\u003ebinning.cc\u003c/code\u003e\u003c/a\u003e,  \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc\"\u003e\u003ccode\u003eroibin.cc\u003c/code\u003e\u003c/a\u003e and \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h\"\u003e\u003ccode\u003eroibin_impl.h\u003c/code\u003e\u003c/a\u003e in the \u003ccode\u003esrc/plugins/compressors\u003c/code\u003e subdirectory.  The automated tuning implementation was used directly from \u003ca href=\"https://github.com/robertu94/libpressio_opt\"\u003eOptZConfig/LibPressioOpt\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"#obtaining-data\"\u003eObtaining Data\u003c/a\u003e to request the dataset used.\u003c/p\u003e\n\u003cp\u003eThe quality assessment software was not designed in this paper.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor ease of evaluation, we provide a docker container to evaluate our performance results.\u003c/p\u003e\n\u003cp\u003eThere are several key steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eObtaining Data\u003c/li\u003e\n\u003cli\u003eInstalling the software (either in a container or on the host system)\u003c/li\u003e\n\u003cli\u003eRunning the experiments\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eObtaining Data\u003c/h3\u003e\u003ca id=\"user-content-obtaining-data\" class=\"anchor\" aria-label=\"Permalink: Obtaining Data\" href=\"#obtaining-data\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe data for these experiments are extremely large (6+TB for one complete dataset used in the quality assessment). The full Se-SAD dataset is publicly available here \u003ca href=\"https://cxidb.org/id-54.html\" rel=\"nofollow\"\u003ehttps://cxidb.org/id-54.html\u003c/a\u003e, but require some domain knowledge to process the entire dataset. We include a subset of the data for testing roibin-sz3. For more information about CXI files used for this paper, contact the authors.\u003c/p\u003e\n\u003cp\u003eTo run in the container, you may need to set the files to world readable \u003ccode\u003echmod a+r\u003c/code\u003e to be read inside the container depending on your container manager.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eQuality Assessment\u003c/h3\u003e\u003ca id=\"user-content-quality-assessment\" class=\"anchor\" aria-label=\"Permalink: Quality Assessment\" href=\"#quality-assessment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe quality analysis results (Figures 1,4-8 and Table 3)  were produced using \u003ca href=\"https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial\" rel=\"nofollow\"\u003ePSOCAKE\u003c/a\u003e, \u003ca href=\"https://phenix-online.org\" rel=\"nofollow\"\u003ePHENIX\u003c/a\u003e, and \u003ca href=\"https://www.ccp4.ac.uk\" rel=\"nofollow\"\u003eCCP4\u003c/a\u003e.\nCorrect use of this tool requires experience and expertise in serial\ncrystallography and is outside the scope of this document.\u003c/p\u003e\n\u003cp\u003eWhere decompressed outputs were needed for inputs for these tools, they were outputted from the Performance Assessment codes.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eContainer Install (for ease of setup)\u003c/h3\u003e\u003ca id=\"user-content-container-install-for-ease-of-setup\" class=\"anchor\" aria-label=\"Permalink: Container Install (for ease of setup)\" href=\"#container-install-for-ease-of-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe provide a container for \u003ccode\u003ex86_64\u003c/code\u003e image for ease of installation.\u003c/p\u003e\n\u003cp\u003eThis container differs from our experimental setup in 2 ways:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe production build used \u003ccode\u003e-march=native -mtune=native\u003c/code\u003e for architecture optimized builds where as the container does not use these flags to maximize compatablity across \u003ccode\u003ex86_64\u003c/code\u003e hardware.\u003c/li\u003e\n\u003cli\u003eWe use MPICH in the container rather than the OpenMPI because we found MPICH more reliably ran in the container during testing while OpenMPI was the system MPI.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eNOTE this file is \u0026gt;= 6 GB (without datasets; see above), download with caution.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eSingularity\u003c/h4\u003e\u003ca id=\"user-content-singularity\" class=\"anchor\" aria-label=\"Permalink: Singularity\" href=\"#singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can install and start the container on many super computers using singularity.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e this first commmand may issue a ton of warnings regarding xattrs depending on your filesystem on your container host; these were benign in our testing.\u003c/span\u003e\nsingularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -c enables additional confinement than singularity uses by default to prevent polution from /home\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -B bind mounts in the data directory containing your CXI files.\u003c/span\u003e\nsingularity run -c -B path/to/datadir:/data:ro roibin.sif bash\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eDocker\u003c/h4\u003e\u003ca id=\"user-content-docker\" class=\"anchor\" aria-label=\"Permalink: Docker\" href=\"#docker\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can run an example code on a small dataset by running with the following container and requesting a dataset.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003edocker pull ghcr.io/robertu94/roibin:latest\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003emost systems\u003c/span\u003e\ndocker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e if running on a SeLinux enforcing system\u003c/span\u003e\ndocker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuilding the container\u003c/h3\u003e\u003ca id=\"user-content-building-the-container\" class=\"anchor\" aria-label=\"Permalink: Building the container\" href=\"#building-the-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can build the container yourself as follows:\nNOTE this process takes 3+ hours on a modern laptop, and most clusters do not\nprovide sufficient permissions to run container builds on the cluster.\u003c/p\u003e\n\u003cp\u003eAdditional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to build.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install/module load git-lfs, needed to download example_data for building the container\u003c/span\u003e\nsudo dnf install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eFedora/CentOS Stream 8\u003c/span\u003e\nsudo apt-get install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\nspack install git-lfs\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e spack load git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e using spack\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e clone this repository\u003c/span\u003e\ngit clone --recursive https://github.com/robertu94/roibin-sz3-experiments\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e roibin-sz3-experiments\ndocker build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -t roibin\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you forgot to install \u003ccode\u003egit-lfs\u003c/code\u003e before and have an empty \u003ccode\u003eexample_data\u003c/code\u003e folder, you should install \u003ccode\u003egit-lfs\u003c/code\u003e\nand then run the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit lfs fetch\ngit lfs checkout\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eManual Install (for scale)\u003c/h3\u003e\u003ca id=\"user-content-manual-install-for-scale\" class=\"anchor\" aria-label=\"Permalink: Manual Install (for scale)\" href=\"#manual-install-for-scale\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe easiest way to install this manually is with \u003ccode\u003espack\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --recursive https://github.com/robertu94/roibin-sz3-experiments\ngit clone https://github.com/spack/spack\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh\nspack compiler find\n\nspack env activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003esee note about MPI below\u003c/span\u003e\nspack install\n\nmkdir build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake ..\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis software is not compatible with Windows, and hasn\u0027t been tested on MacOS.\u003c/p\u003e\n\u003cp\u003ePlease note all functionality will not work on Debian/Ubuntu (due to known bug in LibPressio we hope to resolve soon).\nPlease use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL, ...).\nAdditionally some of this code requires a newer compiler and may not compile on older versions of CentOS.\u003c/p\u003e\n\u003cp\u003eYou may wish to configure the build to use your local version of MPI.\nPlease see \u003ca href=\"https://spack.readthedocs.io/en/latest/build_settings.html#external-packages\" rel=\"nofollow\"\u003ethe spack guide\u003c/a\u003e for how to do this.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning the Experiments\u003c/h2\u003e\u003ca id=\"user-content-running-the-experiments\" class=\"anchor\" aria-label=\"Permalink: Running the Experiments\" href=\"#running-the-experiments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce the container is installed, you can run our testing commmands.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003empiexec -np \u003cspan class=\"pl-smi\"\u003e$procs\u003c/span\u003e /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ewhere \u003ccode\u003e-f\u003c/code\u003e is the input data file, and \u003ccode\u003e-p\u003c/code\u003e is the configuration to use \u003ccode\u003e-c\u003c/code\u003e is the chunk size.\u003c/p\u003e\n\u003cp\u003ePlease see \u003ccode\u003erun_all.sh\u003c/code\u003e for our production configurations.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eExample Output\u003c/h3\u003e\u003ca id=\"user-content-example-output\" class=\"anchor\" aria-label=\"Permalink: Example Output\" href=\"#example-output\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eNOTE results below from a laptop, not the server grade hardware from the paper\nand in the container with the differences noted above so bandwidth will differ.\nAdditionally, this files results were only reported in aggregate in the paper\nand may not represent the entire 6TB dataset.  It was selected as one of the smaller\nfiles from the data-set to ease reproduce-ability.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003e[demo@620bb069495a app]\u003c/span\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e /app\u003c/span\u003e\n\u003cspan class=\"pl-e\"\u003e[demo@620bb069495a app]\u003c/span\u003e$ \u003cspan class=\"pl-s1\"\u003empiexec -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json -c 32\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:abs \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:lossless \u0026lt;int32\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:pw_rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:abs_err_bound \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:app \u0026lt;char*\u0026gt; = \"SZ\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:config_file \u0026lt;char*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:config_struct \u0026lt;void*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:data_type \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:error_bound_mode \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str \u0026lt;char*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:bin_size \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peak_size \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:tolerance \u0026lt;double\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:gzip_mode \u0026lt;int32\u0026gt; = 3\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:lossless_compressor \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:max_quant_intervals \u0026lt;uint32\u0026gt; = 65536\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:pred_threshold \u0026lt;float\u0026gt; = 0.99\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:prediction_mode \u0026lt;int32\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:protect_value_range \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:psnr_err_bound \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound \u0026lt;double\u0026gt; = 0.001\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:quantization_intervals \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:rel_err_bound \u0026lt;double\u0026gt; = 0.0001\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sample_distance \u0026lt;int32\u0026gt; = 100\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:segment_size \u0026lt;int32\u0026gt; = 36\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step \u0026lt;int32\u0026gt; = 5\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sol_id \u0026lt;int32\u0026gt; = 101\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sz_mode \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:user_params \u0026lt;void*\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:abs \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:compressor \u0026lt;char*\u0026gt; = \"sz\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:reset_mode \u0026lt;bool\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:compressor \u0026lt;char*\u0026gt; = \"pressio\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:nthreads \u0026lt;uint32\u0026gt; = 4\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:shape \u0026lt;data\u0026gt; = data{ type=double dims={3, } has_data=[2, 2, 1, ]}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:has_header \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:prec \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:background \u0026lt;char*\u0026gt; = \"binning\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:centers \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:nthreads \u0026lt;uint32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:roi \u0026lt;char*\u0026gt; = \"fpzip\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:roi_size \u0026lt;data\u0026gt; = data{ type=double dims={3, } has_data=[8, 8, 0, ]}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:compressor \u0026lt;char*\u0026gt; = \"roibin\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:reset_mode \u0026lt;bool\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eprocessing 0 256\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eglobal_cr=51.805\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ewallclock_ms=2811\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecompress_ms=1098\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecompress_bandwidth_GBps=1.08781\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ewallclock_bandwidth_GBps=0.424909\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn this output, the lines beginning with \u003ccode\u003e/pressio\u003c/code\u003e are the represent the configuration used for the experiment.\nAll of the configurations we used can be found in the \u003ccode\u003e/app/share\u003c/code\u003e directory.\nMore details on the meanings of these options by calling \u003ccode\u003epressio -a help \u0026lt;compressor_id\u0026gt;\u003c/code\u003e where the compressor id is one of \u003ccode\u003ebinning\u003c/code\u003e, \u003ccode\u003eroi\u003c/code\u003e, \u003ccode\u003eopt\u003c/code\u003e, \u003ccode\u003efpzip\u003c/code\u003e, \u003ccode\u003esz\u003c/code\u003e, \u003ccode\u003esz3\u003c/code\u003e, \u003ccode\u003ezfp\u003c/code\u003e, \u003ccode\u003emgard\u003c/code\u003e, \u003ccode\u003eblosc\u003c/code\u003e, etc...\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003e-o\u003c/code\u003e flag provided in some of our run codes outputs the decompressed dataset.\nThere is also a \u003ccode\u003e-d\u003c/code\u003e and \u003ccode\u003e-D\u003c/code\u003e which together output fine grained metrics on individual events.\u003c/p\u003e\n\u003cp\u003ethe lines \u003ccode\u003eprocessing \u0026lt;start\u0026gt; \u0026lt;end\u0026gt;\u003c/code\u003e show the progress of each stage of the compression.\nFor example \u003ccode\u003eprocessing 0 256\u003c/code\u003e means that the first 256 events are being processed.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eglobal_cr\u003c/code\u003e is the compression ratio across all events.\n\u003ccode\u003ewallclock_ms\u003c/code\u003e is the wall clock time including IO from the CXI file.  In the real system, there would not be the IO from the CXI files.\n\u003ccode\u003ecompress_ms\u003c/code\u003e is the compression clock time.\n\u003ccode\u003ecompress_bandwidth_GBps\u003c/code\u003e is the compression bandwidth in GB/s.\n\u003ccode\u003ewallclock_bandwidth_GBps\u003c/code\u003e is the wallclock bandwidth in GB/s\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eResults for Figures\u003c/h2\u003e\u003ca id=\"user-content-results-for-figures\" class=\"anchor\" aria-label=\"Permalink: Results for Figures\" href=\"#results-for-figures\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe script \u003ccode\u003erun_all.sh\u003c/code\u003e contains configurations for all runs for all results in the paper.  Each specific configuration corresponds to a configuration file in the \u003ccode\u003eshare\u003c/code\u003e directory.  We would comment and uncomment specific sections to run various sub experiments. All results output metrics files (not the decompressed data) are also included from all past runs.\u003c/p\u003e\n\u003cp\u003eThe results for table 2 are in from the lines in the sectoin labeled \"full_table2\".\nThe results for table 3 come from the section labeled \"full scale\" with cxi_file set to the appropriate dataset.\nThe results for table 4 come from the section labeled \"tune\"\nThe results for table 5 come from the section labeled \"scalability\"\nThe results for table 6 come from the section labeled \"overview\"\u003c/p\u003e\n\u003cp\u003eMany of the visualizations come from the section labeled \"full scale\"\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1648861627.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "JuliaParallel/github-actions-buildcache",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack buildcache for MPI.jl CI\u003c/h1\u003e\u003ca id=\"user-content-spack-buildcache-for-mpijl-ci\" class=\"anchor\" aria-label=\"Permalink: Spack buildcache for MPI.jl CI\" href=\"#spack-buildcache-for-mpijl-ci\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository provides a \u003ca href=\"https://spack.readthedocs.io/en/latest/binary_caches.html#oci-docker-v2-registries-as-build-cache\" rel=\"nofollow\"\u003eSpack OCI buildcache\u003c/a\u003e to be used in CI of \u003ca href=\"https://github.com/JuliaParallel/MPI.jl\"\u003e\u003ccode\u003eMPI.jl\u003c/code\u003e\u003c/a\u003e and other JuliaParallel projects.\nThis is based on \u003ca href=\"https://github.com/spack/github-actions-buildcache\"\u003espack/github-actions-buildcache\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYou can see the \u003ca href=\"https://github.com/JuliaParallel/github-actions-buildcache/pkgs/container/github-actions-buildcache\"\u003elist of packages\u003c/a\u003e produced by this buildcache.\u003c/p\u003e\n\u003cp\u003eIf you want to have more packages in this buildcache, add them to the \u003ca href=\"./spack.yaml\"\u003e\u003ccode\u003espack.yaml\u003c/code\u003e\u003c/a\u003e file.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 15,
    "topics": [],
    "updated_at": 1698970197.0
  },
  {
    "data_format": 2,
    "description": "Spack config for CCI DCS (AiMOS) system",
    "filenames": [
      "rhel8NvhpcWdmapp/spack.yaml",
      "spack.yaml"
    ],
    "full_name": "SCOREC/dcs-spack-config",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003edcs-spack-config\u003c/h1\u003e\u003ca id=\"user-content-dcs-spack-config\" class=\"anchor\" aria-label=\"Permalink: dcs-spack-config\" href=\"#dcs-spack-config\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCCI DCS (AiMOS) spack configuration and scripts for building the XGC depdencies\nwith the IBM XL compilers and Spectrum-MPI.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003econtents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: contents\" href=\"#contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ecompilers.yaml - compiler list\u003c/p\u003e\n\u003cp\u003econfig.yaml - global config\u003c/p\u003e\n\u003cp\u003einstall.sh - package installation commands\u003c/p\u003e\n\u003cp\u003emodules.yaml - hierarchical layout for lua modules\u003c/p\u003e\n\u003cp\u003epackages.yaml - system installed packages\u003c/p\u003e\n\u003cp\u003eREADME.md - this file\u003c/p\u003e\n\u003cp\u003esetupSpack.sh - env needed for executing spack commands\u003c/p\u003e\n\u003cp\u003espack.yaml - list of packages to install\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003esetup\u003c/h2\u003e\u003ca id=\"user-content-setup\" class=\"anchor\" aria-label=\"Permalink: setup\" href=\"#setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@github.com:spack/spack.git spack\ncd !$\ngit checkout v0.13.3\n# add the simmetrix-simmodsuite package from the develop branch\ngit cherry-pick 5ddf5e2\n# create the environment\nspack env create v0133\nspack env activate v0133\n# copy the yaml files into the v0133\ncp /path/to/the/dir/with/the/yaml/files/* var/spack/environments/v0133/.\n# copy the compiler yaml file into the spack etc dir\ncp /path/to/the/dir/with/the/yaml/files/compilers.yaml etc/spack/.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003einstall cmake\u003c/h2\u003e\u003ca id=\"user-content-install-cmake\" class=\"anchor\" aria-label=\"Permalink: install cmake\" href=\"#install-cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe bootstrap step of the cmake install fails with the XL compilers.  I\ninstalled it manually outside of the environment with spack and gcc4.8.5\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install cmake%gcc@4.8.5_rhel7\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen added the path to \u003ccode\u003epackages.yaml\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eresuming work in an environment\u003c/h2\u003e\u003ca id=\"user-content-resuming-work-in-an-environment\" class=\"anchor\" aria-label=\"Permalink: resuming work in an environment\" href=\"#resuming-work-in-an-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003esource /gpfs/u/software/dcs-spack-src/dcs-spack-config/setupSpack.sh\nspack env activate v0133\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1633029356.0
  },
  {
    "data_format": 2,
    "description": "simple margo-projected keyval service",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-sdskv",
    "latest_release": "v0.1.14",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSDSKV (SDS Key/Val)\u003c/h1\u003e\u003ca id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" aria-label=\"Permalink: SDSKV (SDS Key/Val)\" href=\"#sdskv-sds-keyval\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSDSKV can easily be installed using Spack:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install sdskeyval\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis will install SDSKV (and any required dependencies).\nAvailable backends will be \u003cem\u003eMap\u003c/em\u003e (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass \u003ccode\u003e+bdb\u003c/code\u003e and \u003ccode\u003e+leveldb\u003c/code\u003e respectively. For example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install sdskeyval+bdb+leveldb\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eNote that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eArchitecture\u003c/h2\u003e\u003ca id=\"user-content-architecture\" class=\"anchor\" aria-label=\"Permalink: Architecture\" href=\"#architecture\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eList most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its \u003cem\u003eaddress\u003c/em\u003e and \u003cem\u003emultiplex id\u003c/em\u003e, manages one or more\ndatabases, referenced externally by their database id.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStarting a daemon\u003c/h2\u003e\u003ca id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-label=\"Permalink: Starting a daemon\" href=\"#starting-a-daemon\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esdskv-server-daemon [OPTIONS] \u0026lt;listen_addr\u0026gt; \u0026lt;db name 1\u0026gt;[:map|:bwt|:bdb|:ldb] \u0026lt;db name 2\u0026gt;[:map|:bwt|:bdb|:ldb] ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esdskv-server-daemon tcp://localhost:1234 foo:bdb bar\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003elisten_addr is the address at which to listen; database names should be provided in the form\n\u003cem\u003ename:type\u003c/em\u003e where \u003cem\u003etype\u003c/em\u003e is \u003cem\u003emap\u003c/em\u003e (std::map), \u003cem\u003ebwt\u003c/em\u003e (BwTree), \u003cem\u003ebdb\u003c/em\u003e (Berkeley DB), or \u003cem\u003eldb\u003c/em\u003e (LevelDB).\u003c/p\u003e\n\u003cp\u003eFor database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).\u003c/p\u003e\n\u003cp\u003eThe following additional options are accepted:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-f\u003c/code\u003e provides the name of the file in which to write the address of the daemon.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m\u003c/code\u003e provides the mode (providers or databases).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eClient API\u003c/h2\u003e\u003ca id=\"user-content-client-api\" class=\"anchor\" aria-label=\"Permalink: Client API\" href=\"#client-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe client API is available in \u003cem\u003esdskv-client.h\u003c/em\u003e.\nThe codes in the \u003cem\u003etest\u003c/em\u003e folder illustrate how to use it.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProvider API\u003c/h2\u003e\u003ca id=\"user-content-provider-api\" class=\"anchor\" aria-label=\"Permalink: Provider API\" href=\"#provider-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe server-side API is available in \u003cem\u003esdskv-server.h\u003c/em\u003e.\nThe code of the daemon (\u003cem\u003esrc/sdskv-server-daemon.c\u003c/em\u003e) can be used as an example.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCustom key comparison function\u003c/h3\u003e\u003ca id=\"user-content-custom-key-comparison-function\" class=\"anchor\" aria-label=\"Permalink: Custom key comparison function\" href=\"#custom-key-comparison-function\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIt is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eint (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eIts return value must be \u0026lt; 0 if key1 \u0026lt; key2, 0 if key1 = key2, \u0026gt; 0 if key1 \u0026gt; key2.\nIt must define a total order of the key space.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eC++ API\u003c/h2\u003e\u003ca id=\"user-content-c-api\" class=\"anchor\" aria-label=\"Permalink: C++ API\" href=\"#c-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAn object-oriented C++ API is available in \u003ccode\u003esdskv-client.hpp\u003c/code\u003e and \u003ccode\u003esdskv-server.hpp\u003c/code\u003e.\nOn the client side this API provides the \u003ccode\u003eclient\u003c/code\u003e, \u003ccode\u003eprovider_handle\u003c/code\u003e, and \u003ccode\u003edatabase\u003c/code\u003e objects.\nExamples of usage of these objects can be found in the \u003ccode\u003etest/sdskv-cxx-test.cc\u003c/code\u003e.\nOn the server side, this API provides a \u003ccode\u003eprovider\u003c/code\u003e object.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBenchmark\u003c/h2\u003e\u003ca id=\"user-content-benchmark\" class=\"anchor\" aria-label=\"Permalink: Benchmark\" href=\"#benchmark\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSDSKV can be compiled with \u003ccode\u003e--enable-benchmark\u003c/code\u003e (or \u003ccode\u003e+benchmark\u003c/code\u003e in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use \u003ccode\u003eCXX=mpicxx\u003c/code\u003e in\nyour configure step, for example), and it will build and install the \u003ccode\u003esdskv-benchmark\u003c/code\u003e program.\u003c/p\u003e\n\u003cp\u003eThis program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.\u003c/p\u003e\n\u003cp\u003eThe following is an example of a JSON file.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-json\"\u003e\u003cpre\u003e{\n\t\u003cspan class=\"pl-ent\"\u003e\"protocol\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etcp\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\u003cspan class=\"pl-ent\"\u003e\"seed\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e,\n\t\u003cspan class=\"pl-ent\"\u003e\"server\"\u003c/span\u003e : {\n\t\t\u003cspan class=\"pl-ent\"\u003e\"use-progress-thread\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"rpc-thread-count\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"database\"\u003c/span\u003e : {\n\t\t\t\u003cspan class=\"pl-ent\"\u003e\"type\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emap\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\t\u003cspan class=\"pl-ent\"\u003e\"name\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ebenchmark-db\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\t\u003cspan class=\"pl-ent\"\u003e\"path\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/dev/shm\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\t\t}\n\t},\n\t\u003cspan class=\"pl-ent\"\u003e\"benchmarks\"\u003c/span\u003e : [\n\t{\n\t\t\u003cspan class=\"pl-ent\"\u003e\"type\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eput\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"repetitions\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e10\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"num-entries\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e30\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"key-sizes\"\u003c/span\u003e : [ \u003cspan class=\"pl-c1\"\u003e8\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e32\u003c/span\u003e ],\n\t\t\u003cspan class=\"pl-ent\"\u003e\"val-sizes\"\u003c/span\u003e : [ \u003cspan class=\"pl-c1\"\u003e24\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e48\u003c/span\u003e ],\n\t\t\u003cspan class=\"pl-ent\"\u003e\"erase-on-teardown\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n\t},\n\t{\n\t\t\u003cspan class=\"pl-ent\"\u003e\"type\"\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eget\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"repetitions\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e10\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"num-entries\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e30\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"key-sizes\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e64\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"val-sizes\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e128\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-ent\"\u003e\"erase-on-teardown\"\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n\t}\n\t]\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003eserver\u003c/code\u003e field sets up the provider and the database. Database types can be \u003ccode\u003emap\u003c/code\u003e, \u003ccode\u003eldb\u003c/code\u003e, or \u003ccode\u003ebdb\u003c/code\u003e.\nThen follows the \u003ccode\u003ebenchmarks\u003c/code\u003e entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A \u003cem\u003esetup\u003c/em\u003e phase, an \u003cem\u003eexecution\u003c/em\u003e phase, and a \u003cem\u003eteardown\u003c/em\u003e phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n\u003cem\u003eget\u003c/em\u003e benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to \u003ccode\u003etrue\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eEach benchmark entry has a \u003ccode\u003etype\u003c/code\u003e (which may be \u003ccode\u003eput\u003c/code\u003e, \u003ccode\u003eput-multi\u003c/code\u003e, \u003ccode\u003eget\u003c/code\u003e, \u003ccode\u003eget-multi\u003c/code\u003e, \u003ccode\u003elength\u003c/code\u003e,\n\u003ccode\u003elength-multi\u003c/code\u003e, \u003ccode\u003eerase\u003c/code\u003e, and \u003ccode\u003eerase-multi\u003c/code\u003e), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the \u003ccode\u003eput\u003c/code\u003e benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval \u003ccode\u003e[8, 32 [\u003c/code\u003e (32 excluded).\nThe value size will be chosen randomly in a uniform manner in \u003ccode\u003e[24, 48 [\u003c/code\u003e (48 excluded). Note that\nyou may also set a specific size instead of a range.\u003c/p\u003e\n\u003cp\u003eAn MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1635867720.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack-envs/rocm/spack.yaml"
    ],
    "full_name": "simonpintarelli/acclapack-tests",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1667393188.0
  },
  {
    "data_format": 2,
    "description": "Python library using Mochi to broadcast data",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-s4m",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eMochi S4M (Share for Me)\u003c/h1\u003e\u003ca id=\"user-content-mochi-s4m-share-for-me\" class=\"anchor\" aria-label=\"Permalink: Mochi S4M (Share for Me)\" href=\"#mochi-s4m-share-for-me\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis service provides a simple non-blocking broadcast/receive\nmechanism based on Mochi.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling\u003c/h2\u003e\u003ca id=\"user-content-installing\" class=\"anchor\" aria-label=\"Permalink: Installing\" href=\"#installing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMake sure you have \u003ca href=\"https://spack.io/\" rel=\"nofollow\"\u003espack\u003c/a\u003e installed and setup.\nIf needed, install it and set it up as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/spack/spack.git\n$ . spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou then need to clone the \u003ccode\u003emochi-spack-packages\u003c/code\u003e repository\nand make it available to spack:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n$ spack repo add mochi-spack-packages\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFinally, you can install S4M as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack install py-mochi-s4m\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsing\u003c/h2\u003e\u003ca id=\"user-content-using\" class=\"anchor\" aria-label=\"Permalink: Using\" href=\"#using\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eS4M has a very simple API consisting of an \u003ccode\u003eS4MService\u003c/code\u003e class with\ntwo functions: \u003ccode\u003ebroadcast\u003c/code\u003e, and \u003ccode\u003ereceive\u003c/code\u003e. It requires mpi4py to\nbootstrap the set of processes. The \u003ca href=\"test/test.py\"\u003etest.py\u003c/a\u003e file\nprovides a comprehensive use case.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1663070268.0
  },
  {
    "data_format": 2,
    "description": "Container recipes used by Spack for test purposes",
    "filenames": [
      "clingo/spack.yaml"
    ],
    "full_name": "spack/spack-ci-containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack CI containers\u003c/h1\u003e\u003ca id=\"user-content-spack-ci-containers\" class=\"anchor\" aria-label=\"Permalink: Spack CI containers\" href=\"#spack-ci-containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains recipes for containers that are\nused to test Spack under CI.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0 licenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack-ci-containers/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-ci-containers/blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-ci-containers/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack-ci-containers/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1621989328.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "openpmd/spack.yaml"
    ],
    "full_name": "aparnasasidharan2017/H5Apps",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1705613269.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Tools/machines/lxplus-cern/spack.yaml"
    ],
    "full_name": "Change72/WarpX-2312",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eWarpX\u003c/h1\u003e\u003ca id=\"user-content-warpx\" class=\"anchor\" aria-label=\"Permalink: WarpX\" href=\"#warpx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1\u0026amp;branchName=development\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9322d48a1ef1d4949f877013f47676310b6774d0e750615ed2cecf4ec2d7eca3/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74\" alt=\"Code Status development\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f9d8b15b61c55052071805cafa2f278fb4a2dd4372acb0b7ee63620a65d15e7/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Installation Tests\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly\u0026amp;label=nightly%20packages\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://warpx.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0beb5ef504dfacd71832068b9c4531e7dd837a2f801f3bd55ff8b36d89aa6951/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/warpx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/86f588e641d33c0f54e4fe9494235aea0398003a5d5eac847133d2da8b9fccea/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1d9ef8a9eb8118b83cc146955af7c9fc3721e5d80e4eed459eb558c6f596b73/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/ECP-WarpX/WarpX/discussions\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667\" alt=\"Discussions\" data-canonical-src=\"https://img.shields.io/badge/chat-discussions-turquoise.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://warpx.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/ECP-WarpX/WarpX/compare/development\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a6f861e33c8f14a8e4119adb07d24668e8d2fc773bf9e83829fa62732251df0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667\" alt=\"GitHub commits since last release\" data-canonical-src=\"https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.exascaleproject.org/research/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3d90ef357e4a9590dd0cf06c730de1b41c601ebe7ca2eb10beee42fd406053e0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765\" alt=\"Exascale Computing Project\" data-canonical-src=\"https://img.shields.io/badge/supported%20by-ECP-orange\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\" alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/647bd6e78a284bf08e53bd7038f210400464c5a5ed8beedd3391512ebb2aaefb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\" alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License WarpX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.4571577\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/65fec93ca7f0122e02994a743ea08ff139c085192a9e94ac627b966b8058e3b4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.1109/SC41404.2022.00008\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c5d3f4fb049eab48f59d6f9bb6e34570ad406e2691f5dcda65167dec4ad0d08a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667\" alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWarpX is an advanced \u003cstrong\u003eelectromagnetic \u0026amp; electrostatic Particle-In-Cell\u003c/strong\u003e code.\nIt supports many features including Perfectly-Matched Layers (PML), mesh refinement, and the boosted-frame technique.\u003c/p\u003e\n\u003cp\u003eWarpX is a \u003cem\u003ehighly-parallel and highly-optimized code\u003c/em\u003e, which can run on GPUs and multi-core CPUs, and includes load balancing capabilities.\nWarpX scales to the world\u0027s largest supercomputers and was awarded the \u003ca href=\"https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/\" rel=\"nofollow\"\u003e2022 ACM Gordon Bell Prize\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://picmi-standard.github.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICMI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22PICMI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openPMD.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22openPMD%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://yt-project.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"yt-project\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22yt%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn order to learn how to install and run the code, please see the online documentation:\n\u003ca href=\"https://warpx.readthedocs.io\" rel=\"nofollow\"\u003ehttps://warpx.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTo contact the developers, feel free to open an issue on this repo, or visit our discussions page at \u003ca href=\"https://github.com/ECP-WarpX/WarpX/discussions\"\u003ehttps://github.com/ECP-WarpX/WarpX/discussions\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22AMReX%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://picsar.net\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICSAR\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22PICSAR%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD-api\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22openPMD-api%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"ADIOS\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22ADIOS%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.hdfgroup.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"HDF5\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22HDF5%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"http://www.ascent-dav.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"Ascent\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22Ascent%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://sensei-insitu.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"SENSEI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22SENSEI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur workflow is described in \u003ca href=\"CONTRIBUTING.rst\"\u003eCONTRIBUTING.rst\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright Notice\u003c/h2\u003e\u003ca id=\"user-content-copyright-notice\" class=\"anchor\" aria-label=\"Permalink: Copyright Notice\" href=\"#copyright-notice\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWarpX Copyright (c) 2018, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Innovation \u0026amp; Partnerships Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.\u003c/p\u003e\n\u003cp\u003ePlease see the full license agreement in \u003ca href=\"LICENSE.txt\"\u003eLICENSE.txt\u003c/a\u003e.\nThe SPDX license identifier is \u003ccode\u003eBSD-3-Clause-LBNL\u003c/code\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1701817698.0
  },
  {
    "data_format": 2,
    "description": "Python utilities to generate HEPnOS configurations",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "hepnos/HEPnOS-Wizard",
    "latest_release": "v0.0.2",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eHEPnOS-Wizard\u003c/h1\u003e\u003ca id=\"user-content-hepnos-wizard\" class=\"anchor\" aria-label=\"Permalink: HEPnOS-Wizard\" href=\"#hepnos-wizard\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis package contains scripts to help setup valid configurations\nfor the HEPnOS storage service.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1641579766.0
  },
  {
    "data_format": 2,
    "description": "\ud83d\udd28 A template for using Enzyme with CMake",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "EnzymeAD/CMake-Template",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCMake-Template\u003c/h1\u003e\u003ca id=\"user-content-cmake-template\" class=\"anchor\" aria-label=\"Permalink: CMake-Template\" href=\"#cmake-template\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstall dependencies\u003c/h3\u003e\u003ca id=\"user-content-install-dependencies\" class=\"anchor\" aria-label=\"Permalink: Install dependencies\" href=\"#install-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ecmake\u003c/li\u003e\n\u003cli\u003emake\u003c/li\u003e\n\u003cli\u003ellvm\u003c/li\u003e\n\u003cli\u003eenzyme\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUsing spack:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env activate .\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsing homebrew:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebrew bundle install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConfigure and build\u003c/h3\u003e\u003ca id=\"user-content-configure-and-build\" class=\"anchor\" aria-label=\"Permalink: Configure and build\" href=\"#configure-and-build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eConfigure the CMake project using the version of Enzyme installed on the system:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build \u0026amp;\u0026amp; cd build\ncmake ..\nmake\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eConfigure the CMake project using a custom Enzyme version:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build \u0026amp;\u0026amp; cd build\ncmake -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [
      "cmake",
      "enzyme-ad",
      "template"
    ],
    "updated_at": 1687815556.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "chipbuster/ljkdfhsgblkdsjhfglksdjfhg",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCMake-Template\u003c/h1\u003e\u003ca id=\"user-content-cmake-template\" class=\"anchor\" aria-label=\"Permalink: CMake-Template\" href=\"#cmake-template\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstall dependencies\u003c/h3\u003e\u003ca id=\"user-content-install-dependencies\" class=\"anchor\" aria-label=\"Permalink: Install dependencies\" href=\"#install-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ecmake\u003c/li\u003e\n\u003cli\u003emake\u003c/li\u003e\n\u003cli\u003ellvm\u003c/li\u003e\n\u003cli\u003eenzyme\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUsing spack:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env activate .\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsing homebrew:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebrew bundle install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConfigure and build\u003c/h3\u003e\u003ca id=\"user-content-configure-and-build\" class=\"anchor\" aria-label=\"Permalink: Configure and build\" href=\"#configure-and-build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eConfigure the CMake project using the version of Enzyme installed on the system:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build \u0026amp;\u0026amp; cd build\ncmake ..\nmake\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eConfigure the CMake project using a custom Enzyme version:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build \u0026amp;\u0026amp; cd build\ncmake -DEnzyme_DIR=/path/to/Enzyme/enzyme/build \nmake\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1698092884.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "packages/spack.yaml"
    ],
    "full_name": "aminaramoon/config",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1673135222.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "nantes-m2-rps-exp/qqbar2mumu-2022",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eProjet exp\u00e9rimental - Production de quarkonia\u003c/h1\u003e\u003ca id=\"user-content-projet-exp\u00e9rimental---production-de-quarkonia\" class=\"anchor\" aria-label=\"Permalink: Projet exp\u00e9rimental - Production de quarkonia\" href=\"#projet-exp\u00e9rimental---production-de-quarkonia\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCe d\u00e9pot git h\u00e9berge les fichiers n\u00e9cessaires pour d\u00e9marrer le projet \"Production de quarkonia\" du Master 2 RPS de l\u0027Universit\u00e9 de Nantes. Il est principalement \u00e0 destination des \u00e9tudiants qui r\u00e9alisent ce projet. Le \"vous\" ci-dessous s\u0027adresse donc \u00e0 ces \u00e9tudiants.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003ePour ce projet le language de programmation choisi est Python. Nous recommandons de l\u0027utiliser par le biais de \u003ca href=\"https://jupyter.org\" rel=\"nofollow\"\u003e\"Notebooks Jupyter\"\u003c/a\u003e qui permettent de m\u00e9langer le code, la documentation et les r\u00e9sultats de l\u0027ex\u00e9cution du code.\u003c/p\u003e\n\u003cp\u003eJupyter est un outil commun dans le domaine de la science des donn\u00e9es. Il y a bien des fa\u00e7ons d\u0027utiliser Jupyter et de nombreux tutoriels sont disponibles en ligne pour aller plus loin, mais vous trouverez ci-dessous trois m\u00e9thodes pour d\u00e9marrer :\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eune \u003ca href=\"conda/README.md\"\u003em\u00e9thode locale bas\u00e9e sur conda\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eune \u003ca href=\"cloud/README.md\"\u003em\u00e9thode cloud\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eune \u003ca href=\"multipass/README.md\"\u003em\u00e9thode locale bas\u00e9e sur multipass\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eA noter que seule la troisi\u00e8me m\u00e9thode permet, a priori, de r\u00e9aliser toutes les t\u00e2ches n\u00e9cessaires \u00e0 ce projet, car elle offre des interfaces Python de paquets C++ d\u00e9velopp\u00e9s sp\u00e9cifiquement pour ce projet, alors que les deux premi\u00e8res ne permettent d\u0027acc\u00e9der qu\u0027\u00e0 des paquets Python \"g\u00e9n\u00e9riques\". Les deux premi\u00e8res m\u00e9thodes permettent n\u00e9anmoins de d\u00e9marrer assez rapidement.\u003c/p\u003e\n\u003cp\u003ePour ce projet, vous utiliserez \u00e9galement \u003ca href=\"https://git.com\" rel=\"nofollow\"\u003eGit\u003c/a\u003e et \u003ca href=\"https://github.com\"\u003eGitHub\u003c/a\u003e. Si ce n\u0027est pas d\u00e9j\u00e0 le cas, il vous faudra \u003ca href=\"https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\" rel=\"nofollow\"\u003einstaller git sur votre machine\u003c/a\u003e et vous \u003ca href=\"https://fr.wikihow.com/cr%C3%A9er-un-compte-sur-GitHub\" rel=\"nofollow\"\u003ecr\u00e9\u00e9r un compte GitHub\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eComme pour Jupyter, un nombre important de ressources documentaires et tutoriels sont disponibles sur le net pour commencer avec git si c\u0027est votre premi\u00e8re approche ou encore pour approfondir votre ma\u00eetrise de cet outil si vous le connaissez d\u00e9j\u00e0 un peu.\u003c/p\u003e\n\u003cp\u003eVous trouverez dans le \u003ca href=\"git/README.md\"\u003edocument \u003ccode\u003egit/README.md\u003c/code\u003e\u003c/a\u003e les commandes de base pour d\u00e9marrer avec ce d\u00e9p\u00f4t git en particulier.\u003c/p\u003e\n\u003cp\u003eUne fois la premi\u00e8re installation r\u00e9alis\u00e9e, commencez par vous familiariser avec Jupyter en utilisant le \u003ca href=\"notebooks/muon-eta-distribution.ipynb\"\u003enotebook d\u0027exemple\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1667463557.0
  },
  {
    "data_format": 2,
    "description": "my spack environments for software builds",
    "filenames": [
      "esmfbld/spack.yaml",
      "esmfserialbld/spack.yaml"
    ],
    "full_name": "jedwards4b/spackenvironments",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1664981968.0
  },
  {
    "data_format": 2,
    "description": "Spack configuration installed at /g/data/ik11/spack/ to provide ACCESS-OM3 dependencies",
    "filenames": [
      "environments/cesm-0_x_0/spack.yaml",
      "environments/common_tools_and_libraries/spack.yaml"
    ],
    "full_name": "COSIMA/spack-config",
    "latest_release": "access-om3-v0.2.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCOSIMA Spack Configuration\u003c/h1\u003e\u003ca id=\"user-content-cosima-spack-configuration\" class=\"anchor\" aria-label=\"Permalink: COSIMA Spack Configuration\" href=\"#cosima-spack-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains the spack configuration and the spack environments used\nby COSIMA to deploy software on gadi.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation instructions\u003c/h2\u003e\u003ca id=\"user-content-installation-instructions\" class=\"anchor\" aria-label=\"Permalink: Installation instructions\" href=\"#installation-instructions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eClone this repository and its submodules to some appropriate location (e.g.,\n\u003ccode\u003e/g/data/ik11/spack/0.20.1\u003c/code\u003e):\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ git clone --recursive https://github.com/COSIMA/spack-config.git /g/data/ik11/spack/0.20.1\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNext, create the python virtual environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e /g/data/ik11/spack/0.20.1\n$ ./bootstrap_venv.sh\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFinally, to use this spack installation one just needs to activate the python\nenvironment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$  \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e /g/data/ik11/spack/0.20.1/venv/bin/activate\n$ which spack\n\u003cspan class=\"pl-en\"\u003espack\u003c/span\u003e ()\n{ \n    \u003cspan class=\"pl-c1\"\u003e:\u003c/span\u003e this is a shell \u003cspan class=\"pl-k\"\u003efunction\u003c/span\u003e \u003cspan class=\"pl-en\"\u003efrom:\u003c/span\u003e /g/data/ik11/spack/0.20.1/spack/share/spack/setup-env.sh;\n    \u003cspan class=\"pl-c1\"\u003e:\u003c/span\u003e the real spack script is here: /g/data/ik11/spack/0.20.1/spack/bin/spack\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e\n    _spack_shell_wrapper \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e$@\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$?\u003c/span\u003e\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling software\u003c/h2\u003e\u003ca id=\"user-content-installing-software\" class=\"anchor\" aria-label=\"Permalink: Installing software\" href=\"#installing-software\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIt is recommended that all software be installed using spack\nenvironments. Currently the following environments are provided (the names\nshould be self-explanatory):\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eaccess-om3-0_1_0\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eaccess-om3-devel\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecesm-0_1_0\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecommon_tools_and_libraries\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eInstallation of a spack environment is usually quite straightforward, but\nbecause this can be a CPU intensive operation and take quite some time, it is\nbest to do this in parallel and to use an interactive job.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep-by-step instructions:\u003c/h3\u003e\u003ca id=\"user-content-step-by-step-instructions\" class=\"anchor\" aria-label=\"Permalink: Step-by-step instructions:\" href=\"#step-by-step-instructions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eActivate spack environment\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFirst activate the spack environment\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack env activate \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eenv\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ewhere \u003ccode\u003e\u0026lt;env\u0026gt;\u003c/code\u003e by the actual name of the environment.\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eDownload the sources\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAs the compute nodes do not have internet access, one needs to download all the\nnecessary sources from the login node. This is done using a spack mirror.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack mirror create -d sources -a\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eHere \u003ccode\u003esources\u003c/code\u003e is the name of a mirror that has already been configured.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eSubmit interactive job\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis should not use more than a single node. Also, make sure to add \u003ccode\u003egdata/ik11\u003c/code\u003e\nand \u003ccode\u003escratch/ik11\u003c/code\u003e to the storage options.\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eInstall software\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOnce the job has started, because it starts a completely new shell session, one\nneeds to activate again both the python and the spack environments:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$  \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e /g/data/ik11/spack/0.20.1/venv/bin/activate\n$ spack env activate \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eenv\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen one can simply do\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack install \u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn this case, although each individual build will use some level of parallelism,\nspack will proceed through the installation of the packages sequentially. To\nfully use parallelism one needs to tell spack to create a Makefile and use this\nto install the software:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack env depfile -o Makefile\n$ make -j\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn the end, all the packages should be available in some subdirectory of\n\u003ccode\u003e/g/data/ik11/spack/0.20.1/opt/\u003c/code\u003e and the corresponding environment modules are\ninstalled under a subdirectory of \u003ccode\u003e/g/data/ik11/spack/0.20.1/modules\u003c/code\u003e. The\nactual subdirectories depend on the selected environement.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1692145219.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "docker/hepnos/spack.yaml"
    ],
    "full_name": "HEPonHPC/hepnos_eventselection",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1658856345.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Casper system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-casper",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eNCAR Spack Deployment\u003c/h1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-label=\"Permalink: NCAR Spack Deployment\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ecasper\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eSun Oct 29 16:46:01 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003ef18d293b1ca60227bc1b9147ac97b664d212f7ef\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.10\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/casper/23.10\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/work/csgteam/spack-deployments/casper/23.10/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1693796472.0
  },
  {
    "data_format": 2,
    "description": "spack envs",
    "filenames": [
      "_experimental/envs/alpinedav/ubuntu_18_devel/spack.yaml"
    ],
    "full_name": "Alpine-DAV/spack_configs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003espack_configs\u003c/h1\u003e\u003ca id=\"user-content-spack_configs\" class=\"anchor\" aria-label=\"Permalink: spack_configs\" href=\"#spack_configs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eshared spack configs repo\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1639176281.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "classes/04_2/spack_containers/spack.yaml"
    ],
    "full_name": "okanteh24/msds_hpc",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDS 7347 High-Performance Computing (HPC) and Data Science\u003c/h1\u003e\u003ca id=\"user-content-ds-7347-high-performance-computing-hpc-and-data-science\" class=\"anchor\" aria-label=\"Permalink: DS 7347 High-Performance Computing (HPC) and Data Science\" href=\"#ds-7347-high-performance-computing-hpc-and-data-science\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAssignments\u003c/h2\u003e\u003ca id=\"user-content-assignments\" class=\"anchor\" aria-label=\"Permalink: Assignments\" href=\"#assignments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003eKey\u003c/th\u003e\n\u003cth align=\"left\"\u003eValue\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA\u003c/td\u003e\n\u003ctd align=\"left\"\u003eAssignment\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eL\u003c/td\u003e\n\u003ctd align=\"left\"\u003eLab\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP\u003c/td\u003e\n\u003ctd align=\"left\"\u003eProject\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003eAssignment\u003c/th\u003e\n\u003cth align=\"left\"\u003eIssued\u003c/th\u003e\n\u003cth align=\"left\"\u003eDue\u003c/th\u003e\n\u003cth align=\"left\"\u003eDeliverable\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA1\u003c/td\u003e\n\u003ctd align=\"left\"\u003e04-26\u003c/td\u003e\n\u003ctd align=\"left\"\u003eNA\u003c/td\u003e\n\u003ctd align=\"left\"\u003eFork class repo.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA2\u003c/td\u003e\n\u003ctd align=\"left\"\u003e04-28\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-03\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/assignment_02.md\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA3\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-05\u003c/td\u003e\n\u003ctd align=\"left\"\u003eNA\u003c/td\u003e\n\u003ctd align=\"left\"\u003eDetail the CPU, GPU, memory, and hard drive for your own computer.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA4.1\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-10\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-17\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/assignment_04.sh\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eL1\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-12\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-19\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/lab_01.{yaml,md}\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA4.2\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-17\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-24\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/assignment_04.dockerfile\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eL2\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-19\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-26\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/lab_02.{dockerfile,png,jpg}\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA5.1\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-24\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-31\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/assignment_05.out\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP1\u003c/td\u003e\n\u003ctd align=\"left\"\u003e05-26\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-02\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eproject/proposal.md\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eL3\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-07\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-21\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/lab_03.{yaml,sh,make or cmake}\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP2\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-09\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-16\u003c/td\u003e\n\u003ctd align=\"left\"\u003eCreate new GitHub repo from project template.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP3\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-16\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-21\u003c/td\u003e\n\u003ctd align=\"left\"\u003ePrototype of multi-job Slurm submit script.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA5.2\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-21\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-23\u003c/td\u003e\n\u003ctd align=\"left\"\u003e\u003ccode\u003eassignments/assignment_05.txt\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP4\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-23\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-28\u003c/td\u003e\n\u003ctd align=\"left\"\u003eImplement one subtask of your workflow using \"easiest\" installation path.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP5\u003c/td\u003e\n\u003ctd align=\"left\"\u003e06-30\u003c/td\u003e\n\u003ctd align=\"left\"\u003eNA\u003c/td\u003e\n\u003ctd align=\"left\"\u003eExplore various file formats for your data and compare performance.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP6\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-05\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-12\u003c/td\u003e\n\u003ctd align=\"left\"\u003eComplete non-optimized and basic workflow, reduce data or analysis complexity if needed.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP7\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-14\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-19\u003c/td\u003e\n\u003ctd align=\"left\"\u003eReport three targets for optimization and baseline performance\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eP8\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-19\u003c/td\u003e\n\u003ctd align=\"left\"\u003e07-28\u003c/td\u003e\n\u003ctd align=\"left\"\u003eImplement initial improvements for your three optimization targets\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1658639789.0
  },
  {
    "data_format": 2,
    "description": "Muon Collider software repository for Spack",
    "filenames": [
      "environments/mucoll-common/spack.yaml",
      "environments/mucoll-release/spack.yaml"
    ],
    "full_name": "MuonColliderSoft/mucoll-spack",
    "latest_release": "v2.8",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package repository for Muon Collider software stack\u003c/h1\u003e\u003ca id=\"user-content-spack-package-repository-for-muon-collider-software-stack\" class=\"anchor\" aria-label=\"Permalink: Spack package repository for Muon Collider software stack\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository holds a set of Spack recipes for Muon Collider software (under namespace \u003ccode\u003emucoll\u003c/code\u003e) based on \u003ca href=\"https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\"\u003eKey4hep\u003c/a\u003e stack. It extends the corresponding \u003ca href=\"https://github.com/key4hep/key4hep-spack\"\u003ekey4hep-stack\u003c/a\u003e repository, which is required for installation, overriding several packages by the ones customised for Muon Collider simulation studies.\u003c/p\u003e\n\u003cp\u003eAfter installing \u003ca href=\"https://github.com/key4hep/spack\"\u003eSpack\u003c/a\u003e and downloading the \u003ca href=\"https://github.com/key4hep/key4hep-spack\"\u003ekey4hep-spack\u003c/a\u003e and \u003ca href=\"https://github.com/MuonColliderSoft/mucoll-spack\"\u003emucoll-spack\u003c/a\u003e repositories, the whole software stack can be installed using the following commands:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Add repositories\u003c/span\u003e\nspack repo add ./key4hep-spack\nspack repo add ./mucoll-spack\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Create a Spack environment\u003c/span\u003e\nspack env create sim\nspack env activate sim\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Copy package configurations\u003c/span\u003e\ncp ./mucoll-spack/environments/mucoll-release/\u003cspan class=\"pl-k\"\u003e*\u003c/span\u003e.yaml \u003cspan class=\"pl-smi\"\u003e$SPACK_ENV\u003c/span\u003e/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install the software stack\u003c/span\u003e\nspack add mucoll-stack\nspack concretize --reuse\nspack install --fail-fast\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Load the Muon Collider environment\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$MUCOLL_STACK\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSetting up the environment\u003c/h2\u003e\u003ca id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-label=\"Permalink: Setting up the environment\" href=\"#setting-up-the-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWhen signing in to a machine with the installed sofware stack (VM or Docker container), it has to be loaded into the environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate sim\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$MUCOLL_STACK\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePackage versioning\u003c/h2\u003e\u003ca id=\"user-content-package-versioning\" class=\"anchor\" aria-label=\"Permalink: Package versioning\" href=\"#package-versioning\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePreferred convention for version names in Spack is numbers separated by dots, without leading zeros, e.g. \u003ccode\u003e1.2.13\u003c/code\u003e.\nConversion to tag names in \u003ccode\u003emucoll\u003c/code\u003e packages is provided by \u003ccode\u003eMCIlcsoftpackage\u003c/code\u003e class defined in \u003ccode\u003epackages/mucoll-stack/mucoll_utils.py\u003c/code\u003e, e.g. for \u003ca href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\u003e\u003ccode\u003elcgeo\u003c/code\u003e\u003c/a\u003e package version \u003ccode\u003e0.17\u003c/code\u003e corresponds to tag name \u003ccode\u003ev00-17-MC\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAdding new versions for individual packages\u003c/h2\u003e\u003ca id=\"user-content-adding-new-versions-for-individual-packages\" class=\"anchor\" aria-label=\"Permalink: Adding new versions for individual packages\" href=\"#adding-new-versions-for-individual-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAfter a new tag for the package is created, e.g. \u003ccode\u003ev00-17-MC\u003c/code\u003e in \u003ccode\u003elcgeo\u003c/code\u003e repository, it can be added to this Spack repository in two steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGet the archive checksum for the new tag\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack checksum lcgeo 0.17\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Validates archive URL and returns the checksum\u003c/span\u003e\n    version(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e0.17\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e, sha256=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eAdd the returned version definition to the corresponding package file: \u003ca href=\"packages/lcgeo/package.py\"\u003e\u003ccode\u003epackages/lcgeo/package.py\u003c/code\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNOTE: This repository only contains packages maintained by the Muon Collider collaboration.\nIf the version of interest is missing from Spack for some other package, the line with a new version definition should be added to the package file in the corresponding repository.\u003cbr\u003e\nTo see locations of other repositories: \u003ccode\u003espack repo list\u003c/code\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCreating a new stack release\u003c/h2\u003e\u003ca id=\"user-content-creating-a-new-stack-release\" class=\"anchor\" aria-label=\"Permalink: Creating a new stack release\" href=\"#creating-a-new-stack-release\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo introduce a new release version for the whole software stack, update the version number in \u003ca href=\"packages/mucoll-stack/package.py\"\u003e\u003ccode\u003epackages/mucoll-stack/package.py\u003c/code\u003e\u003c/a\u003e and then update versions of all the relevant packages in [environments/mucoll-release/packages.yaml].\u003cbr\u003e\nTest this new configuration in a fresh environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Create a development environment\u003c/span\u003e\nspack env create dev\nspack env activate dev\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Copy the package configuration\u003c/span\u003e\ncp ./mucoll-spack/environments/mucoll-release/\u003cspan class=\"pl-k\"\u003e*\u003c/span\u003e.yaml \u003cspan class=\"pl-smi\"\u003e$SPACK_ENV\u003c/span\u003e/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Add stack with updated version to the environment\u003c/span\u003e\nspack add mucoll-stack\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Check which packages would be installed\u003c/span\u003e\nspack spec --reuse -NIt\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ePackages that are already installed in the \u003ccode\u003esim\u003c/code\u003e environment are known to Spack and will be reused, providing a clear indication of which part of the dependency tree will be modified by the new release.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1679435634.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "2lambda123/CHM",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eThe Canadian Hydrological Model\u003c/h1\u003e\u003ca id=\"user-content-the-canadian-hydrological-model\" class=\"anchor\" aria-label=\"Permalink: The Canadian Hydrological Model\" href=\"#the-canadian-hydrological-model\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Canadian Hydrological Model (CHM) is a novel modular unstructured mesh based approach for hydrological modelling. It can move between spatial scale, temporal scale, and spatial extents. It is designed for developing and testing process representations for hydrological models.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#motivation\"\u003eMotivation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#design-goals\"\u003eDesign goals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#publications\"\u003ePublications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#features\"\u003eFeatures\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#spatial-scales\"\u003eSpatial Scales\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#visualization\"\u003eVisualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#netcdf-support\"\u003enetCDF support\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#process-representations\"\u003eProcess representations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#unstructured-mesh\"\u003eUnstructured mesh\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#parallel-computing\"\u003eParallel computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#uncertainty-analysis\"\u003eUncertainty analysis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#demonstration\"\u003eDemonstration\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#snowcast\"\u003eSnowCast\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#large-extent\"\u003eLarge extent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#point-scale\"\u003ePoint scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#blowing-snow\"\u003eBlowing snow\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUsage\u003c/h1\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDetails on how to use CHM, as well as more implimentation details, can be found in the \u003ca href=\"https://chm.readthedocs.io/en/dev/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eMotivation\u003c/h1\u003e\u003ca id=\"user-content-motivation\" class=\"anchor\" aria-label=\"Permalink: Motivation\" href=\"#motivation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eModelling of hydrological processes at any scale is hampered by large uncertainties in parameters and forcing data, incomplete process representations (the scientific conceptualization of a phenomena codified numerically), and arbitrary process representation selections and linkages (collectively \u2018model structure\u2019). There is also consistent difficulty or an inability to easily test and estimate the uncertainty due to variations in model structure, parameter values, number of parameters, forcing data requirements, and spatial discretization requirements (collectively \u2018model complexity\u2019).\u003c/p\u003e\n\u003cp\u003eIn this work, a new distributed model framework is presented that can examine a variety of process representations, process linkages and levels of model complexity. Algorithms can be easily interchanged, removed, and decoupled while preserving the underlying model framework. Thus, uncertainty propagation and subsequent feedbacks within the model structure can be quantified. Unstructured meshes represent the spatial heterogeneity of surface and sub-surface features in a computationally efficient manner and also decreases number of parameters and initial conditions. The parallel architecture allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured meshes, fewer than 5% of the computational elements of high-resolution structured (raster) grids are usually necessary.  This preserves surface and sub-surface heterogeneity but results in fewer parameters and initial conditions.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDesign goals\u003c/h1\u003e\u003ca id=\"user-content-design-goals\" class=\"anchor\" aria-label=\"Permalink: Design goals\" href=\"#design-goals\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eMulti-scale, multi-physics, variable complexity and domain model\u003c/li\u003e\n\u003cli\u003eAssessment of model structural, parameter, and data uncertainty\u003c/li\u003e\n\u003cli\u003eEasily test multiple hypotheses, avoid rigid model structures\u003c/li\u003e\n\u003cli\u003eIncorporate existing code\u003c/li\u003e\n\u003cli\u003eContribute to decision support systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePublications\u003c/h1\u003e\u003ca id=\"user-content-publications\" class=\"anchor\" aria-label=\"Permalink: Publications\" href=\"#publications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe following publications provide an overview of CHM and its capabilities\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eV. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin, N.E. Wayand, J. Shea, K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting modelling of mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model (CHM) v1.0: a multi-scale, multi-extent, variable-complexity hydrological model \u2013 design and overview. Geoscientific Model Development, 13(1):225--247, 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A Finite Volume Blowing Snow Model for Use With Variable Resolution Meshes. Water Resources Research, 56(2), 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B, R. J. Spiteri, J.W. Pomeroy, and H.S. Wheater. Multi-objective unstructured triangular mesh generation for use in hydrological and land surface models. Computers \u0026amp; Geosciences, 119:49--67, 2018.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eFeatures\u003c/h1\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink: Features\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpatial Scales\u003c/h2\u003e\u003ca id=\"user-content-spatial-scales\" class=\"anchor\" aria-label=\"Permalink: Spatial Scales\" href=\"#spatial-scales\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCHM is applicable to multiple scales from the basin scale, to the provincial/state scale and beyond. It may also be applied at a single point-scale.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVisualization\u003c/h2\u003e\u003ca id=\"user-content-visualization\" class=\"anchor\" aria-label=\"Permalink: Visualization\" href=\"#visualization\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOutput is in the vtu file format, allowing for visualization, analysis, and timeseries animation in \u003ca href=\"https://www.paraview.org/\" rel=\"nofollow\"\u003eParaView\u003c/a\u003e. Date-time support has been added to ParaView via an filter \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\u003e\u003cimg src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003enetCDF support\u003c/h2\u003e\u003ca id=\"user-content-netcdf-support\" class=\"anchor\" aria-label=\"Permalink: netCDF support\" href=\"#netcdf-support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInput meterology may be either in a standard ASCII file, or as a netCDF file allowing for ease of use when using climate model outputs.\u003c/p\u003e\n\u003cp\u003eThe below figure shows virtual stations that correspond to the center of the 2.5 km GEM numerical weather prediction output in netCDF format.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProcess representations\u003c/h2\u003e\u003ca id=\"user-content-process-representations\" class=\"anchor\" aria-label=\"Permalink: Process representations\" href=\"#process-representations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eProcess represetenation will be extented to include the entirety of the hydrological cycle. However, current representation includes mostly surface and cold regions processes\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eProcess\u003c/th\u003e\n\u003cth\u003eModule\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCanopy\u003c/td\u003e\n\u003ctd\u003eOpen/forest (exp/log) (Pomeroy et al., 1998; Ellis et al., 2010)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSnowpack\u003c/td\u003e\n\u003ctd\u003e2-layer Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al., 1999); Various albedo e.g., CLASS (Verseghy 1991)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSoil\u003c/td\u003e\n\u003ctd\u003eFrozen soil infiltration (Gray et al., 2001)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMass redistribution\u003c/td\u003e\n\u003ctd\u003ePBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eInput meterology is spatially interpolated and down-scaled from the input station or virtual-station (e.g., from numerical weather prediction) to produce a spatially distributed driving dataset. There are a number of ways to downscale these meterology.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eVariable\u003c/th\u003e\n\u003cth\u003eType\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eAir temperature\u003c/td\u003e\n\u003ctd\u003eLinear lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989, Dodson et al., 1997)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRelative humidity\u003c/td\u003e\n\u003ctd\u003eLinear lapse rates (measured, seasonal, constant) (Kunkel, 1989)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHorizontal wind\u003c/td\u003e\n\u003ctd\u003eTopographic curvature (Liston, et al., 2006); Mason-Sykes (Mason and Sykes, 1979); uniform wind\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePrecipitation\u003c/td\u003e\n\u003ctd\u003eElevation based lapse (Thornton, 1997)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePrecipitation Phase\u003c/td\u003e\n\u003ctd\u003eLinear; Psychometric (Harder and Pomeroy, 2013); Threshold\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSolar radiation\u003c/td\u003e\n\u003ctd\u003eTerrain shadows (Marsh et al., 2011, Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting (Iqbal, 19xx)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLongwave\u003c/td\u003e\n\u003ctd\u003eT, RH based (Sicart et al., 2006); Constant (Marty et al., 2002)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUnstructured mesh\u003c/h2\u003e\u003ca id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-label=\"Permalink: Unstructured mesh\" href=\"#unstructured-mesh\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCHM uses an unstructured triangular mesh to representent the terrain. This mesh is generated by \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"\u003e\u003cimg src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e, a novel multi-objective unstructured mesh generation software that allows mesh generation to be generated from an arbitrary number of hydrologically important features while maintaining a variable spatial resolution. Triangle quality is guaranteed as well as a smooth graduation from small to large triangles. Including these additional features resulted in a better representation of spatial heterogeneity versus classic topography-only mesh generation while significantly reducing the total number of computational elements.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eParallel computing\u003c/h2\u003e\u003ca id=\"user-content-parallel-computing\" class=\"anchor\" aria-label=\"Permalink: Parallel computing\" href=\"#parallel-computing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn CHM, parallelism is currently implemented via the shared memory API OpenMP. As described above, modules may either be point-scale models that are applied to each triangle independently or require knowledge of the surrounding triangles. Mixing these two types of parallelism complicates the implementation of parallel code. To provide as much seamless parallelism as possible to the modules, each module declares the type of algorithm it is: data parallel or domain parallel. Data parallel modules are point-scale models that are applied to every triangle. Domain parallel modules are modules that require knowledge of surrounding mesh points. Thus, after the topological sort is performed to determine module execution order, the modules are scheduled together into groups that share a parallelism type\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUncertainty analysis\u003c/h2\u003e\u003ca id=\"user-content-uncertainty-analysis\" class=\"anchor\" aria-label=\"Permalink: Uncertainty analysis\" href=\"#uncertainty-analysis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA key feature of CHM is the ability to, on the command line, change any value specified by a configuration parameter. CHM provides a seamless mechanism to easily allow modules to obtain parameter data from configuration files.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003esubprocess\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eshutil\u003c/span\u003e\n\n\n\u003cspan class=\"pl-s1\"\u003eprj_path\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"CHM.config\"\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003ecf1\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.VistaView.file:vv_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf2\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.UpperClearing.file:uc_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf3\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.FiserraRidge.file:fr_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf4\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"--add-module Dodson_NSA_ta\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003esubprocess\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003echeck_call\u003c/span\u003e([\u003cspan class=\"pl-s\"\u003e\u0027./CHM %s %s %s %s %s\u0027\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e%\u003c/span\u003e (\u003cspan class=\"pl-s1\"\u003eprj_path\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf1\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf2\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf3\u003c/span\u003e,\u003cspan class=\"pl-s1\"\u003ecf4\u003c/span\u003e)], \u003cspan class=\"pl-s1\"\u003eshell\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003eTrue\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDemonstration\u003c/h1\u003e\u003ca id=\"user-content-demonstration\" class=\"anchor\" aria-label=\"Permalink: Demonstration\" href=\"#demonstration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSnowCast\u003c/h2\u003e\u003ca id=\"user-content-snowcast\" class=\"anchor\" aria-label=\"Permalink: SnowCast\" href=\"#snowcast\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"http://www.snowcast.ca\" rel=\"nofollow\"\u003eSnowCast\u003c/a\u003e is an experimental, daily data product that uses the Global Environmental Multiscale (GEM) model forecasts from Environment and Climate Change Canada (ECCC) to drive the Canadian Hydrological Model (CHM). Estimates of snowpack are provided over the a Bow River Basin, centered over Banff, Canada.\u003c/p\u003e\n\u003cp\u003eSnowCast is developed as part of \u003ca href=\"https://gwf.usask.ca/\" rel=\"nofollow\"\u003eGlobal Water Futures\u003c/a\u003e and the \u003ca href=\"https://www.usask.ca/hydrology/\" rel=\"nofollow\"\u003eCentre for Hydrology\u003c/a\u003e, University of Saskatchewan.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLarge extent\u003c/h2\u003e\u003ca id=\"user-content-large-extent\" class=\"anchor\" aria-label=\"Permalink: Large extent\" href=\"#large-extent\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHourly solar radiation modelling for the territory of Yukon, Canada.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePoint scale\u003c/h2\u003e\u003ca id=\"user-content-point-scale\" class=\"anchor\" aria-label=\"Permalink: Point scale\" href=\"#point-scale\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eComparison of CHM driving Snobal and Snowpack at the Upper Clearing site at Marmot Creek Research Basin in Alberta, Canada\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBlowing snow\u003c/h2\u003e\u003ca id=\"user-content-blowing-snow\" class=\"anchor\" aria-label=\"Permalink: Blowing snow\" href=\"#blowing-snow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBlowing snow for a small sub-basin of Wolf Creek Reserach Basin, located in the Yukon, Canada.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1701550455.0
  },
  {
    "data_format": 2,
    "description": "Exercise caching in the mochi context",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "roblatham00/cashersize",
    "latest_release": null,
    "readme": "\u003cp\u003eYour project \"cachersize\" has been setup!\nEnjoy programming with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1652377734.0
  },
  {
    "data_format": 2,
    "description": "Python binding for Mochi\u0027s Colza microservice",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-colza",
    "latest_release": null,
    "readme": "\u003cp\u003ePy-Colza is a Python interface for the \u003ca href=\"https://github.com/mochi-hpc/mochi-colza\"\u003eColza Mochi microservice\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1633974570.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "FTHPC/Correlation_Compressibility",
    "latest_release": "v0.1",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCompressibility Analysis (Correlation_Compressibility)\u003c/h1\u003e\u003ca id=\"user-content-compressibility-analysis-correlation_compressibility\" class=\"anchor\" aria-label=\"Permalink: Compressibility Analysis (Correlation_Compressibility)\" href=\"#compressibility-analysis-correlation_compressibility\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStatement of Purpose\u003c/h2\u003e\u003ca id=\"user-content-statement-of-purpose\" class=\"anchor\" aria-label=\"Permalink: Statement of Purpose\" href=\"#statement-of-purpose\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo contains scripts to perform compressibility analysis on several leading lossy compressors.\nThe compressibility analysis relies on deriving statistics on scientific data and explore their relationships to their compression ratios from various lossy compressors (based on various compression scheme).\nThe extracted relationships between compression ratios and statistical predictors are modeled via regression models, which provide a statistical framework to predict compression ratios for the different studied lossy compressors.\u003c/p\u003e\n\u003cp\u003eThis repo contains an automatic framework of scripts that perform the compression of scientific datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit Grooming), the derivation of the statistical predictors of compression ratios (SVD, standard deviation, quantized entropy), and scripts to perform the training of the regression models (linear and spline regressions) as well as the validation of the regression predictions.\nA runtime analysis is also performed and associated codes are provided.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMain code structures\u003c/h3\u003e\u003ca id=\"user-content-main-code-structures\" class=\"anchor\" aria-label=\"Permalink: Main code structures\" href=\"#main-code-structures\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCompression metrics, including compression ratios, and derivation of statistical predictors (SVD, standard deviation, quantized entropy) codes are found in \u003ccode\u003ecompress_package\u003c/code\u003e and are run via \u003ccode\u003escripts/run.sh\u003c/code\u003e as described in the section \"How to compute statistical predictors and compression analysis on datasets\".\nLinear and spline regressions training and validation (functions \u003ccode\u003ecr_regression_linreg\u003c/code\u003e and \u003ccode\u003ecr_regression_gam\u003c/code\u003e from the script \u003ccode\u003ereplicate_figures/functions_paper.R\u003c/code\u003e).\nCodes for the different runtime analysis are found in the folder \u003ccode\u003eruntime_analysis\u003c/code\u003e and are automated with the script \u003ccode\u003eruntime.sh\u003c/code\u003e, the study includes compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled) variogram and local (tiled) variogram, and runtime for training and prediction of the regressions.\u003cbr\u003e\nFinally, the script \u003ccode\u003ereplicate_figures/graphs_paper_container.R\u003c/code\u003e replicates and saves all the figures from the paper ad as well as numbers from the tables.\u003c/p\u003e\n\u003cp\u003eFor each dataset in the \u003ccode\u003edataset\u003c/code\u003e folder, slicing is performed for each variable field (e.g. density in Miranda), each slice is stored in a class. The class is updated as compressions with the 8 compressors is performed and updated as the statistical predictors are derived. Results of each class are stored in a .csv file (example of csv files can be found at \u003ccode\u003ereplicate_figures/generated_data/\u003c/code\u003e).\nAll the datasets stored in the \u003ccode\u003edataset\u003c/code\u003e folder can be analyzed with the given set of codes, one needs to source \u003ccode\u003escripts/config.json\u003c/code\u003e with the appropriate dataset name as described in the below section \"How to compute statistical predictors and compression analysis on datasets\".\nThe regression analysis and its prediction is then performed on R dataframes based on the aforementioned .csv files.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSystem Information\u003c/h2\u003e\u003ca id=\"user-content-system-information\" class=\"anchor\" aria-label=\"Permalink: System Information\" href=\"#system-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe hardware and software versions used for the performance evaluations can be found in the table below. These nodes come from Clemson University\u0027s Palmetto Cluster.\u003c/p\u003e\n\u003cp\u003eThese nodes have:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ecomponent\u003c/th\u003e\n\u003cth\u003eversion\u003c/th\u003e\n\u003cth\u003ecomponent\u003c/th\u003e\n\u003cth\u003eversion\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCPU\u003c/td\u003e\n\u003ctd\u003eIntel Xeon 6148G (40 cores)\u003c/td\u003e\n\u003ctd\u003esz2\u003c/td\u003e\n\u003ctd\u003e2.1.12.2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGPU\u003c/td\u003e\n\u003ctd\u003e2 Nvidia v100\u003c/td\u003e\n\u003ctd\u003esz3\u003c/td\u003e\n\u003ctd\u003e3.1.3.1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMemory\u003c/td\u003e\n\u003ctd\u003e372GB\u003c/td\u003e\n\u003ctd\u003ezfp\u003c/td\u003e\n\u003ctd\u003e0.5.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eNetwork\u003c/td\u003e\n\u003ctd\u003e2 Mellanox MT27710 (HDR)\u003c/td\u003e\n\u003ctd\u003emgard\u003c/td\u003e\n\u003ctd\u003e1.0.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFileSystem\u003c/td\u003e\n\u003ctd\u003eBeeGFS 7.2.3 (24 targets)\u003c/td\u003e\n\u003ctd\u003ebit grooming\u003c/td\u003e\n\u003ctd\u003e2.1.9\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCompiler\u003c/td\u003e\n\u003ctd\u003eGCC 8.4.1\u003c/td\u003e\n\u003ctd\u003edigit rounding\u003c/td\u003e\n\u003ctd\u003e2.1.9\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eOS\u003c/td\u003e\n\u003ctd\u003eCentOS 8.2.2004\u003c/td\u003e\n\u003ctd\u003eR\u003c/td\u003e\n\u003ctd\u003e4.1.3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMPI\u003c/td\u003e\n\u003ctd\u003eOpenMPI 4.0.5\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e3.9.12\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLibPressio\u003c/td\u003e\n\u003ctd\u003e0.83.4\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eFirst time setup\u003c/h2\u003e\u003ca id=\"user-content-first-time-setup\" class=\"anchor\" aria-label=\"Permalink: First time setup\" href=\"#first-time-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eContainer Installation (for ease of setup)\u003c/h3\u003e\u003ca id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\" aria-label=\"Permalink: Container Installation (for ease of setup)\" href=\"#container-installation-for-ease-of-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe provide a container for \u003ccode\u003ex86_64\u003c/code\u003e image for ease of installation.\u003c/p\u003e\n\u003cp\u003eThis container differs from our experimental setup slightly. The production build used \u003ccode\u003e-march=native -mtune=native\u003c/code\u003e for architecture optimized builds where as the container does not use these flags to maximize compatibility across \u003ccode\u003ex86_64\u003c/code\u003e hardware.\u003c/p\u003e\n\u003cp\u003eNOTE this file is \u0026gt;= 11 GB , download with caution.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eManual Installation\u003c/h3\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-label=\"Permalink: Manual Installation\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBy default, it is recommended to follow the install locations that are indicated on the top of \u003ccode\u003escripts/run.sh\u003c/code\u003e\nand the top of \u003ccode\u003econfig.json\u003c/code\u003e. These two files provide the configuration options to get the program running.\u003c/p\u003e\n\u003cp\u003eSpack should be installed in the following location: \u003ccode\u003e$HOME/spack/\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis Github repo should be cloned in the following location: \u003ccode\u003e$HOME/Correlation_Compressibility/\u003c/code\u003e\nThis location is also referenced as the \u003ccode\u003eCOMPRESS_HOME\u003c/code\u003e environment variable.\u003c/p\u003e\n\u003cp\u003eA dataset folder called \u0027datasets\u0027 should be in the following location: \u003ccode\u003e$HOME/Correlation_Compressibility/datasets/\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eClone the repo but make sure to install or load \u003ccode\u003egit-lfs\u003c/code\u003e first.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install/module load git-lfs, needed to download example_data for building the container\u003c/span\u003e\nsudo dnf install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eFedora/CentOS Stream 8\u003c/span\u003e\nsudo apt-get install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\nspack install git-lfs\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e spack load git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e using spack\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e clone this repository\u003c/span\u003e\ngit clone https://github.com/FTHPC/Correlation_Compressibility \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you forgot to install \u003ccode\u003egit-lfs\u003c/code\u003e before and have an empty file in the  \u003ccode\u003edatasets\u003c/code\u003e folder, you should install \u003ccode\u003egit-lfs\u003c/code\u003e\nand then run the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit lfs fetch\ngit lfs checkout\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce Spack is installed, there is a \u003ccode\u003espack.yaml\u003c/code\u003e configuration file containing the Spack environment necessary to run the program.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e\ngit clone --depth=1 https://github.com/spack/spack\ngit clone --depth=1 https://github.com/robertu94/spack_packages \n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh \nspack compiler find\nspack external find \nspack repo add --scope=site ./spack_packages \n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility \nspack env activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\nspack install\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e COMPRESS_HOME=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility \u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThese commands will install the environment. The environment only needs to be installed once.\nIf you are using an older \u0026lt; gcc11, then you will need to add the following to the \u003ccode\u003espack.yaml\u003c/code\u003e file:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e^libstdcompat+boost\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eafter \u003ccode\u003e^mgard@robertu94+cuda\u003c/code\u003e but before the \u003ccode\u003e,\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTo run the training and prediction timing analysis demonstration\u003c/h3\u003e\u003ca id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\" class=\"anchor\" aria-label=\"Permalink: To run the training and prediction timing analysis demonstration\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn order to run the timing analysis, a dataset must be specified.\nThere are two datasets setup within this demonstration.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esh runtime_analysis/runtime.sh -d [DATASET]\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e[DATASET] can be either [NYX] or [SCALE]\u003c/p\u003e\n\u003cp\u003eAfter running the above script, an *.RData file(s) will be produced giving the approprirate timing information of\nthe training and prediction for the regression models.\u003c/p\u003e\n\u003cp\u003eNote: A quicker and more efficient quantized entropy method is demonstrated in \u003ccode\u003eqentropy.cc\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eThe following below runs \u003ccode\u003eqentropy.cc\u003c/code\u003e\n\u003c/h4\u003e\u003ca id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\" aria-label=\"Permalink: The following below runs qentropy.cc\" href=\"#the-following-below-runs-qentropycc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eg++ -std=c++2a -O3 qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote: Please run the runtime analysis for both datasets before running the following section.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eReplication of figures: how to run statistical prediction of compression ratios and the prediction validation\u003c/h3\u003e\u003ca id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\" class=\"anchor\" aria-label=\"Permalink: Replication of figures: how to run statistical prediction of compression ratios and the prediction validation\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e  saves the graphs presented in the paper and provides associated validation metrics (correlation and median absolute error percentage).\u003c/p\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e will source the scripts  \u003ccode\u003eload_dataset_paper.R\u003c/code\u003e and \u003ccode\u003efunctions_paper.R\u003c/code\u003e that respectively load the dataset of interest and perform the regression analysis (training and prediction in cross-validation).\nAs a consequence the scripts  \u003ccode\u003eload_dataset_paper.R\u003c/code\u003e and \u003ccode\u003efunctions_paper.R\u003c/code\u003e do not need to be run by the user.\u003c/p\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e  is run via the command:\n\u003ccode\u003ebash sh replicate.sh\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFrom running the script once, it will save all Figures 1, 3, 4 and 5 into .png files from the paper as well as corresponding validation metrics.\nFigure 2 is not saved as it provides a simple vizualization of slices of the datasets.\nSlices of the datasets are generated in the Section \"How to compute statistical predictors and compression metrics\" and can be stored, however we do not save them here to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in the R console.\nAll printed validation metrics are save into a file named \u003ccode\u003efigure_replication.log\u003c/code\u003e.\nFigures and the log-file are saved in the same folder as the one where R script is run and the filename structure is \u003ccode\u003efigY_*.png\u003c/code\u003e with Y is the figure number reference in the paper and \u003ccode\u003e*\u003c/code\u003e provides additional informnation about the data and the compressor.\u003cbr\u003e\nNumbers for Table 4 are saved in the last section in .txt files \u003ccode\u003estatistic_benchmark_runtime_X.txt\u003c/code\u003e with X the studied dataset (NYX or SCALE).\u003c/p\u003e\n\u003cp\u003eIn order to limit the container size to aid reproducibility, we only added a restricted number of scientific datasets in the container and we rely on csv files from our production runs (saved as described above in the Section \"How to compute statistical predictors on datasets\").\nMore datasets are available on \u003ca href=\"https://sdrbench.github.io\" rel=\"nofollow\"\u003eSDRBench\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1675473427.0
  },
  {
    "data_format": 2,
    "description": "CCI DRP Spack configuration",
    "filenames": [
      "openFoam24/spack.yaml"
    ],
    "full_name": "SCOREC/drp-spack-config",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003edrp-spack-config\u003c/h1\u003e\u003ca id=\"user-content-drp-spack-config\" class=\"anchor\" aria-label=\"Permalink: drp-spack-config\" href=\"#drp-spack-config\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCCI DRP Spack configuration\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003econtents\u003c/h1\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: contents\" href=\"#contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eopenFoam24 - spack environment for an OpenFoam Organization 2.4.0 install\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1593654195.0
  },
  {
    "data_format": 2,
    "description": "Software environments",
    "filenames": [
      "catalog-config/libxc-5.2.3/spack.yaml"
    ],
    "full_name": "toxa81/se",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSoftware environments\u003c/h1\u003e\u003ca id=\"user-content-software-environments\" class=\"anchor\" aria-label=\"Permalink: Software environments\" href=\"#software-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDeployment steps\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eclone spack \u003ccode\u003egit clone https://github.com/spack/spack.git\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eenable spack \u003ccode\u003esource enable-spack\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003esrun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16\u003c/li\u003e\n\u003cli\u003einstall gcc-11.3.0 view \u003ccode\u003espack -e  ./env-spec/gcc-11.3.0/ install\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003einstall nvhpc-22.9 \u003ccode\u003esrun -N1 --partition=nvgpu spack -e . install -j64\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003espack compiler find $(spack find --format {prefix.bin} gcc@11)\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1669195550.0
  },
  {
    "data_format": 2,
    "description": "Mirror only. Primary repository is at https://gitlab.com/alecbcs/dotfiles",
    "filenames": [
      "home/.spack/environments/default/spack.yaml"
    ],
    "full_name": "alecbcs/dotfiles",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003edotfiles\u003c/h1\u003e\u003ca id=\"user-content-dotfiles\" class=\"anchor\" aria-label=\"Permalink: dotfiles\" href=\"#dotfiles\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eby Alec Scott and \u003ca href=\"https://github.com/tgamblin/dotfiles\"\u003eTodd Gamblin\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTable of Contents\u003c/h2\u003e\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" aria-label=\"Permalink: Table of Contents\" href=\"#table-of-contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/home/.bashrc\"\u003eBash Config\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"/home/.emacs.d\"\u003eEmacs Config\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/home/.emacs.d/init/init-prog-langs.el\"\u003eProgramming Languages\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.emacs.d/init/init-markdown.el\"\u003eMarkdown\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.emacs.d/init/init-org.el\"\u003eOrg\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.emacs.d/init/init-podman.el\"\u003ePodman\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.emacs.d/init/init-lsp.el\"\u003eLSP\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.gitconfig\"\u003eGit Config\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.zshrc\"\u003eZSH Config\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/home/.zshenv\"\u003eZSH Env\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo get started there are three easy steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFork this repo, then clone your fork to your computer.\u003c/li\u003e\n\u003cli\u003ePut your dotfiles in \u003ccode\u003ehome/\u003c/code\u003e and check them in.\u003c/li\u003e\n\u003cli\u003eRun the \u003ccode\u003elink\u003c/code\u003e script to create symbolic links in your home directory.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eNow your dotfiles are in a git repo and you can clone them anywhere and keep\nthem synchronized.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eLinking in Your Dotfiles on a New Computer\u003c/h4\u003e\u003ca id=\"user-content-linking-in-your-dotfiles-on-a-new-computer\" class=\"anchor\" aria-label=\"Permalink: Linking in Your Dotfiles on a New Computer\" href=\"#linking-in-your-dotfiles-on-a-new-computer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ealec@laptop dotfiles % ./link\nlinking dotfiles\n  from: /Users/alecbcs/src/dotfiles/home\n  into: /Users/alecbcs\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e exclude a file/directory\u003c/span\u003e\nalec@laptop dotfiles % ./link -e .emacs.d\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf something goes wrong, not to worry.  \u003ccode\u003elink\u003c/code\u003e keeps backups in \u003ccode\u003e~/.dotfiles-backup\u003c/code\u003e.  You can run \u003ccode\u003eunlink\u003c/code\u003e to delete all the symbolic links and put your old config files back where they were:\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eUnlinking Your Dotfiles from a Computer\u003c/h4\u003e\u003ca id=\"user-content-unlinking-your-dotfiles-from-a-computer\" class=\"anchor\" aria-label=\"Permalink: Unlinking Your Dotfiles from a Computer\" href=\"#unlinking-your-dotfiles-from-a-computer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ealec@laptop dotfiles % ./unlink\nunlinking dotfiles\n  from: /Users/alecbcs/src/dotfiles/home\n  into: /Users/alecbcs\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1662179736.0
  },
  {
    "data_format": 2,
    "description": "A mirror of Ristra\u0027s internal gitlab repository. ",
    "filenames": [
      ".gitlab-ci/env/dry-run/spack.yaml"
    ],
    "full_name": "laristra/ristra_spackages",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eRistra Spackages\u003c/h1\u003e\u003ca id=\"user-content-ristra-spackages\" class=\"anchor\" aria-label=\"Permalink: Ristra Spackages\" href=\"#ristra-spackages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains the custom spackage files for the repos in laristra family.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBasic Usage\u003c/h2\u003e\u003ca id=\"user-content-basic-usage\" class=\"anchor\" aria-label=\"Permalink: Basic Usage\" href=\"#basic-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe assume the user wish to work in the home directory and already have a spack instance setup.  The minimum required version of spack is 0.15.2.\u003c/p\u003e\n\u003cp\u003eTo get the content of this repo\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone git@gitlab.lanl.gov:laristra/ristra_spackages.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo use the custom spackage files with your spack\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack repo add ristra_spackages/spack-repo\n==\u0026gt; Added repo with namespace \u0027lanl_ristra\u0027.\n\n$ spack repo list\n==\u0026gt; 2 package repositories.\nlanl_ristra        /home/\u0026lt;user\u0026gt;/ristra_spackages/spack-repo\nbuiltin            /home/\u0026lt;user\u0026gt;/spack/var/spack/repos/builtin\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e[Optional]\nTo ensure you have this custom repo in your spack all the time, move the \u003ccode\u003erepos.yaml\u003c/code\u003e into your spack config folder\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ mv /home/\u0026lt;user\u0026gt;/.spack/linux/repos.yaml /home/\u0026lt;user\u0026gt;/spack/etc/spack/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlease see the \u003ca href=\"https://spack.readthedocs.io/en/latest/configuration.html\" rel=\"nofollow\"\u003eSpack documentation\u003c/a\u003e for more detailed info.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1649449003.0
  },
  {
    "data_format": 2,
    "description": "Simulate interactions between two fully-charged PAA chains with varying amounts of CaCl2 added",
    "filenames": [
      "software/requirements/spack/spack.yaml"
    ],
    "full_name": "alec-glisman/Simulation-Two-Chain-PAA",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSimulation Two Chain PAA\u003c/h1\u003e\u003ca id=\"user-content-simulation-two-chain-paa\" class=\"anchor\" aria-label=\"Permalink: Simulation Two Chain PAA\" href=\"#simulation-two-chain-paa\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eSummary:\u003c/strong\u003e PLUMED-patched GROMACS molecular dynamics simulations repository used for studying the multi-valent ion mediated interactions between two polyanions.\u003cbr\u003e\n\u003cstrong\u003eAuthors:\u003c/strong\u003e \u003ca href=\"https://github.com/alec-glisman\"\u003eAlec Glisman\u003c/a\u003e, \u003ca href=\"https://github.com/sritejamantha\"\u003eSriteja Mantha\u003c/a\u003e\u003cbr\u003e\n\u003cstrong\u003eGitHub actions:\u003c/strong\u003e\n\u003ca href=\"https://github.com/alec-glisman/Simulation-Two-Chain-PAA/actions/workflows/code-linting.yml\"\u003e\u003cimg src=\"https://github.com/alec-glisman/Simulation-Two-Chain-PAA/actions/workflows/code-linting.yml/badge.svg\" alt=\"Linting\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003cstrong\u003eThird-party services:\u003c/strong\u003e\n\u003ca href=\"https://wakatime.com/badge/github/alec-glisman/gromacs\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8ec8d5b31066076b6c84091c24462d94a35caf7c07a73038ec3b54b9a94d123/68747470733a2f2f77616b6174696d652e636f6d2f62616467652f6769746875622f616c65632d676c69736d616e2f67726f6d6163732e737667\" alt=\"wakatime\" data-canonical-src=\"https://wakatime.com/badge/github/alec-glisman/gromacs.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProject structure\u003c/h2\u003e\u003ca id=\"user-content-project-structure\" class=\"anchor\" aria-label=\"Permalink: Project structure\" href=\"#project-structure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eEach subdirectory contains its own \u003ccode\u003eREADME.md\u003c/code\u003e file with more detailed information about the project.\nWe present a brief summary of each subdirectory below, but strongly recommend that users read the other documentation for a better idea of how to use the code.\u003c/p\u003e\n\u003cp\u003eThe project contains many configuration and styling files for various tools, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"./.github/READ.md\"\u003e\u003ccode\u003e.github/\u003c/code\u003e\u003c/a\u003e: GitHub workflows and issue templates directory.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./.vscode/README.md\"\u003e\u003ccode\u003e.vscode/\u003c/code\u003e\u003c/a\u003e: Visual Studio Code editor settings and configuration directory.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e.clang-format\u003c/code\u003e: Clang-format configuration file for C++ code.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e.pylintrc\u003c/code\u003e: Pylint configuration file for Python code.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e.shellcheckrc\u003c/code\u003e: ShellCheck configuration file for shell scripts.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e.wakatime-project\u003c/code\u003e: Wakatime configuration file for time tracking.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eCITATIONS.md\u003c/code\u003e: List of citations for the project.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eLICENSE\u003c/code\u003e: Project license file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe molecular dynamics simulations are contained in the following subdirectories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"./data/README.md\"\u003e\u003ccode\u003edata\u003c/code\u003e\u003c/a\u003e: Data files output from simulation.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./force-field/README.md\"\u003e\u003ccode\u003eforce-fields\u003c/code\u003e\u003c/a\u003e: Force fields in GROMACS format used to model various system components.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./intial-structure/README.md\"\u003e\u003ccode\u003einitial-structure\u003c/code\u003e\u003c/a\u003e: Energy minimized initial structures for polyelectrolytes and crystalline lattices.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./parameters/README.md\"\u003e\u003ccode\u003eparameters\u003c/code\u003e\u003c/a\u003e: GROMACS mdp parameter files and simulation pipeline input variables.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./python/README.md\"\u003e\u003ccode\u003epython\u003c/code\u003e\u003c/a\u003e: Helper Python scripts called by the simulation pipeline.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./scripts/README.md\"\u003e\u003ccode\u003escripts\u003c/code\u003e\u003c/a\u003e: Bash scripts used to run simulations and analyze data output using GROMACS and PLUMED command line interface tools.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./software/README.md\"\u003e\u003ccode\u003esoftware\u003c/code\u003e\u003c/a\u003e: GROMACS and PLUMED source code and build scripts as well as environment configuration files.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"./submission/README.md\"\u003e\u003ccode\u003esubmission\u003c/code\u003e\u003c/a\u003e: Slurm job submission scripts used to run simulations on the group\u0027s HPC cluster.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConfiguration\u003c/h3\u003e\u003ca id=\"user-content-configuration\" class=\"anchor\" aria-label=\"Permalink: Configuration\" href=\"#configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eVarious formatting files are included (\u003ccode\u003e.clang-format\u003c/code\u003e, \u003ccode\u003e.pylintrc\u003c/code\u003e, and \u003ccode\u003e.shelcheckrc\u003c/code\u003e) to ensure consistent code formatting and style.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSoftware and environment\u003c/h2\u003e\u003ca id=\"user-content-software-and-environment\" class=\"anchor\" aria-label=\"Permalink: Software and environment\" href=\"#software-and-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFurther information on exact software versions can be found in the \u003ccode\u003esoftware\u003c/code\u003e directory\u0027s \u003ca href=\"software/README.md\"\u003e\u003ccode\u003eREADME.md\u003c/code\u003e\u003c/a\u003e file.\nWe run our simulations using\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBash 5.1.16\u003c/li\u003e\n\u003cli\u003eCMake 3.22.1\u003c/li\u003e\n\u003cli\u003eCUDA 11.8\u003c/li\u003e\n\u003cli\u003eGCC 10.4.0\u003c/li\u003e\n\u003cli\u003eGromacs 2022.3 (Plumed patched and user patched \u003ccode\u003eshare/top/residuetypes.dat\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ePlumed 2.8.1\u003c/li\u003e\n\u003cli\u003ePackmol 20.010\u003c/li\u003e\n\u003cli\u003ePython 3.10.6\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eNomenclature\u003c/h2\u003e\u003ca id=\"user-content-nomenclature\" class=\"anchor\" aria-label=\"Permalink: Nomenclature\" href=\"#nomenclature\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eChemistry\u003c/h3\u003e\u003ca id=\"user-content-chemistry\" class=\"anchor\" aria-label=\"Permalink: Chemistry\" href=\"#chemistry\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eAcr: Acrylic acid\u003c/li\u003e\n\u003cli\u003eP: Poly, as in polymer\u003c/li\u003e\n\u003cli\u003emer: Monomer\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eNumerical\u003c/h3\u003e\u003ca id=\"user-content-numerical\" class=\"anchor\" aria-label=\"Permalink: Numerical\" href=\"#numerical\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eEM: Energy minimization\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStatistical mechanics\u003c/h3\u003e\u003ca id=\"user-content-statistical-mechanics\" class=\"anchor\" aria-label=\"Permalink: Statistical mechanics\" href=\"#statistical-mechanics\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eNVE: Microcanonical ensemble\u003c/li\u003e\n\u003cli\u003eNVT: Canonical ensemble\u003c/li\u003e\n\u003cli\u003eNPT: Isothermal\u2013isobaric ensemble\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [
      "gromacs",
      "molecular-dynamics",
      "plumed",
      "polymer",
      "shell-script"
    ],
    "updated_at": 1708562259.0
  },
  {
    "data_format": 2,
    "description": "A optimizing autotuing plugin for libpressio",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "robertu94/libpressio_opt",
    "latest_release": "0.11.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLibPressioOpt\u003c/h1\u003e\u003ca id=\"user-content-libpressioopt\" class=\"anchor\" aria-label=\"Permalink: LibPressioOpt\" href=\"#libpressioopt\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressioOpt provides a plugin for libpressio that provides optimization routines to configure compressors.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsing LibPressioOpt\u003c/h2\u003e\u003ca id=\"user-content-using-libpressioopt\" class=\"anchor\" aria-label=\"Permalink: Using LibPressioOpt\" href=\"#using-libpressioopt\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease see \u003ccode\u003e./test/opt_example_c.c\u003c/code\u003e for an example of the API.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressioOpt provides three new major features on top of LibPressio:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe \u003ccode\u003eopt\u003c/code\u003e meta compressor which allows for searching for the optimal configuration of the compressor\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003epressio_search\u003c/code\u003e modules which allow for searching for an optimal set of configuration of parameters\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003epressio_search_metrics\u003c/code\u003e modules which compute properties of the search process itself\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSee [Opt Configuration](@ref optoptions) for more information on the configuration options.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003ecmake\u003c/code\u003e version \u003ccode\u003e3.13\u003c/code\u003e or later\u003c/li\u003e\n\u003cli\u003eeither:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003egcc-8.3.0\u003c/code\u003e or later\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eclang-9.0.0\u003c/code\u003e or later\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLibDistributed version 0.0.8 or later\u003c/li\u003e\n\u003cli\u003eLibPressio version 0.40.1 or later\u003c/li\u003e\n\u003cli\u003eAn MPI implementation supporting MPI-3 or later.  Tested on OpenMPI 4.0.2\u003c/li\u003e\n\u003cli\u003eDlib after commit \u003ccode\u003e95271cfe43ffceeadeb1a73bf033794b501e86f4\u003c/code\u003e (after release 19.21)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling LibPressioOpt using Spack\u003c/h2\u003e\u003ca id=\"user-content-installing-libpressioopt-using-spack\" class=\"anchor\" aria-label=\"Permalink: Installing LibPressioOpt using Spack\" href=\"#installing-libpressioopt-using-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressioOpt can be built using \u003ca href=\"https://github.com/spack/spack/\"\u003espack\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/robertu94/spack_packages robertu94_packages\nspack repo add robertu94_packages\nspack install libpressio-opt\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can substantially reduce install times by not installing ImageMagick and PETSc support for libpressio.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install libpressio-opt ^libpressio~magick~petsc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding and Installing LibPressioOpt Manually\u003c/h2\u003e\u003ca id=\"user-content-building-and-installing-libpressioopt-manually\" class=\"anchor\" aria-label=\"Permalink: Building and Installing LibPressioOpt Manually\" href=\"#building-and-installing-libpressioopt-manually\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressioOpt uses CMake to configure build options.  See CMake documentation to see how to configure options\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eCMAKE_INSTALL_PREFIX\u003c/code\u003e - install the library to a local directory prefix\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eBUILD_DOCS\u003c/code\u003e - build the project documentation\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eBUILD_TESTING\u003c/code\u003e - build the test cases\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eBUILD_DIR=build\nmkdir \u003cspan class=\"pl-smi\"\u003e$BUILD_DIR\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$BUILD_DIR\u003c/span\u003e\ncmake ..\nmake\nmake \u003cspan class=\"pl-c1\"\u003etest\u003c/span\u003e\nmake install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo build the documentation:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eBUILD_DIR=build\nmkdir \u003cspan class=\"pl-smi\"\u003e$BUILD_DIR\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$BUILD_DIR\u003c/span\u003e\ncmake .. -DBUILD_DOCS=ON\nmake docs\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e the html docs can be found in $BUILD_DIR/html/index.html\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e the man pages can be found in $BUILD_DIR/man/\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStability\u003c/h2\u003e\u003ca id=\"user-content-stability\" class=\"anchor\" aria-label=\"Permalink: Stability\" href=\"#stability\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAs of version 1.0.0, LibPressioOpt will follow the following API stability guidelines:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe functions defined in files in \u003ccode\u003e./include\u003c/code\u003e are to considered stable\u003c/li\u003e\n\u003cli\u003eThe functions defined in files or its subdirectories in \u003ccode\u003e./include/libpressio_opt_ext/\u003c/code\u003e considered unstable.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStable means:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNew APIs may be introduced with the increase of the minor version number.\u003c/li\u003e\n\u003cli\u003eAPIs may gain additional overloads for C++ compatible interfaces with an increase in the minor version number.\u003c/li\u003e\n\u003cli\u003eAn API may change the number or type of parameters with an increase in the major version number.\u003c/li\u003e\n\u003cli\u003eAn API may be removed with the change of the major version number\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eUnstable means:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe API may change for any reason with the increase of the minor version number\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdditionally, the performance of functions, memory usage patterns may change for both stable and unstable code with the increase of the patch version.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBug Reports\u003c/h2\u003e\u003ca id=\"user-content-bug-reports\" class=\"anchor\" aria-label=\"Permalink: Bug Reports\" href=\"#bug-reports\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease files bugs to the Github Issues page on the robertu94 github repository.\u003c/p\u003e\n\u003cp\u003ePlease read this post on \u003ca href=\"https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\"\u003ehow to file a good bug report\u003c/a\u003e.\u00a0 After reading this post, please provide the following information specific to LibPressioOpt:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYour OS version and distribution information, usually this can be found in \u003ccode\u003e/etc/os-release\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe output of \u003ccode\u003ecmake -L $BUILD_DIR\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe version of each of LibPressioOpts\u0027s dependencies listed in the README that you have installed. Where possible, please provide the commit hashes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCite\u003c/h2\u003e\u003ca id=\"user-content-cite\" class=\"anchor\" aria-label=\"Permalink: Cite\" href=\"#cite\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you find this work useful, please consider citing\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-bibtex\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e@article\u003c/span\u003e{\u003cspan class=\"pl-en\"\u003eunderwood2022optzconfig\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003etitle\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eOptZConfig: Efficient Parallel Optimization of Lossy Compression Configuration\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003eauthor\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eUnderwood, Robert and Calhoun, Jon C and Di, Sheng and Apon, Amy and Cappello, Franck\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003ejournal\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eIEEE Transactions on Parallel and Distributed Systems\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003eyear\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003e2022\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003epublisher\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eIEEE\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor if you only optimize compression ratio\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-bibtex\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e@inproceedings\u003c/span\u003e{\u003cspan class=\"pl-en\"\u003eunderwood2020fraz\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003etitle\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eFraz: A generic high-fidelity fixed-ratio lossy compression framework for scientific floating-point data\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003eauthor\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eUnderwood, Robert and Di, Sheng and Calhoun, Jon C and Cappello, Franck\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003ebooktitle\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003e2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003epages\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003e567--577\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003eyear\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003e2020\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e,\n  \u003cspan class=\"pl-s\"\u003eorganization\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e{\u003c/span\u003eIEEE\u003cspan class=\"pl-pds\"\u003e}\u003c/span\u003e\u003c/span\u003e\n}\n\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1695425113.0
  },
  {
    "data_format": 2,
    "description": "spack config for erp cluster",
    "filenames": [
      "v0171_gcc910/spack.yaml",
      "openFoam24/spack.yaml",
      "v61c1b71_gcc910/spack.yaml",
      "v0201_1/spack.yaml",
      "v0190_gcc910/spack.yaml"
    ],
    "full_name": "SCOREC/centos7-spack-config",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ecentos7-spack-config\u003c/h1\u003e\u003ca id=\"user-content-centos7-spack-config\" class=\"anchor\" aria-label=\"Permalink: centos7-spack-config\" href=\"#centos7-spack-config\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ecentos7 spack configuration and scripts\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003econtents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: contents\" href=\"#contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ecompilers.yaml - compiler list\nconfig.yaml - global config\ninstall.sh - package installation commands\nmodules.yaml - hierarchical layout for lua modules\npackages.yaml - system installed packages\nREADME.md - this file\nsetupSpack.sh - env needed for executing spack commands\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1696768501.0
  },
  {
    "data_format": 2,
    "description": "Prototype for data processing framework",
    "filenames": [
      "spack-env/spack.yaml"
    ],
    "full_name": "MeteoSwiss-APN/icon_data_processing_incubator",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eIcon Data Processing Incubator: Prototype for a data post-processing framework on the basis of xarray.\u003c/h1\u003e\u003ca id=\"user-content-icon-data-processing-incubator-prototype-for-a-data-post-processing-framework-on-the-basis-of-xarray\" class=\"anchor\" aria-label=\"Permalink: Icon Data Processing Incubator: Prototype for a data post-processing framework on the basis of xarray.\" href=\"#icon-data-processing-incubator-prototype-for-a-data-post-processing-framework-on-the-basis-of-xarray\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStart developing\u003c/h2\u003e\u003ca id=\"user-content-start-developing\" class=\"anchor\" aria-label=\"Permalink: Start developing\" href=\"#start-developing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce you created or cloned this repository, make sure the installation is running properly. Install the package dependencies with the provided script \u003ccode\u003esetup_env.sh\u003c/code\u003e.\nCheck available options with\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003etools/setup_env.sh -h\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe distinguish pinned installations based on exported (reproducible) environments and free installations where the installation\nis based on top-level dependencies listed in \u003ccode\u003erequirements/requirements.yaml\u003c/code\u003e. If you start developing, you might want to do an unpinned installation and export the environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003etools/setup_env.sh -u -e -n \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage_env_name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eHint\u003c/em\u003e: If you are the package administrator, it is a good idea to understand what this script does, you can do everything manually with \u003ccode\u003econda\u003c/code\u003e instructions.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eHint\u003c/em\u003e: Use the flag \u003ccode\u003e-m\u003c/code\u003e to speed up the installation using mamba. Of course you will have to install mamba first (we recommend to install mamba into your base\nenvironment \u003ccode\u003econda install -c conda-forge mamba\u003c/code\u003e. If you install mamba in another (maybe dedicated) environment, environments installed with mamba will be located\nin \u003ccode\u003e\u0026lt;miniconda_root_dir\u0026gt;/envs/mamba/envs\u003c/code\u003e, which is not very practical.\u003c/p\u003e\n\u003cp\u003eThe package itself is installed with \u003ccode\u003epip\u003c/code\u003e. For development, install in editable mode:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda activate \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage_env_name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\npip install --editable \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eWarning:\u003c/em\u003e Make sure you use the right pip, i.e. the one from the installed conda environment (\u003ccode\u003ewhich pip\u003c/code\u003e should point to something like \u003ccode\u003epath/to/miniconda/envs/\u0026lt;package_env_name\u0026gt;/bin/pip\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eOnce your package is installed, run the tests by typing:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econda activate \u0026lt;package_env_name\u0026gt;\npytest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf the tests pass, you are good to go. If not, contact the package administrator Tobias Wicky. Make sure to update your requirement files and export your environments after installation\nevery time you add new imports while developing. Check the next section to find some guidance on the development process if you are new to Python and/or APN.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eRoadmap to your first contribution\u003c/h3\u003e\u003ca id=\"user-content-roadmap-to-your-first-contribution\" class=\"anchor\" aria-label=\"Permalink: Roadmap to your first contribution\" href=\"#roadmap-to-your-first-contribution\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eGenerally, the source code of your library is located in \u003ccode\u003esrc/\u0026lt;library_name\u0026gt;\u003c/code\u003e. The blueprint will generate some example code in \u003ccode\u003emutable_number.py\u003c/code\u003e, \u003ccode\u003eutils.py\u003c/code\u003e and \u003ccode\u003ecli.py\u003c/code\u003e. \u003ccode\u003ecli.py\u003c/code\u003e thereby serves as an entry\npoint for functionalities you want to execute from the command line, it is based on the Click library. If you do not need interactions with the command line, you should remove \u003ccode\u003ecli.py\u003c/code\u003e. Moreover, of course there exist other options for command line interfaces,\na good overview may be found here (\u003ca href=\"https://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/\" rel=\"nofollow\"\u003ehttps://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/\u003c/a\u003e), we recommend however to use click. The provided example\ncode should provide some guidance on how the individual source code files interact within the library. In addition to the example code in \u003ccode\u003esrc/\u0026lt;library_name\u0026gt;\u003c/code\u003e, there are examples for\nunit tests in \u003ccode\u003etests/\u0026lt;library_name\u0026gt;/\u003c/code\u003e, which can be triggered with \u003ccode\u003epytest\u003c/code\u003e from the command line. Once you implemented a feature (and of course you also\nimplemented a meaningful test ;-)), you are likely willing to commit it. First, go to the root directory of your package and run pytest.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda activate \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage_env_name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage-root-dir\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\npytest\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you use the tools provided by the blueprint as is, pre-commit will not be triggered locally but only if you push to the main branch\n(or push to a PR to the main branch). If you consider it useful, you can set up pre-commit to run locally before every commit by initializing it once. In the root directory of\nyour package, type:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epre-commit install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you run \u003ccode\u003epre-commit\u003c/code\u003e without installing it before (line above), it will fail and the only way to recover it, is to do a forced reinstallation (\u003ccode\u003econda install --force-reinstall pre-commit\u003c/code\u003e).\nYou can also just run pre-commit selectively, whenever you want by typing (\u003ccode\u003epre-commit run --all-files\u003c/code\u003e). Note that mypy and pylint take a bit of time, so it is really\nup to you, if you want to use pre-commit locally or not. In any case, after running pytest, you can commit and the linters will run at the latest on the GitHub actions server,\nwhen you push your changes to the main branch. Note that pytest is currently not invoked by pre-commit, so it will not run automatically. Automated testing can be set up with\nGitHub Actions or be implemented in a Jenkins pipeline (template for a plan available in \u003ccode\u003ejenkins/\u003c/code\u003e. See the next section for more details.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDevelopment tools\u003c/h2\u003e\u003ca id=\"user-content-development-tools\" class=\"anchor\" aria-label=\"Permalink: Development tools\" href=\"#development-tools\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAs this package was created with the APN Python blueprint, it comes with a stack of development tools, which are described in more detail on\n(\u003ca href=\"https://meteoswiss-apn.github.io/mch-python-blueprint/\" rel=\"nofollow\"\u003ehttps://meteoswiss-apn.github.io/mch-python-blueprint/\u003c/a\u003e). Here, we give a brief overview on what is implemented.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTesting and coding standards\u003c/h3\u003e\u003ca id=\"user-content-testing-and-coding-standards\" class=\"anchor\" aria-label=\"Permalink: Testing and coding standards\" href=\"#testing-and-coding-standards\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTesting your code and compliance with the most important Python standards is a requirement for Python software written in APN. To make the life of package\nadministrators easier, the most important checks are run automatically on GitHub actions. If your code goes into production, it must additionally be tested on CSCS\nmachines, which is only possible with a Jenkins pipeline (GitHub actions is running on a GitHub server).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePre-commit on GitHub actions\u003c/h3\u003e\u003ca id=\"user-content-pre-commit-on-github-actions\" class=\"anchor\" aria-label=\"Permalink: Pre-commit on GitHub actions\" href=\"#pre-commit-on-github-actions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003e.github/workflows/pre-commit.yaml\u003c/code\u003e contains a hook that will trigger the creation of your environment (unpinned) on the GitHub actions server and\nthen run various formatters and linters through pre-commit. This hook is only triggered upon pushes to the main branch (in general: don\u0027t do that)\nand in pull requests to the main branch.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eJenkins\u003c/h3\u003e\u003ca id=\"user-content-jenkins\" class=\"anchor\" aria-label=\"Permalink: Jenkins\" href=\"#jenkins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA jenkinsfile is available in the \u003ccode\u003ejenkins/\u003c/code\u003e folder. It can be used for a multibranch jenkins project, which builds\nboth commits on branches and PRs. Your jenkins pipeline will not be set up\nautomatically. If you need to run your tests on CSCS machines, contact DevOps to help you with the setup of the pipelines. Otherwise, you can ignore the jenkinsfiles\nand exclusively run your tests and checks on GitHub actions.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eFeatures\u003c/h2\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink: Features\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eTODO\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCredits\u003c/h2\u003e\u003ca id=\"user-content-credits\" class=\"anchor\" aria-label=\"Permalink: Credits\" href=\"#credits\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis package was created with \u003ca href=\"https://github.com/copier-org/copier\"\u003e\u003ccode\u003ecopier\u003c/code\u003e\u003c/a\u003e and the \u003ca href=\"https://meteoswiss-apn.github.io/mch-python-blueprint/\" rel=\"nofollow\"\u003e\u003ccode\u003eMeteoSwiss-APN/mch-python-blueprint\u003c/code\u003e\u003c/a\u003e project template.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1703149578.0
  },
  {
    "data_format": 2,
    "description": "Documentation and automation for provisioning the core software environment at University of Colorado Boulder Research Computing",
    "filenames": [
      "spack/environments/develop/spack.yaml"
    ],
    "full_name": "ResearchComputing/core-software",
    "latest_release": null,
    "readme": "\u003cp\u003eThe Research Computing core software environment provides compilers,\nmpi, libraries, language environments, and applications that are of\ngeneral use to the CU Boulder Research Computing user community.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eManual installation procedures\u003c/h2\u003e\u003ca id=\"user-content-manual-installation-procedures\" class=\"anchor\" aria-label=\"Permalink: Manual installation procedures\" href=\"#manual-installation-procedures\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eManual software installation procedures are available in the \u003ccode\u003eSummit\u003c/code\u003e\nand \u003ccode\u003eBlanca\u003c/code\u003e directories, organized by\n\u003ccode\u003eCluster/SoftwareName/VersionNumber\u003c/code\u003e. The \u003ccode\u003eVersionNumber\u003c/code\u003e file\ncontains build notes (bash commands, notes, instructions etc.) to\ninstall that software package for each compiler and MPI.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpack\u003c/h2\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-label=\"Permalink: Spack\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack, when deployed as intended, will be a central part of the\nprovisioning of our Core Software service. Included here is the\nconfiguration and installation script for Spack as installed and\npresented at CU Boulder Research Computing.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1649960895.0
  },
  {
    "data_format": 2,
    "description": "Automated deployment system for the scientific software stack in use at Pawsey",
    "filenames": [
      "systems/setonix/environments/cray_s3_clients/spack.yaml",
      "systems/setonix/environments/bench/spack.yaml",
      "systems/setonix/environments/cray_devel/spack.yaml",
      "systems/setonix/environments/wrf/spack.yaml"
    ],
    "full_name": "PawseySC/pawsey-spack-config",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePawsey Spack Configuration\u003c/h1\u003e\u003ca id=\"user-content-pawsey-spack-configuration\" class=\"anchor\" aria-label=\"Permalink: Pawsey Spack Configuration\" href=\"#pawsey-spack-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eScripts and configuration files used by the Pawsey Supercomputing Research Centre to deploy Spack and to install the scientific software stack on its supercomputing systems.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHere is how to launch the software stack installation.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eMake sure the system you want to install the software stack on has a corresponding directory in \u003ccode\u003esystems\u003c/code\u003e. If not, you can start by creating a copy of an existing one.\u003c/li\u003e\n\u003cli\u003eEdit the file \u003ccode\u003esystems/\u0026lt;system\u0026gt;/settings.sh\u003c/code\u003e as needed.\u003c/li\u003e\n\u003cli\u003eSet and export the \u003ccode\u003eINSTALL_PREFIX\u003c/code\u003e variable to the full path of the filesystem location where you want the installation to be placed in. Note that it has to end with the same string as the one stored in the \u003ccode\u003eDATE_TAG\u003c/code\u003e variable, meaning that installations are versioned by installation date.\u003c/li\u003e\n\u003cli\u003eSet and export the \u003ccode\u003eINSTALL_GROUP\u003c/code\u003e variable to the linux group that is going to own the installed files.\u003c/li\u003e\n\u003cli\u003eSet and export the \u003ccode\u003eSYSTEM\u003c/code\u003e variable to the system you want to run the installation for, if it differs from the content of the \u003ccode\u003ePAWSEY_CLUSTER\u003c/code\u003e environment variable.\u003c/li\u003e\n\u003cli\u003eRun the \u003ccode\u003escripts/install_software_stack.sh\u003c/code\u003e script, preferably in a Slurm job or as a process detached from the login shell to prevent the installation from being aborted in case the SSH connection were to be interrupted unexpectedly.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSingularity\u003c/h3\u003e\u003ca id=\"user-content-singularity\" class=\"anchor\" aria-label=\"Permalink: Singularity\" href=\"#singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou will need to ask the platforms team to apply root permissions to Singularity ss soon as it is installed. The script to run as root is found in the \u003ccode\u003ebin\u003c/code\u003e directory within the spack installation prefix.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSoftware stack modulefile\u003c/h3\u003e\u003ca id=\"user-content-software-stack-modulefile\" class=\"anchor\" aria-label=\"Permalink: Software stack modulefile\" href=\"#software-stack-modulefile\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe platforms team will need to install the \u003ccode\u003e$INSTALL_PREFIX/staff_modulefiles/pawseyenv/*lua\u003c/code\u003e module such that it will be loaded before the Cray compilers. They will also need to update user account creation process, following the updated \u003ccode\u003e$INSTALL_PREFIX/spack/bin/spack_create_user_moduletree.sh\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRepository structure\u003c/h2\u003e\u003ca id=\"user-content-repository-structure\" class=\"anchor\" aria-label=\"Permalink: Repository structure\" href=\"#repository-structure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe repository is composed of the directories:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003efixes/\u003c/code\u003e: patches implemented by Pawsey staff to be applied to Spack prior to production use. They are meant to improve usability of Spack for Pawsey-specific use cases.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003erepo/\u003c/code\u003e: custom Spack package recipes for software not yet supported by Spack or that needed modification in the build process to work on Pawsey systems.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eshpc_registry/\u003c/code\u003e: custom Singularity-HPC (SHPC) recipes to deploy containers.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003escripts/\u003c/code\u003e: BASH scripts used to automate the deployment process.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003esystems/\u0026lt;system\u0026gt;\u003c/code\u003e: a directory containing configuration files specific to a system. Scripts will use these files to customise the Spack deployment and installation of the software stack.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \u003ccode\u003escripts/install_software_stack.sh\u003c/code\u003e is the top-level script that executes the installation from start to finish except licensed software, that need some manual work. Refer to this script also as documentation of the installation process.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eThe \u003ccode\u003escripts\u003c/code\u003e directory\u003c/h2\u003e\u003ca id=\"user-content-the-scripts-directory\" class=\"anchor\" aria-label=\"Permalink: The scripts directory\" href=\"#the-scripts-directory\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis project makes up a build system for the scientific software stack on Pawsey supercomputers. On a high level, there are two logical compontents to it:\none to deploy Spack and SHPC (a software package to manage containers), and the other to use the tools mentioned before to install scientific software.\u003c/p\u003e\n\u003cp\u003eThe deployment of Spack and SHPC is implemented through the following executables BASH scripts within the \u003ccode\u003escripts\u003c/code\u003e directory:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003einstall_spack.sh\u003c/code\u003e installs Spack on the system and creates the directory structure for the system-wide software stack installation.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003einstall_python.sh\u003c/code\u003e installs Python using Spack. To do so, and only in this case, Spack chooses \u003ccode\u003ecray-python\u003c/code\u003e as interpreter. Once Python is installed for different architectures and versions, \u003ccode\u003ecray-python\u003c/code\u003e won\u0027t be used anymore.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003einstall_shpc.sh\u003c/code\u003e installs SHPC, a tool used to deploy containers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe software stack deployment is implemented in these scripts instead:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003econcretize_environments.sh\u003c/code\u003e runs the concretization step for all Spack environments to be installed.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003einstall_environments.sh\u003c/code\u003e will install all Spack environments using Spack.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003einstall_shpc_containers.sh\u003c/code\u003e will pull Pawsey-supported containers and install them using SHPC.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003epost_installation_operations.sh\u003c/code\u003e refreshes Lmod modulefiles for the installed software, applies permissions to licensed software, and other operations needed after the full stack deployment executed by Spack.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eThe \u003ccode\u003esystems/\u0026lt;system\u0026gt;\u003c/code\u003e directory\u003c/h2\u003e\u003ca id=\"user-content-the-systemssystem-directory\" class=\"anchor\" aria-label=\"Permalink: The systems/\u0026lt;system\u0026gt; directory\" href=\"#the-systemssystem-directory\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is where system specific configurations are placed. In particular, the following items must always be present.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003econfigs/\u003c/code\u003e is a directory containing \u003ccode\u003eyaml\u003c/code\u003e configuraiton files for Spack. There are three types of configuration:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003esite/\u003c/code\u003e: Spack configuration files that are valid for all users, which will sit in \u003ccode\u003e$spack/etc/spack\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eproject/\u003c/code\u003e: Spack configuration files that are valid for project-wide installations executed by any user using the dedicated script \u003ccode\u003espack_project.sh\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003espackuser/\u003c/code\u003e: Spack configuration files for system-wide installs, performed by Pawsey staff, which will sit in \u003ccode\u003e/home/spack/.spack/\u003c/code\u003e, allowing the \u003ccode\u003espack\u003c/code\u003e user to override system-wide settings.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eenvironments/\u003c/code\u003e: Spack environments to be deployed.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etemplates/\u003c/code\u003e: modulefile templates for Spack.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eNotes\u003c/h2\u003e\u003ca id=\"user-content-notes\" class=\"anchor\" aria-label=\"Permalink: Notes\" href=\"#notes\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eModule categories in use\u003c/h3\u003e\u003ca id=\"user-content-module-categories-in-use\" class=\"anchor\" aria-label=\"Permalink: Module categories in use\" href=\"#module-categories-in-use\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eSpack (with compiler/arch tree)\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eNOTE\u003c/strong\u003e: if updating list, still need to manually update \u003ccode\u003etemplates/modules/modulefile.lua\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eastro-applications\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebio-applications\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eapplications\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elibraries\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eprogramming-languages\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eutilities\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003evisualisation\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epython-packages\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebenchmarking\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edeveloper-tools\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edependencies\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePawsey custom builds (with compiler/arch tree)\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecustom/modules\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePawsey utilities (without compiler/arch tree: Spack, SHPC, utility scripts)\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epawsey/modules\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSHPC containers modules (without compiler/arch tree)\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econtainers/modules\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTesting Modules\u003c/h3\u003e\u003ca id=\"user-content-testing-modules\" class=\"anchor\" aria-label=\"Permalink: Testing Modules\" href=\"#testing-modules\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCurrent \u003ccode\u003emodules.yaml\u003c/code\u003e and the template \u003ccode\u003emodulefile.lua\u003c/code\u003e rely on additional features of Spack found in the feature/improved-lmod-modules (\u003ca href=\"https://github.com/PawseySC/spack/tree/feature/improved-lmod-modules\"\u003ehttps://github.com/PawseySC/spack/tree/feature/improved-lmod-modules\u003c/a\u003e).\u003cbr\u003e\nThe update provides extra tokens that can be used when creating the module name and also extra keywords to the template.\u003cbr\u003e\nThese features have now been packaged in a patch, that is applied by \u003ccode\u003einstall_spack.sh\u003c/code\u003e.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1708834244.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "environments/hpccf/farm/genomics/spack.yaml",
      "environments/hpccf/franklin/general/spack.yaml",
      "environments/hpccf/farm/core/spack.yaml",
      "environments/hpccf/farm/r-stack/spack.yaml",
      "environments/hpccf/franklin/cluster-core/spack.yaml"
    ],
    "full_name": "ucdavis/spack-ucdavis",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack @ UC Davis\u003c/h1\u003e\u003ca id=\"user-content-spack--uc-davis\" class=\"anchor\" aria-label=\"Permalink: Spack @ UC Davis\" href=\"#spack--uc-davis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpack repos and configs for UC Davis HPCCF Clusters\u003c/h2\u003e\u003ca id=\"user-content-spack-repos-and-configs-for-uc-davis-hpccf-clusters\" class=\"anchor\" aria-label=\"Permalink: Spack repos and configs for UC Davis HPCCF Clusters\" href=\"#spack-repos-and-configs-for-uc-davis-hpccf-clusters\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo contains package specs, configurations, and utility scripts for\n\u003ca href=\"https://spack.readthedocs.io/en/latest/index.html\" rel=\"nofollow\"\u003espack\u003c/a\u003e deployments on\nclusters managed by the UC Davis High Performance Computing Core Facility.\u003c/p\u003e\n\u003cp\u003eThe structure of this repo is as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003erepos/hpccf\u003c/code\u003e: Our spack package specifications. This includes both overrides\nof \u003ccode\u003ebuiltin\u003c/code\u003e and from-scratch specs. The packages are namespaced under \u003ccode\u003eucdavis.hpccf\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etemplates/hpccf\u003c/code\u003e: Template extensions for module management.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003econfig/hpccf/[SITE]\u003c/code\u003e: Site-specific configuration files. \u003ccode\u003e[SITE]\u003c/code\u003e directories\ncorrespond to cluster names. These are linked to \u003ccode\u003e${SPACK_ROOT}/etc/spack/\u003c/code\u003e when deployed.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ebin\u003c/code\u003e: Utility scripts.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1709600687.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ppc64le/spack.yaml",
      "x86_64/spack.yaml"
    ],
    "full_name": "eugeneswalker/llvm-containers",
    "latest_release": null,
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1615486265.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "envs/base/spack.yaml"
    ],
    "full_name": "ScottWales/spack-environments",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eNGM Spack Environments \u0026amp; Containers\u003c/h1\u003e\u003ca id=\"user-content-ngm-spack-environments--containers\" class=\"anchor\" aria-label=\"Permalink: NGM Spack Environments \u0026amp; Containers\" href=\"#ngm-spack-environments--containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRepository Layout\u003c/h2\u003e\u003ca id=\"user-content-repository-layout\" class=\"anchor\" aria-label=\"Permalink: Repository Layout\" href=\"#repository-layout\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003ebin/\u003c/code\u003e: User scripts\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eci/\u003c/code\u003e: CI scripts\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003econfig/\u003c/code\u003e: Spack config files\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003econtainers/\u003c/code\u003e: Dockerfiles\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eenvs/\u003c/code\u003e: Environments\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eetc/\u003c/code\u003e: Config files and build scripts\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003erepos/\u003c/code\u003e: Spack Packages\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsing containers\u003c/h2\u003e\u003ca id=\"user-content-using-containers\" class=\"anchor\" aria-label=\"Permalink: Using containers\" href=\"#using-containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eRun container on Gadi\u003c/h3\u003e\u003ca id=\"user-content-run-container-on-gadi\" class=\"anchor\" aria-label=\"Permalink: Run container on Gadi\" href=\"#run-container-on-gadi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLoad the container module\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodule use /scratch/hc46/hc46_gitlab/ngm/modules\nmodule load lfric-v0/gcc-openmpi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003eimagerun\u003c/code\u003e helper script will run a command in the container\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimagerun unifiedmodel_hofx.x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003eimagerun\u003c/code\u003e will also set up bind mode MPI automatically, use it inside of \u003ccode\u003empirun\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003empirun -n 4 imagerun unifiedmodel_hofx.x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eRun container on a generic system\u003c/h3\u003e\u003ca id=\"user-content-run-container-on-a-generic-system\" class=\"anchor\" aria-label=\"Permalink: Run container on a generic system\" href=\"#run-container-on-a-generic-system\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRun from a container using Apptainer\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eapptainer run jopa-intel-openmpi.sif unifiedmodel_hofx.x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eConfigure Bind-mode MPI by mounting your system MPI to /bind/openmpi@4\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003empirun -n 4 apptainer run --bind /apps/openmpi/4.1.4:/bind/openmpi@4 \\\n    jopa-intel-openmpi.sif unifiedmodel_hofx.x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling on a bare system\u003c/h2\u003e\u003ca id=\"user-content-installing-on-a-bare-system\" class=\"anchor\" aria-label=\"Permalink: Installing on a bare system\" href=\"#installing-on-a-bare-system\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstalling environments on NCI Gadi\u003c/h3\u003e\u003ca id=\"user-content-installing-environments-on-nci-gadi\" class=\"anchor\" aria-label=\"Permalink: Installing environments on NCI Gadi\" href=\"#installing-environments-on-nci-gadi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo install an environment on Gadi run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./bin/install_gadi.sh ENV\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewith ENV the name of a directory under \u003ccode\u003eenvs/\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstalling environments on AWS EC2\u003c/h3\u003e\u003ca id=\"user-content-installing-environments-on-aws-ec2\" class=\"anchor\" aria-label=\"Permalink: Installing environments on AWS EC2\" href=\"#installing-environments-on-aws-ec2\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo install an environment on EC2 run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./bin/install_aws.sh ENV\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe instance should be running Amazon Linux. Spack, Mamba and their\ndependencies will be installed if not present.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstalling environments on a generic system\u003c/h3\u003e\u003ca id=\"user-content-installing-environments-on-a-generic-system\" class=\"anchor\" aria-label=\"Permalink: Installing environments on a generic system\" href=\"#installing-environments-on-a-generic-system\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstalling an environment locally requires \u003ccode\u003espack\u003c/code\u003e and \u003ccode\u003emamba\u003c/code\u003e to be installed\nand active.\u003c/p\u003e\n\u003cp\u003eTo install an environment run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./bin/install.sh ENV\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSetting Compiler and MPI version\u003c/h3\u003e\u003ca id=\"user-content-setting-compiler-and-mpi-version\" class=\"anchor\" aria-label=\"Permalink: Setting Compiler and MPI version\" href=\"#setting-compiler-and-mpi-version\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBy default the environment will be built with Spack\u0027s defaults for compiler and MPI.\u003c/p\u003e\n\u003cp\u003eTo use a different version set the \u003ccode\u003eSPACK_COMPILER\u003c/code\u003e and \u003ccode\u003eSPACK_MPI\u003c/code\u003e environment\nvariables, e.g.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport SPACK_COMPILER=intel@2021.8.0\nexport SPACK_MPI=openmpi@4.1.4\n\n./bin/install.sh lfric-v0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewill install the \u003ccode\u003elfric-v0\u003c/code\u003e environment with that compiler and MPI.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1688057708.0
  },
  {
    "data_format": 2,
    "description": "Dockerfile and Spack spec files for hardware optimized benchmark containers",
    "filenames": [
      "hmmer-amd/spack.yaml"
    ],
    "full_name": "dbkinghorn/Benchmark-Containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eBenchmark Containers\u003c/h1\u003e\u003ca id=\"user-content-benchmark-containers\" class=\"anchor\" aria-label=\"Permalink: Benchmark Containers\" href=\"#benchmark-containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a collection of container spec files used to build the images available on \u003ca href=\"https://hub.docker.com/orgs/pugetsystems/repositories\" rel=\"nofollow\"\u003ehttps://hub.docker.com/orgs/pugetsystems/repositories\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMost of these images are based on performance optimized application builds for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.\u003c/p\u003e\n\u003cp\u003eThese container images are the basis for some of our Scientific and Machine Learning benchmarks at \u003ca href=\"pugetsystems.com\"\u003ePuget Systems\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFiles for each application include,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpack spec.yaml (build specifications with targeted optimizations)\u003c/li\u003e\n\u003cli\u003eDockerfiles (Multi-stage build/install)\u003c/li\u003e\n\u003cli\u003e*Enroot container-bundle (self running) build scripts\u003c/li\u003e\n\u003cli\u003eBenchmarks\u003c/li\u003e\n\u003cli\u003eUsage notes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e* Enroot container bundles are self-running containers. No container runtime (docker) install is needed. These \".run\" files are generally too large to be hosted on GitHub. Download locations will be provided at a later time.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1676846633.0
  },
  {
    "data_format": 2,
    "description": "Spack repo for multimedia development",
    "filenames": [
      "examples/c-embed-python/spack.yaml"
    ],
    "full_name": "salotz/snailpacks",
    "latest_release": null,
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [
      "spack",
      "spack-repo",
      "scopes-lang",
      "multimedia",
      "game-development",
      "package-manager",
      "development-environment"
    ],
    "updated_at": 1648089720.0
  },
  {
    "data_format": 2,
    "description": "Micro-benchmarks created using PMDK and Intel Optane DCPMM performance comparisons for all generations, including the very last persistent memory, 300 series.",
    "filenames": [
      "spack/envs/pegasus/spack.yaml"
    ],
    "full_name": "range3/pmembench",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003epmembench\u003c/h1\u003e\u003ca id=\"user-content-pmembench\" class=\"anchor\" aria-label=\"Permalink: pmembench\" href=\"#pmembench\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003epmem2bench\u003c/h2\u003e\u003ca id=\"user-content-pmem2bench\" class=\"anchor\" aria-label=\"Permalink: pmem2bench\" href=\"#pmem2bench\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"eval/README.md\"\u003eClick here for an evaluation using the Intel Optane DCPMM 300/200/100 series!\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003epmemobjbench\u003c/h2\u003e\u003ca id=\"user-content-pmemobjbench\" class=\"anchor\" aria-label=\"Permalink: pmemobjbench\" href=\"#pmemobjbench\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1704890871.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "robertu94/libpressio-sperr",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLibPressio-SPERR\u003c/h1\u003e\u003ca id=\"user-content-libpressio-sperr\" class=\"anchor\" aria-label=\"Permalink: LibPressio-SPERR\" href=\"#libpressio-sperr\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA LibPressio compressor plugin for SPERR. Packaged seperately because of GPL Licensing\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eVia Spack\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/robertu94/spack_packages robertu94_packages\nspack repo add ./robertu94_packages\n\nspack install libpressio-sperr\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eManually Via CMake\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# install cmake, sperr, libpressio and dependencies first\n\ncmake -S . -B build -DCMAKE_INSTALL_PREFIX\ncmake --build build\ncmake --install\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1658183703.0
  },
  {
    "data_format": 2,
    "description": "Toolset to deploy software stacks",
    "filenames": [
      "samples/spack.yaml"
    ],
    "full_name": "epfl-scitas/spack-sdploy",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003espack-sdploy\u003c/h1\u003e\u003ca id=\"user-content-spack-sdploy\" class=\"anchor\" aria-label=\"Permalink: spack-sdploy\" href=\"#spack-sdploy\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack extension for automatic package configuration and deployment.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to install\u003c/h2\u003e\u003ca id=\"user-content-how-to-install\" class=\"anchor\" aria-label=\"Permalink: How to install\" href=\"#how-to-install\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can try out this Spack extension be executing 4 easy steps:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet up and activate a local python environment\u003c/li\u003e\n\u003cli\u003eSet up and activate \u003ccode\u003espack\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eInstall \u003ccode\u003espack-sdploy\u003c/code\u003e dependencies\u003c/li\u003e\n\u003cli\u003eClone and configure spack-sdploy\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis 4 steps are now detailed in the next section.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep-by-step installation\u003c/h3\u003e\u003ca id=\"user-content-step-by-step-installation\" class=\"anchor\" aria-label=\"Permalink: Step-by-step installation\" href=\"#step-by-step-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eJust for a matter of completeness, all the steps needed get up and running with\nspack-sdploy extension will be covered, which can be a bit pedantic.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eSet up and activate a local python environment\u003c/h4\u003e\u003ca id=\"user-content-set-up-and-activate-a-local-python-environment\" class=\"anchor\" aria-label=\"Permalink: Set up and activate a local python environment\" href=\"#set-up-and-activate-a-local-python-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIt is recommended that a Python environment be used to support sdploy. This same\nPython can also be used to run Spack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 -m venv \u0026lt;path-to-environment-directory\u0026gt;\n. \u0026lt;path-to-environment-directory\u0026gt;/bin/activate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor more information on how to create a virtual environment in Python refer to\nthe PEP 405 \u2013 Python Virtual Environments documentation.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eSet up and activate Spack\u003c/h4\u003e\u003ca id=\"user-content-set-up-and-activate-spack\" class=\"anchor\" aria-label=\"Permalink: Set up and activate Spack\" href=\"#set-up-and-activate-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSee the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\" rel=\"nofollow\"\u003eSpack documentation\u003c/a\u003e\non how to install Spack. For sake of completeness, we copy paste the commands here:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eInstall \u003ccode\u003espack-sdploy\u003c/code\u003e dependencies\u003c/h4\u003e\u003ca id=\"user-content-install-spack-sdploy-dependencies\" class=\"anchor\" aria-label=\"Permalink: Install spack-sdploy dependencies\" href=\"#install-spack-sdploy-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUp to now the only dependency of spack-sdploy if jinja2. Once you have activated\nPython environment, you can simply use pip to install the packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install jinja2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eClone and configure spack-sdploy\u003c/h4\u003e\u003ca id=\"user-content-clone-and-configure-spack-sdploy\" class=\"anchor\" aria-label=\"Permalink: Clone and configure spack-sdploy\" href=\"#clone-and-configure-spack-sdploy\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@github.com:epfl-scitas/spack-sdploy\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo activate the spack-sdploy extension you must add it to the config.yaml. If\nyou already have another Spack installation and just want to try out\nspack-sdploy may very well create a temporary directory to store the\nconfiguration and then use the SPACK_USER_CONFIG_PATH variable to point this new\ndirectory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand then, inside the temporary_config directory, write a config.yaml file with\nthe following contents:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econfig:\n  extensions:\n  - /path/to/spack-sdploy\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBe sure you do not change the spack-dploy directory. Spack forces the extensions\nto follow strict rules. Please see the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\u003eSpack Extensions\u003c/a\u003e\ndocumentation for more details about this subject. At this point you should now\nbe able to call \u003ccode\u003espack -h\u003c/code\u003e and see the new Spack commands deployed by the\nspack-sdploy extension.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to use\u003c/h2\u003e\u003ca id=\"user-content-how-to-use\" class=\"anchor\" aria-label=\"Permalink: How to use\" href=\"#how-to-use\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAt the present time, spack-sdploy will add 2 commands to your already existing\nSpack commands. These commandes are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack write-spack-yaml\nspack write-packages-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn the future we may change the names of these commands, but for now lets just\nimagine these are short and easy to type commands.\u003c/p\u003e\n\u003cp\u003eAs you may have guessed it (if you haven\u0027t that\u0027s ok), write-spack-yaml will\nwrite the spack.yaml file and write-packages-yaml will write the packages.yaml\nfile. Of course, Spack does not (yet!) guess what you may want to install and\nfor that purpose, both these commands will read all the specs you want in your\nspack.yaml file by reading another file you have previously written and which\nwe call by stack.yaml.\u003c/p\u003e\n\u003cp\u003eFor the time being, spack-sdploy already comes with a dummy stack.yaml so we can\nget started using the new commands.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ewrite-spack-yaml\u003c/h2\u003e\u003ca id=\"user-content-write-spack-yaml\" class=\"anchor\" aria-label=\"Permalink: write-spack-yaml\" href=\"#write-spack-yaml\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003espack write-spack-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ewrite-packages-yaml\u003c/h2\u003e\u003ca id=\"user-content-write-packages-yaml\" class=\"anchor\" aria-label=\"Permalink: write-packages-yaml\" href=\"#write-packages-yaml\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003espack write-packages-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ewrite-activate-list\u003c/h2\u003e\u003ca id=\"user-content-write-activate-list\" class=\"anchor\" aria-label=\"Permalink: write-activate-list\" href=\"#write-activate-list\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003espack write-activate-list -p \u0026lt;platform\u0026gt; -s \u0026lt;stack\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWrite to file named \u003ccode\u003epackages_to_activate\u003c/code\u003e list of packages to activate, using \u003ccode\u003espack activate \u0026lt;package\u0026gt;\u003c/code\u003e. Packages are writen one per line.\u003c/p\u003e\n\u003cp\u003ePackages to activate can be marked in the stack file in two possible ways: by adding the keyword \u003ccode\u003eactivate: true\u003c/code\u003e in the metadata section of a list of packages or by adding the keyword \u003ccode\u003eactivate: true\u003c/code\u003e to an individual package. Duplicates are removed.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1707117642.0
  },
  {
    "data_format": 2,
    "description": "Gitlab CI automation of Spack testing with RADIUSS projects builds.",
    "filenames": [
      "spack-environments/raja-suite/spack.yaml"
    ],
    "full_name": "LLNL/radiuss-spack-testing",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eRADIUSS Spack Testing\u003c/h1\u003e\u003ca id=\"user-content-radiuss-spack-testing\" class=\"anchor\" aria-label=\"Permalink: RADIUSS Spack Testing\" href=\"#radiuss-spack-testing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe RADIUSS project promotes and supports key High Performance Computing (HPC) open-source software developed at the LLNL. These tools and libraries cover a wide range of features a team would need to develop a modern simulation code targeting HPC plaftorms.\u003c/p\u003e\n\u003cp\u003eRADIUSS Spack Testing is a sub-project from the RADIUSS initiative providing a\ntesting infrastructure to test Spack Packages automatically in GitLab while\ntracking changes in Spack.\u003c/p\u003e\n\u003cp\u003eAccess the \u003ca href=\"https://radiuss-spack-testing.readthedocs.io/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe primary goal of this repo is to be used in Gitlab. The Gitlab CI configuration is such that it will use Spack pipeline feature to generate and run a pipeline that builds one of the environments in the \u003ccode\u003espack-environments\u003c/code\u003e directory.\u003c/p\u003e\n\u003cp\u003eThe specific environment to be built is controlled by the CI variable \u003ccode\u003eENV_NAME\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstalling\u003c/h3\u003e\u003ca id=\"user-content-installing\" class=\"anchor\" aria-label=\"Permalink: Installing\" href=\"#installing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis project requires no installation.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease read \u003ca href=\"https://github.com/LLNL/radiuss-spack-testing/CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e for details on our code of conduct, and the process for submitting pull requests to us.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVersioning\u003c/h2\u003e\u003ca id=\"user-content-versioning\" class=\"anchor\" aria-label=\"Permalink: Versioning\" href=\"#versioning\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eversion: 1.0.0\u003c/p\u003e\n\u003cp\u003eTODO: Not even sure how to handle versioning here.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAdrien M Bernede\u003c/p\u003e\n\u003cp\u003eSee also the list of \u003ca href=\"https://github.com/LLNL/radiuss-spack-testing/contributors\"\u003econtributors\u003c/a\u003e who participated in this project.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis project is licensed under the MIT License - see the \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e file for details\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under the MIT License.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/LLNL/radiuss-spack-testing/blob/master/LICENSE\"\u003eLICENSE\u003c/a\u003e,\n\u003ca href=\"https://github.com/LLNL/radiuss-spack-testing/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/LLNL/radiuss-spack-testing/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-793462\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgments\u003c/h2\u003e\u003ca id=\"user-content-acknowledgments\" class=\"anchor\" aria-label=\"Permalink: Acknowledgments\" href=\"#acknowledgments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 7,
    "topics": [
      "radiuss"
    ],
    "updated_at": 1679009672.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ci/fms-gnu/spack.yaml"
    ],
    "full_name": "NOAA-GFDL/HPC-ME",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eHPC-ME: HPC Portable Containers for Model Environments\u003c/h1\u003e\u003ca id=\"user-content-hpc-me-hpc-portable-containers-for-model-environments\" class=\"anchor\" aria-label=\"Permalink: HPC-ME: HPC Portable Containers for Model Environments\" href=\"#hpc-me-hpc-portable-containers-for-model-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContents\u003c/h2\u003e\u003ca id=\"user-content-contents\" class=\"anchor\" aria-label=\"Permalink: Contents\" href=\"#contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#what-is-hpc-me\"\u003eWhat is HPC-ME\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#list-of-current-compilers\"\u003eList of current compilers/MPI/OS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#list-of-current-libraries\"\u003eList of current libraries\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#how-to-build\"\u003eHow to build\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#how-to-use\"\u003eHow to use\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#gfdl-example\"\u003eGFDL example\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#planned-improvements\"\u003ePlanned improvements\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWhat is HPC-ME\u003c/h2\u003e\u003ca id=\"user-content-what-is-hpc-me\" class=\"anchor\" aria-label=\"Permalink: What is HPC-ME\" href=\"#what-is-hpc-me\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHPC Portable Container - Model Environments is a set of Dockerfiles, Singularity Definition files, and containers to provide portable model environments for scientific applications that require the same set of libraries.  The ultimate goal is to have a community-based list of libraries that are needed for compiling, executing, and post-processing earth science models.  We all use many of the same underlying libraries, and by working together we can agree upon a community-based approach to making container usage as standardized as possible.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eList of current compilers/MPI/OS\u003c/h2\u003e\u003ca id=\"user-content-list-of-current-compilersmpios\" class=\"anchor\" aria-label=\"Permalink: List of current compilers/MPI/OS\" href=\"#list-of-current-compilersmpios\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor each container, there is a full version that contains the programming environment and a smaller runtime environment that can be used to run compiled executables. (The runtime container definition files will be added soon.)\n#- \u003ca href=\"Dockerfile_gnu_ubuntu20.04\"\u003egcc 8/mpich/ubuntu 20.04\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"Dockerfile_gnu_rhel8\"\u003egcc 8/mpich/RHEL8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"Dockerfile_intel_ubuntu18.04\"\u003eintel oneAPI 2022.1/mpich(impi)/ubuntu 18.04\u003c/a\u003e\n#- \u003ca href=\"Dockerfile_intel_centos8\"\u003eintel oneAPI 2021.4/mpich(impi)/centos 8\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eList of current libraries\u003c/h2\u003e\u003ca id=\"user-content-list-of-current-libraries\" class=\"anchor\" aria-label=\"Permalink: List of current libraries\" href=\"#list-of-current-libraries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is the current list of most of the libraries used in the HPC-ME containers (We are trying to keep this up-to-date).\nThe complete list should be found in the respective YAML file.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#automake\" rel=\"nofollow\"\u003eautomake@1.16.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#bacio\" rel=\"nofollow\"\u003ebacio@2.4.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#berkeley-db\" rel=\"nofollow\"\u003eberkeley-db@18.1.40\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#bison\" rel=\"nofollow\"\u003ebison@3.7.6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#bzip2\" rel=\"nofollow\"\u003ebzip2@1.0.8\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#cmake\" rel=\"nofollow\"\u003ecmake@3.21.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#crtm\" rel=\"nofollow\"\u003ecrtm@2.3.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#curl\" rel=\"nofollow\"\u003ecurl@7.78.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#diffutils\" rel=\"nofollow\"\u003ediffutils@3.7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#esmf\" rel=\"nofollow\"\u003eesmf@8.1.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#expat\" rel=\"nofollow\"\u003eexpat@2.4.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#g2\" rel=\"nofollow\"\u003eg2@3.4.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#g2tmpl\" rel=\"nofollow\"\u003eg2tmpl@1.10.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#gdbm\" rel=\"nofollow\"\u003egdbm@1.19\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#gsl\" rel=\"nofollow\"\u003egsl@2.7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#hdf5\" rel=\"nofollow\"\u003ehdf5@1.10.7\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#ip\" rel=\"nofollow\"\u003eip@3.3.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#ip2\" rel=\"nofollow\"\u003eip2@1.1.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#jasper\" rel=\"nofollow\"\u003ejasper@2.0.32\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libbsd\" rel=\"nofollow\"\u003elibbsd@0.11.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libiconv\" rel=\"nofollow\"\u003elibiconv@1.16\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libjpeg-turbo\" rel=\"nofollow\"\u003elibjpeg-turbo@2.1.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libmd\" rel=\"nofollow\"\u003elibmd@1.0.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libpng\" rel=\"nofollow\"\u003elibpng@1.6.37\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libsigsegv\" rel=\"nofollow\"\u003elibsigsegv@2.13\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libtool\" rel=\"nofollow\"\u003elibtool@2.4.6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libxml2\" rel=\"nofollow\"\u003elibxml2@2.9.12\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#libyaml\" rel=\"nofollow\"\u003elibyaml@0.2.5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#lmod\" rel=\"nofollow\"\u003elmod@8.5.6\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#m4\" rel=\"nofollow\"\u003em4@1.4.19\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#nasm\" rel=\"nofollow\"\u003enasm@2.15.05\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#nccmp\" rel=\"nofollow\"\u003enccmp@1.8.6.5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#nco\" rel=\"nofollow\"\u003enco@4.7.9\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#ncurses\" rel=\"nofollow\"\u003encurses@6.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#nemsio\" rel=\"nofollow\"\u003enemsio@2.5.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#netcdf-c\" rel=\"nofollow\"\u003enetcdf-c@4.8.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#netcdf-fortran\" rel=\"nofollow\"\u003enetcdf-fortran@4.5.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#numactl\" rel=\"nofollow\"\u003enumactl@2.0.14\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openssl\" rel=\"nofollow\"\u003eopenssl@1.1.1m\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#parallel-netcdf\" rel=\"nofollow\"\u003eparallel-netcdf@1.12.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#perl\" rel=\"nofollow\"\u003eperl@5.34.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#pkgconf\" rel=\"nofollow\"\u003epkgconf@1.8.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#readline\" rel=\"nofollow\"\u003ereadline@8.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#sfcio\" rel=\"nofollow\"\u003esfcio@1.4.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#sigio\" rel=\"nofollow\"\u003esigio@2.3.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#sp\" rel=\"nofollow\"\u003esp@2.3.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#udunits\" rel=\"nofollow\"\u003eudunits@2.2.28\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#w3emc\" rel=\"nofollow\"\u003ew3emc@2.9.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#w3nco\" rel=\"nofollow\"\u003ew3nco@2.4.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#wrf-io\" rel=\"nofollow\"\u003ewrf-io@1.2.0\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#xerces-c\" rel=\"nofollow\"\u003exerces-c@3.2.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#xz\" rel=\"nofollow\"\u003exz@5.2.5\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#zlib\" rel=\"nofollow\"\u003ezlib@1.2.11\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to build\u003c/h2\u003e\u003ca id=\"user-content-how-to-build\" class=\"anchor\" aria-label=\"Permalink: How to build\" href=\"#how-to-build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eWe plan to make this step optional soon.\u003c/strong\u003e In order to build the Docker images, you will need access to a computer with root-like access, and either docker or singularity installed. If you do not have root-like access to a suitable machine, you can still run images that were already created (e.g. on Docker hub), and we plan on hosting runnable Docker images along with the Dockerfiles in this repository soon. If you have root-like access and docker, start by choosing one of the currently supported model environments from the list above. Then build the Docker container from the Dockerfile using docker build; for example, to build the gcc8/mpich/ubuntu18 container:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edocker build --file Dockerfile_gnu_ubuntu20.04 . --tag hpc-me.ubuntu.gnu\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe build process takes approximately 2-3 hours, as the packages are downloaded and compiled using Spack. After a successful build, you will see that the image was built and tagged successfully:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSuccessfully built 90a878af77b4\nSuccessfully tagged hpc-me.rhel8.gnu:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, you may run the container using docker or singularity on the same host. To run the image on a different machine, pushing the image to Docker Hub is recommended. Note that you will need a DockerHub account to do this (replace USER with your Docker user ID in the examples below). For example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edocker tag hpc-me.rhel8.gnu USER/hpc-me.rhel8.gnu\ndocker login\ndocker push USER/hpc-me.rhel8.gnu:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to use\u003c/h2\u003e\u003ca id=\"user-content-how-to-use\" class=\"anchor\" aria-label=\"Permalink: How to use\" href=\"#how-to-use\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe plan to make improvements on this process. Also, while we plan on making Docker images available on the GitHub container registry, currently you must build the images yourself. Please start with the \u003ca href=\"#how-to-build\"\u003eBuild instructions\u003c/a\u003e to generate a Docker image with your desired OS/compiler HPC-ME environment. Then you may run the container using docker or singularity; singularity is more likely than docker to be available on HPC environments.\u003c/p\u003e\n\u003cp\u003eThe usage documentation consists of some general notes on serial/parallel usage, files inside and outside the container, downloading the containers, and then specific usage scenarios:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#serial-applications-using-docker\"\u003eSerial applications using docker\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#serial-applications-using-singularity\"\u003eSerial applications using singularity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#parallel-applications-using-singularity\"\u003eParallel applications using singularity\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSerial and parallel usage\u003c/h3\u003e\u003ca id=\"user-content-serial-and-parallel-usage\" class=\"anchor\" aria-label=\"Permalink: Serial and parallel usage\" href=\"#serial-and-parallel-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHPC-ME containers are intended for both serial and parallel applications. Serial applications include compiling model executables, generating input grids, and post-processing model output. Earth system, climate, and weather models require parallelism to run efficiently, and use one of the Message Passage Interface (MPI) implementations OpenMPI, Intel MPI, or mpich. GCC-based HPC-ME containers use the mpich-based MPI library, which is widely available on most HPC sites, and the Intel-based containers contain both mpich and Intel MPI.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eNotes on filesystems and writing files\u003c/h3\u003e\u003ca id=\"user-content-notes-on-filesystems-and-writing-files\" class=\"anchor\" aria-label=\"Permalink: Notes on filesystems and writing files\" href=\"#notes-on-filesystems-and-writing-files\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe recommend not saving or modifying files within the environment container, and instead create and modify files on your regular filesystem. To do this, you will need to connect your filesystem to your container using bind mounts.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDownloading containers and managing images on the filesystem\u003c/h3\u003e\u003ca id=\"user-content-downloading-containers-and-managing-images-on-the-filesystem\" class=\"anchor\" aria-label=\"Permalink: Downloading containers and managing images on the filesystem\" href=\"#downloading-containers-and-managing-images-on-the-filesystem\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce you have pushed your images to DockerHub, you will need to download them before using. In the examples below, replace USER with your Docker Hub ID. If using docker,\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003edocker pull USER/hpc-me.rhel8.gnu:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf using singularity,\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esingularity pull docker://USER/hpc-me.rhel8.gnu:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf using singularity, the image file (SIF format) is saved to the current working directory\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; ls *.sif\n-rwxr-xr-x 532M Dec 10 16:09 hpc-me.rhel8.gnu_latest.sif*\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf using docker, the downloaded image is handled by the central docker service.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSerial applications using docker\u003c/h3\u003e\u003ca id=\"user-content-serial-applications-using-docker\" class=\"anchor\" aria-label=\"Permalink: Serial applications using docker\" href=\"#serial-applications-using-docker\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou may activate an interactive shell within the desired HPC-ME container using docker. After running the container, the compilers and tools available within the container will be accessible in your PATH; e.g.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt; docker run -it hpc-me.rhel8.gnu:latest\n\n[root@0d2cf64e1175 /]# which nf-config\n/opt/view/bin/nf-config\n\n[root@0d2cf64e1175 /]# nf-config --version\nnetCDF-Fortran 4.5.3\n\n[root@0d2cf64e1175 /]# nf-config --cflags\n-I/opt/software/linux-rhel8-x86_64/gcc-8.4.1/netcdf-fortran-4.5.3-g5qfkdlp36unt2s4j4wyrc6heh2sa64n/include\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSerial applications using singularity\u003c/h3\u003e\u003ca id=\"user-content-serial-applications-using-singularity\" class=\"anchor\" aria-label=\"Permalink: Serial applications using singularity\" href=\"#serial-applications-using-singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSingularity can run Docker images and is more likely to be available on HPC environments. As with docker run, the HPC-ME tools and compilers are available in the shell, somewhat similar to loading a set of Environment Modules prepared by site administrators.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u0026gt;singularity run hpc-me.rhel8.gnu_latest.sif\n\nSingularity\u0026gt; which nf-config\n/opt/view/bin/nf-config\n\nSingularity\u0026gt; nf-config --version\nnetCDF-Fortran 4.5.3\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eParallel applications using singularity\u003c/h3\u003e\u003ca id=\"user-content-parallel-applications-using-singularity\" class=\"anchor\" aria-label=\"Permalink: Parallel applications using singularity\" href=\"#parallel-applications-using-singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHPC-ME containers can provide the runtime environment for MPI applications. For instance, one could compile an MPI application using the instructions above using one of the HPC-ME development containers; and then run the application using the corresponding runtime HPC-ME container.\u003c/p\u003e\n\u003cp\u003ePlease note that we are continuing to improve the usability of HPC-ME containers as well as provide more usage examples.\u003c/p\u003e\n\u003cp\u003eUsually, GFDL climate models are run on gaea by submitting a runscript to the Slurm scheduler. The runscript loads needed runtime Environment Modules, prepares input directories and files, and executes the MPI executable using srun. The HPC-ME containers provide the necessary runtime environment, obviating the need for loading Environment Modules. Currently, our approach for using the HPC-ME containers is as follows:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCreate a new container, starting with the desired HPC-ME runtime container\u003c/li\u003e\n\u003cli\u003eAdd the MPI-compiled executable to the container filesystem\u003c/li\u003e\n\u003cli\u003eSet the MPI-compiled executable to as the container\u0027s command (so that when the container is run the MPI executable within the container runs)\u003c/li\u003e\n\u003cli\u003eRun the singularity container SIF file using srun within the runscript, replacing the traditional MPI executable.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eReplace \"srun executable.x\" with \"srun singularity run container.SIF\"\u003c/li\u003e\n\u003cli\u003eAdd --mpi=pmi2 to the srun call, which connects the system MPI to the container MPI to the singularity run call\u003c/li\u003e\n\u003cli\u003eBind the working directory so that the container has access to the input files and can write output files (singularity run -B=/path/to/workdir)\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eSubmit the modified runscript to the scheduler\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWe plan to provide more examples and usage scenarios, such as using the HPC-ME containers as-is (i.e. not creating a new container as described above)\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGFDL example\u003c/h2\u003e\u003ca id=\"user-content-gfdl-example\" class=\"anchor\" aria-label=\"Permalink: GFDL example\" href=\"#gfdl-example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAn example of using an HPC-ME container with the GFDL FRE workflow can be found \u003ca href=\"GFDL_EXAMPLE.md\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePlanned improvements\u003c/h2\u003e\u003ca id=\"user-content-planned-improvements\" class=\"anchor\" aria-label=\"Permalink: Planned improvements\" href=\"#planned-improvements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHPC-ME is a work in progress under active development, so please check back or follow the repository for more updates.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild cache\u003c/h3\u003e\u003ca id=\"user-content-build-cache\" class=\"anchor\" aria-label=\"Permalink: Build cache\" href=\"#build-cache\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe are working to create a build cache for the libraries listed so that building the containers is quick and easy.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eGithub container registry\u003c/h3\u003e\u003ca id=\"user-content-github-container-registry\" class=\"anchor\" aria-label=\"Permalink: Github container registry\" href=\"#github-container-registry\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe are working to add CI capability to this repository, so that the containers will be automatically built and stored in the github container registry. This will make building unnecessary for most cases, though users may build the containers themselves if they wish (e.g. for custom modifications).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMore usage examples and documentation, especially for MPI applications\u003c/h3\u003e\u003ca id=\"user-content-more-usage-examples-and-documentation-especially-for-mpi-applications\" class=\"anchor\" aria-label=\"Permalink: More usage examples and documentation, especially for MPI applications\" href=\"#more-usage-examples-and-documentation-especially-for-mpi-applications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe are still learning how to best use the HPC-ME containers with MPI appliations, so please check back.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDisclaimer\u003c/h3\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-label=\"Permalink: Disclaimer\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is provided\non an \u0027as is\u0027 basis and the user assumes responsibility for its use. DOC has\nrelinquished control of the information and no longer has responsibility to\nprotect the integrity, confidentiality, or availability of the information. Any\nclaims against the Department of Commerce stemming from the use of its GitHub\nproject will be governed by all applicable Federal law. Any reference to\nspecific commercial products, processes, or services by service mark,\ntrademark, manufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial product\nor activity by DOC or the United States Government.\u003c/p\u003e\n\u003cp\u003eThis project code is made available through GitHub but is managed by NOAA-GFDL\nat \u003ca href=\"https://gitlab.gfdl.noaa.gov\" rel=\"nofollow\"\u003ehttps://gitlab.gfdl.noaa.gov\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1710337744.0
  },
  {
    "data_format": 2,
    "description": "NCAR supercomputer user software installed and maintained using Spack",
    "filenames": [
      "clusters/casper/spack.yaml"
    ],
    "full_name": "NCAR/ncar-spack",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003encar-spack\u003c/h1\u003e\u003ca id=\"user-content-ncar-spack\" class=\"anchor\" aria-label=\"Permalink: ncar-spack\" href=\"#ncar-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWhat is ncar-spack?\u003c/h2\u003e\u003ca id=\"user-content-what-is-ncar-spack\" class=\"anchor\" aria-label=\"Permalink: What is ncar-spack?\" href=\"#what-is-ncar-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains cluster configurations for NCAR HPC software stacks, a deployment script, and helper scripts that get installed into a cluster deployment to facilitate reproducible and consistent package management across the consulting team.\u003c/p\u003e\n\u003cp\u003eIt is also important to note what this repository is \u003cstrong\u003enot\u003c/strong\u003e. It is not a fork of Spack itself - though a cluster \u003cem\u003eshould\u003c/em\u003e use the CSG Spack fork. It is also not for tracking a production cluster deployment. Rather, this repository contains the recipe and the tools for starting a deployment, which is then tracked in its own repo!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe following instructions describe cloning this repository and starting a new cluster deployment. If you want to know how to install a package into an existing deployment, create a new cluster recipe, or update a cluster recipe in this repository from changes made in production, see the appropriate section below.\u003c/p\u003e\n\u003cp\u003eTo get started, simply clone this repository either as yourself or as \u003cem\u003ecsgteam\u003c/em\u003e. If you plan to produce a public production cluster deployment, you will need to run as \u003cem\u003ecsgteam\u003c/em\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@github.com:NCAR/ncar-spack.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003eThe clone command above assumes SSH-key usage!\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eVim users: YAML configuration\u003c/h4\u003e\u003ca id=\"user-content-vim-users-yaml-configuration\" class=\"anchor\" aria-label=\"Permalink: Vim users: YAML configuration\" href=\"#vim-users-yaml-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSince Spack will output YAML lines with two-space indentation, the following Vim settings are recommended:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ cat ~/.vim/after/ftplugin/yaml.vim\nsetlocal shiftwidth=2\nsetlocal tabstop=2\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDeploying a cluster from scratch\u003c/h2\u003e\u003ca id=\"user-content-deploying-a-cluster-from-scratch\" class=\"anchor\" aria-label=\"Permalink: Deploying a cluster from scratch\" href=\"#deploying-a-cluster-from-scratch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCluster definitions are contained in the \u003ccode\u003eclusters\u003c/code\u003e subdirectory and typically contain the following components:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eclusters/\n\u251c\u2500\u2500 casper\n\u2502   \u251c\u2500\u2500 constraints.cfg - external packages, and packages required to use the system GCC\n\u2502   \u251c\u2500\u2500 main.cfg        - top-level path, name, and version settings for the cluster deployment\n\u2502   \u251c\u2500\u2500 packages.cfg    - an inventory of packages to be built upon deployment (and beyond)\n\u2502   \u251c\u2500\u2500 postprocess     - a bash script that runs last and does cluster prep that Spack cannot\n\u2502   \u251c\u2500\u2500 repos.cfg       - any custom package repositories to include (i.e. ncar.hpcd recipes)\n\u2502   \u2514\u2500\u2500 spack.yaml      - the Spack environment template that will become the cluster stack\n...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRemember, these are simply templates! To generate a cluster deployment from one of these recipes, simply run the \u003ccode\u003edeploy\u003c/code\u003e script in the top-level directory. For example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./deploy [--production] [--no-pkgs] casper\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis command will clone csg-spack-fork and check out the branch specified in the cluster\u0027s \u003cstrong\u003emain.cfg\u003c/strong\u003e (or use the \u003ccode\u003encar-mods\u003c/code\u003e branch if left blank), copy the cluster recipe template and replace placeholders with proper paths and settings, set up a build cache mirror if one does not already exist, and (\u003cem\u003eif \u003ccode\u003e--no-pkgs\u003c/code\u003e is not set\u003c/em\u003e) will build the packages specified in \u003cstrong\u003epackages.cfg\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003e--production\u003c/code\u003e flag can only be specified when running as \u003cem\u003ecsgteam\u003c/em\u003e. Without this flag, a \u003cem\u003etest\u003c/em\u003e deployment will be created at the location configured in the cluster definition (probably your scratch directory). Doing a test deployment can be a good way to learn how this all works without breaking things, and is recommended! \ud83d\udc4d\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003eKeep in mind that changes made after you deploy a cluster will cause divergence from the recipe contained in this repo. This is expected, but if you wish to propagate those changes to a new version of the deployment, you should merge them into the recipe and push the changes to ncar-spack (see below)!\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling a new package\u003c/h2\u003e\u003ca id=\"user-content-installing-a-new-package\" class=\"anchor\" aria-label=\"Permalink: Installing a new package\" href=\"#installing-a-new-package\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAs new versions of popular libraries (e.g., \u003cem\u003enetcdf\u003c/em\u003e) are released, and users request new packages, consultants will need to augment cluster deployments. All of the tools to do this robustly are provided in a cluster deployment. Here, we will run through an example for a production install, and so these steps assume working as \u003cem\u003ecsgteam\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eFirst, a word about how the deployment is structured. There should exist one Spack clone, and two Spack environments: a \u003cem\u003ebuild\u003c/em\u003e environment and a \u003cem\u003epublic\u003c/em\u003e environment. The build environment is what you will interact with. Packages are build from source in the \u003cem\u003ebuild\u003c/em\u003e environment, and any changes should not be visible to users. Only when you are happy with your changes in the \u003cem\u003ebuild\u003c/em\u003e environment should you \u003ccode\u003epublish\u003c/code\u003e them into the \u003cem\u003epublic\u003c/em\u003e environment.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eEnvironment prep: \u003ccode\u003eclean_bash\u003c/code\u003e and \u003ccode\u003espacktivate\u003c/code\u003e\n\u003c/h3\u003e\u003ca id=\"user-content-environment-prep-clean_bash-and-spacktivate\" class=\"anchor\" aria-label=\"Permalink: Environment prep: clean_bash and spacktivate\" href=\"#environment-prep-clean_bash-and-spacktivate\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBefore doing anything with a cluster deployment, you should first launch a clean bash shell that has been scrubbed of personal settings and modules. Since this step is fundamental to using \u003cem\u003encar-spack\u003c/em\u003e, a script called \u003ccode\u003eclean_bash\u003c/code\u003e is provided in the csg-spack-fork to do this for you. The script will also initialize Spack to run in your environment, and change your directory to the \u003cem\u003ebuild\u003c/em\u003e environment.\u003c/p\u003e\n\u003cp\u003eThe script can be found in the \u003ccode\u003ebin\u003c/code\u003e directory of the clone Spack, and it is also typically configured to run as a shell function when you are \u003cem\u003ecsgteam\u003c/em\u003e (via \u003cstrong\u003e.bashrc\u003c/strong\u003e settings).\u003c/p\u003e\n\u003cp\u003eOnce you are in a sanitized bash shell, you can \"activate\" the \u003cem\u003ebuild\u003c/em\u003e environment. This step is important, because otherwise Spack will make decisions based on the configuration in the Spack clone settings directory, rather than our environment settings contained in \u003cstrong\u003espack.yaml\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eFor example:\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eclean_bash\nspacktivate -p .\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSince \u003ccode\u003eclean_bash\u003c/code\u003e places you in the \u003cem\u003ebuild\u003c/em\u003e directory, you can use \u003ccode\u003e.\u003c/code\u003e to indicate the environment path. The \u003ccode\u003e-p\u003c/code\u003e option provides a nice prompt decorator indicating the build environment is active.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUpdating the \u003cem\u003ebuiltin\u003c/em\u003e repo to get new package versions\u003c/h3\u003e\u003ca id=\"user-content-updating-the-builtin-repo-to-get-new-package-versions\" class=\"anchor\" aria-label=\"Permalink: Updating the builtin repo to get new package versions\" href=\"#updating-the-builtin-repo-to-get-new-package-versions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUnfortunately, some terminology is overloaded here. In addition to Spack itself being a Git repository, Spack stores its package recipes in a package repository. The default repo is called \u003cem\u003ebuiltin\u003c/em\u003e, and is contained with Spack itself in the Spack Git repo. The problem is that checking out a newer version of Spack or its \u003cem\u003ebuiltin\u003c/em\u003e repo will update many things - including the package API and package recipes. This can cause packages to concretize differently and reduce reproducibility, and in some cases can even break the whole deployment.\u003c/p\u003e\n\u003cp\u003e\ud83d\udea8 \u003cstrong\u003eUpdating the entire Spack clone should be avoided - consider this a scenario for creating a new deployment!\u003c/strong\u003e \ud83d\udea8\u003c/p\u003e\n\u003cp\u003eSo let\u0027s say a user wants the latest and greatest version of a package, and the version you see provided by our Spack clone is older (use \u003ccode\u003espack info \u0026lt;package\u0026gt;\u003c/code\u003e to check versions). In this scenario, aim for the least invasive changes possible. Typically, this means checking out only the desired package from the main Spack upstream. The \u003ccode\u003edeploy\u003c/code\u003e script will configure the cloned Spack to have an upstream remote to the main Spack repo.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eExample: Installing the latest ESMF\u003c/h4\u003e\u003ca id=\"user-content-example-installing-the-latest-esmf\" class=\"anchor\" aria-label=\"Permalink: Example: Installing the latest ESMF\" href=\"#example-installing-the-latest-esmf\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA user wants ESMF 8.6.0, but the deployed Spack clone only provides up to 8.5.2. Here is how you would obtain a newer version:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd $SPACK_ROOT/var/spack/repos/builtin/packages\ngit fetch upstream develop\ngit checkout upstream/develop -- esmf\ncd $SPACK_ENV\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThese commands will only check out the updated ESMF package recipe (including the \u003cstrong\u003epackage.py\u003c/strong\u003e and any new/modified patches). Note that sometimes you will need to update dependencies too if your package has changes that are incompatible with the current dependency recipe. But aim for the least number of changes possible to get a successful build. And if the version the user wants is provided already (or they don\u0027t care which version), then great, skip this section!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConfiguring an optimal package build\u003c/h3\u003e\u003ca id=\"user-content-configuring-an-optimal-package-build\" class=\"anchor\" aria-label=\"Permalink: Configuring an optimal package build\" href=\"#configuring-an-optimal-package-build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBefore installing any package, you should always run these two commands:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003ccode\u003espack info \u0026lt;spec\u0026gt;\u003c/code\u003e - tells you which versions are availabe and which variants can be used to modify how the package will be built\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003espack spec -I -l \u0026lt;spec\u0026gt;\u003c/code\u003e - shows you exactly how the package will be built as currently configured, including the dependencies Spack will use; the \u003ccode\u003e-I\u003c/code\u003e flag will decorate the output with an indicator telling you whether the package is currently installed \u003ccode\u003e[+]\u003c/code\u003e, an external \u003ccode\u003e[e]\u003c/code\u003e, or needs to be installed \u003ccode\u003e[-]\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFirst, think about which variants you will need to configure to meet the user\u0027s request. Also, consider whether the package should use the system compiler or be built with our \u003cem\u003emodule-loadable\u003c/em\u003e compilers. It typically makes sense to use the system compiler for lower level packages that get used as dependencies often like \u003cem\u003epython\u003c/em\u003e and \u003cem\u003eqt\u003c/em\u003e. On the other hand, if a package depends on MPI you will almost certainly want to built it using the module compilers.\u003c/p\u003e\n\u003cp\u003eThe package build can be configured either in the \u003cem\u003espec\u003c/em\u003e or specifying preferences and requirements in the \u003cstrong\u003espack.yaml\u003c/strong\u003e. I prefer the latter, when possible, as these settings will often influence how the package gets used as dependencies, and will also help narrow the behavior if a user wants to use our deployment as a Spack \u003cem\u003eupstream\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eIf you wish to constrain any uninstalled dependencies of your package to use the system compiler, add them to the \u003cstrong\u003econstraints.cfg\u003c/strong\u003e file in the \u003cem\u003ebuild\u003c/em\u003e environment and then run \u003ccode\u003ebin/add_constraints\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuilding the package\u003c/h3\u003e\u003ca id=\"user-content-building-the-package\" class=\"anchor\" aria-label=\"Permalink: Building the package\" href=\"#building-the-package\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce you are happy with the build configuration and have implemented any desired constraints/preferences/requirements, you can install the package into the build environment. You \u003cem\u003ecould\u003c/em\u003e do this with the following Spack command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install --add \u0026lt;spec\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHowever, this method will not span multiple compilers/MPIs and also does not log who performed the install. Instead, a helper script is provided to make complex installs easier (and put logs in an easy to find location).\u003c/p\u003e\n\u003cp\u003eTo install the package, add the \u003ccode\u003e\u0026lt;spec\u0026gt;\u003c/code\u003e into the \u003cstrong\u003epackages.cfg\u003c/strong\u003e file in an appropriate subsection - packages can be one of the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003esingleton\u003c/strong\u003e - only a single configuration of this package is installed\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003ecdep\u003c/strong\u003e - the package will be installed for every non-system compiler defined in \u003cstrong\u003epackages.cfg\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003emdep\u003c/strong\u003e - the package will be installed for the matrix of compilers and MPIs defined in this file\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEventual user access to the package can be configured via the \u003ccode\u003eaccess\u003c/code\u003e tag. By default, a new package will produce an environment module that can be loaded. However, you can configure the package to appear in the \u003cem\u003eview\u003c/em\u003e instead using \u003ccode\u003eaccess=view\u003c/code\u003e. Any package in the \u003cem\u003eview\u003c/em\u003e will be in the user environment by default when the \u003cstrong\u003encarenv\u003c/strong\u003e module is loaded, as if it were a system package installed using zypper/yum/apt-get.\u003c/p\u003e\n\u003cp\u003eThere are many additional specifications that can be set on sections and individual packages in this configuration file. See existing listings for inspiration (\u003cem\u003efull documentation TBD\u003c/em\u003e).\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003eNote that compilers and MPIs installed into the \u003cstrong\u003espack.yaml\u003c/strong\u003e but not listed in \u003cstrong\u003epackages.cfg\u003c/strong\u003e will NOT be used for cdep and mdep  sections. This is another useful feature of using \u003cstrong\u003epackages.cfg\u003c/strong\u003e - think of it a record of the \"actively updated\" compiler and MPI stacks, while \u003cstrong\u003espack.yaml\u003c/strong\u003e contains both active and inactive/deprecated versions.\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eOnce you have added the package \u003ccode\u003e\u0026lt;spec\u0026gt;\u003c/code\u003e to \u003cstrong\u003epackages.cfg\u003c/strong\u003e, you can begin the source builds by running \u003ccode\u003ebin/install_packages\u003c/code\u003e. If all goes well, this should install the package(s) and any necessary dependencies into the \u003cem\u003ebuild\u003c/em\u003e environment. If something goes wrong, ask colleagues in \u003cstrong\u003e#spack\u003c/strong\u003e on the \u003cstrong\u003ehpc-ucar\u003c/strong\u003e Slack. \ud83d\udcac\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTesting the package\u003c/h3\u003e\u003ca id=\"user-content-testing-the-package\" class=\"anchor\" aria-label=\"Permalink: Testing the package\" href=\"#testing-the-package\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce you have successfully built the package, you should run the following additional steps to prepare the build environment for testing:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack module lmod refresh -y\nbin/postprocess\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEven if your package does not produce a new environment module, it is good to run these commands to get a sense of how the production environment will look to users. Once this is ready, you can use a helper script to switch your environment from the default (production \u003cem\u003epublic\u003c/em\u003e) to the build stack:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebin/use_modules[.csh]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou should see your package binaries/libraries/headers either in the default environment (if set to exist in the \u003cem\u003eview\u003c/em\u003e) or in the module listing from \u003ccode\u003emodule avail\u003c/code\u003e. At this point, do whatever testing you need to do to ensure the package seems robust. \u003cstrong\u003eYou can also ask the user to run \u003ccode\u003euse_modules\u003c/code\u003e and they can provide you feedback, before you ever make the package available to other users!\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePublishing the package\u003c/h3\u003e\u003ca id=\"user-content-publishing-the-package\" class=\"anchor\" aria-label=\"Permalink: Publishing the package\" href=\"#publishing-the-package\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFinally, assuming all goes well to this point and testing was a success, you can publish the changes from the \u003cem\u003ebuild\u003c/em\u003e environment to the \u003cem\u003epublic\u003c/em\u003e environment. A helper script should handle all of this for you.\u003c/p\u003e\n\u003cp\u003e\ud83d\udea8 \u003cstrong\u003eYou should rarely, if ever, need to manually make changes to the public environment!\u003c/strong\u003e \ud83d\udea8\u003c/p\u003e\n\u003cp\u003eAll published changes get committed and pushed to a GitHub repo (if this is a production deployment) called \u003ccode\u003espack-\u0026lt;cluster\u0026gt;\u003c/code\u003e . This repo is publicly visible and can be used by the community to report bugs and request new packages. Thus, the publish script expects one argument - a commit message.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebin/publish \"Installed latest emacs for benkirk in #4\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003epublish\u003c/code\u003e script will describe all of the changes it makes, including package installs, \u003cstrong\u003espack.yaml\u003c/strong\u003e changes,  refreshing the module tree, and postprocessing.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eWhat if something went wrong?\u003c/h4\u003e\u003ca id=\"user-content-what-if-something-went-wrong\" class=\"anchor\" aria-label=\"Permalink: What if something went wrong?\" href=\"#what-if-something-went-wrong\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is finnicky and it is rather easy to get in a pickle, but \u003cem\u003emost\u003c/em\u003e situations are recoverable if addressed early. If you are unsure about what to do, please ask for help in our \u003cstrong\u003ehpc-ucar #spack\u003c/strong\u003e Slack channel!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUpdating a cluster definition with production changes\u003c/h2\u003e\u003ca id=\"user-content-updating-a-cluster-definition-with-production-changes\" class=\"anchor\" aria-label=\"Permalink: Updating a cluster definition with production changes\" href=\"#updating-a-cluster-definition-with-production-changes\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTODO: document when and how to do this\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1695826388.0
  },
  {
    "data_format": 2,
    "description": "SC Tutorials",
    "filenames": [
      "exercises/spack_containerize/spack.yaml"
    ],
    "full_name": "supercontainers/sc-tutorials",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eGetting Started with Containers on HPC\u003c/h1\u003e\u003ca id=\"user-content-getting-started-with-containers-on-hpc\" class=\"anchor\" aria-label=\"Permalink: Getting Started with Containers on HPC\" href=\"#getting-started-with-containers-on-hpc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eView this on the \u003ca href=\"https://supercontainers.github.io/sc-tutorials/\" rel=\"nofollow\"\u003eTutorial Homepage\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHPC Containers Tutorial Session\u003c/h2\u003e\u003ca id=\"user-content-hpc-containers-tutorial-session\" class=\"anchor\" aria-label=\"Permalink: HPC Containers Tutorial Session\" href=\"#hpc-containers-tutorial-session\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/ecp.jpg\"\u003e\u003cimg src=\"fig/ecp.jpg\" width=\"200\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/pawsey.png\"\u003e\u003cimg src=\"fig/pawsey.png\" width=\"200\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/nvidia.png\"\u003e\u003cimg src=\"fig/nvidia.png\" width=\"200\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDetails\u003c/h2\u003e\u003ca id=\"user-content-details\" class=\"anchor\" aria-label=\"Permalink: Details\" href=\"#details\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFull-day Tutorial Session\u003c/p\u003e\n\u003cp\u003eVenue: Supercomputing Conference (SC 23)\u003c/p\u003e\n\u003cp\u003eDate: Sunday November 12, 2023 8:30am - 5pm Mountain Standard Time (GMT -7)\u003c/p\u003e\n\u003cp\u003eLocation: Denver CO, USA\u003c/p\u003e\n\u003cp\u003eLink: \u003ca href=\"https://sc23.supercomputing.org/presentation/?id=tut108\u0026amp;sess=sess220\" rel=\"nofollow\"\u003eSC 2023 Tutorial Details\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eKeywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAbstract\u003c/h2\u003e\u003ca id=\"user-content-abstract\" class=\"anchor\" aria-label=\"Permalink: Abstract\" href=\"#abstract\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWithin just the past few years, the use of containers has revolutionized the way in which industries and enterprises have developed and deployed computational software and distributed systems. The containerization model has gained traction within the HPC community as well with the promise of improved reliability, reproducibility, portability, and levels of customization that were previously not possible on supercomputers. This adoption has been enabled by a number of HPC Container runtimes that have emerged including Singularity, Shifter, Enroot, Charliecloud and others.\u003c/p\u003e\n\u003cp\u003eThis hands-on tutorial looks to train users on the usability of containers on HPC resources. We will provide a detailed background on Linux containers, along with introductory hands-on experience building a container image, sharing the container and running it on a HPC cluster. Furthermore, the tutorial will provide more advanced information on how to run MPI-based and GPU-enabled HPC applications, how to optimize I/O intensive workflows, and how to setup GUI enabled interactive sessions. Cutting-edge examples will include machine learning and bioinformatics. Users will leave the tutorial with a solid foundational understanding of how to utilize containers with HPC resources through Shifter and Singularity, as well as an in-depth knowledge to deploy custom containers on their own resources.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease consult the website for prerequisites and recommended setup steps.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eQuestions\u003c/h2\u003e\u003ca id=\"user-content-questions\" class=\"anchor\" aria-label=\"Permalink: Questions\" href=\"#questions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can ask questions verbally or with this \u003ca href=\"https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing\" rel=\"nofollow\"\u003eGoogle Doc\u003c/a\u003e.\nPlease append your question below the others in the document.\u003c/p\u003e\n\u003cp\u003eWe have also created a Slack Team for this.  The invitation link is \u003ca href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSchedule - Autogenerated from the metadata\u003c/h2\u003e\u003ca id=\"user-content-schedule---autogenerated-from-the-metadata\" class=\"anchor\" aria-label=\"Permalink: Schedule - Autogenerated from the metadata\" href=\"#schedule---autogenerated-from-the-metadata\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1699813666.0
  },
  {
    "data_format": 2,
    "description": "Mochi-based distributed event-streaming service for HPC",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mofka",
    "latest_release": "v0.0.4",
    "readme": "\u003cp align=\"center\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/_static/MofkaLogo-light.svg#gh-light-mode-only\"\u003e\u003cimg src=\"docs/_static/MofkaLogo-light.svg#gh-light-mode-only\" height=\"220\" width=\"210\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/_static/MofkaLogo-dark.svg#gh-dark-mode-only\"\u003e\u003cimg src=\"docs/_static/MofkaLogo-dark.svg#gh-dark-mode-only\" height=\"220\" width=\"210\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/p\u003e\n\u003cp\u003eMofka is a streaming service for high-performance computing application.\nIt relies on the \u003ca href=\"https://wordpress.cels.anl.gov/mochi/\" rel=\"nofollow\"\u003eMochi\u003c/a\u003e toolbox of\nHPC software service components. Please refer to the \u003ca href=\"https://mofka.readthedocs.io/\" rel=\"nofollow\"\u003eReadTheDocs\u003c/a\u003e\nfor more information.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1698415058.0
  },
  {
    "data_format": 2,
    "description": "Images used to run Gitlab pipelines in the cloud",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "spack/gitlab-runners",
    "latest_release": "v2024-01-29",
    "readme": "\u003cp\u003eThis repository contains images that are used to run Gitlab pipelines to validate PRs in Spack.\u003c/p\u003e\n\u003cp\u003eThe recipes have been modified from ones in: \u003ca href=\"https://github.com/UO-OACISS/e4s\"\u003ehttps://github.com/UO-OACISS/e4s\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1685684158.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ubuntu-gcc/spack.yaml"
    ],
    "full_name": "fnalacceleratormodeling/synergia2-containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003esynergia2-containers\u003c/h1\u003e\u003ca id=\"user-content-synergia2-containers\" class=\"anchor\" aria-label=\"Permalink: synergia2-containers\" href=\"#synergia2-containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains docker recipes for building containers that contain all dependencies for synergia2. These recipes are generated using \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003espack environments\u003c/a\u003e via \u003ca href=\"https://spack.readthedocs.io/en/latest/containers.html\" rel=\"nofollow\"\u003e\u003ccode\u003espack containerize\u003c/code\u003e\u003c/a\u003e, with some minor modifications. GithubActions is used to build these containers for \u003ccode\u003ex86_64_v2\u003c/code\u003e ISA and these containers can be pulled from the github container registry. For instructions on how to pull a particular image, visit the page associated with it \u003ca href=\"https://github.com/orgs/fnalacceleratormodeling/packages?repo_name=synergia2-containers\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThese containers are used as test environments for testing synergia2 via GithubActions.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1678463172.0
  },
  {
    "data_format": 2,
    "description": "Storage system for Deep Learning models designed using the Mochi components.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/flamestore",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eWhat is FlameStore?\u003c/h1\u003e\u003ca id=\"user-content-what-is-flamestore\" class=\"anchor\" aria-label=\"Permalink: What is FlameStore?\" href=\"#what-is-flamestore\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFlameStore is a Mochi component to access Keras deep learning models\nand store them in various backends (right now: in memory, on a local\nfile system, or on a composition of SDSKV and BAKE providers).\u003c/p\u003e\n\u003cp\u003eFlameStore is developped by Matthieu Dorier (\u003ca href=\"mailto:mdorier@anl.gov\"\u003emdorier@anl.gov\u003c/a\u003e).\nMore information on how to install and use is available\n\u003ca href=\"https://xgitlab.cels.anl.gov/sds/flamestore/wikis/home\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1700115196.0
  },
  {
    "data_format": 2,
    "description": "GSI related utilities",
    "filenames": [
      "ci/spack.yaml"
    ],
    "full_name": "NOAA-EMC/GSI-utils",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eGSI-Utils\u003c/h1\u003e\u003ca id=\"user-content-gsi-utils\" class=\"anchor\" aria-label=\"Permalink: GSI-Utils\" href=\"#gsi-utils\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eGSI Utility Tools\u003c/p\u003e\n\u003cp\u003eThese are GSI utilities for various functions.\u003c/p\u003e\n\u003cp\u003eFor installation instruction see \u003ca href=\"./INSTALL.md\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1690297134.0
  },
  {
    "data_format": 2,
    "description": "fast spack builds on slow filesystem",
    "filenames": [
      "recipe/nvhpc.spack.yaml",
      "packages/nvhpc/spack.yaml"
    ],
    "full_name": "eth-cscs/spack-stack",
    "latest_release": null,
    "stargazers_count": 2,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1684144105.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "Tools/machines/lxplus-cern/spack.yaml"
    ],
    "full_name": "AMReX-Microelectronics/artemis_bakup",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eARTEMIS\u003c/h1\u003e\u003ca id=\"user-content-artemis\" class=\"anchor\" aria-label=\"Permalink: ARTEMIS\" href=\"#artemis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eARTEMIS (Adaptive Refinement Time-domain ElectrodynaMIcs Solver) is a code for modeling micromagnetics and electrodynamic waves in next-generation microelectornics.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://picmi-standard.github.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICMI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22PICMI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openPMD.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22openPMD%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://yt-project.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"yt-project\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22yt%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn order to learn how to install and run the code, please see the online documentation:\n\u003ca href=\"https://artemis-em.readthedocs.io\" rel=\"nofollow\"\u003ehttps://artemis-em.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTo contact the developers, feel free to open an issue on this repo.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22AMReX%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://picsar.net\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICSAR\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22PICSAR%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD-api\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22openPMD-api%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"ADIOS\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22ADIOS%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.hdfgroup.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"HDF5\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22HDF5%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"http://www.ascent-dav.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"Ascent\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22Ascent%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://sensei-insitu.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"SENSEI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22SENSEI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur workflow is described in \u003ca href=\"CONTRIBUTING.rst\"\u003eCONTRIBUTING.rst\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWarpX Copyright (c) 2018-2023, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Innovation \u0026amp; Partnerships Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.\u003c/p\u003e\n\u003cp\u003eLicense for WarpX can be found at \u003ca href=\"LICENSE.txt\"\u003eLICENSE.txt\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1688585950.0
  },
  {
    "data_format": 2,
    "description": "memoized spack configs for some DOE systems",
    "filenames": [
      "anl/polaris/polaris.spack.yaml",
      "rice/gpu/gpu.spack.yaml"
    ],
    "full_name": "jmellorcrummey/spack-configs",
    "latest_release": null,
    "readme": "\u003cp\u003eThis directory contains the various files, scripts, and instructions for installing hpctoolkit\nat various sites, using Spack to do the install.\u003c/p\u003e\n\u003cp\u003eThe top-level directory has an \u003ca href=\"install.txt\"\u003einstall.txt\u003c/a\u003e script with detailed,\nand hopefully, idiot-proof instructions for using Spack to install hpctoolkit.\u003c/p\u003e\n\u003cp\u003eIt has a \u003ccode\u003ebin\u003c/code\u003e directory, containing a script named \u003ccode\u003espacklink\u003c/code\u003e that will set up a spack\nrepository to do the installation at a specific \u003ccode\u003e\u0026lt;site\u0026gt;\u003c/code\u003e on a specific \u003ccode\u003e\u0026lt;machine\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIt has a number of sub-directories, named by \u003ccode\u003e\u0026lt;site\u0026gt;\u003c/code\u003e.\nEach of those subdirectories contains one or more subdirectories, named by \u003ccode\u003e\u0026lt;machine\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eEach of those \u003ccode\u003e\u0026lt;site\u0026gt;/\u0026lt;machine\u0026gt;\u003c/code\u003e subdirectories contains several files:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.config.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003especifies the directories in which to put the module files and packages for a particular install.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.modules.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003especifies information about the modules to be built\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.packages.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003ethis includes configuration for the software environment, including MPI, CUDA, python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.spack.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003ethis specifies a Spack environment file, which allows building several HPCToolkit configurations\nwith Spack in one go. If present, the \u003ccode\u003espacklink\u003c/code\u003e script will create a new directory parallel to\nthe Spack repository called \u003ccode\u003espack-env\u003c/code\u003e. The installation steps then become:\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e  $ spack/bin/spack -e spack-env concretize \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e add \"-f\" to re-concretize as needed\u003c/span\u003e\n  $ spack/bin/spack -e spack-env install\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1658934301.0
  },
  {
    "data_format": 2,
    "description": "ACCESS-OM2: ACCESS Ocean-Sea Ice Model",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "ACCESS-NRI/ACCESS-OM2",
    "latest_release": "2024.03.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eACCESS-OM2: ACCESS Ocean-Ice Model Release Configurations\u003c/h1\u003e\u003ca id=\"user-content-access-om2-access-ocean-ice-model-release-configurations\" class=\"anchor\" aria-label=\"Permalink: ACCESS-OM2: ACCESS Ocean-Ice Model Release Configurations\" href=\"#access-om2-access-ocean-ice-model-release-configurations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAbout the model\u003c/h2\u003e\u003ca id=\"user-content-about-the-model\" class=\"anchor\" aria-label=\"Permalink: About the model\" href=\"#about-the-model\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-OM2 is a global coupled ocean - sea ice model developed by \u003ca href=\"http://www.cosima.org.au\" rel=\"nofollow\"\u003eCOSIMA\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eACCESS-OM2 consists of the \u003ca href=\"https://github.com/ACCESS-NRI/MOM5\"\u003eMOM 5\u003c/a\u003e ocean model, \u003ca href=\"https://github.com/ACCESS-NRI/cice5\"\u003eCICE 5\u003c/a\u003e sea ice model, and a file-based atmosphere called \u003ca href=\"https://github.com/ACCESS-NRI/libaccessom2\"\u003eYATM\u003c/a\u003e coupled together using \u003ca href=\"https://github.com/ACCESS-NRI/oasis3-mct\"\u003eOASIS3-MCT v2.0\u003c/a\u003e. ACCESS-OM2 builds on the ACCESS-OM (\u003ca href=\"http://www.bom.gov.au/jshess/docs/2013/bi2_hres.pdf\" rel=\"nofollow\"\u003eBi et al., 2013\u003c/a\u003e) and AusCOM (\u003ca href=\"https://50years.acs.org.au/content/dam/acs/50-years/journals/jrpit/JRPIT39.2.137.pdf\" rel=\"nofollow\"\u003eRoberts et al., 2007\u003c/a\u003e; \u003ca href=\"https://www.cawcr.gov.au/technical-reports/CTR_027.pdf\" rel=\"nofollow\"\u003eBi and Marsland, 2010\u003c/a\u003e) models originally developed at \u003ca href=\"http://www.csiro.au\" rel=\"nofollow\"\u003eCSIRO\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe model code, configurations and performance were described in \u003ca href=\"https://doi.org/10.5194/gmd-13-401-2020\" rel=\"nofollow\"\u003eKiss et al. (2020)\u003c/a\u003e, with further details in the draft \u003ca href=\"https://github.com/COSIMA/ACCESS-OM2-1-025-010deg-report\"\u003eACCESS-OM2 technical report\u003c/a\u003e. The current code and configurations differ from this version in a number of ways (biogeochemistry, updated forcing, improvements and bug fixes), as described by \u003ca href=\"https://doi.org/10.1029/2021GL097211\" rel=\"nofollow\"\u003eSolodoch et al. (2022)\u003c/a\u003e, \u003ca href=\"https://dx.doi.org/10.1029/2023JC019697\" rel=\"nofollow\"\u003eHayashida et al. (2023)\u003c/a\u003e, \u003ca href=\"https://doi.org/10.5194/egusphere-2023-390\" rel=\"nofollow\"\u003eMenviel et al. (2023)\u003c/a\u003e and \u003ca href=\"https://doi.org/10.5194/gmd-2023-123\" rel=\"nofollow\"\u003eWang et al. (2023)\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSupport\u003c/h2\u003e\u003ca id=\"user-content-support\" class=\"anchor\" aria-label=\"Permalink: Support\" href=\"#support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://www.access-nri.org.au\" rel=\"nofollow\"\u003eACCESS-NRI\u003c/a\u003e has assumed responsibility for supporting ACCESS-OM2 for the Australian Research Community. As part of this support ACCESS-NRI has developed a new build and deployment system for ACCESS-OM2 to align with plans for supporting a range of Earth System Models.\u003c/p\u003e\n\u003cp\u003eAny questions about ACCESS-NRI releases of ACCESS-OM2 should be done through the \u003ca href=\"https://forum.access-hive.org.au/\" rel=\"nofollow\"\u003eACCESS-Hive Forum\u003c/a\u003e. See the \u003ca href=\"https://forum.access-hive.org.au/t/access-help-and-support/908\" rel=\"nofollow\"\u003eACCESS Help and Support topic\u003c/a\u003e for details on how to do this.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild\u003c/h3\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-NRI is using \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003espack\u003c/a\u003e, a build from source package manager designed for use with high performance computing. This repository contains a \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003espack environment\u003c/a\u003e definition file (\u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2/blob/main/spack.yaml\"\u003e\u003ccode\u003espack.yaml\u003c/code\u003e\u003c/a\u003e) that defines all the essential components of the ACCESS-OM2 model, including exact versions.\u003c/p\u003e\n\u003cp\u003eSpack automatically builds all the components and their dependencies, producing model component executables. Spack already contains support for compiling thousands of common software packages. Spack packages for the components in ACCESS-OM2 are defined in the \u003ca href=\"https://github.com/ACCESS-NRI/spack_packages/\"\u003espack packages repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eACCESS-OM2 is built and deployed automatically to \u003ccode\u003egadi\u003c/code\u003e on NCI (see below). However it is possible to use spack to compile the model using the \u003ccode\u003espack.yaml\u003c/code\u003e environment file in this repository. To do so follow the \u003ca href=\"https://forum.access-hive.org.au/t/how-to-build-access-om2-on-gadi/1545\" rel=\"nofollow\"\u003einstructions on the ACCESS Forum for configuring spack on \u003ccode\u003egadi\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThen clone this repository and run the following commands on \u003ccode\u003egadi\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env create access-om2 spack.yaml\nspack env activate access-om2\nspack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eto create a spack environment called \u003ccode\u003eaccess-om2\u003c/code\u003e and build all the ACCESS-OM2 components, the locations of which can be found using \u003ccode\u003espack find --paths\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIn contrast, the \u003ca href=\"https://github.com/COSIMA/access-om2\"\u003eCOSIMA ACCESS-OM2 repository\u003c/a\u003e uses \u003ca href=\"https://git-scm.com/book/en/v2/Git-Tools-Submodules\" rel=\"nofollow\"\u003esubmodules\u003c/a\u003e to bring all the code dependencies into a single repository and build all the models together.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDeployment\u003c/h3\u003e\u003ca id=\"user-content-deployment\" class=\"anchor\" aria-label=\"Permalink: Deployment\" href=\"#deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eACCESS-OM2 is deployed automatically when a new version of the \u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2/blob/main/spack.yaml\"\u003e\u003ccode\u003espack.yaml\u003c/code\u003e\u003c/a\u003e file is committed to \u003ccode\u003emain\u003c/code\u003e or a dedicated \u003ccode\u003ebackport/VERSION\u003c/code\u003e branch. All the ACCESS-OM2 components are built using \u003ccode\u003espack\u003c/code\u003e on \u003ccode\u003egadi\u003c/code\u003e and installed under the \u003ca href=\"https://my.nci.org.au/mancini/project/vk83\" rel=\"nofollow\"\u003e\u003ccode\u003evk83\u003c/code\u003e\u003c/a\u003e project in \u003ccode\u003e/g/data/vk83\u003c/code\u003e. It is necessary to be a member of \u003ca href=\"https://my.nci.org.au/mancini/project/vk83\" rel=\"nofollow\"\u003e\u003ccode\u003evk83\u003c/code\u003e\u003c/a\u003e project to use ACCESS-NRI deployments of ACCESS-OM2.\u003c/p\u003e\n\u003cp\u003eThe deployment process also creates a GitHub release with the same tag. All releases are available under the \u003ca href=\"https://github.com/ACCESS-NRI/ACCESS-OM2/releases\"\u003eReleases page\u003c/a\u003e. Each release has a changelog and meta-data with detailed information about the build and deployment, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epaths on \u003ccode\u003egadi\u003c/code\u003e to all executables built in the deployment process (\u003ccode\u003espack.location\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003ea \u003ccode\u003espack.lock\u003c/code\u003e file, which is a complete build provenance document, listing all the components that were built and their dependencies, versions, compiler version, build flags and build architecture\u003c/li\u003e\n\u003cli\u003ethe environment \u003ccode\u003espack.yaml\u003c/code\u003e file used for deployment\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdditionally the deployment creates environment modulefiles, the \u003ca href=\"https://opus.nci.org.au/display/Help/Environment+Modules\" rel=\"nofollow\"\u003estandard method for deploying software on \u003ccode\u003egadi\u003c/code\u003e\u003c/a\u003e. To view available ACCESS-OM2 versions:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emodule use /g/data/vk83/apps/spack/0.20/release/modules/linux-rocky8-x86_64\nmodule avail access-om2\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor users of ACCESS-OM2 model configurations released by ACCESS-NRI the exact location of the ACCESS-OM2 model executables is not required. Model configurations will be updated with new model components when necessary.\u003c/p\u003e\n\u003cp\u003eFor information on contributing your own fixes to the ACCESS-OM2 \u003ccode\u003espack.yaml\u003c/code\u003e, see the \u003ca href=\"./CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e file.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 10,
    "topics": [
      "model",
      "ocean",
      "sea-ice",
      "spack"
    ],
    "updated_at": 1711425904.0
  },
  {
    "data_format": 2,
    "description": "E4S \u00e0 la carte is a tool that allows a user to customize a container image by adding packages to it. These can be system packages and Spack packages. ",
    "filenames": [
      "examples/ubuntu/light_spack.yaml"
    ],
    "full_name": "E4S-Project/e4s-alc",
    "latest_release": "v1.0.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eE4S \u00e0 la Carte\u003c/h1\u003e\u003ca id=\"user-content-e4s-\u00e0-la-carte\" class=\"anchor\" aria-label=\"Permalink: E4S \u00e0 la Carte\" href=\"#e4s-\u00e0-la-carte\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDescription\u003c/h2\u003e\u003ca id=\"user-content-description\" class=\"anchor\" aria-label=\"Permalink: Description\" href=\"#description\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eE4S \u00e0 la Carte is a practical tool designed to facilitate the generation of Dockerfiles infused with OS packages, Spack packages, as well as custom commands. In the simplifying the process, this tool targets the elimination of manual Dockerfile scripting, enabling users to concentrate on critical aspects such as application-specific resources and configurations.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOur documentation is located here: \u003ca href=\"https://e4s-alc.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003eDocumentation\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe \u003ccode\u003ee4s-alc\u003c/code\u003e tool is designed to facilitate the process of crafting Dockerfiles. This tool leverages \u003ccode\u003e.yaml\u003c/code\u003e files as input to generate Dockerfiles.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstalling \u003ccode\u003ee4s-alc\u003c/code\u003e is simple.\u003c/p\u003e\n\u003cp\u003eClone the project:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/E4S-Project/e4s-alc.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRun \u003ccode\u003emake\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd e4s-alc \u0026amp;\u0026amp; make install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExample\u003c/h2\u003e\u003ca id=\"user-content-example\" class=\"anchor\" aria-label=\"Permalink: Example\" href=\"#example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHere is an example \u003ccode\u003e.yaml\u003c/code\u003e file. This input file creates a Dockerfile using a Rhel8 base image. It installs gcc@11.2 and installs kokkos using gcc@11.2. Notice how I\u0027ve chosen to exclude parameters to fit my build. This is one of the example \u003ccode\u003e.yaml\u003c/code\u003e files in the \u003ccode\u003eexamples\u003c/code\u003e directory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# rhel8-gcc11.2-kokkos.yaml\n\n######## Base group ########\nbackend: podman\nregistry: registry.access.redhat.com\nimage: ubi8/ubi\n\n####### Spack group #######\nspack-version: latest\nspack-compiler: gcc@11.2\nspack-packages:\n  - kokkos\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eI build the Dockerfile and image with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ee4s-alc create -f rhel8-gcc11.2-kokkos.yaml\npodman build .\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, run the image in interactive mode and inspect the install:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[root@c5ad0d45ba1d /]# module avail\n----------------------------- /modulefiles/linux-rhel8-power9le -----------------------------------\ngcc/11.2.0  kokkos/4.0.01  \n[root@c5ad0d45ba1d /]# module load gcc\n[root@c5ad0d45ba1d /]# module load kokkos\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eExample YAML file with matrix feature\u003c/h4\u003e\u003ca id=\"user-content-example-yaml-file-with-matrix-feature\" class=\"anchor\" aria-label=\"Permalink: Example YAML file with matrix feature\" href=\"#example-yaml-file-with-matrix-feature\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHere is an example \u003ccode\u003e.yaml\u003c/code\u003e file that creates multiple Dockerfiles using a single \u003ccode\u003e.yaml\u003c/code\u003e file. Notice that for each \u003ccode\u003eregistry-image-matrix\u003c/code\u003e item that we specify, we build out a Dockerfile using each \u003ccode\u003espack-compiler-matrix\u003c/code\u003e item. This feature could be powerful for testing Spack packages across different operating systems and compilers.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebackend: podman\nregistry-image-matrix:\n  - registry.access.redhat.com/ubi8/ubi\n  - ubuntu:20.04\n\n####### Spack group #######\nspack: True\nspack-version: latest\n\nspack-compiler-matrix:\n  - gcc@8.5.0 \n  - gcc@11.2.0 \n  - gcc@12.0\n  - gcc@12.3.0\n\nspack-packages: \n  - kokkos\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis \u003ccode\u003e.yaml\u003c/code\u003e file would create a directory named \u003ccode\u003edockerfiles\u003c/code\u003e that contains the following Dockerfiles:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eDockerfile.rhel8.8-gcc@8.5.0\nDockerfile.rhel8.8-gcc@11.5.0\nDockerfile.rhel8.8-gcc@12.0\nDockerfile.rhel8.8-gcc@12.3.0\nDockerfile.ubuntu20.04-gcc@8.5.0\nDockerfile.ubuntu20.04-gcc@11.5.0\nDockerfile.ubuntu20.04-gcc@12.0\nDockerfile.ubuntu20.04-gcc@12.3.0\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1711952858.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Derecho system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-derecho",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eNCAR Spack Deployment\u003c/h1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-label=\"Permalink: NCAR Spack Deployment\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ederecho\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eThu Aug 31 09:31:25 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003ec33150e8d9241c6175a6b599b2afde1e6ea3c891\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.09\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack version\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/derecho/23.09\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/work/csgteam/spack-deployments/derecho/23.09/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1695826459.0
  },
  {
    "data_format": 2,
    "description": "The CELL Adaptive mesh Refinement (CELLAR) application provides cell-based adaptive mesh refinement data structures and execution for parallel computing architectures.",
    "filenames": [
      "spack/snow/spack.yaml",
      "spack/ci/spack.yaml",
      "spack/darwin-power9/spack.yaml"
    ],
    "full_name": "lanl/CELLAR",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCELLAR  -  EAP Core\u003c/h1\u003e\u003ca id=\"user-content-cellar-----eap-core\" class=\"anchor\" aria-label=\"Permalink: CELLAR  -  EAP Core\" href=\"#cellar-----eap-core\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCELLAR is a C++ project that forms the foundation of cell based AMR for applications\u003c/p\u003e\n\u003cp\u003eIt provides the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAMR Mesh Datastructure\u003c/li\u003e\n\u003cli\u003eAMR Mesh Reconstruction\u003c/li\u003e\n\u003cli\u003eCommunication Patterns\u003c/li\u003e\n\u003cli\u003eC++ Error Handling and Tracing\u003c/li\u003e\n\u003cli\u003ePerformance Monitoring\u003c/li\u003e\n\u003cli\u003eC++/Fortran Interop\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding\u003c/h2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-label=\"Permalink: Building\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe easiest way to install dependencies is using \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e.\nAfter\n\u003ca href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\"\u003einstalling Spack\u003c/a\u003e,\nyou can start build dependencies.\u003c/p\u003e\n\u003cp\u003eThe following instructions assume that you have Spack 0.13 or newer. You can check your\nSpack version like so:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack --version\n0.13.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFirst, add \u003ca href=\"https://github.com/lanl/cellar-spack\"\u003elanl/cellar-spack\u003c/a\u003e\nto your list of spack repos.\u003c/p\u003e\n\u003cp\u003eOnce you have the \u003ccode\u003elanl/cellar-spack\u003c/code\u003e installed, then you can install all\ndependencies using\n\u003ca href=\"https://spack.readthedocs.io/en/latest/tutorial_environments.html#\" rel=\"nofollow\"\u003eSpack environments\u003c/a\u003e.\nYou\u0027ll need to use a modern-ish C++ compiler that supports C++14:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ module load gcc/9.3.0\n$ spack compiler find\n$ cd path/to/eap-core\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen issue the following commands. This will build all of eap-core\u0027s dependencies.:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack env create -d spack/default\n$ spack env activate -d $PWD/spack/default\n$ spack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAny time you open a new shell, you\u0027ll need to re-activate the Spack environment:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack env activate -d $PWD/spack/default\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you\u0027re ready to build eap-core. First configure the project using CMake:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build \u0026amp;\u0026amp; cd build\ncmake ..\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd then build:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake -j\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor snow, substitute in spack/snow in the above instructions in place of spack/default. If you need\nto change the environment use \"spack env deactivate\".\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCode contributors should read the \u003ca href=\"DEVELOPERS.md\"\u003eDevelopers Guide\u003c/a\u003e prior to\nsending a pull request.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1694614627.0
  },
  {
    "data_format": 2,
    "description": "Configuration scripts for BOUT++",
    "filenames": [
      "lassen/spack_env/bout_petsc_with_hypre/spack.yaml",
      "perlmutter/boutdev-spack-env/spack.yaml",
      "lassen/spack_env/bout/spack.yaml"
    ],
    "full_name": "boutproject/BOUT-configs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eConfiguration scripts\u003c/h1\u003e\u003ca id=\"user-content-configuration-scripts\" class=\"anchor\" aria-label=\"Permalink: Configuration scripts\" href=\"#configuration-scripts\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo contains scripts to setup the environment and provide build\nconfigurations for BOUT++ on deployment machines.\u003c/p\u003e\n\u003cp\u003eThere is one sub-directory for each machine (\"cori\", \"lassen\", \"perlmutter\").\nSee the README of each sub-directory for machine specific instructions.\u003c/p\u003e\n\u003cp\u003eThe repo includes \u003ccode\u003espack\u003c/code\u003e (release v0.21.1) as a submodule, used to create\nreproducible, self-contained environments on different machines.\u003c/p\u003e\n\u003cp\u003e\ud83d\udea7 This repo is under active development, \u003ccode\u003eperlmutter\u003c/code\u003e configuration\nis in a stable state, other machines are under update.\nIssues and PRs to \u003ccode\u003emain\u003c/code\u003e are welcome.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eClone the repo and initialize submodules\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recurse-submodules https://github.com/boutproject/BOUT-configs.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEnter the machine sub-directory desired and follow the instructions.\nTypical usage is to \u003ccode\u003esource setup-env.sh\u003c/code\u003e to activate the spack enviroment,\nwhich will install any needed software dependencies through \u003ccode\u003espack\u003c/code\u003e, and\nconfigure BOUT++ using either scripts under the machine\u0027s \u003ccode\u003escripts\u003c/code\u003e directory\nor with the user\u0027s own configuration.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContact\u003c/h2\u003e\u003ca id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFeel free to contact Giorgis Georgakoudis \u003ca href=\"mailto:georgakoudis1@llnl.gov\"\u003egeorgakoudis1@llnl.gov\u003c/a\u003e for comments,\nsuggestions, or questions.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 19,
    "topics": [],
    "updated_at": 1710477337.0
  },
  {
    "data_format": 2,
    "description": "Localized documentation for Spack",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "spack/localized-docs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLocalized Documentation for Spack\u003c/h1\u003e\u003ca id=\"user-content-localized-documentation-for-spack\" class=\"anchor\" aria-label=\"Permalink: Localized Documentation for Spack\" href=\"#localized-documentation-for-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains translations of \u003ca href=\"/spack/spack\"\u003eSpack\u003c/a\u003e\u0027s\ndocumentation.  It implements the workflow described in the\n\u003ca href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\" rel=\"nofollow\"\u003eSphinx docs\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe instructions here describe how you can contribute by:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAdding to an existing translation, and\u003c/li\u003e\n\u003cli\u003eCreating a translation in a new language.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eFirst, init the \u003ccode\u003espack\u003c/code\u003e submodule:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003egit clone https://github.com/spack/localized-docs\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e localized-docs\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003egit submodule init\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003egit submodule update\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTo use this repository you\u0027ll need Sphinx, some plugins for it, and\n\u003ccode\u003egettext\u003c/code\u003e.  To install these dependencies, using \u003ccode\u003epip\u003c/code\u003e and \u003ccode\u003ebrew\u003c/code\u003e, you\ncan run:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003epip3 install -r requirements.txt\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003ebrew install gettext\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUsing Spack, you can just take advantage of the \u003ccode\u003espack.yaml\u003c/code\u003e file at\nthe root of this repo:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack install\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack env activate .\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will install the tools you need and put them in your \u003ccode\u003ePATH\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAdding to an existing translation\u003c/h2\u003e\u003ca id=\"user-content-adding-to-an-existing-translation\" class=\"anchor\" aria-label=\"Permalink: Adding to an existing translation\" href=\"#adding-to-an-existing-translation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTranslations in this repository are stored in \u003ccode\u003e.po\u003c/code\u003e files under\n\u003ccode\u003etranslations\u003c/code\u003e.  There is one translation per languages, and each file is\nnamed according to its\n\u003ca href=\"https://www.gnu.org/software/gettext/manual/html_node/Language-Codes.html#Language-Codes\" rel=\"nofollow\"\u003eISO-639 language code\u003c/a\u003e.\nSo, the Japanese translation data for Spack is stored in\n\u003ccode\u003etranslations/ja.po\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to add to an existing translation, all you need to do is edit\nthe appropriate \u003ccode\u003e.po\u003c/code\u003e file and add translated strings to it.  \u003ccode\u003e.po\u003c/code\u003e files\nare comprised of \u003ccode\u003emsgid\u003c/code\u003e/\u003ccode\u003emsgstr\u003c/code\u003e pairs.  The \u003ccode\u003emsgid\u003c/code\u003e corresponds to an\nEnglish string in the original documentation, and the \u003ccode\u003emsgstr\u003c/code\u003e is its\ntranslation in the target language.  For example, for Japanese, the\ntranslation of \"Basic Usage\" is stored like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#: ../spack/lib/spack/docs/basic_usage.rst:10\nmsgid \"Basic Usage\"\nmsgstr \"\u57fa\u672c\u7684\u306a\u4f7f\u3044\u65b9\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo add a translation:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eUpdate \u003ccode\u003emsgstr\u003c/code\u003e elements in the appropriate \u003ccode\u003e.po\u003c/code\u003e files;\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003emake\u003c/code\u003e;\u003c/li\u003e\n\u003cli\u003eCommit the results;\u003c/li\u003e\n\u003cli\u003eSubmit a pull request so that we can merge your changes.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThat\u0027s all!  Merged pull requests will automatically trigger a rebuild of\nthe translated docs, and you should see your changes at\n\u003ca href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"\u003espack.readthedocs.io\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to look at the documentation while you\u0027re editing it, running\n\u003ccode\u003emake\u003c/code\u003e also generates per-language builds of the docs in \u003ccode\u003ehtml/\u0026lt;lang\u0026gt;\u003c/code\u003e.\nSo, to see the Japanese documentation, you can run \u003ccode\u003emake\u003c/code\u003e and open\n\u003ccode\u003ehtml/ja/index.html\u003c/code\u003e in a local web browser.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCreating a new translation\u003c/h2\u003e\u003ca id=\"user-content-creating-a-new-translation\" class=\"anchor\" aria-label=\"Permalink: Creating a new translation\" href=\"#creating-a-new-translation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo create a new translation, add the language to the \u003ccode\u003elanguages\u003c/code\u003e list in\nthe \u003ccode\u003eMakefile\u003c/code\u003e.  For example, if the only language is Japanese (\u003ccode\u003eja\u003c/code\u003e) and\nyou want to add German (\u003ccode\u003ede\u003c/code\u003e), just add \u003ccode\u003ede\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-makefile\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003elanguages\u003c/span\u003e = ja de\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eRunning \u003ccode\u003emake\u003c/code\u003e, will create files in \u003ccode\u003edocs\u003c/code\u003e, \u003ccode\u003elocale\u003c/code\u003e, and\n\u003ccode\u003etranslations\u003c/code\u003e, and \u003ccode\u003ehtml\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e    translations/de.po          # German translation file\n    translations/de.mo          # generated from de.po\n    locale/de/LC_MESSAGES/*.mo  # symlinks to translations/de.mo\n    docs/de/                    # a Sphinx build directory for German docs\n    html/de/                    # HTML built by Sphinx from docs/de\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAdd everything \u003cem\u003eexcept\u003c/em\u003e \u003ccode\u003ehtml\u003c/code\u003e, then commit. \u003ccode\u003ehtml\u003c/code\u003e is ignored by default\n(see \u003ccode\u003e.gitignore\u003c/code\u003e), so you can just run this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003egit add \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003egit commit\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSee instructions above for how to start translating.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWorkflow\u003c/h2\u003e\u003ca id=\"user-content-workflow\" class=\"anchor\" aria-label=\"Permalink: Workflow\" href=\"#workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository implements the\n\u003ca href=\"https://www.sphinx-doc.org/en/master/usage/advanced/intl.html\" rel=\"nofollow\"\u003eworkflow described here\u003c/a\u003e.\nMost users will only need to concern themselves with \u003ccode\u003etranslations/*.po\u003c/code\u003e\nfiles, but we provide a short summary here so that you can understand how\neverything works.\u003c/p\u003e\n\u003cp\u003eTranslation is done as follows:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eFirst, we use (or rather Sphinx uses) the \u003ccode\u003egettext\u003c/code\u003e tool to extract\nstrings to be translated from each \u003ccode\u003e.rst\u003c/code\u003e document in the Spack\ndocumentation. This results in a set of \u003ccode\u003e.pot\u003c/code\u003e files in\n\u003ccode\u003etemplates/*.pot\u003c/code\u003e.  These contain keys (\u003ccode\u003emsgid\u003c/code\u003es) for unique strings,\nas well as their location (file and line number) in the documentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe merge the \u003ccode\u003e.pot\u003c/code\u003e files into a single \u003ccode\u003emerged.pot\u003c/code\u003e file to eliminate\nduplicate strings in multiple files.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003emerged.pot\u003c/code\u003e is used to create an initial \u003ccode\u003etranslations/\u0026lt;lang\u0026gt;.po\u003c/code\u003e\nfile.  Translations are added to \u003ccode\u003emsgstr\u003c/code\u003e fields in the \u003ccode\u003e.po\u003c/code\u003e file.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA single \u003ccode\u003etranslations/\u0026lt;lang\u0026gt;.mo\u003c/code\u003e file is generated from the \u003ccode\u003e.po\u003c/code\u003e\nfile. The \u003ccode\u003e.mo\u003c/code\u003e file is in a special binary format.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWe generate symlinks in \u003ccode\u003elocale/\u0026lt;lang\u0026gt;/LC_MESSAGES/*.mo\u003c/code\u003e that all\npoint back to the single, unified \u003ccode\u003etranslations/\u0026lt;lang\u0026gt;.mo\u003c/code\u003e file.  The\n\u003ccode\u003elocale\u003c/code\u003e directory can then be used with Sphinx to build translated\ndocumentation.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe top-level \u003ccode\u003eMakefile\u003c/code\u003e implements this workflow, so you don\u0027t have to\nthink too much about it.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository is part of Spack, which distributed under the terms of\nboth the MIT license and the Apache License (Version 2.0). Users may\nchoose either license, at their option.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/localized-docs/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/localized-docs//blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/localized-docs/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e,\nand \u003ca href=\"https://github.com/spack/localized-docs/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e\nfor details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-647188\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1621989548.0
  },
  {
    "data_format": 2,
    "description": "Artifacts of SC\u002723 paper \"AMRIC: A Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh Refinement Applications\"",
    "filenames": [
      "warpx_directory/WarpX/Docs/spack.yaml"
    ],
    "full_name": "hipdac-lab/SC23-AMRIC",
    "latest_release": "v0.1.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eAMRIC: A Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh Refinement Applications\u003c/h1\u003e\u003ca id=\"user-content-amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\" class=\"anchor\" aria-label=\"Permalink: AMRIC: A Novel In Situ Lossy Compression Framework for Efficient I/O in Adaptive Mesh Refinement Applications\" href=\"#amric-a-novel-in-situ-lossy-compression-framework-for-efficient-io-in-adaptive-mesh-refinement-applications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://zenodo.org/badge/latestdoi/658166802\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d0d2e976dd91e413f1525d14e8ca69f13f70ff17c5c7e104fd4bff574a3cd689/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3635383136363830322e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/658166802.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAMRIC is a novel in-situ lossy compression framework that leverages the HDF5 filter to enhance both I/O efficiency and compression quality for Adaptive Mesh Refinement (AMR) applications. AMRIC was integrated into the \u003ca href=\"https://amrex-codes.github.io/amrex/\" rel=\"nofollow\"\u003eAMReX\u003c/a\u003e framework and evaluated on two real-world AMR applications, Nyx and WarpX.\u003c/p\u003e\n\u003cp\u003eWhile preparing the artifacts, we executed them on a single node from the Chameleon Cloud, equipped with two Intel Xeon Gold 6242 CPUs and 192 GB of memory (specifically, \u003ccode\u003ecompute_skylake\u003c/code\u003e configuration). We recommend that reviewers also use the Chameleon Cloud for artifact evaluation.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMethod 1: Use Singularity Image (Recommended)\u003c/h2\u003e\u003ca id=\"user-content-method-1-use-singularity-image-recommended\" class=\"anchor\" aria-label=\"Permalink: Method 1: Use Singularity Image (Recommended)\" href=\"#method-1-use-singularity-image-recommended\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe entire workflow takes approximately 10 minutes to execute, including downloading container image and preparing environment (3 mins), running WarpX simulation (3 mins), running Nyx simulation (3 mins), and evaluating compression performance (1 min).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMinimum system requirements\u003c/h3\u003e\u003ca id=\"user-content-minimum-system-requirements\" class=\"anchor\" aria-label=\"Permalink: Minimum system requirements\" href=\"#minimum-system-requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOS: Ubuntu (20.04 is recommended)\u003c/p\u003e\n\u003cp\u003eMemory: \u0026gt;= 16 GB RAM\u003c/p\u003e\n\u003cp\u003eProcessor: \u0026gt;= 8 cores\u003c/p\u003e\n\u003cp\u003eStorage: \u0026gt;= 32 GBs\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 1: Install Singularity\u003c/h3\u003e\u003ca id=\"user-content-step-1-install-singularity\" class=\"anchor\" aria-label=\"Permalink: Step 1: Install Singularity\" href=\"#step-1-install-singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstall \u003ca href=\"https://singularity-tutorial.github.io/01-installation/\" rel=\"nofollow\"\u003eSingularity\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 2: Download the pre-built Singularity image file via gdown\u003c/h3\u003e\u003ca id=\"user-content-step-2-download-the-pre-built-singularity-image-file-via-gdown\" class=\"anchor\" aria-label=\"Permalink: Step 2: Download the pre-built Singularity image file via gdown\" href=\"#step-2-download-the-pre-built-singularity-image-file-via-gdown\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePress Enter after finishing.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo pip3 install gdown\ngdown https://drive.google.com/uc?id=14v_xUmET-HvCFO3LqmD4sNJL65jBcd0L\u0026amp;export=download\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor via GitHub\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/hipdac-lab/SC23-AMRIC-Image.git\ncat SC23-AMRIC-Image/img/amric.sif-* \u0026gt; amric.sif\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 3: Build and run the image file (need root privilege)\u003c/h3\u003e\u003ca id=\"user-content-step-3-build-and-run-the-image-file-need-root-privilege\" class=\"anchor\" aria-label=\"Permalink: Step 3: Build and run the image file (need root privilege)\" href=\"#step-3-build-and-run-the-image-file-need-root-privilege\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003esudo singularity build --sandbox artiAmr amric.sif\nsudo singularity shell --writable artiAmr\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 4: Set up environmental variables\u003c/h3\u003e\u003ca id=\"user-content-step-4-set-up-environmental-variables\" class=\"anchor\" aria-label=\"Permalink: Step 4: Set up environmental variables\" href=\"#step-4-set-up-environmental-variables\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003eexport OMPI_DIR=/opt/ompi \nexport OMPI_VERSION=4.1.1\nexport PATH=$OMPI_DIR/bin:$PATH\nexport LD_LIBRARY_PATH=$OMPI_DIR/lib:$LD_LIBRARY_PATH\nexport MANPATH=$OMPI_DIR/share/man:$MANPATH\nexport C_INCLUDE_PATH=/opt/ompi/include:$C_INCLUDE_PATH\nexport CPLUS_INCLUDE_PATH=/opt/ompi/include:$CPLUS_INCLUDE_PATH\nexport OMPI_ALLOW_RUN_AS_ROOT=1\nexport OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 5: Run WarpX simulation with no compression, AMReX\u0027s original compression, and AMRIC\u003c/h3\u003e\u003ca id=\"user-content-step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\" class=\"anchor\" aria-label=\"Permalink: Step 5: Run WarpX simulation with no compression, AMReX\u0027s original compression, and AMRIC\" href=\"#step-5-run-warpx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/wpx256/\n. bash.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 6: Run NYX simulation with no compression, AMReX\u0027s original compression, and AMRIC\u003c/h3\u003e\u003ca id=\"user-content-step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\" class=\"anchor\" aria-label=\"Permalink: Step 6: Run NYX simulation with no compression, AMReX\u0027s original compression, and AMRIC\" href=\"#step-6-run-nyx-simulation-with-no-compression-amrexs-original-compression-and-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/nyx128/\n. bash.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 7: Evaluate WarpX\u0027s data quality and compression ratio for original AMReX compression and our AMRIC\u003c/h3\u003e\u003ca id=\"user-content-step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\" class=\"anchor\" aria-label=\"Permalink: Step 7: Evaluate WarpX\u0027s data quality and compression ratio for original AMReX compression and our AMRIC\" href=\"#step-7-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/wpx256/diags/\n. decomp.sh \u0026gt; temp.txt\n. qualityCR.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 8: Evaluate NYX\u0027s data quality and compression ratio for original AMReX compression and our AMRIC\u003c/h3\u003e\u003ca id=\"user-content-step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\" class=\"anchor\" aria-label=\"Permalink: Step 8: Evaluate NYX\u0027s data quality and compression ratio for original AMReX compression and our AMRIC\" href=\"#step-8-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/nyx128/run/\n. decomp.sh \u0026gt; temp.txt\n. qualityCR.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 9: Compare I/O perf for baselines (i.e., no compression and ori AMReX compression) and AMRIC in WarpX\u003c/h3\u003e\u003ca id=\"user-content-step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\" class=\"anchor\" aria-label=\"Permalink: Step 9: Compare I/O perf for baselines (i.e., no compression and ori AMReX compression) and AMRIC in WarpX\" href=\"#step-9-compare-io-perf-for-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/wpx256/otfile/\n. io.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 10: Compare I/O performance between baselines and AMRIC in NYX\u003c/h3\u003e\u003ca id=\"user-content-step-10-compare-io-performance-between-baselines-and-amric-in-nyx\" class=\"anchor\" aria-label=\"Permalink: Step 10: Compare I/O performance between baselines and AMRIC in NYX\" href=\"#step-10-compare-io-performance-between-baselines-and-amric-in-nyx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd /home/nyx128/otfile/\n. io.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMethod 2: Build From Source\u003c/h2\u003e\u003ca id=\"user-content-method-2-build-from-source\" class=\"anchor\" aria-label=\"Permalink: Method 2: Build From Source\" href=\"#method-2-build-from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMinimum system \u0026amp; software libraries requirements\u003c/h3\u003e\u003ca id=\"user-content-minimum-system--software-libraries-requirements\" class=\"anchor\" aria-label=\"Permalink: Minimum system \u0026amp; software libraries requirements\" href=\"#minimum-system--software-libraries-requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOS: Linux (Ubuntu is recommended)\u003c/p\u003e\n\u003cp\u003eMemory: \u0026gt;= 16 GB RAM\u003c/p\u003e\n\u003cp\u003eProcessor: \u0026gt;= 8 cores\u003c/p\u003e\n\u003cp\u003egcc/9.4.0 (or 9.3.0)\u003c/p\u003e\n\u003cp\u003ecmake (\u0026gt;= 3.23)\u003c/p\u003e\n\u003cp\u003eOpenMPI/4.1.1 (install scripts provided, or spectrum-mpi)\u003c/p\u003e\n\u003cp\u003epython/3.8\u003c/p\u003e\n\u003cp\u003ehdf5/1.12.2 (install scripts provided)\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 1: Download AMRIC, checkpoint files, and set up environmental variables (2 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\" class=\"anchor\" aria-label=\"Permalink: Step 1: Download AMRIC, checkpoint files, and set up environmental variables (2 mins)\" href=\"#step-1-download-amric-checkpoint-files-and-set-up-environmental-variables-2-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/hipdac-lab/SC23-AMRIC.git\ncd SC23-AMRIC\nexport AMRIC_HOME=$(pwd)\necho \"# start of AMRIC env\" \u0026gt;\u0026gt; ~/.bashrc\necho export AMRIC_HOME=$(pwd) \u0026gt;\u0026gt; ~/.bashrc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 2: Load or install CMake and numpy. For example, in Ubuntu\u003c/h3\u003e\u003ca id=\"user-content-step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\" class=\"anchor\" aria-label=\"Permalink: Step 2: Load or install CMake and numpy. For example, in Ubuntu\" href=\"#step-2-load-or-install-cmake-and-numpy-for-example-in-ubuntu\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003epip3 install numpy\nsudo snap install cmake --classic\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 3: Load or install OpenMPI. For example, in Ubuntu (7 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\" class=\"anchor\" aria-label=\"Permalink: Step 3: Load or install OpenMPI. For example, in Ubuntu (7 mins)\" href=\"#step-3-load-or-install-openmpi-for-example-in-ubuntu-7-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003esudo bash openmpi.sh \n. mpi_env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 4: Download and install the HDF5 library (4 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-4-download-and-install-the-hdf5-library-4-mins\" class=\"anchor\" aria-label=\"Permalink: Step 4: Download and install the HDF5 library (4 mins)\" href=\"#step-4-download-and-install-the-hdf5-library-4-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e. hdf5.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 5: Install optimized SZ3 compressor and H5Z-SZ3 compression filter (5 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\" class=\"anchor\" aria-label=\"Permalink: Step 5: Install optimized SZ3 compressor and H5Z-SZ3 compression filter (5 mins)\" href=\"#step-5-install-optimized-sz3-compressor-and-h5z-sz3-compression-filter-5-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e. compressor.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 6: Install AMReX and Nyx with AMRIC (8 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-6-install-amrex-and-nyx-with-amric-8-mins\" class=\"anchor\" aria-label=\"Permalink: Step 6: Install AMReX and Nyx with AMRIC (8 mins)\" href=\"#step-6-install-amrex-and-nyx-with-amric-8-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e. nyx.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 7: Install WarpX with AMRIC (9 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-7-install-warpx-with-amric-9-mins\" class=\"anchor\" aria-label=\"Permalink: Step 7: Install WarpX with AMRIC (9 mins)\" href=\"#step-7-install-warpx-with-amric-9-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e. warpx.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 8: Download qcat (compression analysis tool, 1 min)\u003c/h3\u003e\u003ca id=\"user-content-step-8-download-qcat-compression-analysis-tool-1-min\" class=\"anchor\" aria-label=\"Permalink: Step 8: Download qcat (compression analysis tool, 1 min)\" href=\"#step-8-download-qcat-compression-analysis-tool-1-min\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e. qcat.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 9: Run WarpX with no compression, AMReX\u2019s original compression, and AMRIC (3 mins)\u003c/h3\u003e\u003ca id=\"user-content-step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\" class=\"anchor\" aria-label=\"Permalink: Step 9: Run WarpX with no compression, AMReX\u2019s original compression, and AMRIC (3 mins)\" href=\"#step-9-run-warpx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/warpx_directory/WarpX\n. runwarpx.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 10: Run NYX with no compression, AMReX\u2019s original compression, and AMRIC (3 mins).\u003c/h3\u003e\u003ca id=\"user-content-step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\" class=\"anchor\" aria-label=\"Permalink: Step 10: Run NYX with no compression, AMReX\u2019s original compression, and AMRIC (3 mins).\" href=\"#step-10-run-nyx-with-no-compression-amrexs-original-compression-and-amric-3-mins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/Nyx/Exec/AMR-density\n. runnyx.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 11: Evaluate WarpX\u2019s data quality and compression ratio for original AMReX compression and our AMRIC.\u003c/h3\u003e\u003ca id=\"user-content-step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\" class=\"anchor\" aria-label=\"Permalink: Step 11: Evaluate WarpX\u2019s data quality and compression ratio for original AMReX compression and our AMRIC.\" href=\"#step-11-evaluate-warpxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/warpx_directory/WarpX/diags\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss-w .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack-w .\ncp $AMRIC_HOME/qcat/install/bin/compareData .\n. decomp.sh \u0026gt; out.txt\n. qualityCR.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 12: Evaluate NYX\u2019s data quality and compression ratio for original AMReX compression and our AMRIC.\u003c/h3\u003e\u003ca id=\"user-content-step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\" class=\"anchor\" aria-label=\"Permalink: Step 12: Evaluate NYX\u2019s data quality and compression ratio for original AMReX compression and our AMRIC.\" href=\"#step-12-evaluate-nyxs-data-quality-and-compression-ratio-for-original-amrex-compression-and-our-amric\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/Nyx/Exec/AMR-density/run\ncp $AMRIC_HOME/qcat/install/bin/compareData .\ncp $AMRIC_HOME/SZ_SLE/build/tools/H5Z-SZ3/test/des .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/ss .\ncp $AMRIC_HOME/orisz3/build/tools/H5Z-SZ3/test/stack .\n. decomp.sh \u0026gt; out.txt\n. qualityCR.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 13: Compare I/O performance between baselines (i.e., no compression and ori AMReX compression) and AMRIC in WarpX.\u003c/h3\u003e\u003ca id=\"user-content-step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\" class=\"anchor\" aria-label=\"Permalink: Step 13: Compare I/O performance between baselines (i.e., no compression and ori AMReX compression) and AMRIC in WarpX.\" href=\"#step-13-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-warpx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/warpx_directory/WarpX/otfile\n. io.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 14: Compare I/O performance between baselines (i.e., no compression and ori AMReX compression) and AMRIC in Nyx.\u003c/h3\u003e\u003ca id=\"user-content-step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\" class=\"anchor\" aria-label=\"Permalink: Step 14: Compare I/O performance between baselines (i.e., no compression and ori AMReX compression) and AMRIC in Nyx.\" href=\"#step-14-compare-io-performance-between-baselines-ie-no-compression-and-ori-amrex-compression-and-amric-in-nyx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003ecd $AMRIC_HOME/Nyx/Exec/AMR-density/otfile\n. io.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExpected Evaluation Results\u003c/h2\u003e\u003ca id=\"user-content-expected-evaluation-results\" class=\"anchor\" aria-label=\"Permalink: Expected Evaluation Results\" href=\"#expected-evaluation-results\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eThe expected results for WarpX\u2019s data quality and compression ratio (method 1 step 6) are:\u003c/h3\u003e\u003ca id=\"user-content-the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\" class=\"anchor\" aria-label=\"Permalink: The expected results for WarpX\u2019s data quality and compression ratio (method 1 step 6) are:\" href=\"#the-expected-results-for-warpxs-data-quality-and-compression-ratio-method-1-step-6-are\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e----- Data Quality for original AMReX Compression -----\nPSNR = 58.600102\n---------- Data Quality for AMRIC-SZ-L/R ----------\nPSNR = 61.749515\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 59.146966\n---------- CR for original AMReX Compression ----------\nCR is: 14.62\n---------- CR for AMRIC-SZ-L/R ----------\nCR is: 108.94\n---------- CR for AMRIC-SZInterp ----------\nCR is: 131.41\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eThe expected results for Nyx\u2019s data quality and compression ratio (method 1 step 7) are:\u003c/h3\u003e\u003ca id=\"user-content-the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\" class=\"anchor\" aria-label=\"Permalink: The expected results for Nyx\u2019s data quality and compression ratio (method 1 step 7) are:\" href=\"#the-expected-results-for-nyxs-data-quality-and-compression-ratio-method-1-step-7-are\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e----- Data Quality for original AMReX Compression -----\nPSNR = 61.977332\n---------- Data Quality for AMRIC-SZ_L/R ----------\nPSNR = 66.650492\n---------- Data Quality for AMRIC-SZInterp ----------\nPSNR = 66.566370\n---------- CR for original AMReX Compression ----------\nCR is: 6.53\n---------- CR for AMRIC-SZ_L/R ----------\nCR is: 13.08\n---------- CR for AMRIC-SZInterp ----------\nCR is: 11.25\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eThe expected results for WarpX\u2019s I/O performance  (method 1 step 8) are:\u003c/h3\u003e\u003ca id=\"user-content-the-expected-results-for-warpxs-io-performance--method-1-step-8-are\" class=\"anchor\" aria-label=\"Permalink: The expected results for WarpX\u2019s I/O performance  (method 1 step 8) are:\" href=\"#the-expected-results-for-warpxs-io-performance--method-1-step-8-are\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e---------- Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression Total time = 1.514 seconds\nNo Compression Preprocess time = 0.216 seconds\nNo Compression writing time = 1.322 seconds\n...\n------------------------ END ------------------------\n------ Writing Time for original AMReX Compression ------\n***** run 0 *****\noriginal AMReX Total time = 4.734 seconds\noriginal AMReX Preprocess time = 0.189 seconds\noriginal AMReX Writing+Compression time = 4.493 seconds\n...\n------------------------ END ------------------------\n---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R Total time = 1.115 seconds\nAMRIC-SZ_L/R Preprocess time = 0.223 seconds\nAMRIC-SZ_L/R Writing+Compression time = 0.906 seconds\n...\n------------------------ END ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n***** run 0 *****\nAMRIC-SZ_Interp Total time = 1.878 seconds\nAMRIC-SZ_Interp Preprocess time = 0.950 seconds\nAMRIC-SZ_Interp Writing+Compression time = 0.937 seconds\n...\n------------------------ END ------------------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eThe expected results for Nyx\u2019s I/O performance  (method 1 step 9) are:\u003c/h3\u003e\u003ca id=\"user-content-the-expected-results-for-nyxs-io-performance--method-1-step-9-are\" class=\"anchor\" aria-label=\"Permalink: The expected results for Nyx\u2019s I/O performance  (method 1 step 9) are:\" href=\"#the-expected-results-for-nyxs-io-performance--method-1-step-9-are\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003e---------- Writing Time for No Compression ----------\n***** run 0 *****\nNo Compression Total time = 0.195 seconds\nNo Compression Preprocess time = 0.016 seconds\nNo Compression writing time = 0.177 seconds\n...\n------------------------ END ------------------------\n----- Writing Time for original AMReX Compression -----\n***** run 0 *****\noriginal AMReX Total time = 0.674 seconds\noriginal AMReX Preprocess time = 0.020 seconds\noriginal AMReX Writing+Compression time = 0.649 seconds\n...\n------------------------ END ------------------------\n---------- Writing Time for AMRIC-SZ_L/R ----------\n***** run 0 *****\nAMRIC-SZ_L/R Total time = 0.182 seconds\nAMRIC-SZ_L/R Preprocess time = 0.018 seconds\nAMRIC-SZ_L/R Writing+Compression time = 0.155 seconds\n...\n------------------------ END ------------------------\n---------- Writing Time for AMRIC-SZInterp ----------\n***** run 0 *****\nAMRIC-SZ_Interp Total time = 0.230 seconds\nAMRIC-SZ_Interp Preprocess time = 0.102 seconds\nAMRIC-SZ_Interp Writing+Compression time = 0.122 seconds\n...\n------------------------ END ------------------------\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1699637463.0
  },
  {
    "data_format": 2,
    "description": "Scripts to help building Exawind codes on various systems",
    "filenames": [
      "etc/spack/spack/spack.yaml",
      "etc/spack/nrel-eagle/spack.yaml"
    ],
    "full_name": "Exawind/exawind-builder",
    "latest_release": "v0.1.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eExaWind Code Builder\u003c/h1\u003e\u003ca id=\"user-content-exawind-code-builder\" class=\"anchor\" aria-label=\"Permalink: ExaWind Code Builder\" href=\"#exawind-code-builder\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\"\u003eDocumentation\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eExaWind Builder is a collection of bash scripts to configure and compile the\ncodes used within the \u003ca href=\"https://github.com/exawind\"\u003eExaWind\u003c/a\u003e project on various\nhigh-performance computing (HPC) systems. The builder provides the following\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePlatform configuration\u003c/strong\u003e: Provides the minimal set of modules that must be\nloaded when compiling with different compilers and MPI libraries on different\nHPC systems.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSoftware configuration\u003c/strong\u003e: Provides baseline CMake configuration that can be\nused to configure the various options when building a \u003cem\u003eproject\u003c/em\u003e, e.g.,\nenable/disable optional modules, automate specification of paths to various\nlibraries, configure release vs. debug builds.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eBuild script generation\u003c/strong\u003e: Generates an executable end-user script for a\ncombination of \u003cem\u003esystem\u003c/em\u003e, \u003cem\u003ecompiler\u003c/em\u003e, and \u003cem\u003eproject\u003c/em\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eExawind environment generation\u003c/strong\u003e: Generates a source-able, platform-specific\nscript that allows the user to recreate the exact environment used to build\nthe codes during runtime.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe build scripts are intended for developers who might want to compile the\ncodes with different configuration options, build different branches during\ntheir development cycle, or link to a different development version of a library\nthat is currently not available in the standard installation on the system. Please see the\n\u003ca href=\"https://exawind.github.io/exawind-builder\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e for\ndetails on how to use this to build ExaWind software.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation and usage\u003c/h2\u003e\u003ca id=\"user-content-installation-and-usage\" class=\"anchor\" aria-label=\"Permalink: Installation and usage\" href=\"#installation-and-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUsing exawind-builder with pre-installed ExaWind environment\u003c/h3\u003e\u003ca id=\"user-content-using-exawind-builder-with-pre-installed-exawind-environment\" class=\"anchor\" aria-label=\"Permalink: Using exawind-builder with pre-installed ExaWind environment\" href=\"#using-exawind-builder-with-pre-installed-exawind-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExaWind Builder is already installed and setup on OLCF Summit, NREL\nEagle/Rhodes, and NERSC Cori systems. On these systems, you can proceed directly\nto using build scripts from the central installation. Please consult \u003ca href=\"https://exawind.github.io/exawind-builder/basic.html#basic-usage\" rel=\"nofollow\"\u003euser\nmanual\u003c/a\u003e to\nlearn how to use the scripts.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBootstrapping exawind-builder with pre-configured system definitions\u003c/h3\u003e\u003ca id=\"user-content-bootstrapping-exawind-builder-with-pre-configured-system-definitions\" class=\"anchor\" aria-label=\"Permalink: Bootstrapping exawind-builder with pre-configured system definitions\" href=\"#bootstrapping-exawind-builder-with-pre-configured-system-definitions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExaWind builder has \u003ca href=\"https://exawind.github.io/exawind-builder/introduction.html#pre-configured-systems\" rel=\"nofollow\"\u003epre-built\nconfigurations\u003c/a\u003e\nfor several systems. On these systems you can use the \u003ccode\u003ebootstrap\u003c/code\u003e script to\nquickly get up and running. Please consult \u003ca href=\"https://exawind.github.io/exawind-builder/installation.html\" rel=\"nofollow\"\u003einstallation\nmanual\u003c/a\u003e. The\nrelevant steps are shown below.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Download bootstrap script\u003c/span\u003e\ncurl -fsSL -o bootstrap.sh https://raw.githubusercontent.com/exawind/exawind-builder/master/bootstrap.sh\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Make it executable\u003c/span\u003e\nchmod a+x bootstrap.sh\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Execute bootstrap and provide system/compiler combination\u003c/span\u003e\n./bootstrap.sh -s [SYSTEM] -c [COMPILER]\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Examples\u003c/span\u003e\n./bootstrap.sh -s spack -c clang       \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e On MacOS with homebrew\u003c/span\u003e\n./bootstrap.sh -s ornl-summit -c gcc   $ Oakridge Summit system\n./bootstrap.sh -s eagle -c gcc         \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e NREL Eagle\u003c/span\u003e\n./bootstrap.sh -s cori -c intel        \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e NERSC Cori\u003c/span\u003e\n./bootstrap.sh -s snl-ascicgpu -c gcc  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e SNL GPU development machine\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCreating new system configuration\u003c/h3\u003e\u003ca id=\"user-content-creating-new-system-configuration\" class=\"anchor\" aria-label=\"Permalink: Creating new system configuration\" href=\"#creating-new-system-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can add new system definitions to exawind-builder for use on new systems\nthat are not used by ExaWind team. Please see \u003ca href=\"https://exawind.github.io/exawind-builder/advanced.html\" rel=\"nofollow\"\u003emanual\ninstallation\u003c/a\u003e and\n\u003ca href=\"https://exawind.github.io/exawind-builder/newsys.html\" rel=\"nofollow\"\u003eadding a new system\u003c/a\u003e\nsections in the user manual.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLinks\u003c/h2\u003e\u003ca id=\"user-content-links\" class=\"anchor\" aria-label=\"Permalink: Links\" href=\"#links\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.exawind.org\" rel=\"nofollow\"\u003eExaWind\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/exawind\"\u003eExaWind GitHub Organization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://a2e.energy.gov/about/hfm\" rel=\"nofollow\"\u003eA2e HFM\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 6,
    "topics": [
      "cmake",
      "build",
      "exawind",
      "hpc",
      "exawind-builder"
    ],
    "updated_at": 1643028069.0
  },
  {
    "data_format": 2,
    "description": "pflotran .in-files for testcases",
    "filenames": [
      "installs/spack.yaml"
    ],
    "full_name": "JuliaPelzer/Phd_simulation_groundtruth",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePrerequisite (installs)\u003c/h1\u003e\u003ca id=\"user-content-prerequisite-installs\" class=\"anchor\" aria-label=\"Permalink: Prerequisite (installs)\" href=\"#prerequisite-installs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003epflotran (explanation below)\u003c/li\u003e\n\u003cli\u003epython 3.8.10 or newer (tested with this version)\u003c/li\u003e\n\u003cli\u003epython packages (installation via pip possible): numpy, noise\u003c/li\u003e\n\u003cli\u003ebash 5.0.17 or newer (tested with this version)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to install Pflotran using spack:\u003c/h2\u003e\u003ca id=\"user-content-how-to-install-pflotran-using-spack\" class=\"anchor\" aria-label=\"Permalink: How to install Pflotran using spack:\" href=\"#how-to-install-pflotran-using-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e. spack/share/spack/setup-env.sh\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ecopy \u003ccode\u003espack.yaml\u003c/code\u003e (pflotran specific) to folder and go there (e.g. \"cd test_nn/installs/\")\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack env activate .\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install\u003c/code\u003e / \u003ccode\u003espack install pflotran\u003c/code\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e\nneed internet access for it\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003enext login:\u003c/h3\u003e\u003ca id=\"user-content-next-login\" class=\"anchor\" aria-label=\"Permalink: next login:\" href=\"#next-login\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003ecd ../\u003c/code\u003e\n\u003ccode\u003e. spack/share/spack/setup-env.sh\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ego to folder with \u003ccode\u003espack.yaml\u003c/code\u003e (e.g. test_nn/installs)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack env activate .\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install pflotran\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePhd_simulation_groundtruth\u003c/h1\u003e\u003ca id=\"user-content-phd_simulation_groundtruth\" class=\"anchor\" aria-label=\"Permalink: Phd_simulation_groundtruth\" href=\"#phd_simulation_groundtruth\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ebuilds datasets with definable number of data points; based on one pflotran.in file, varying pressure gradients in external \u003ccode\u003e.txt\u003c/code\u003e file (and varying permeability fields based on \u003ccode\u003eperlin_noise\u003c/code\u003e in external \u003ccode\u003e.h5\u003c/code\u003e files)\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIf you use this script on a new computer\u003c/h2\u003e\u003ca id=\"user-content-if-you-use-this-script-on-a-new-computer\" class=\"anchor\" aria-label=\"Permalink: If you use this script on a new computer\" href=\"#if-you-use-this-script-on-a-new-computer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eremember to copy all (!) required files (see \u003ccode\u003e/dummy_dataset\u003c/code\u003e + \u003ccode\u003e*.sh\u003c/code\u003e bash-script + \u003ccode\u003e/scripts\u003c/code\u003e and \u003ccode\u003etest_*.py\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eif you run the script for a varying permeability field, check that you have all required files in dummy_dataset:\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003epflotran_vary_perm.in\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003esettings.yaml\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eset the \u003ccode\u003e$PFLOTRAN_DIR\u003c/code\u003e (in \u003ccode\u003e~/.zshrc\u003c/code\u003e or \u003ccode\u003e~/.bashrc\u003c/code\u003e or similar)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to run the script\u003c/h2\u003e\u003ca id=\"user-content-how-to-run-the-script\" class=\"anchor\" aria-label=\"Permalink: How to run the script\" href=\"#how-to-run-the-script\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ealways start from the dataset-directory where dummy_dataset, bash-script and scripts are located\u003c/li\u003e\n\u003cli\u003ethe datasets you want to simulate will be created in a subfolder\u003c/li\u003e\n\u003cli\u003erun script via \u003ccode\u003ebash \u0026lt;name_of_script\u0026gt;\u003c/code\u003e (here \u003ccode\u003e\u0026lt;name_of_script\u0026gt;\u003c/code\u003e is \u003ccode\u003emake_dataset_vary_perm.sh\u003c/code\u003e) \u003ccode\u003e\u0026lt;CLA_NUMBER_VARIATIONS_PRESSURE\u0026gt; \u0026lt;CLA_PRESSURE_CASE\u0026gt; \u0026lt;CLA_NUMBER_VARIATIONS_PERMEABILITY\u0026gt; \u0026lt;CLA_PERM_CASE\u0026gt; \u0026lt;CLA_DIMENSIONS\u0026gt; \u0026lt;CLA_NAME\u0026gt; \u0026lt;CLA_VISUALISATION\u0026gt;\u003c/code\u003e with the respective commandline arguments\n-CLA_NUMBER_VARIATIONS_PRESSURE and CLA_NUMBER_VARIATIONS_PERMEABILITY: number of variations of pressure and permeability field (e.g. 10 10)\n\u003cul\u003e\n\u003cli\u003eCLA_PRESSURE_CASE currently has two options: \"1D\" creates a dataset with a constant pressure field that only varies in the y-component (MOST LIKELY WHAT YOU WANT); \"2D\" creates a dataset with a constant pressure field that varies in the x- and y-component\u003c/li\u003e\n\u003cli\u003eCLA_PERM_CASE currently has two options: \"vary\" creates a dataset with a varying permeability field (through perlin noise); \"iso\" creates a dataset with a constant permeability field\u003c/li\u003e\n\u003cli\u003eCLA_DIMENSIONS: whether the dataset should be 2D or 3D\u003c/li\u003e\n\u003cli\u003eCLA_NAME is the name of the dataset to create, i.e. of the subfolder to create in the current directory\u003c/li\u003e\n\u003cli\u003eCLA_VISULISATION is an \u003cstrong\u003eoptional\u003c/strong\u003e commandline argument defining whether to produce some automated pictures (selfmade in python) : if you want it, write \"vis\" as CLA_VISUALISATION, else leave it empty\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIf you encounter an unexpected error\u003c/h2\u003e\u003ca id=\"user-content-if-you-encounter-an-unexpected-error\" class=\"anchor\" aria-label=\"Permalink: If you encounter an unexpected error\" href=\"#if-you-encounter-an-unexpected-error\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eyou can see that e.g. if a file fort.86 is produced\u003c/li\u003e\n\u003cli\u003ecomment \u003ccode\u003e-screen_output off\u003c/code\u003e out in the bash-script to get a log output from pflotran\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to change the size of the domain\u003c/h2\u003e\u003ca id=\"user-content-how-to-change-the-size-of-the-domain\" class=\"anchor\" aria-label=\"Permalink: How to change the size of the domain\" href=\"#how-to-change-the-size-of-the-domain\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003epflotran.in\u003c/code\u003e :\n\u003cul\u003e\n\u003cli\u003eadapt \u003ccode\u003eREGION all\u003c/code\u003e if domain should be larger than 200x2000x100m\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003echange the \u003ccode\u003esize\u003c/code\u003e and \u003ccode\u003encells\u003c/code\u003e in \u003ccode\u003esettings.yaml\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003echeck whether the heat pump is still located reasonably and if you change that position, remember to adapt the visualization and slicing as well\u003c/li\u003e\n\u003cli\u003eyou probably also want to change the frequency (for the permeability field) in \u003ccode\u003esettings.yaml\u003c/code\u003e \u003ccode\u003esettings.frequency = (4,4,2)\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow to get vtk output to view in paraview\u003c/h2\u003e\u003ca id=\"user-content-how-to-get-vtk-output-to-view-in-paraview\" class=\"anchor\" aria-label=\"Permalink: How to get vtk output to view in paraview\" href=\"#how-to-get-vtk-output-to-view-in-paraview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ein \u003ccode\u003epflotran.in\u003c/code\u003e change the following line:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eFORMAT VTK\u003c/code\u003e (approx. line 213)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1702456131.0
  },
  {
    "data_format": 2,
    "description": "Initial Cabana/Cajita Low/High-order Z-model Interface Solver. Benchmark for evaluating the performance of algorithms requiring global communication. Beatnik is also a precursor to potential later a High Performance Parallel Interface solver.",
    "filenames": [
      "configs/llnl/lassen/spack.yaml",
      "configs/llnl/quartz/spack.yaml",
      "configs/unm/hopper/spack.yaml",
      "configs/llnl/tioga/spack.yaml"
    ],
    "full_name": "CUP-ECS/beatnik",
    "latest_release": "v1.0.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eBeatnik - A Prototype High Performance Parallel Interface Benchmark\u003c/h1\u003e\u003ca id=\"user-content-beatnik---a-prototype-high-performance-parallel-interface-benchmark\" class=\"anchor\" aria-label=\"Permalink: Beatnik - A Prototype High Performance Parallel Interface Benchmark\" href=\"#beatnik---a-prototype-high-performance-parallel-interface-benchmark\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDescription\u003c/h2\u003e\u003ca id=\"user-content-description\" class=\"anchor\" aria-label=\"Permalink: Description\" href=\"#description\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBeatnik is a benchmark for global communication based on Pandya and Shkoller\u0027s 3D fluid interace \"Z-Model\" in the Cabana/Cajita mesh framework [1]. The goals\nof Beatnik are to:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eProvide an interesting and meaningful benchmark for numerical methods that require global communication, for example for far-field force calculations. This includes fast fourier transforms, distance sort cutoff-based methods, and (eventually) fast multi-pole methods.\u003c/li\u003e\n\u003cli\u003eUnderstand the performance characteristics of different parallel decompositions of the Z-Model based on both a 2D decomposition based on logical mesh location location and a space-filling curve mesh decomposition.\u003c/li\u003e\n\u003cli\u003eProvide a working prototype parallel implementation of the fluid interface model that other codes can use to create multi-scale models and codes.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBeatnik uses a simple mesh-based representation of the surface manifold as a Cabana grid 2D mesh in I/J space and a regular block 2D decomposition of this manifold. The physical position of each element in the mesh is stored as a separate vector in the nodes of the mesh. This design results in simple and efficient computation and communication strategies for surface normals, artificial viscosity, and Fourier transforms elements. However, it complicates methods where the data decomposition and communication is based on the spatial location of manifold points, requiring them to either maintain a separate spatial decomposition of the surface or to continually construct a spatial decomposition. A surface mesh that decomposed the mesh by spatial location would be an interesting alternative but would have the opposite issue - communication for surface calculations would be more complex but the (expensive) far force methods that rely on spatial decompositions (e.g. distance sort and spatial tree methods like the fast multi-pole method) would be less expensive.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding Beatnik\u003c/h2\u003e\u003ca id=\"user-content-building-beatnik\" class=\"anchor\" aria-label=\"Permalink: Building Beatnik\" href=\"#building-beatnik\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBeatnik relies on multiple external packages to build, including:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eECP CoPA\u0027s Cabana/Grid particle and mesh framework [2]\u003c/li\u003e\n\u003cli\u003eUT-Knoxville\u0027s HeFFTe fast fourier transform library [3]\u003c/li\u003e\n\u003cli\u003eA high-performance GPU-aware MPI implementation such as OpenMPI, MPICH, or MVAPICH\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo ease building Beatnik, the configs/ directory includes Spack configuration files for building in spack environments on multiple systems and test case run scripts for a variety of systems. In addition, the latest version of Spack includes a package description for directly building Beatnik. More information on building Beatnik can be found in the README.md file in the configs/ directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning Beatnik\u003c/h2\u003e\u003ca id=\"user-content-running-beatnik\" class=\"anchor\" aria-label=\"Permalink: Running Beatnik\" href=\"#running-beatnik\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBy default, Beatnik solves a simple multi-mode rocket rig problem sized for a single serial CPU core with approximately 4GB of memory. It also includes command line options to change initial problem state, I/O frequency, and to weak-scale scale up the initial problem to larger number of processes. It also includes problem-specific command line parameters; setting these parameters accurately generally requires expertise in fluid interface models. However, we provide several useful examples drawn from the ZModel papers that recreate the results in those papers.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eGeneral command line parameters\u003c/h3\u003e\u003ca id=\"user-content-general-command-line-parameters\" class=\"anchor\" aria-label=\"Permalink: General command line parameters\" href=\"#general-command-line-parameters\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-x [cuda|threads|serial]\u003c/code\u003e - The node-level parallelism/accelerator backend to use\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-F [write-frequency]\u003c/code\u003e - Interval between timesteps when I/O is written\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-O [solution order]\u003c/code\u003e - Order of solver to use (\u0027high\u0027, \u0027medium\u0027, or \u0027low\u0027). \u0027low\u0027 is the default.\u003c/li\u003e\n\u003cli\u003e`-w [weak scaling factor] - Scale up the problem specification, including the x/y bounding box, to be N times larger\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eProblem-specific command line parameters\u003c/h3\u003e\u003ca id=\"user-content-problem-specific-command-line-parameters\" class=\"anchor\" aria-label=\"Permalink: Problem-specific command line parameters\" href=\"#problem-specific-command-line-parameters\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-n [i/j mesh dimension ]\u003c/code\u003e - Number of points on the interface manifold in the I and J dimensions\u003c/li\u003e\n\u003cli\u003e`-t [timesteps] - number of timesteps to simulate\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-I [interface initialization]\u003c/code\u003e - Function to use for interface initial condition. Currently only \u0027cos\u0027 and \u0027sech2\u0027 are supported.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m [magnitude]\u003c/code\u003e - The maximum magnitude of the initialization function.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-p [period]\u003c/code\u003e - The number of periods of the interface in the initial bounding box\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-a [atwood]\u003c/code\u003e - Atwood\u0027s constant for the difference in pressure between the two fluids\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-g [gravity]\u003c/code\u003e - Gravitational acceleration in the -Z direction\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-a [atwood]\u003c/code\u003e -  Atwood\u0027s constant for the difference in pressure between the two fluids\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-M [mu]\u003c/code\u003e - Mu, the artificial viscosity constant used in the Z-Model\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-e [epsilon]\u003c/code\u003e - Epsilon, the desingularization constant used in the Z-Model expressed as a fraction of the distance between interface mesh points\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eExample 1: Periodic Multi-mode Rocket Rig\u003c/h3\u003e\u003ca id=\"user-content-example-1-periodic-multi-mode-rocket-rig\" class=\"anchor\" aria-label=\"Permalink: Example 1: Periodic Multi-mode Rocket Rig\" href=\"#example-1-periodic-multi-mode-rocket-rig\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe simplest test case and the one to which the rocketrig example program defaults is an initial interface distributed according to a cosine function. Simple usage examples:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eSerial execution: \u003ccode\u003ebin/rocketrig -x serial\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eCuda execution (on systems with GPUs) with a 512x512 mesh: \u003ccode\u003ebin/rocketrig -x cuda -n 512\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eCuda execution with a 1024x1024 problem scaled up to be sixteen times as large in terms of bounding box and number of total points with no I/O: bin/rocketrig -x cuda -n 1024 -F 0 -w 16`\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eExample 2: Non-periodic Single-mode Gaussian Rollup\u003c/h3\u003e\u003ca id=\"user-content-example-2-non-periodic-single-mode-gaussian-rollup\" class=\"anchor\" aria-label=\"Permalink: Example 2: Non-periodic Single-mode Gaussian Rollup\" href=\"#example-2-non-periodic-single-mode-gaussian-rollup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAnother test case is a single-mode rollup test where the intitial interface is set according to a hyperbolic secant function. This testcase recreates the the Gaussian perturbation results in Panda and Shkoller\u0027s paper from sections 2.3 and 2.4.  To run this testcase with a high-order model, use the following command line parameters. Note that this works best with a GPU accelerator, as the exact high-order far field force solver is very compute intensive and is generally impractical for non-trivial mesh sizes without GPU acceleration:\n\u003ccode\u003ebin/rocketrig -x cuda -O high -n 64 -I sech2 -m 0.1 -p 9.0 -b free -a 0.15 -M 2 -e 2\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePlanned Development Steps\u003c/h2\u003e\u003ca id=\"user-content-planned-development-steps\" class=\"anchor\" aria-label=\"Permalink: Planned Development Steps\" href=\"#planned-development-steps\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBeatnik is being implemented in multiple distinct steps, with associated planned releases:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eVersion 1.0 Features\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eA low-order model implementation that relies on Cabana Grid/HeFFTe Fourier transforms for estimating velocity interface at mesh points.\u003c/li\u003e\n\u003cli\u003eA high-order model implementation based on brute-force exact computation of long-range forces\u003c/li\u003e\n\u003cli\u003eA medium-order model that uses the Fourier transform for estimating interface velocity and the far-field force solver for estimating how the vorticity changes at each interface point.\u003c/li\u003e\n\u003cli\u003eSupport for periodic boundary conditions and free boundary conditions\u003c/li\u003e\n\u003cli\u003eSimple benchmark examples including a single-mode Gaussian roll-up test and the multi-mode rocket rig experiment.\u003c/li\u003e\n\u003cli\u003eDirect support for weak scaling of benchmarks through command line arguments\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eVersion 1.X Planned Features\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eRearchitecting of the z-model solve into explicitly-coupled surface mesh and spatial mesh solvers\u003c/li\u003e\n\u003cli\u003eA spatial mesh cutoff-based approach for calculating far-field forces using the Cabana particle framework. The goal of this work is to understand the accuracy/performance tradeoffs in the Z-Model, particularly in the medium-order\u003c/li\u003e\n\u003cli\u003eImproved timestep, desingularization, and artificial viscosity parameter handling. The goal of this is to provide good defaults when other input parameters are changed.\u003c/li\u003e\n\u003cli\u003eAdditional interface initialization options, including Gaussian random and file-based interface initialization (also useful for checkpointing)\u003c/li\u003e\n\u003cli\u003eSupport for coupling with other applications through either I/O (e.g. ADIOS) or Communication (e.g. Portage)\u003c/li\u003e\n\u003cli\u003eAdditional test case definitions\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePotential later (e.g. \u0026gt;=2.0) features\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDirect fast multi-pole or P3M solver for scalable, high precision high-order model solves.\u003c/li\u003e\n\u003cli\u003eSupport for multiple interface manifolds in a single simulation.\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgment, Contributors, and Copyright Information\u003c/h2\u003e\u003ca id=\"user-content-acknowledgment-contributors-and-copyright-information\" class=\"anchor\" aria-label=\"Permalink: Acknowledgment, Contributors, and Copyright Information\" href=\"#acknowledgment-contributors-and-copyright-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBeatnik is primarily available as open source under a 3-Clause BSD License. It is being developed at the University of New Mexico, Tennessee Tech University, and the University of Alabama under funding the U.S. Department of Energy\u0027s Predictive Science Academic Alliance Partnership III (PSAAP-III) program. Contributors to Beatnik development include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePatrick G. Bridges (\u003ca href=\"mailto:patrickb@unm.edu\"\u003epatrickb@unm.edu\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eThomas Hines (\u003ca href=\"mailto:tmhines3@ua.edu\"\u003etmhines3@ua.edu\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eJered Dominguez-Trujillo (\u003ca href=\"mailto:jereddt@unm.edu\"\u003ejereddt@unm.edu\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eJacob McCullough (\u003ca href=\"mailto:jmccullough12@unm.edu\"\u003ejmccullough12@unm.edu\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eJason Stewart (\u003ca href=\"mailto:jastewart@unm.edu\"\u003ejastewart@unm.edu\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe general structure of Beatnik and the rocketrig examples were taken from the ExaMPM proxy application (\u003ca href=\"https://github.com/ECP-copa/ExaMPM\"\u003ehttps://github.com/ECP-copa/ExaMPM\u003c/a\u003e) developed by the ECP Center for Particle Applications (CoPA), which was also available under a 3-Clause BSD License when used for creating application structure.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eReferences\u003c/h2\u003e\u003ca id=\"user-content-references\" class=\"anchor\" aria-label=\"Permalink: References\" href=\"#references\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eGavin Pandya and Steve Shkoller. \"3d Interface Models for Raleigh-Taylor Instability.\" Published as arxiv.org preprint \u003ca href=\"https://arxiv.org/abs/2201.04538\" rel=\"nofollow\"\u003ehttps://arxiv.org/abs/2201.04538\u003c/a\u003e, 2022.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ECP-copa/Cabana/\"\u003ehttps://github.com/ECP-copa/Cabana/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInnovative Computing Laboratory. \"heFFTe.\" URL: \u003ca href=\"https://icl.utk.edu/fft/\" rel=\"nofollow\"\u003ehttps://icl.utk.edu/fft/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1696885371.0
  },
  {
    "data_format": 2,
    "description": "This repository provides a set of configuration files and example scripts for running Mochi experiments on various platforms.",
    "filenames": [
      "ANL/Aurora/spack.yaml",
      "ORNL/Summit/spack.yaml",
      "ANL/Bebop/spack.yaml",
      "generic/spack.yaml",
      "ANL/JLSE/spack.yaml",
      "ORNL/Crusher/spack.yaml",
      "ANL/Cooley/spack.yaml"
    ],
    "full_name": "mochi-hpc-experiments/platform-configurations",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePlatform configurations for Mochi\u003c/h1\u003e\u003ca id=\"user-content-platform-configurations-for-mochi\" class=\"anchor\" aria-label=\"Permalink: Platform configurations for Mochi\" href=\"#platform-configurations-for-mochi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository provides Spack configuration files, example job scripts, and\nnotes about building and running Mochi-based codes on various platforms.\nPlease refer to the subdirectory for your platform of interest for more\ninformation.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003egeneric\u003c/code\u003e subdirectory contains a minimal Spack environment example that\ncan be used as a starting point for systems for which there is no existing\nrecipe.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsing spack.yaml files\u003c/h2\u003e\u003ca id=\"user-content-using-spackyaml-files\" class=\"anchor\" aria-label=\"Permalink: Using spack.yaml files\" href=\"#using-spackyaml-files\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eEach platform subdirectory in this repository provides a \u003ccode\u003espack.yaml\u003c/code\u003e file.\nA \u003ccode\u003espack.yaml\u003c/code\u003e file fully describes a Spack environment, including\nsystem-provided packages and compilers. It does so independently of any\n\u003ccode\u003ecompilers.yaml\u003c/code\u003e or \u003ccode\u003epackages.yaml\u003c/code\u003e files installed in \u003ccode\u003e~/.spack\u003c/code\u003e, thereby\npreventing interference with user-specific spack configurations as much as\npossible.\u003c/p\u003e\n\u003cp\u003eYou may use \u003ccode\u003espack.yaml\u003c/code\u003e files to create a\n\u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003eSpack environment\u003c/a\u003e\nin which Mochi packages will be installed.\u003c/p\u003e\n\u003cp\u003eIf you don\u0027t have Spack installed on your platform, clone it and set it up\nas follows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/spack/spack.git\n$ . spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRemember that the second line needs to be executed every time you open a new\nterminal; it may be helpful to create an alias in your bashrc file as a\nshortcut.\u003c/p\u003e\n\u003cp\u003eYou will then need to clone \u003ccode\u003emochi-spack-packages\u003c/code\u003e, which contains the Mochi packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow clone the present repository and \u003ccode\u003ecd\u003c/code\u003e into the subdirectory relevant\nto your platform. For example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git\n$ cd platform-configurations/ANL/Bebop\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, execute the following commands\n(changing \u003cem\u003emyenv\u003c/em\u003e into an appropriate name for your environment).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack env create myenv spack.yaml\n$ spack env activate myenv\n$ spack repo add /where/you/cloned/mochi-spack-packages\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eChange to a directory outside of the \u003ccode\u003eplatform-configurations\u003c/code\u003e folders\nand activate the environment as follows.\u003c/p\u003e\n\u003cp\u003eYou may now add specs to your environment. For instance if you want\nto install Margo, execute the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack add mochi-margo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf the \u003ccode\u003espack.yaml\u003c/code\u003e file provides multiple compilers and you want\nto use another than the default one, specify the compiler explicitely,\nfor example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack add mochi-margo %gcc@8.2.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote that the \u003ccode\u003espack.yaml\u003c/code\u003e file you used may already have a spec\nadded as an example (usually \u003ccode\u003emochi-margo\u003c/code\u003e). You can remove it as\nfollows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack rm mochi-margo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you have added the specs you need in your environment, install\neverything by executing the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou may add more specs later on. For more information on how to manage\nSpack environments, please refer to the Spack documentation.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing to this repository\u003c/h2\u003e\u003ca id=\"user-content-contributing-to-this-repository\" class=\"anchor\" aria-label=\"Permalink: Contributing to this repository\" href=\"#contributing-to-this-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eShould you want to contribute a \u003ccode\u003espack.yaml\u003c/code\u003e for a particular machine,\nplease submit a merge request with it, and ensure the following.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should contain the compiler(s) that have been tested\nand confirmed to work with Mochi packages.\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should try to list system-provided packages,\nin particular packages used for building (\u003ccode\u003ecmake\u003c/code\u003e, \u003ccode\u003eautoconf\u003c/code\u003e, etc.),\nand relevant system-provided MPI implementations.\n\u003cul\u003e\n\u003cli\u003eNote that this must be done manually.  Spack provides a \u003ccode\u003espack external find\u003c/code\u003e command that can be used to locate a subset of system packages,\nbut it does not populate the \u003ccode\u003espack.yaml\u003c/code\u003e file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should contain the relevant variants for packages,\nin particular the transport methods to use with \u003ccode\u003elibfabric\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eThe path to the \u003ccode\u003espack.yaml\u003c/code\u003e file should be of the form\n\u003ccode\u003e\u0026lt;institution\u0026gt;/\u0026lt;platform\u0026gt;/spack.yaml\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003ePlease make sure that your \u003ccode\u003espack.yaml\u003c/code\u003e is a reliable way to work with\nMochi on the target platform, other people will rely on it!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can also contribute changes to existing \u003ccode\u003espack.yaml\u003c/code\u003e files, in particular\nto add working compilers, system packages, etc. As always, please test that\nnew setups work before creating a merge request.\u003c/p\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1682086466.0
  },
  {
    "data_format": 2,
    "description": "Registry to store workflow descriptions",
    "filenames": [
      "kaust/exageostat/spack.yaml",
      "minimal_workflow/wordcount/spack.yaml"
    ],
    "full_name": "eflows4hpc/workflow-registry",
    "latest_release": "2nd_stack_release",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eWorkflow Registry\u003c/h1\u003e\u003ca id=\"user-content-workflow-registry\" class=\"anchor\" aria-label=\"Permalink: Workflow Registry\" href=\"#workflow-registry\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a repository to store the Workflow descriptions using the eFlows4HPC methodology. This description consist of at least the TOSCA description of the worklfow, the code of the their different steps and their required software per step.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRepository structure\u003c/h2\u003e\u003ca id=\"user-content-repository-structure\" class=\"anchor\" aria-label=\"Permalink: Repository structure\" href=\"#repository-structure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWorkflow descriptions have to be included inside this repository according to the following structure.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eworkflow-registry\n  |- workflow_1\n  |    |- tosca\n  |    |    |- types.yml               TOSCA description of the different components involved in the workflow\n  |    |       ... \n  |    |- step_1\n  |    |    |- eflows4hpc.yml          Sofware requirements for this workflow step. It can include apt pip and Spack specifications \n  |    |    |- src                     PyCOMPSs code of the workflow step\n  |    |       ...\n  |    |- step_2\n  |         ....\n  |- workflow_2                                \n  |\t...\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIncluding new Workflows\u003c/h2\u003e\u003ca id=\"user-content-including-new-workflows\" class=\"anchor\" aria-label=\"Permalink: Including new Workflows\" href=\"#including-new-workflows\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo include new workflows in the repository, first create a new fork of the repository and  include a new folder for the workflow with a subfolder for the TOSCA description and the different workflow steps. Finally, create a pull request with the new workflow description. This pull request will be reviewed and included in the repository.\u003c/p\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1711452398.0
  },
  {
    "data_format": 2,
    "description": "Spack environments for OLCF resources.",
    "filenames": [
      "hosts/peak/envs/base/spack.yaml",
      "hosts/borg/envs/base/spack.yaml",
      "hosts/summit/envs/base/spack.yaml",
      "hosts/ascent/envs/base/spack.yaml",
      "hosts/ascent/envs/base-rh7/spack.yaml",
      "hosts/frontier/envs/base/spack.yaml",
      "hosts/bones/envs/base/spack.yaml"
    ],
    "full_name": "mpbelhorn/olcf-spack-environments",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eOLCF Spack Environments\u003c/h1\u003e\u003ca id=\"user-content-olcf-spack-environments\" class=\"anchor\" aria-label=\"Permalink: OLCF Spack Environments\" href=\"#olcf-spack-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo contains the infrastructure and environment definitions to deploy\nsite-provided software on OLCF resources via Spack environments.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eClone this repo and it\u0027s facility-modified spack fork somewhere on an OLCF\nfilesystem:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recurse-submodules git@github.com:mpbelhorn/olcf-spack-environments.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recurse-submodules https://github.com/mpbelhorn/olcf-spack-environments\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNext, initialize spack and the build environment. This is done by calling\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eFACSPACK_MY_ENVS=/path/to/host-specific/private/envs FACSPACK_ENV_NAME=base . ./init-facility-spack.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will configure the spack build- and run-time environment build and install\nthe facility spack environment \u003ccode\u003eFACSPACK_ENV_NAME\u003c/code\u003e tracked by this repo for the\ncurrent machine in a private location under \u003ccode\u003eFACSPACK_MY_ENVS\u003c/code\u003e. Both of these\nvariables are optional. If omitted, each variable will take on their default\nvalues:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eFACSPACK_MY_ENVS=\"/sw/${_THIS_HOST}/spack-envs\"\nFACSPACK_ENV_NAME=\"base\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003esuch that sourcing this script by itself\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e. ./init-facility-spack.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewill setup the runtime shell environment to manipulate the production spack\nenvironment on the current system.\u003c/p\u003e\n\u003cp\u003eThis repo will always track at least one spack environment per machine named\n\u003ccode\u003ebase\u003c/code\u003e which is the complete standard software environment used in production\nfor that machine. Furthermore, only the user account with owner permissions on\nthe production environment may be used to manipulate it in the default\n\u003ccode\u003eFACSPACK_MY_ENVS\u003c/code\u003e.  This is an intentional safety mechanism to prevent multiple\nusers from concurrently modifying the production environment. Users may set an\nalternate \u003ccode\u003eFACSPACK_MY_ENVS\u003c/code\u003e under which they can run build tests using any\ntracked \u003ccode\u003ehosts/${_THIS_HOST}/${FACSPACK_ENV_NAME}/spack.yaml\u003c/code\u003e file in this repo.\u003c/p\u003e\n\u003cp\u003eFrom these variables, a unique path per each environment name will be\nconstructed:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eFACSPACK_ENV=\"${FACSPACK_MY_ENVS}/${FACSPACK_ENV_NAME}\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe value of \u003ccode\u003e${_THIS_HOST}\u003c/code\u003e is determined automatically from the hostname on\nwhich the init script is being run. For each system and environment tracked in\nthis repo that you wish to work on, ensure that the final expanded value of\n\u003ccode\u003eFACSPACK_ENV\u003c/code\u003e corresponds to an actual existing directory.\u003c/p\u003e\n\u003cp\u003eConfiguration paths in our \u003ccode\u003espack.yaml\u003c/code\u003e environments that are not fixed to\nuniversal values are expressed in terms of relative paths to either the spack\ninstance setup by \u003ccode\u003einit-facility-spack\u003c/code\u003e or the path to the \u003ccode\u003eFACSPACK_MY_ENVS\u003c/code\u003e.\nThese paths are referenced in the \u003ccode\u003espack.yaml\u003c/code\u003e files via environment variables\nset by \u003ccode\u003einit-facility-spack\u003c/code\u003e. This allows the \u003ccode\u003espack.yaml\u003c/code\u003e environment files to\ndefine portable and relocatable spack environments which can be re-deployed in\narbitrary private locations by any users without needing to modify the\nenvironment file.\u003c/p\u003e\n\u003cp\u003eThe following variables are exported in Spack\u0027s runtime environment by\n\u003ccode\u003einit-facility-spack\u003c/code\u003e and can be referred to in the \u003ccode\u003espack.yaml\u003c/code\u003e the enviornment\nfiles tracked in this repo.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e${FACSPACK_ENV}\u003c/code\u003e:\nPath to where spack environment will be installed. Contains subdirs \u003ccode\u003eopt\u003c/code\u003e\nand \u003ccode\u003emodules\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e${FACSPACK_ENV_MODULEROOT}\u003c/code\u003e:\nShortcut to \u003ccode\u003e${FACSPACK_ENV}/modules\u003c/code\u003e under which static and\nspack-generated modules are generated. Contains subdirectories \u003ccode\u003espack\u003c/code\u003e,\n\u003ccode\u003eflat\u003c/code\u003e, and \u003ccode\u003esite\u003c/code\u003e corresponding to lmod, tcl, and static modulefiles\nrespectively.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e${FACSPACK_CONF_COMMON}\u003c/code\u003e:\nPath to facility-wide common configuration files under \u003ccode\u003e${this_repo}/share\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e${FACSPACK_CONF_HOST}\u003c/code\u003e:\nPath to host-specific configuration files under \u003ccode\u003e${this_repo}/hosts/${_THIS_HOST}\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere are (as of spack v0.15.0) a couple exceptional paths used in \u003ccode\u003espack.yaml\u003c/code\u003e\nfiles which cannot de-reference environment variables. These affect\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMirrors\u003c/li\u003e\n\u003cli\u003eExtensions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSpack does not internally expand environment variables in the configuration of\nthese items so they must be expressed as hard-coded full path strings. The\ndefault values in this repo should point to permanent world-readable paths on\nthe OLCF filesystem populated with OLCF-maintained extensions and mirrors.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpack Fork\u003c/h2\u003e\u003ca id=\"user-content-spack-fork\" class=\"anchor\" aria-label=\"Permalink: Spack Fork\" href=\"#spack-fork\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe upstream development branch of spack is not used directly. Instead, the OLCF\nhas implemented some customizations that are tracked in the \"olcf-X.Y.Z\"\nbranches of a \u003ca href=\"https://github.com/mpbelhorn/olcf-spack/tree/olcf-0.15.0\"\u003efacility fork of spack\u003c/a\u003e\nwhere \u003ccode\u003eX.Y.Z\u003c/code\u003e refers to the tagged release of upstream spack from which the\nOLCF-modified branch is forked.\u003c/p\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1704744678.0
  },
  {
    "data_format": 2,
    "description": "HPC Container Tutorial at SC20",
    "filenames": [
      "exercises/spack_contenerize/spack.yaml",
      "files/spack_contenerize/spack.yaml"
    ],
    "full_name": "supercontainers/sc20-tutorial",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUsing Containers to Accelerate HPC\u003c/h1\u003e\u003ca id=\"user-content-using-containers-to-accelerate-hpc\" class=\"anchor\" aria-label=\"Permalink: Using Containers to Accelerate HPC\" href=\"#using-containers-to-accelerate-hpc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eView this on \u003ca href=\"https://supercontainers.github.io/sc20-tutorial/\" rel=\"nofollow\"\u003eGitHub Pages\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eECP Supercontainers Tutorial Session\u003c/h2\u003e\u003ca id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" aria-label=\"Permalink: ECP Supercontainers Tutorial Session\" href=\"#ecp-supercontainers-tutorial-session\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/ecp.jpg\"\u003e\u003cimg src=\"fig/ecp.jpg\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/pawsey.jpeg\"\u003e\u003cimg src=\"fig/pawsey.jpeg\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDetails\u003c/h2\u003e\u003ca id=\"user-content-details\" class=\"anchor\" aria-label=\"Permalink: Details\" href=\"#details\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHalf-day Tutorial Session\u003c/p\u003e\n\u003cp\u003eVenue: Supercomputing Conference 2020 (SC20\u0027)\u003c/p\u003e\n\u003cp\u003eDate: Tuesday, 10 November 2020 2:30pm - 6:30pm (Eastern Standard Time)\u003c/p\u003e\n\u003cp\u003eLocation: Virtual (Atlanta, GA, USA)\u003c/p\u003e\n\u003cp\u003eLink: \u003ca href=\"https://sc20.supercomputing.org/presentation/?id=tut129\u0026amp;sess=sess271\" rel=\"nofollow\"\u003eContainer Computing for HPC and Scientific Workflows @ SC20\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTopic Area: Programming Models \u0026amp; Systems Software\u003c/p\u003e\n\u003cp\u003eKeywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eEC2 Login\u003c/h2\u003e\u003ca id=\"user-content-ec2-login\" class=\"anchor\" aria-label=\"Permalink: EC2 Login\" href=\"#ec2-login\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThese will be provided the day of the tutorial.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAbstract\u003c/h2\u003e\u003ca id=\"user-content-abstract\" class=\"anchor\" aria-label=\"Permalink: Abstract\" href=\"#abstract\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eContainer computing has revolutionized the way applications are developed and delivered. It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity and Charliecloud enable a new paradigm for scientific and technical computing. However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches. This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes. The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.\u003c/p\u003e\n\u003cp\u003eThis is an updated version of the highly successful tutorial presented at SC16, SC17, SC18 and SC19.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a hands-on tutorial. Participants should bring a laptop and load or pre-install a terminal and/or ssh client in advance to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances.\u003c/p\u003e\n\u003cdiv\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/AWS_logo.png\"\u003e\u003cimg src=\"fig/AWS_logo.png\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis tutorial is supported by the Amazon AWS Machine Learning Research Awards. EC2 images and temporary login credentials will be distributed onsite at the tutorial.\u003c/p\u003e\n\u003cp\u003eAfter the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.\u003c/p\u003e\n\u003cp\u003eUS-West-Oregon: ami-0fe12765123c6a840\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOptional Prerequisites\u003c/h3\u003e\u003ca id=\"user-content-optional-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Optional Prerequisites\" href=\"#optional-prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUsers can also install Docker and Singularity prior to attending the tutorial session. Here, it may be beneficial to create a docker and sylabs (singularity) account in advance at \u003ca href=\"https://cloud.docker.com/\" rel=\"nofollow\"\u003ehttps://cloud.docker.com/\u003c/a\u003e and \u003ca href=\"https://cloud.sylabs.io/\" rel=\"nofollow\"\u003ehttps://cloud.sylabs.io/\u003c/a\u003e This accounts will be needed to create images on docker cloud/dockerhub and sylabs cloud.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://sylabs.io/guides/3.3/user-guide/\" rel=\"nofollow\"\u003eInstall Singularity on Linux\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://repo.sylabs.io/desktop/\" rel=\"nofollow\"\u003eInstall Singualrity on Mac\u003c/a\u003e (Alpha)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\"\u003eInstall Docker for Desktop\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eQuestions\u003c/h2\u003e\u003ca id=\"user-content-questions\" class=\"anchor\" aria-label=\"Permalink: Questions\" href=\"#questions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can ask questions verbally or with this \u003ca href=\"https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing\" rel=\"nofollow\"\u003eGoogle Doc\u003c/a\u003e.\nPlease append your question below the others in the document.\u003c/p\u003e\n\u003cp\u003eWe have also created a Slack Team for this.  The invitation link is \u003ca href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSchedule\u003c/h2\u003e\u003ca id=\"user-content-schedule\" class=\"anchor\" aria-label=\"Permalink: Schedule\" href=\"#schedule\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e14:30 - 14:45 Introduction to containers in HPC (Shane)\u003cbr\u003e\nIncluding defining jargon (containers, images, registries/repos,..)\u003c/p\u003e\n\u003cp\u003e14:45 - 15:25 Build and run your first Docker container (Shane)\u003cbr\u003e\nIncluding also minimal pull and run examples, to define these concepts\u003c/p\u003e\n\u003cp\u003e15:25 - 15:40 BREAK\u003c/p\u003e\n\u003cp\u003e15:40 - 16:15 Deploy containers on a supercomputer (Marco)\u003c/p\u003e\n\u003cp\u003e16:15 - 16:40 High-performance containers (Marco)\u003c/p\u003e\n\u003cp\u003e16:40 - 16:55 BREAK\u003c/p\u003e\n\u003cp\u003e16:55 - 17:15 Best practices (Shane)\u003c/p\u003e\n\u003cp\u003e17:15 - 17:35 E4S containers initiative (Sameer)\u003c/p\u003e\n\u003cp\u003e17:35 - 17:55 Advanced container builds (Eduardo)\u003c/p\u003e\n\u003cp\u003e17:55 - 18:00 Wrap-up and final Q\u0026amp;A\u003c/p\u003e\n\n",
    "stargazers_count": 4,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1653465626.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Gust test system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-gust",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eNCAR Spack Deployment\u003c/h1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-label=\"Permalink: NCAR Spack Deployment\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003egust\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eThu Mar 30 18:51:24 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003efd3fc5c8cd67abe692e5e38bae52f29fb32700a3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.04\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack version\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/gust/23.04\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/work/csgteam/spack-deployments/gust/23.04/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 13,
    "topics": [],
    "updated_at": 1705084500.0
  },
  {
    "data_format": 2,
    "description": "Dockerfile and artifacts (minus build cache) to create Spack tutorial container.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "spack/spack-tutorial-container",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack Tutorial Container\u003c/h1\u003e\u003ca id=\"user-content-spack-tutorial-container\" class=\"anchor\" aria-label=\"Permalink: Spack Tutorial Container\" href=\"#spack-tutorial-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains a container image you can use to do the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/tutorial.html\" rel=\"nofollow\"\u003eSpack Tutorial\u003c/a\u003e.\nIt\u0027s exactly like the AWS images we use when we give the tutorial at\nconferences.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-tutorial-container/blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-tutorial-container/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack-tutorial-container/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1708354611.0
  },
  {
    "data_format": 2,
    "description": "Spack Environments Templates for OLCF resources",
    "filenames": [
      "linux-rhel8-zen2/cirrus/spack.yaml",
      "linux-sles15-zen2/spock/spack.yaml",
      "linux-centos7-broadwell/or-slurm/spack.yaml",
      "cray-sles15-zen3/frontier/spack.yaml",
      "linux-rhel8-ppc64le/summit/spack.yaml"
    ],
    "full_name": "olcf/spack-environments",
    "latest_release": null,
    "readme": "\u003cp\u003eOLCF Spack Environments Templates\u003c/p\u003e\n\u003cp\u003eCompanion files the for: \u003ca href=\"https://docs.olcf.ornl.gov/software/spack_environments.html\" rel=\"nofollow\"\u003eOLCF Documentaton for spack environments\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePurpose\u003c/h2\u003e\u003ca id=\"user-content-purpose\" class=\"anchor\" aria-label=\"Permalink: Purpose\" href=\"#purpose\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe provided Spack environment files are intended to assist OLCF users in setup their development environment at the\nOLCF.  The base environment file includes the compilers and packages that are installed at the system level.\u003c/p\u003e\n\u003cp\u003eSpack documentation can be found \u003ca href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 19,
    "topics": [],
    "updated_at": 1705687927.0
  },
  {
    "data_format": 2,
    "description": "Training material on using containers in an HPC setting. ",
    "filenames": [
      "demos/spack_blast/spack.yaml"
    ],
    "full_name": "PawseySC/hpc-container-training",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eReadme\u003c/h1\u003e\u003ca id=\"user-content-readme\" class=\"anchor\" aria-label=\"Permalink: Readme\" href=\"#readme\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 5,
    "topics": [
      "docker",
      "singularity",
      "hpc",
      "pawsey",
      "training-materials"
    ],
    "updated_at": 1711687834.0
  },
  {
    "data_format": 2,
    "description": "Notes and manifests for testing batch and HPC-style processing on Red Hat OpenShift",
    "filenames": [
      "gromacs/spack.yaml"
    ],
    "full_name": "naps-product-sa/openshift-batch",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eopenshift-batch\u003c/h1\u003e\u003ca id=\"user-content-openshift-batch\" class=\"anchor\" aria-label=\"Permalink: openshift-batch\" href=\"#openshift-batch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTesting batch capabilities of OpenShift\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSimple NFS Storage\u003c/h2\u003e\u003ca id=\"user-content-simple-nfs-storage\" class=\"anchor\" aria-label=\"Permalink: Simple NFS Storage\" href=\"#simple-nfs-storage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eJust create a simple NFS server for shared storage this uses the upstream: \u003ca href=\"https://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner/tree/nfs-server-provisioner-1.8.0\"\u003ehttps://github.com/kubernetes-sigs/nfs-ganesha-server-and-external-provisioner/tree/nfs-server-provisioner-1.8.0\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ oc apply -k simple-nfs/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTodo\u003c/h2\u003e\u003ca id=\"user-content-todo\" class=\"anchor\" aria-label=\"Permalink: Todo\" href=\"#todo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eAWS FSx Lustre support in demo\u003c/li\u003e\n\u003cli\u003eMove users to external ldap maybe with \u003ca href=\"https://github.com/glauth/glauth\"\u003ehttps://github.com/glauth/glauth\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eImplement UID/GID enforcement per namespace\u003c/li\u003e\n\u003cli\u003eMore advanced view of how jobs are scheduled and placed on the cluster\u003c/li\u003e\n\u003cli\u003eAdd and schedule workloads to specialized hardware like GPU or IB\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1699820410.0
  },
  {
    "data_format": 2,
    "description": "Bash shell script for installing xSDK and other IDEAS packages",
    "filenames": [
      "platformFiles/summit/spack.yaml"
    ],
    "full_name": "xsdk-project/installxSDK",
    "latest_release": "v0.1.1",
    "stargazers_count": 5,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1700846395.0
  },
  {
    "data_format": 2,
    "description": ":ocean: Machine learning model for predicting ocean bathymetry",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "adamjstewart/bathymetry",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ebathymetry\u003c/h1\u003e\u003ca id=\"user-content-bathymetry\" class=\"anchor\" aria-label=\"Permalink: bathymetry\" href=\"#bathymetry\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\ud83c\udf0a Machine learning model for predicting ocean bathymetry\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/adamjstewart/bathymetry/actions/workflows/black.yaml\"\u003e\u003cimg src=\"https://github.com/adamjstewart/bathymetry/actions/workflows/black.yaml/badge.svg\" alt=\"black\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/adamjstewart/bathymetry/actions/workflows/flake8.yaml\"\u003e\u003cimg src=\"https://github.com/adamjstewart/bathymetry/actions/workflows/flake8.yaml/badge.svg\" alt=\"flake8\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/adamjstewart/bathymetry/actions/workflows/isort.yaml\"\u003e\u003cimg src=\"https://github.com/adamjstewart/bathymetry/actions/workflows/isort.yaml/badge.svg\" alt=\"isort\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/adamjstewart/bathymetry/actions/workflows/mypy.yaml\"\u003e\u003cimg src=\"https://github.com/adamjstewart/bathymetry/actions/workflows/mypy.yaml/badge.svg\" alt=\"mypy\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSystem Requirements\u003c/h2\u003e\u003ca id=\"user-content-system-requirements\" class=\"anchor\" aria-label=\"Permalink: System Requirements\" href=\"#system-requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe versions listed below are what was used in our paper. Newer or older versions may also work. If you encounter any issues with newer versions, please open an issue.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSoftware Dependencies\u003c/h3\u003e\u003ca id=\"user-content-software-dependencies\" class=\"anchor\" aria-label=\"Permalink: Software Dependencies\" href=\"#software-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ePython 3.11.7\u003c/li\u003e\n\u003cli\u003ecartopy 0.22.0\u003c/li\u003e\n\u003cli\u003ecmocean 3.0.3\u003c/li\u003e\n\u003cli\u003egeocube 0.4.2\u003c/li\u003e\n\u003cli\u003egeopandas 0.14.1\u003c/li\u003e\n\u003cli\u003ematplotlib 3.8.2\u003c/li\u003e\n\u003cli\u003enetcdf4 1.6.5\u003c/li\u003e\n\u003cli\u003enumpy 1.26.2\u003c/li\u003e\n\u003cli\u003epandas 2.1.4\u003c/li\u003e\n\u003cli\u003epygeos 0.14\u003c/li\u003e\n\u003cli\u003escikit-learn 1.3.2\u003c/li\u003e\n\u003cli\u003escipy 1.11.4\u003c/li\u003e\n\u003cli\u003eshapely 2.0.2\u003c/li\u003e\n\u003cli\u003exarray 2023.12.0\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOperating Systems\u003c/h3\u003e\u003ca id=\"user-content-operating-systems\" class=\"anchor\" aria-label=\"Permalink: Operating Systems\" href=\"#operating-systems\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003emacOS 14.1.2\u003c/li\u003e\n\u003cli\u003eUbuntu 22.04.3\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eHardware Requirements\u003c/h3\u003e\u003ca id=\"user-content-hardware-requirements\" class=\"anchor\" aria-label=\"Permalink: Hardware Requirements\" href=\"#hardware-requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eShould run on any CPU or RAM size, including on a laptop\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation Guide\u003c/h2\u003e\u003ca id=\"user-content-installation-guide\" class=\"anchor\" aria-label=\"Permalink: Installation Guide\" href=\"#installation-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFirst, clone this project:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u0026gt; \u003cspan class=\"pl-s1\"\u003egit clone https://github.com/adamjstewart/bathymetry.git\u003c/span\u003e\n\u0026gt; \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e bathymetry\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen, install the Python dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u0026gt; \u003cspan class=\"pl-s1\"\u003epip install -r requirements.txt\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should only take a few seconds to install.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eData\u003c/h2\u003e\u003ca id=\"user-content-data\" class=\"anchor\" aria-label=\"Permalink: Data\" href=\"#data\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAll data should be stored in the same root directory. The default is \u003ccode\u003edata\u003c/code\u003e, but a different directory can be specified with \u003ccode\u003e--data-dir\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCRUST1.0\u003c/h3\u003e\u003ca id=\"user-content-crust10\" class=\"anchor\" aria-label=\"Permalink: CRUST1.0\" href=\"#crust10\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis model is trained on the \u003ca href=\"https://igppweb.ucsd.edu/~gabi/crust1.html\" rel=\"nofollow\"\u003eCRUST1.0\u003c/a\u003e dataset. In order to reproduce this work, you will need to download both the \u003ca href=\"http://igppweb.ucsd.edu/~gabi/crust1/crust1.0.tar.gz\" rel=\"nofollow\"\u003ebasic model\u003c/a\u003e and the \u003ca href=\"http://igppweb.ucsd.edu/~gabi/crust1/crust1.0-addon.tar.gz\" rel=\"nofollow\"\u003eadd-on\u003c/a\u003e that includes the crustal type file. Then, extract the tarballs in a \u003ccode\u003ecrust1.0\u003c/code\u003e directory within the data directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSeafloor Age\u003c/h3\u003e\u003ca id=\"user-content-seafloor-age\" class=\"anchor\" aria-label=\"Permalink: Seafloor Age\" href=\"#seafloor-age\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSeafloor age data can be found at \u003ca href=\"https://www.earthbyte.org/category/resources/data-models/seafloor-age/\" rel=\"nofollow\"\u003eEarthByte\u003c/a\u003e. For this model, we downsample all seafloor age data to 1-degree resolution. We test with several different seafloor age datasets:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.earthbyte.org/webdav/ftp/earthbyte/agegrid/2020/Grids/age.2020.1.GTS2012.6m.nc\" rel=\"nofollow\"\u003eage2020\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.earthbyte.org/webdav/ftp/Data_Collections/Muller_etal_2019_Tectonics/Muller_etal_2019_Agegrids/Muller_etal_2019_Tectonics_v2.0_PresentDay_AgeGrid.nc\" rel=\"nofollow\"\u003eage2019\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.earthbyte.org/webdav/ftp/Data_Collections/Muller_etal_2016_AREPS/Muller_etal_2016_AREPS_Agegrids/Muller_etal_2016_AREPS_Agegrids_v1.17/Muller_etal_2016_AREPS_v1.17_PresentDay_AgeGrid.nc\" rel=\"nofollow\"\u003eage2016\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.earthbyte.org/webdav/ftp/papers/Muller_etal_OceanChemistry/Grids/agegrid_0.nc\" rel=\"nofollow\"\u003eage2013\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.earthbyte.org/webdav/ftp/Data_Collections/Muller_etal_2008_G3/Seafloor_ages/age.3.6.unscaled.nc\" rel=\"nofollow\"\u003eage2008\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEach of these files should be placed in their respective directories within the data directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePlate Boundaries\u003c/h3\u003e\u003ca id=\"user-content-plate-boundaries\" class=\"anchor\" aria-label=\"Permalink: Plate Boundaries\" href=\"#plate-boundaries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe plate boundaries shapefiles can be downloaded from the \u003ca href=\"https://github.com/fraxen/tectonicplates\"\u003eWorld tectonic plates and boundaries\u003c/a\u003e. Download and extract a zip file of the entire repository within the data directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDemo\u003c/h2\u003e\u003ca id=\"user-content-demo\" class=\"anchor\" aria-label=\"Permalink: Demo\" href=\"#demo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo train a ridge regression model, run the following command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u0026gt; \u003cspan class=\"pl-s1\"\u003epython3 train.py ridge\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eReading datasets...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/age2020/age.2020.1.GTS2012.6m.nc...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/crust1.0/crust1.bnds...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/crust1.0/crust1.vp...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/crust1.0/crust1.vs...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/crust1.0/crust1.rho...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/crust1.0/CNtype1-1.txt...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eReading data/tectonicplates-master/PB2002_plates.shp...\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003ePreprocessing...\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eCross-validation...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 2\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 3\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 4\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 5\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 6\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eGroup 7\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eEvaluating...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eRMSE: 0.591818050597389\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eR^2:  0.7508725821083216\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eSaving predictions...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eWriting checkpoints/checkpoint-ridge-100-True-False-None-False-1-auto-0.0001.pickle...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eWriting checkpoints/truth.nc...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eWriting checkpoints/ridge.nc...\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis should only take a few seconds to run. Replace \"ridge\" with other models to compare performance metrics. Note that MLP will take much longer (around an hour on a laptop).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eReproducibility\u003c/h2\u003e\u003ca id=\"user-content-reproducibility\" class=\"anchor\" aria-label=\"Permalink: Reproducibility\" href=\"#reproducibility\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo reproduce all experimental results from our paper, see the scripts in the \u003ccode\u003ejobs\u003c/code\u003e directory. Specifically:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eridge*.sh\u003c/code\u003e, \u003ccode\u003esvr*.sh\u003c/code\u003e, \u003ccode\u003emlp*.sh\u003c/code\u003e: find optimal hyperparameters for all models\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etrain.sh\u003c/code\u003e: reproduce results with optimal hyperparameters\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eablation.sh\u003c/code\u003e: feature and layer ablation study\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eplot.sh\u003c/code\u003e: generate some basic maps of the results\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese jobs were submitted using the Slurm Workload Manager on TACC and ICCP. The scripts should work on any system, but may be slow unless you use a cluster. If you use a different cluster, you may need to change the job configuration parameters.\u003c/p\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 3,
    "topics": [
      "machine-learning",
      "bathymetry",
      "crust",
      "geodynamics"
    ],
    "updated_at": 1710852153.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      ".gitlab/spack/environments/corona/spack.yaml",
      ".gitlab/spack/environments/quartz/spack.yaml",
      ".gitlab/spack/environments/pascal/spack.yaml"
    ],
    "full_name": "LLNL/DiHydrogen",
    "latest_release": "v0.3.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDiHydrogen\u003c/h1\u003e\u003ca id=\"user-content-dihydrogen\" class=\"anchor\" aria-label=\"Permalink: DiHydrogen\" href=\"#dihydrogen\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDiHydrogen is the second version of the\n\u003ca href=\"https://github.com/llnl/elemental\"\u003eHydrogen\u003c/a\u003e fork of the well-known\ndistributed linear algebra library,\n\u003ca href=\"https://github.com/elemental/elemental\"\u003eElemental\u003c/a\u003e.  DiHydrogen aims\nto be a basic distributed multilinear algebra interface with a\nparticular emphasis on the needs of the distributed machine learning\neffort, \u003ca href=\"https://github.com/llnl/lbann\"\u003eLBANN\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDiHydrogen is distributed under the terms of the Apache License (Version 2.0).\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under the Apache-2.0 licenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/LLNL/DiHydrogen/blob/develop/LICENSE\"\u003eLICENSE\u003c/a\u003e,\n\u003ca href=\"https://github.com/LLNL/DiHydrogen/blob/develop/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/LLNL/DiHydrogen/blob/develop/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: Apache-2.0\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-800100\u003c/p\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 11,
    "topics": [
      "cpp",
      "math-physics"
    ],
    "updated_at": 1706928333.0
  },
  {
    "data_format": 2,
    "description": "Documentations and tutorials for Margo, Thallium, Argobots, Mercury, and other Mochi libraries.",
    "filenames": [
      "code/spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-doc",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg\" alt=\"build\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eMochi documentation\u003c/h1\u003e\u003ca id=\"user-content-mochi-documentation\" class=\"anchor\" aria-label=\"Permalink: Mochi documentation\" href=\"#mochi-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains a Sphinx-based documentation\nfor the Mochi libraries: Margo, Thallium, Argobots, Mercury,\nABT-IO, and SSG, as well as corresponding code examples.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding the documentation\u003c/h2\u003e\u003ca id=\"user-content-building-the-documentation\" class=\"anchor\" aria-label=\"Permalink: Building the documentation\" href=\"#building-the-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo build and/or contribute to this documentation, you must have a Sphinx and\na few related extensions installed.  These can be installed as follows using\nPython\u0027s \u003ccode\u003epip\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install sphinx\npip install sphinx_rtd_theme\npip install sphinx_copybutton\npip install recommonmark\npip install breathe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAlternatively, those required packages may also be available in your\nplatform\u0027s primary package manager.  For example, in Ubuntu 23.04 you could\ndo the following instead of using pip:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt install python3-breathe python3-recommonmark python3-sphinx-copybutton python3-sphinx-rtd-theme\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou must also install the \u003ccode\u003edoxygen\u003c/code\u003e documentation system.  This is likely\navailable in your platform\u0027s primary package manager.  For example on Ubuntu:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt install doxygen\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you have these dependencies installed, clone this\nrepository and cd into it. You can change the documentation\nby editing the files in the source subdirectory (these files\nuse the .rst format). You can build the documentation\nusing the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd docs\nmake html\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd check the result by opening the \u003ccode\u003ebuild/html/index.html\u003c/code\u003e page\nthat has been created in the docs directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding the code examples\u003c/h2\u003e\u003ca id=\"user-content-building-the-code-examples\" class=\"anchor\" aria-label=\"Permalink: Building the code examples\" href=\"#building-the-code-examples\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo build the code, you will need spack and the\n\u003ca href=\"https://github.com/mochi-hpc/mochi-spack-packages\"\u003emochi repo\u003c/a\u003e setup.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd code\nspack env create mochi-doc-env spack.yaml\nspack env activate mochi-doc-env\nspack install\nmkdir build\ncd build\ncmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc\nmake\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1702435305.0
  },
  {
    "data_format": 2,
    "description": "Spack build cache for Github Actions",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "spack/github-actions-buildcache",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack buildcache for GitHub Actions\u003c/h1\u003e\u003ca id=\"user-content-spack-buildcache-for-github-actions\" class=\"anchor\" aria-label=\"Permalink: Spack buildcache for GitHub Actions\" href=\"#spack-buildcache-for-github-actions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repo provides a buildcache to speed up Spack in your GitHub Actions.\u003c/p\u003e\n\u003cp\u003eCurrently it provides binaries from Spack \u003ccode\u003edevelop\u003c/code\u003e for\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e%gcc@13 os=ubuntu22.04 target=x86_64_v3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e%gcc@12 os=ubuntu22.04 target=x86_64_v3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e%gcc@11 os=ubuntu22.04 target=x86_64_v3\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e%clang@15 os=ubuntu22.04 target=x86_64_v3\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo use it, add an environment \u003ccode\u003espack.yaml\u003c/code\u003e to the root of your own repository\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003espack\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eview\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003emy_view\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003especs\u003c/span\u003e:\n  - \u003cspan class=\"pl-s\"\u003epython@3.11\u003c/span\u003e\n\n  \u003cspan class=\"pl-ent\"\u003econfig\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003einstall_tree\u003c/span\u003e:\n      \u003cspan class=\"pl-ent\"\u003eroot\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e/opt/spack\u003c/span\u003e\n\n  \u003cspan class=\"pl-ent\"\u003epackages\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003eall\u003c/span\u003e:\n      \u003cspan class=\"pl-ent\"\u003erequire\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e%gcc@12 target=x86_64_v3\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand Spack install it in a GitHub Action:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eBuild\u003c/span\u003e\n\n\u003cspan class=\"pl-ent\"\u003eon\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003epush\u003c/span\u003e\n\n\u003cspan class=\"pl-ent\"\u003ejobs\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eexample\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003eruns-on\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eubuntu-22.04\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003esteps\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eCheckout\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003euses\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eactions/checkout@v4\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eSetup Spack\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003euses\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack/setup-spack@v2\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eConcretize\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . concretize\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eInstall\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . install --no-check-signature\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eRun\u003c/span\u003e\n        \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e./my_view/bin/python -c \u0027print(\"hello world\")\u0027\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCaching your own binaries\u003c/h2\u003e\u003ca id=\"user-content-caching-your-own-binaries\" class=\"anchor\" aria-label=\"Permalink: Caching your own binaries\" href=\"#caching-your-own-binaries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you want to cache your own binaries too, there are three steps to take:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eUse padding in the install root, and add an additional mirror to \u003ccode\u003espack.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003espack\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003econfig\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003einstall_tree\u003c/span\u003e:\n      \u003cspan class=\"pl-ent\"\u003eroot\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e/opt/spack\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003epadded_length\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003e128\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003emirrors\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003elocal-buildcache\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eoci://ghcr.io/\u0026lt;username\u0026gt;/spack-buildcache\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eConfigure the permissions for \u003ccode\u003eGITHUB_TOKEN\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003ejobs\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eexample\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003eruns-on\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eubuntu-22.04\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003epermissions\u003c/span\u003e:\n      \u003cspan class=\"pl-ent\"\u003epackages\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ewrite\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eAdd an extra job step that pushes installed Spack packages to the local\nbuildcache:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003ejobs\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eexample\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003esteps\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ePush packages and update index\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e|\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e        spack -e . mirror set --push --oci-username ${{ github.actor }} --oci-password \"${{ secrets.GITHUB_TOKEN }}\" local-buildcache\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e        spack -e . buildcache push --base-image ubuntu:22.04 --unsigned --update-index local-buildcache\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003c/span\u003e      \u003cspan class=\"pl-ent\"\u003eif\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e${{ !cancelled() }}\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNOTE: Make sure to add \u003ccode\u003eif: ${{ !cancelled() }}\u003c/code\u003e, so that binaries for successfully\ninstalled packages are available also when a dependent fails to build.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCaching your own binaries in \u003cem\u003eprivate\u003c/em\u003e repos and buildcaches\u003c/h3\u003e\u003ca id=\"user-content-caching-your-own-binaries-in-private-repos-and-buildcaches\" class=\"anchor\" aria-label=\"Permalink: Caching your own binaries in private repos and buildcaches\" href=\"#caching-your-own-binaries-in-private-repos-and-buildcaches\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWhen your local buildcache is stored in a private GitHub package,\nyou need to specify the OCI credentials already \u003cem\u003ebefore\u003c/em\u003e \u003ccode\u003espack concretize\u003c/code\u003e.\nThis is because Spack needs to fetch the buildcache index. Also, remember to\nremove the \u003ccode\u003e--push\u003c/code\u003e flag from \u003ccode\u003espack mirror set\u003c/code\u003e, since fetching needs\ncredentials too:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003ejobs\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eexample-private\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003esteps\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eLogin\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . mirror set --oci-username ${{ github.actor }} --oci-password \"${{ secrets.GITHUB_TOKEN }}\" local-buildcache\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eConcretize\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . concretize\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eInstall\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . install --no-check-signature\u003c/span\u003e\n\n    - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ePush packages and update index\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003erun\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack -e . buildcache push --base-image ubuntu:22.04 --unsigned --update-index local-buildcache\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFrom a security perspective, notice that the \u003ccode\u003eGITHUB_TOKEN\u003c/code\u003e is exposed to every\nsubsequent job step. (This is no different from \u003ccode\u003edocker login\u003c/code\u003e, which also likes\nto store credentials in the home directory.)\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you want to make more packages available, contribute to\n\u003ca href=\"spack.yaml\"\u003espack.yaml\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuild strategy\u003c/h2\u003e\u003ca id=\"user-content-build-strategy\" class=\"anchor\" aria-label=\"Permalink: Build strategy\" href=\"#build-strategy\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSince compiling software in GitHub actions is relatively slow, this stack is\nbuilt using \u003ccode\u003econcretizer:reuse:dependencies\u003c/code\u003e. That means that the latest\nversions of the packages listed in \u003ca href=\"spack.yaml\"\u003espack.yaml\u003c/a\u003e are built, but\ntheir dependencies are only updated when a package compatibility rule requires\nit. The stack is currently built on demand, not on a schdule.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis project is part of Spack. Spack is distributed under the terms of both the\nMIT license and the Apache License (Version 2.0). Users may choose either\nlicense, at their option.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0 licenses.\u003c/p\u003e\n\u003cp\u003eSee LICENSE-MIT, LICENSE-APACHE, COPYRIGHT, and NOTICE for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1707067801.0
  },
  {
    "data_format": 2,
    "description": "ISC 2023 -- Getting Started with Containers on HPC",
    "filenames": [
      "files/spack_containerize/spack.yaml",
      "exercises/spack_containerize/spack.yaml"
    ],
    "full_name": "supercontainers/isc-tutorial",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eGetting Started with Containers on HPC\u003c/h1\u003e\u003ca id=\"user-content-getting-started-with-containers-on-hpc\" class=\"anchor\" aria-label=\"Permalink: Getting Started with Containers on HPC\" href=\"#getting-started-with-containers-on-hpc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eView this on the \u003ca href=\"https://supercontainers.github.io/isc-tutorial/\" rel=\"nofollow\"\u003eTutorial Homepage\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eECP Supercontainers Tutorial Session\u003c/h2\u003e\u003ca id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" aria-label=\"Permalink: ECP Supercontainers Tutorial Session\" href=\"#ecp-supercontainers-tutorial-session\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/ecp.jpg\"\u003e\u003cimg src=\"fig/ecp.jpg\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/pawsey.jpeg\"\u003e\u003cimg src=\"fig/pawsey.jpeg\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDetails\u003c/h2\u003e\u003ca id=\"user-content-details\" class=\"anchor\" aria-label=\"Permalink: Details\" href=\"#details\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHalf-day Tutorial Session\u003c/p\u003e\n\u003cp\u003eVenue: International Supercomputing Conference (ISC 2023)\u003c/p\u003e\n\u003cp\u003eDate: 21 May 2023 2:00pm - 6:00pm, Central European Summer Time CEST (GMT+2)\u003c/p\u003e\n\u003cp\u003eLocation: Hamburg, Germany\u003c/p\u003e\n\u003cp\u003eLink: \u003ca href=\"https://app.swapcard.com/event/isc-high-performance-2023/planning/UGxhbm5pbmdfMTIyMDgwMA==\" rel=\"nofollow\"\u003eISC 2023 Schedule\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eKeywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eEC2 Login\u003c/h2\u003e\u003ca id=\"user-content-ec2-login\" class=\"anchor\" aria-label=\"Permalink: EC2 Login\" href=\"#ec2-login\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThese will be provided the day of the tutorial.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAbstract\u003c/h2\u003e\u003ca id=\"user-content-abstract\" class=\"anchor\" aria-label=\"Permalink: Abstract\" href=\"#abstract\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eContainer computing has revolutionized the way applications are developed and delivered.  It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer.  Tools like Docker, Shifter, Singularity, Charliecloud and Podman enable a new paradigm for scientific and technical computing.  However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches.  This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes.  The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.\u003c/p\u003e\n\u003cp\u003eThis is an updated version of the highly successful tutorial presented at SC16-21 and ISC19-22.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a hands-on tutorial.  Participants should bring a laptop and load or pre-install a terminal and/or ssh client in advance to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances.\u003c/p\u003e\n\u003cdiv\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"fig/AWS_logo.png\"\u003e\u003cimg src=\"fig/AWS_logo.png\" width=\"250\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis tutorial is supported by the Amazon AWS Machine Learning Research Awards.  EC2 images and temporary login credentials will be distributed onsite at the tutorial.\u003c/p\u003e\n\u003cp\u003eAfter the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.\u003c/p\u003e\n\u003cp\u003eUS-West-2 Oregon: ami-08ab931791269deeb\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOptional Prerequisites\u003c/h3\u003e\u003ca id=\"user-content-optional-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Optional Prerequisites\" href=\"#optional-prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUsers can also install Docker and Singularity prior to attending the tutorial session.  Here, it may be beneficial to create Docker and Sylabs (Singularity) accounts in advance at \u003ca href=\"https://cloud.docker.com/\" rel=\"nofollow\"\u003ehttps://cloud.docker.com/\u003c/a\u003e and \u003ca href=\"https://cloud.sylabs.io/\" rel=\"nofollow\"\u003ehttps://cloud.sylabs.io/\u003c/a\u003e.  These accounts will be needed to create images on Docker Cloud/Dockerhub and Sylabs Cloud.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://sylabs.io/guides/3.7/user-guide/\" rel=\"nofollow\"\u003eInstall Singularity on Linux\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://repo.sylabs.io/desktop/\" rel=\"nofollow\"\u003eInstall Singularity on Mac\u003c/a\u003e (Alpha)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\"\u003eInstall Docker for Desktop\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eQuestions\u003c/h2\u003e\u003ca id=\"user-content-questions\" class=\"anchor\" aria-label=\"Permalink: Questions\" href=\"#questions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can ask questions verbally or with this \u003ca href=\"https://docs.google.com/document/d/1zrWRGeDEbokQq03hAHxZzXpNzBSp4YSKJhHiNtjSe1Y/edit?usp=sharing\" rel=\"nofollow\"\u003eGoogle Doc\u003c/a\u003e.\nPlease append your question below the others in the document.\u003c/p\u003e\n\u003cp\u003eWe have also created a Slack Team for this.  The invitation link is in the Google Doc.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSchedule (See the git pages site for the autogenerated version)\u003c/h2\u003e\u003ca id=\"user-content-schedule-see-the-git-pages-site-for-the-autogenerated-version\" class=\"anchor\" aria-label=\"Permalink: Schedule (See the git pages site for the autogenerated version)\" href=\"#schedule-see-the-git-pages-site-for-the-autogenerated-version\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e14:00 - 14:15 Introduction to containers in HPC (Shane)\u003cbr\u003e\nIncluding defining jargon (containers, images, registries/repos,..)\u003c/p\u003e\n\u003cp\u003e14:15 - 14:55 Build and run your first container (Eduardo)\u003cbr\u003e\nBasic of containers and understanding the OCI Image Spec\u003c/p\u003e\n\u003cp\u003e14:55 - 15:30 Deploy containers on a supercomputer (Marco)\u003c/p\u003e\n\u003cp\u003e15:30 - 16:00 High-performance containers (Marco)\u003c/p\u003e\n\u003cp\u003e16:00 - 16:30 BREAK\u003c/p\u003e\n\u003cp\u003e16:30 - 17:05 Best practices (Shane)\u003c/p\u003e\n\u003cp\u003e17:05 - 17:35 E4S containers initiative (Sameer)\u003c/p\u003e\n\u003cp\u003e17:35 - 17:55 Advanced container builds (Eduardo)\u003c/p\u003e\n\u003cp\u003e17:55 - 18:00 Wrap-up and final Q\u0026amp;A\u003c/p\u003e\n",
    "stargazers_count": 6,
    "subscribers_count": 8,
    "topics": [
      "hpc",
      "containers",
      "singularity-container",
      "singularity",
      "shifter",
      "docker",
      "tutorial",
      "supercomputer"
    ],
    "updated_at": 1684672326.0
  },
  {
    "data_format": 2,
    "description": "Nonlinear CG methods for wave-function optimization in DFT",
    "filenames": [
      "spack-envs/q-e-sirius-cpu-only/spack.yaml"
    ],
    "full_name": "simonpintarelli/nlcglib",
    "latest_release": "v0.9.1",
    "stargazers_count": 6,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1705083092.0
  },
  {
    "data_format": 2,
    "description": "Repository for c2sm spack config and repo files",
    "filenames": [
      "upstreams/daint/icon-dsl/spack.yaml"
    ],
    "full_name": "C2SM/spack-c2sm",
    "latest_release": "v0.20.1.7",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eThe spack extension of C2SM and MCH\u003c/h1\u003e\u003ca id=\"user-content-the-spack-extension-of-c2sm-and-mch\" class=\"anchor\" aria-label=\"Permalink: The spack extension of C2SM and MCH\" href=\"#the-spack-extension-of-c2sm-and-mch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c31b5169516720383f9b49508fd95cfc457c5907282d9b1001af3280dc35326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/ansicolortags/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSpack is the package manager used by C2SM and MeteoSwiss to install and deploy software on supercomputers, local machines and the cloud.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentations\u003c/h2\u003e\u003ca id=\"user-content-documentations\" class=\"anchor\" aria-label=\"Permalink: Documentations\" href=\"#documentations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eInfos about c2sm-supported software and machines\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/latest\" rel=\"nofollow\"\u003espack-c2sm latest\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.20.1.4\" rel=\"nofollow\"\u003espack-c2sm v0.20.1.4\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.20.1.3\" rel=\"nofollow\"\u003espack-c2sm v0.20.1.3\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.20.1.0\" rel=\"nofollow\"\u003espack-c2sm v0.20.1.0\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.12\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.12\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.10\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.10\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.9\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.9\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.8\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.8\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.7\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.7\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.6\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.6\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.5\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.5\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.4\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.4\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.3\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.3\u003c/a\u003e [deprecated]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.2\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.2\u003c/a\u003e [deprecated]\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.1\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.1\u003c/a\u003e [deprecated]\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGeneral infos about spack\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.20.1/\" rel=\"nofollow\"\u003eOfficial spack v0.20.1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/\" rel=\"nofollow\"\u003eOfficial spack v0.18.1\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWorkflow\u003c/h2\u003e\u003ca id=\"user-content-workflow\" class=\"anchor\" aria-label=\"Permalink: Workflow\" href=\"#workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWith spack v0.18 we suggest local/individual spack instances and the use of spack environments.\u003c/p\u003e\n\u003cp\u003eA user clones the spack repo\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --depth 1 --recurse-submodules --shallow-submodules -b v0.20.1.5 https://github.com/C2SM/spack-c2sm.git\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003egets spack in the command line\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e spack-c2sm/setup-env.sh\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eactivates an environment\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epath_to_env\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand starts exploring\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack info \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\nspack spec \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand building\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack install \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\nspack dev-build \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ea package.\u003c/p\u003e\n\u003cp\u003eUpdating spack-c2sm is in the hands of the user.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit pull\ngit submodule update --recursive\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAfter an update we advice to clean\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack uninstall -a\nspack clean -a\nrm -rf \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/.spack\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand rebuild.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCommand cheat sheet\u003c/h2\u003e\u003ca id=\"user-content-command-cheat-sheet\" class=\"anchor\" aria-label=\"Permalink: Command cheat sheet\" href=\"#command-cheat-sheet\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eCommand\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eClone\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003egit clone --depth 1 --recurse-submodules --shallow-submodules -b \u0026lt;branch/tag\u0026gt; https://github.com/C2SM/spack-c2sm.git\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLoad\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003e. spack-c2sm/setup-env.sh\u003c/code\u003e autodetects machine \u003cbr\u003eor\u003cbr\u003e\u003ccode\u003e. spack-c2sm/setup-env.sh \u0026lt;machine\u0026gt;\u003c/code\u003e forces machine\u003cbr\u003eor\u003cbr\u003e\u003ccode\u003e. spack-c2sm/setup-env.sh unknown\u003c/code\u003e uses blank config\u003cbr\u003e\u003ccode\u003espack compiler find\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find\" rel=\"nofollow\"\u003eautodetects compilers\u003c/a\u003e\u003cbr\u003e\u003ccode\u003espack external find --all\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find\" rel=\"nofollow\"\u003eautodetects externally installed packages\u003c/a\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eUpdate\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003egit pull\u003c/code\u003e\u003cbr\u003e\u003ccode\u003egit submodule update --recursive\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eClean\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack uninstall -a\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall\" rel=\"nofollow\"\u003euninstalls all packages\u003c/a\u003e\u003cbr\u003e\u003ccode\u003espack clean -a\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean\" rel=\"nofollow\"\u003ecleans all misc caches\u003c/a\u003e\u003cbr\u003e\u003ccode\u003erm -rf ~/.spack\u003c/code\u003e removes user scope data\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies\" rel=\"nofollow\"\u003e\u003cstrong\u003eSpec syntax\u003c/strong\u003e\u003c/a\u003e: \u003ccode\u003e\u0026lt;package\u0026gt;\u003c/code\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier\" rel=\"nofollow\"\u003e\u003ccode\u003e@\u0026lt;version\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier\" rel=\"nofollow\"\u003e\u003ccode\u003e%\u0026lt;compiler\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants\" rel=\"nofollow\"\u003e\u003ccode\u003e+\u0026lt;variant\u0026gt; ~\u0026lt;variant\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies\" rel=\"nofollow\"\u003e\u003ccode\u003e^\u0026lt;sub-package\u0026gt; +\u0026lt;sub-package-variant\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags\" rel=\"nofollow\"\u003e\u003ccode\u003e\u0026lt;compiler flags\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eCommand\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eFind\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack find\u003c/code\u003e lists all installed packages. \u003cbr\u003e\u003ccode\u003espack find \u0026lt;spec\u0026gt;\u003c/code\u003e lists all installed packages that match the spec.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eInfo\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack info \u0026lt;package\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpec\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack spec \u0026lt;spec\u0026gt;\u003c/code\u003e concretizes abstract spec (unspecfied variant = \u003cstrong\u003eany\u003c/strong\u003e)\u003cbr\u003e\u003cem\u003eSpack is not required to use the default of an unspecified variant. The default value is only a tiebreaker for the concretizer.\u003c/em\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eInstall\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack install \u0026lt;spec\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLocate\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack location --install-dir \u0026lt;spec\u0026gt;\u003c/code\u003e prints location of \u003cstrong\u003eall\u003c/strong\u003e installs that satisfy the spec\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load\" rel=\"nofollow\"\u003eLoad env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack load \u0026lt;spec\u0026gt;\u003c/code\u003e loads run environment\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/environments.html\" rel=\"nofollow\"\u003eActivate env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack env activate \u0026lt;env_name\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/environments.html\" rel=\"nofollow\"\u003eDeactivate env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack deactivate\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n",
    "stargazers_count": 6,
    "subscribers_count": 18,
    "topics": [],
    "updated_at": 1711548583.0
  },
  {
    "data_format": 2,
    "description": "An event driven synchronization application for bridging GitHub and GitLab",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "LLNL/hubcast",
    "latest_release": null,
    "readme": "\u003cdiv align=\"center\"\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"logo/logo.svg\"\u003e\u003cimg src=\"logo/logo.svg\" width=\"400\" alt=\"Hubcast logo\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003cbr clear=\"all\"\u003e\n\u003c/h1\u003e\u003ca id=\"\" class=\"anchor\" aria-label=\"Permalink: \" href=\"#\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003e\u003ca href=\"#features\"\u003eFeatures\u003c/a\u003e \u00a0 \u2022 \u00a0 \u003ca href=\"/docs/getting-started.md\"\u003eGetting Started\u003c/a\u003e \u00a0 \u2022 \u00a0 \u003ca href=\"/docs/getting-started.md\"\u003eConfig\u003c/a\u003e \u00a0 \u2022 \u00a0 \u003ca href=\"/docs/CONTRIBUTING.md\"\u003eContributing\u003c/a\u003e \u00a0 \u2022 \u00a0 \u003ca href=\"https://github.com/LLNL/hubcast/releases\"\u003eChangelog\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003cp\u003eHubcast is an event driven synchronization application for bridging GitHub and GitLab. It automates various workflow tasks and handles jobs like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSyncing branches from GitHub to GitLab.\u003c/li\u003e\n\u003cli\u003eReporting CI job statuses back to GitHub from GitLab Workflow Runs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.apache.org/licenses/LICENSE-2.0\" rel=\"nofollow\"\u003ehttp://www.apache.org/licenses/LICENSE-2.0\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: Apache-2.0\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-847946\u003c/p\u003e\n",
    "stargazers_count": 6,
    "subscribers_count": 5,
    "topics": [
      "ci",
      "github-app",
      "gitlab-ci"
    ],
    "updated_at": 1709843655.0
  },
  {
    "data_format": 2,
    "description": "Utility library to handle small, reusable pools of both device memory buffers (via allocators) and device executors (with multiple scheduling policies).",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "SC-SGS/CPPuddle",
    "latest_release": "v0.3.1",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCPPuddle\u003c/h3\u003e\u003ca id=\"user-content-cppuddle\" class=\"anchor\" aria-label=\"Permalink: CPPuddle\" href=\"#cppuddle\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml\"\u003e\u003cimg src=\"https://github.com/SC-SGS/CPPuddle/actions/workflows/cmake.yml/badge.svg\" alt=\"ctest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/view/Octo-Tiger%20and%20Dependencies/job/CPPuddle/job/master/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1fb52bcf1fb6b241adb67e33da2e2093e2f6e3569a3f400b53f7b8f65bd12958/68747470733a2f2f73696d7367732e696e666f726d6174696b2e756e692d7374757474676172742e64652f6a656e6b696e732f6275696c645374617475732f69636f6e3f6a6f623d4350507564646c652532466d617374657226636f6e6669673d616c6c6275696c6473\" alt=\"Build Status\" data-canonical-src=\"https://simsgs.informatik.uni-stuttgart.de/jenkins/buildStatus/icon?job=CPPuddle%2Fmaster\u0026amp;config=allbuilds\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003ePurpose\u003c/h4\u003e\u003ca id=\"user-content-purpose\" class=\"anchor\" aria-label=\"Permalink: Purpose\" href=\"#purpose\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository was initially created to explore how to best use HPX and Kokkos together!\nFor fine-grained GPU tasks, we needed a way to avoid excessive allocations of one-usage GPU buffers (as allocations block the device for all streams) and creation/deletion of GPU executors (as those are usually tied to a stream which is expensive to create as well).\u003c/p\u003e\n\u003cp\u003eWe currently test/use CPPuddle in \u003ca href=\"https://github.com/STEllAR-GROUP/octotiger\"\u003eOcto-Tiger\u003c/a\u003e, together with \u003ca href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\u003eHPX-Kokkos\u003c/a\u003e.\nIn this use-case, allocating GPU buffers for all sub-grids in advance would have wasted a lot of memory. On the other hand, unified memory would have caused unnecessary GPU to CPU page migrations (as the old input data gets overwritten anyway). Allocating buffers on-the-fly would have blocked the device. Hence, we currently test this buffer management solution!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eTools provided by this repository\u003c/h4\u003e\u003ca id=\"user-content-tools-provided-by-this-repository\" class=\"anchor\" aria-label=\"Permalink: Tools provided by this repository\" href=\"#tools-provided-by-this-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eAllocators that reuse previousely allocated buffers if available (works with normal heap memory, pinned memory, aligned memory, CUDA/HIP device memory, and Kokkos Views). Note that separate buffers do not coexist on a single chunk of continuous memory, but use different allocations.\u003c/li\u003e\n\u003cli\u003eExecutor pools and various scheduling policies (round robin, priority queue, multi-gpu), which rely on reference counting to gauge the current load of a executor instead of querying the device itself. Tested with CUDA, HIP and Kokkos executors provided by HPX / HPX-Kokkos.\u003c/li\u003e\n\u003cli\u003eSpecial Executors/Allocators for on-the-fly work GPU aggregation (using HPX).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe documentation of the current master branch is available \u003ca href=\"https://sc-sgs.github.io/CPPuddle/\" rel=\"nofollow\"\u003ehere\u003c/a\u003e. In particular, the public functionality for the memory recycling in available in the namespace \u003ca href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1memory__recycling.html\" rel=\"nofollow\"\u003ememory_recycling\u003c/a\u003e, for the executor pools it is available in the namespace \u003ca href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1executor__recycling.html\" rel=\"nofollow\"\u003eexecutor_recycling\u003c/a\u003e and the work aggregation (kernel fusion) functionality is available in the namespace \u003ca href=\"https://sc-sgs.github.io/CPPuddle/namespacecppuddle_1_1kernel__aggregation.html\" rel=\"nofollow\"\u003ework_aggregation\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eRequirements\u003c/h4\u003e\u003ca id=\"user-content-requirements\" class=\"anchor\" aria-label=\"Permalink: Requirements\" href=\"#requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eC++17\u003c/li\u003e\n\u003cli\u003eCMake (\u0026gt;= 3.16)\u003c/li\u003e\n\u003cli\u003eOptional (for the header-only utilities / test): CUDA, Boost, \u003ca href=\"https://github.com/STEllAR-GROUP/hpx\"\u003eHPX\u003c/a\u003e, \u003ca href=\"https://github.com/kokkos/kokkos\"\u003eKokkos\u003c/a\u003e, \u003ca href=\"https://github.com/STEllAR-GROUP/hpx-kokkos\"\u003eHPX-Kokkos\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe submodules can be used to obtain the optional dependencies which are required for testing the header-only utilities. If these tests are not required, the submodule (and the respective buildscripts in /scripts) can be ignored safely.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eBuild / Install\u003c/h4\u003e\u003ca id=\"user-content-build--install\" class=\"anchor\" aria-label=\"Permalink: Build / Install\" href=\"#build--install\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eA spack package for CPPuddle is available in the \u003ca href=\"https://github.com/G-071/octotiger-spack\"\u003eoctotiger-spack repository\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBasic CMake build\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode\u003e  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                                                             \n  cmake --build /path/to/build --target install  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf installed correctly, CPPuddle can be used in other CMake-based projects via\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efind_package(CPPuddle REQUIRED)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eRecommended CMake build:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode\u003e  cmake -H/path/to/source -B$/path/to/build -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/path/to/install/cppuddle -DCPPUDDLE_WITH_HPX=ON -DCPPUDDLE_WITH_HPX_AWARE_ALLOCATORS=ON -DCPPUDDLE_WITH_TESTS=OFF -DCPPUDDLE_WITH_COUNTERS=OFF                                                             \n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 7,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1710270566.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml",
      "spack-configs/cori-e4s-20.10/prod/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/prod/tools/spack.yaml",
      "spack-configs/cori-e4s-20.10/spack.yaml",
      "spack-configs/perlmutter-user-spack/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/prod/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-23.08/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/cuda/spack.yaml",
      "spack-configs/perlmutter-spack-develop/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/cce/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/prod/data/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/math-libs/spack.yaml",
      "spack-configs/perlmutter-e4s-23.05/data/spack.yaml",
      "spack-configs/cori-e4s-22.02/spack.yaml",
      "spack-configs/perlmutter-e4s-23.08/prod/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/prod/gcc/spack.yaml"
    ],
    "full_name": "NERSC/spack-infrastructure",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack Infrastructure\u003c/h1\u003e\u003ca id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-label=\"Permalink: Spack Infrastructure\" href=\"#spack-infrastructure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Spack Infrastructure Project makes use of \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack package manager\u003c/a\u003e to install spack software stack on NERSC systems. This project contains spack configuration (\u003ccode\u003espack.yaml\u003c/code\u003e) required to build the spack stacks. The spack stack is based on \u003ca href=\"https://e4s.io/\" rel=\"nofollow\"\u003eExtreme-Scale Scientific Software Stack\u003c/a\u003e (E4S) where we install spack packages provided by E4S and use the recommended spack branch. We leverage \u003ca href=\"https://docs.gitlab.com/ee/ci/\" rel=\"nofollow\"\u003eGitlab CI\u003c/a\u003e to automate deployment to ensure reproducible and automated builds. For more details about this project you can see the documentation at \u003ca href=\"https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\"\u003ehttps://nersc-spack-infrastructure.rtfd.io\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSoftware Deployment Overview\u003c/h2\u003e\u003ca id=\"user-content-software-deployment-overview\" class=\"anchor\" aria-label=\"Permalink: Software Deployment Overview\" href=\"#software-deployment-overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe software deployment consist of the following steps\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAcquire Spack Configuration from E4S project \u003ca href=\"https://github.com/E4S-Project/e4s\"\u003ehttps://github.com/E4S-Project/e4s\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eCreate one or more spack configuration files (spack.yaml) with list of E4S packages and integrate spack configuration for NERSC system\u003c/li\u003e\n\u003cli\u003eCreate a Gitlab Job to trigger the pipeline for TDS and Deployment system\u003c/li\u003e\n\u003cli\u003eCreate a Modulefile as entry point to stack\u003c/li\u003e\n\u003cli\u003eWrite User Documentation\u003c/li\u003e\n\u003cli\u003eShare spack configuration with open-source community\u003c/li\u003e\n\u003cli\u003eSend announcement to all NERSC users\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 1: Acquire Spack Configuration\u003c/h3\u003e\u003ca id=\"user-content-step-1-acquire-spack-configuration\" class=\"anchor\" aria-label=\"Permalink: Step 1: Acquire Spack Configuration\" href=\"#step-1-acquire-spack-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAt NERSC, we plan our software deployment with E4S releases which is typically every 3 months however we perform deployment every 6 months. Once E4S has released the spack configuration we acquire the spack configuration which is typically found in \u003ca href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\u003ehttps://github.com/E4S-Project/e4s/tree/master/environments\u003c/a\u003e. We also acquire the spack \u003ca href=\"https://github.com/spack/spack/branches\"\u003ebranch\u003c/a\u003e used by E4S team as our baseline, this would be documented in the release notes. The name of branch map to the E4S version so version 23.05 will have a branch \u003ca href=\"https://github.com/spack/spack/tree/e4s-23.05\"\u003ee4s-23.05\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNext, we copy the packages into our project and create the spack configuration\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 2: Create Spack Configuration\u003c/h3\u003e\u003ca id=\"user-content-step-2-create-spack-configuration\" class=\"anchor\" aria-label=\"Permalink: Step 2: Create Spack Configuration\" href=\"#step-2-create-spack-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn this step we create the spack configuration. First we create a sub-directory in \u003cem\u003espack-configs\u003c/em\u003e with the naming convention to distinguish E4S version. This typically includes the\nname of the system such as \u003ccode\u003ecori\u003c/code\u003e or \u003ccode\u003eperlmutter\u003c/code\u003e followed by name of e4s version such as \u003ccode\u003ee4s-23.05\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003etree -L 1 spack-configs\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack-configs\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cori-e4s-20.10\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cori-e4s-21.02\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cori-e4s-21.05\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cori-e4s-22.02\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 perlmutter-e4s-21.11\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 perlmutter-e4s-22.05\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 perlmutter-e4s-22.11\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 perlmutter-e4s-23.05\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 perlmutter-spack-develop\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2514\u2500\u2500 perlmutter-user-spack\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e10 directories, 0 files\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eInside one of the stacks, you will see several sub-directories that are used for defining a sub-stack. These sub-stacks correspond to \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003espack environments\u003c/a\u003e. The \u003ccode\u003eprod\u003c/code\u003e directory is used for production deployment to install from the buildcache.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003etree -L 3 spack-configs/perlmutter-e4s-22.11\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack-configs/perlmutter-e4s-22.11\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cce\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 cuda\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 definitions.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 gcc\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u251c\u2500\u2500 nvhpc\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e\u2514\u2500\u2500 prod\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u251c\u2500\u2500 cce\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u251c\u2500\u2500 cuda\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u251c\u2500\u2500 gcc\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    \u2514\u2500\u2500 nvhpc\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e        \u2514\u2500\u2500 spack.yaml\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e9 directories, 9 files\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe create a special file named \u003ccode\u003edefinitions.yaml\u003c/code\u003e that is used for declaring definitions that is referenced in \u003ccode\u003espack.yaml\u003c/code\u003e. This file is appended to all spack configuration. We do this\nto ensure all specs are defined in one place.\u003c/p\u003e\n\u003cp\u003eDuring this step, we will create the spack configuration and specify our preferred compilers and package preference. We install software in buildcache so it can be relocated to production path. In order to accomplish this task, we use \u003ca href=\"https://spack.readthedocs.io/en/latest/pipelines.html\" rel=\"nofollow\"\u003espack pipelines\u003c/a\u003e that uses \u003ccode\u003espack ci generate\u003c/code\u003e and \u003ccode\u003espack ci rebuild\u003c/code\u003e to perform parallel pipeline execution. During this step, we determine which packages to install from E4S and add our own packages to comply with our site preference.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 3: Create Gitlab Job for Automation\u003c/h3\u003e\u003ca id=\"user-content-step-3-create-gitlab-job-for-automation\" class=\"anchor\" aria-label=\"Permalink: Step 3: Create Gitlab Job for Automation\" href=\"#step-3-create-gitlab-job-for-automation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOnce spack configuration is written, we create a gitlab job to trigger the pipeline. This can be done by specifying a job in \u003ca href=\"https://github.com/NERSC/spack-infrastructure/blob/main/.gitlab-ci.yml\"\u003e.gitlab-ci.yml\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe gitlab job can be triggered through \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"nofollow\"\u003escheduled pipelines\u003c/a\u003e, \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"nofollow\"\u003eweb-interface\u003c/a\u003e, or merge request to the project. A typical gitlab job will look something like this. Shown below is for E4S 23.05 generate job. We make use of gitlab feature named \u003ca href=\"https://docs.gitlab.com/ee/ci/yaml/index.html#extends\" rel=\"nofollow\"\u003eextends\u003c/a\u003e which allows us to reuse configuration. The \u003ccode\u003espack ci generate\u003c/code\u003e command will be the same for each substack. There is two jobs, first is the generate step performed by \u003ccode\u003espack ci generate\u003c/code\u003e and this triggers the downstream job created by spack.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003e.perlmutter-e4s-23.05-generate\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003estage\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003egenerate\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003eneeds\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e[\"perlmutter:check_spack_dependencies\"]\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003etags\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e[perlmutter-e4s]\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003einterruptible\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003eallow_failure\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003erules\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003eif\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") \u0026amp;\u0026amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")\u003c/span\u003e\n    - \u003cspan class=\"pl-ent\"\u003eif\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e($CI_PIPELINE_SOURCE == \"merge_request_event\")\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003echanges\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003espack-configs/perlmutter-e4s-23.05/$STACK_NAME/spack.yaml\u003c/span\u003e\n      - \u003cspan class=\"pl-s\"\u003espack-configs/perlmutter-e4s-23.05/definitions.yaml\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003ebefore_script\u003c/span\u003e:\n    \u003cspan class=\"pl-s\"\u003e- *copy_perlmutter_settings\u003c/span\u003e\n    \u003cspan class=\"pl-s\"\u003e- *startup_modules\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003escript\u003c/span\u003e:\n    \u003cspan class=\"pl-s\"\u003e- *e4s_23_05_setup \u003c/span\u003e\n    - \u003cspan class=\"pl-s\"\u003ecd $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/$STACK_NAME\u003c/span\u003e\n    - \u003cspan class=\"pl-s\"\u003ecat $CI_PROJECT_DIR/spack-configs/perlmutter-e4s-23.05/definitions.yaml \u0026gt;\u0026gt; spack.yaml\u003c/span\u003e\n    - \u003cspan class=\"pl-s\"\u003espack env activate --without-view  .\u003c/span\u003e\n    - \u003cspan class=\"pl-s\"\u003espack env st\u003c/span\u003e\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e- spack -d concretize -f | tee $CI_PROJECT_DIR/concretize.log    \u003c/span\u003e\n    - \u003cspan class=\"pl-s\"\u003espack -d ci generate --check-index-only --artifacts-root \"$CI_PROJECT_DIR/jobs_scratch_dir\" --output-file \"${CI_PROJECT_DIR}/jobs_scratch_dir/pipeline.yml\"\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003eartifacts\u003c/span\u003e: \n    \u003cspan class=\"pl-ent\"\u003epaths\u003c/span\u003e:\n    - \u003cspan class=\"pl-s\"\u003e${CI_PROJECT_DIR}/jobs_scratch_dir\u003c/span\u003e\n\n\n\u003cspan class=\"pl-ent\"\u003eperlmutter-e4s-23.05-cce-generate\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003eextends\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e.perlmutter-e4s-23.05-generate\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003evariables\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003eSTACK_NAME\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ecce\u003c/span\u003e\n\n\u003cspan class=\"pl-ent\"\u003eperlmutter-e4s-23.05-cce-build\u003c/span\u003e:\n  \u003cspan class=\"pl-ent\"\u003estage\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ebuild\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003eneeds\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e[\"perlmutter:check_spack_dependencies\", \"perlmutter-e4s-23.05-cce-generate\"]\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003eallow_failure\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003erules\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003eif\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e($CI_PIPELINE_SOURCE == \"schedule\" || $CI_PIPELINE_SOURCE == \"web\") \u0026amp;\u0026amp; ($PIPELINE_NAME == \"PERLMUTTER_E4S_23.05\")\u003c/span\u003e\n    - \u003cspan class=\"pl-ent\"\u003eif\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e($CI_PIPELINE_SOURCE == \"merge_request_event\")\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003echanges\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003espack-configs/perlmutter-e4s-23.05/cce/spack.yaml\u003c/span\u003e\n      - \u003cspan class=\"pl-s\"\u003espack-configs/perlmutter-e4s-23.05/definitions.yaml\u003c/span\u003e\n  \u003cspan class=\"pl-ent\"\u003etrigger\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003einclude\u003c/span\u003e:\n      - \u003cspan class=\"pl-ent\"\u003eartifact\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ejobs_scratch_dir/pipeline.yml\u003c/span\u003e\n        \u003cspan class=\"pl-ent\"\u003ejob\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eperlmutter-e4s-23.05-cce-generate\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003estrategy\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003edepend\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 4: Create Modulefile\u003c/h3\u003e\u003ca id=\"user-content-step-4-create-modulefile\" class=\"anchor\" aria-label=\"Permalink: Step 4: Create Modulefile\" href=\"#step-4-create-modulefile\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn this step, we create a modulefile as entry point to software stack and setup \u003ccode\u003espack\u003c/code\u003e. We do not create spack generated modules for spack packages, instead one is expected to use \u003ccode\u003espack load\u003c/code\u003e.  Shown below are the modulefiles available on NERSC system, they are typically called \u003ccode\u003ee4s/\u0026lt;version\u0026gt;\u003c/code\u003e with a symbolic link to module \u003ccode\u003espack/e4s-\u0026lt;version\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003esiddiq90@login37\u003c/span\u003e\u0026gt; \u003cspan class=\"pl-s1\"\u003eml -t av e4s\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/global/common/software/nersc/pm-2022.12.0/extra_modulefiles:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ee4s/22.05\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ee4s/22.11\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack/e4s-22.05\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack/e4s-22.11\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eShown below is the content of our modulefile, the setup is subject to change\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003esiddiq90@login37\u003c/span\u003e\u0026gt; \u003cspan class=\"pl-s1\"\u003eml --raw show e4s\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e   /global/common/software/nersc/pm-2022.12.0/extra_modulefiles/e4s/22.11.lua:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ewhatis([[\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e        The Extreme-scale Scientific Software Stack (E4S) is a collection of open source software packages for running scientific applications on high-performance computing (HPC) platforms.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e        ]])\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ehelp([[ The Extreme-scale Scientific Software Stack (E4S) is a community effort to provide open source software packages for developing, deploying and running scientific applications on high-performance computing (HPC) platforms. E4S provides from-source builds and containers of a broad collection of HPC software packages.\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eReferences:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  - E4S User Docs: https://e4s.readthedocs.io/en/latest/index.html\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  - E4S 22.11 Docs: https://docs.nersc.gov/applications/e4s/perlmutter/22.11/\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  - E4S Homepage: https://e4s-project.github.io/\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  - E4S GitHub: https://github.com/E4S-Project/e4s\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e        ]])\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003elocal root = \"/global/common/software/spackecp/perlmutter/e4s-22.11/default/spack\"\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003esetenv(\"SPACK_GNUPGHOME\", pathJoin(os.getenv(\"HOME\"), \".gnupg\"))\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003esetenv(\"SPACK_SYSTEM_CONFIG_PATH\", \"/global/common/software/spackecp/perlmutter/spack_settings\")\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e-- setup spack shell functionality\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003elocal shell = myShellType()\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eif (mode() == \"load\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    local spack_setup = \u0027\u0027\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    if (shell == \"sh\" or shell == \"bash\" or shell == \"zsh\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e         spack_setup = pathJoin(root, \"share/spack/setup-env.sh\")\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    elseif (shell == \"csh\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e         spack_setup = pathJoin(root, \"share/spack/setup-env.csh\")\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    elseif (shell == \"fish\")  then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e         spack_setup = pathJoin(root, \"share/spack/setup-env.fish\")\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    end\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    -- If we are unable to find spack setup script let\u0027s terminate now.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    if not isFile(spack_setup) then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e        LmodError(\"Unable to find spack setup script \" .. spack_setup .. \"\\n\")\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    end\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    execute{cmd=\"source \" .. spack_setup, modeA={\"load\"}}\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    LmodMessage([[\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    _______________________________________________________________________________________________________\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e     The Extreme-Scale Scientific Software Stack (E4S) is accessible via the Spack package manager.\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e     In order to access the production stack, you will need to load a spack environment. Here are some tips to get started:\u003c/span\u003e\n\n\n\u003cspan class=\"pl-c1\"\u003e     \u0027spack env list\u0027 - List all Spack environments\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e     \u0027spack env activate gcc\u0027 - Activate the \"gcc\" Spack environment\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e     \u0027spack env status\u0027 - Display the active Spack environment\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e     \u0027spack load amrex\u0027 - Load the \"amrex\" Spack package into your user environment\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e     For additional support, please refer to the following references:\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e       NERSC E4S Documentation: https://docs.nersc.gov/applications/e4s/\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e       E4S Documentation: https://e4s.readthedocs.io\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e       Spack Documentation: https://spack.readthedocs.io/en/latest/\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e       Spack Slack: https://spackpm.slack.com\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    ______________________________________________________________________________________________________\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    ]])\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e-- To remove spack from shell we need to remove a few environment variables, alias and remove $SPACK_ROOT/bin from $PATH\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eelseif (mode() == \"unload\" or mode() == \"purge\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    if (shell == \"sh\" or shell == \"bash\" or shell == \"zsh\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unset SPACK_ENV\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unset SPACK_ROOT\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unset -f spack\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    elseif (shell == \"csh\") then\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unsetenv SPACK_ENV\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unsetenv SPACK_ROOT\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e      execute{cmd=\"unalias spack\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    end\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    -- Need to remove $SPACK_ROOT/bin from $PATH which removes the \u0027spack\u0027 command\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    remove_path(\"PATH\", pathJoin(root, \"bin\"))\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e    -- Remove alias spacktivate. Need to pipe to /dev/null as invalid alias can report error to stderr\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    execute{cmd=\"unalias spacktivate \u0026gt; /dev/null\",modeA={\"unload\"}}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eend\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 5: User Documentation\u003c/h3\u003e\u003ca id=\"user-content-step-5-user-documentation\" class=\"anchor\" aria-label=\"Permalink: Step 5: User Documentation\" href=\"#step-5-user-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUser documentation is fundamental to help assist users with using E4S at NERSC. We document every E4S release with its \u003cem\u003eRelease Date\u003c/em\u003e and \u003cem\u003eEnd of Support\u003c/em\u003e date along with a documentation page outlining the software stack. Our E4S documentation is available at \u003ca href=\"https://docs.nersc.gov/applications/e4s/\" rel=\"nofollow\"\u003ehttps://docs.nersc.gov/applications/e4s/\u003c/a\u003e. The release date is when documentation is live. We perform this action in conjunction with release of modulefile so that user gain access to software stack.\u003c/p\u003e\n\u003cp\u003eUpon completion of this task, we are ready to make announcement to our NERSC users\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 6: Sharing spack configuration with open-source community\u003c/h3\u003e\u003ca id=\"user-content-step-6-sharing-spack-configuration-with-open-source-community\" class=\"anchor\" aria-label=\"Permalink: Step 6: Sharing spack configuration with open-source community\" href=\"#step-6-sharing-spack-configuration-with-open-source-community\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn this step, we share our spack configuration with open-source community that may benefit the wider community. We share our spack configuration at \u003ca href=\"https://github.com/spack/spack-configs\"\u003ehttps://github.com/spack/spack-configs\u003c/a\u003e. In addition, we update the \u003ca href=\"https://e4s.readthedocs.io/en/latest/facility_e4s.html\" rel=\"nofollow\"\u003eE4S Facility Dashboard\u003c/a\u003e that shows all the E4S deployments across all the facilities.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eStep 7: Public Announcement\u003c/h3\u003e\u003ca id=\"user-content-step-7-public-announcement\" class=\"anchor\" aria-label=\"Permalink: Step 7: Public Announcement\" href=\"#step-7-public-announcement\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is the final step of the deployment process, where we make a public announcement in NERSC weekly email, along with various slack channels such as Nersc User Group (NUG), Spack, ECP and E4S slack.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCurrent Challenges\u003c/h2\u003e\u003ca id=\"user-content-current-challenges\" class=\"anchor\" aria-label=\"Permalink: Current Challenges\" href=\"#current-challenges\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThere are several challenges with building spack stack at NERSC which can be summarized as follows\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSystem OS + Cray Programming Environment (CPE) changes\u003c/strong\u003e: A system upgrade such as change to \u003ccode\u003eglibc\u003c/code\u003e or upgrades in CPE can lead to full software stack rebuild, especially if you have external packages set for packages like \u003ccode\u003ecray-mpich\u003c/code\u003e, \u003ccode\u003ecray-libsci\u003c/code\u003e which generally change between versions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eIncompatibile compilers\u003c/strong\u003e: Some packages can\u0027t be built with certain compilers (\u003ccode\u003envhpc\u003c/code\u003e, \u003ccode\u003eaocc\u003c/code\u003e) which could be due to several factors.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn application doesn\u0027t have support though it was be added in newer version but you don\u0027t have it in your spack release used for deployment\u003c/li\u003e\n\u003cli\u003eLack of support in spack package recipe or spack-core base including spack-cray detection. This may require getting fix and cherry-pick commit or waiting for new version\u003c/li\u003e\n\u003cli\u003eSpack Cray detection is an important part in build errors including how one specifies externals via \u003ccode\u003emodules\u003c/code\u003e vs \u003ccode\u003eprefix\u003c/code\u003e both could be provided and it requires experimentation. An example of this is trying to get \u003ccode\u003ecray-mpich\u003c/code\u003e external one could set something like this with modules or prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e  \u003cspan class=\"pl-ent\"\u003ecray-mpich\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003ebuildable\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003eexternals\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003espec\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ecray-mpich@8.1.11 %gcc@9.3.0\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003eprefix\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003emodules\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003ecray-mpich/8.1.11\u003c/span\u003e\n      - \u003cspan class=\"pl-s\"\u003ecudatoolkit/21.9_11.4\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eSpack concretizer\u003c/strong\u003e prevent one from chosing a build configration for a spec. This requires a few troubleshooting step but usually boils down to:\n\u003cul\u003e\n\u003cli\u003eRead the spack package file \u003ccode\u003espack edit \u0026lt;package\u0026gt;\u003c/code\u003e for conflicts and try \u003ccode\u003espack spec\u003c/code\u003e to see concretized spec.\u003c/li\u003e\n\u003cli\u003eTry different version, different compiler, different dependency. Some packages have conflicting variant for instance one can\u0027t enable \u003ccode\u003e+openmp\u003c/code\u003e and \u003ccode\u003e+pthread\u003c/code\u003e it is mutually exclusive.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere is a document \u003ca href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\" rel=\"nofollow\"\u003eSpack E4S Issues on Permlutter\u003c/a\u003e outlining current issues with spack. If you need access to document please contact \u003cstrong\u003eShahzeb Siddiqui\u003c/strong\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContact\u003c/h2\u003e\u003ca id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you need elevated privledge or assistance with this project please contact one of the maintainers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eShahzeb Siddiqui - \u003ca href=\"mailto:shahzebsiddiqui@lbl.gov\"\u003eshahzebsiddiqui@lbl.gov\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eErik Palmer - \u003ca href=\"mailto:epalmer@lbl.gov\"\u003eepalmer@lbl.gov\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eJustin Cook - \u003ca href=\"mailto:JSCook@lbl.gov\"\u003eJSCook@lbl.gov\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S Team: Sameer Shende (\u003ca href=\"mailto:sameer@cs.uoregon.edu\"\u003esameer@cs.uoregon.edu\u003c/a\u003e), Christopher Peyralans (\u003ca href=\"mailto:lpeyrala@uoregon.edu\"\u003elpeyrala@uoregon.edu\u003c/a\u003e), Wyatt Spear (\u003ca href=\"mailto:wspear@cs.uoregon.edu\"\u003ewspear@cs.uoregon.edu\u003c/a\u003e), Nicholas Chaimov (\u003ca href=\"mailto:nchaimov@paratools.com\"\u003enchaimov@paratools.com\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 14,
    "topics": [],
    "updated_at": 1673545287.0
  },
  {
    "data_format": 2,
    "description": "A Spack recipe repository of Key4hep software.",
    "filenames": [
      "environments/key4hep-nightly/spack.yaml",
      "environments/key4hep-ci/spack.yaml",
      "environments/key4hep-release/spack.yaml"
    ],
    "full_name": "key4hep/key4hep-spack",
    "latest_release": "2021-10-29",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package repo for Key4HEP software packaging\u003c/h1\u003e\u003ca id=\"user-content-spack-package-repo-for-key4hep-software-packaging\" class=\"anchor\" aria-label=\"Permalink: Spack package repo for Key4HEP software packaging\" href=\"#spack-package-repo-for-key4hep-software-packaging\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository holds a set of Spack recipes for key4hep software.\u003c/p\u003e\n\u003cp\u003eConsult the the \u003ca href=\"https://cern.ch/key4hep\" rel=\"nofollow\"\u003ekey4hep documentation website\u003c/a\u003e and the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack documentation\u003c/a\u003e for more details.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpack Versions\u003c/h2\u003e\u003ca id=\"user-content-spack-versions\" class=\"anchor\" aria-label=\"Permalink: Spack Versions\" href=\"#spack-versions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe spack recipes in this repository should work with any version of spack (0.19\nis known to work and it\u0027s possible older versions work too, newer than 0.19\nworks). Some of the environments require spack 0.20 or newer since they use (or\nthey include a file that uses) the \u003ccode\u003erequire\u003c/code\u003e keyword which was introduced in\n\u003ca href=\"https://github.com/spack/spack/releases/tag/v0.20.0\"\u003espack 0.20\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRepository Contents\u003c/h2\u003e\u003ca id=\"user-content-repository-contents\" class=\"anchor\" aria-label=\"Permalink: Repository Contents\" href=\"#repository-contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eApart from the recipes for key4hep packages in the folder \u003ccode\u003epackages\u003c/code\u003e, the\nrepository contains a collection of environments used to build the stack in\n\u003ccode\u003eenvironments\u003c/code\u003e and some scripts used for publishing on cvmfs and other utilities\nin \u003ccode\u003escripts\u003c/code\u003e. The builds run in Gitlab CI runners and the workflows can be found\nin the file \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e in the \u003ca href=\"https://gitlab.cern.ch/key4hep/k4-deploy\" rel=\"nofollow\"\u003egitlab\nrepository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAdditionally, the file \u003ccode\u003e.latest-commit\u003c/code\u003e contains the latest commit of Spack used\nfor the recent builds, which is updated from time to time to keep up with the\ndevelop branch of Spack.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCentral Installations\u003c/h2\u003e\u003ca id=\"user-content-central-installations\" class=\"anchor\" aria-label=\"Permalink: Central Installations\" href=\"#central-installations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstallations of the software stack can be found under \u003ccode\u003e/cvmfs/sw.hsf.org\u003c/code\u003e (for\nCentOS 7) and \u003ccode\u003e/cvmfs/sw-nightlies.hsf.org\u003c/code\u003e (for CentOS 7, AlmaLinux 9 and\nUbuntu) see:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\" rel=\"nofollow\"\u003ehttps://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRequirements\u003c/h2\u003e\u003ca id=\"user-content-requirements\" class=\"anchor\" aria-label=\"Permalink: Requirements\" href=\"#requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo compile the key4hep stack some system packages are required; without these,\nthe spack concretization or compilation can fail. The packages needed are an\nOpenGL implementation that can be installed:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eyum install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Centos 7\u003c/span\u003e\napt install -y libgl1-mesa-glx libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\ndnf install -y mesa-libGL mesa-libGL-devel mesa-libGLU mesa-libGLU-devel      \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e AlmaLinux 9\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe environments that make use of these libraries or headers expect them to be\nfound under \u003ccode\u003e/usr\u003c/code\u003e, which is the typical location when they are installed\nsystem-wide (for example in \u003ccode\u003e/usr/include\u003c/code\u003e or \u003ccode\u003e/usr/lib\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eAlternatively, one can install\n\u003ca href=\"https://gitlab.cern.ch/linuxsupport/rpms/HEP_OSlibs\" rel=\"nofollow\"\u003eHEP_OSlibs\u003c/a\u003e, which will\ninstall the previous and more libraries.\u003c/p\u003e\n\u003cp\u003eIn addition, for Ubuntu and Alma 9 the compilers are picked up from the system,\nso, for example, building in an image without \u003ccode\u003egcc\u003c/code\u003e or \u003ccode\u003eglibc\u003c/code\u003e won\u0027t work. These\ncommands should install most of the compilers and the development tools:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eapt install -y build-essential gfortran                            \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\ndnf groupinstall -y \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eDevelopment Tools\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e dnf install -y gfortran \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e AlmaLinux 9\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eDockerfiles with the images that are used to build the key4hep stack can be\nfound in \u003ca href=\"https://github.com/key4hep/key4hep-images\"\u003ehttps://github.com/key4hep/key4hep-images\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1682439760.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "benchmarks/blas-axpy/spack-env/spack.yaml"
    ],
    "full_name": "giordano/julia-on-fugaku",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eJulia on Fugaku (2022-07-23)\u003c/h1\u003e\u003ca id=\"user-content-julia-on-fugaku-2022-07-23\" class=\"anchor\" aria-label=\"Permalink: Julia on Fugaku (2022-07-23)\" href=\"#julia-on-fugaku-2022-07-23\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eNote: many links refer to internal documentation which is accessible only to Fugaku users.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRead the paper\u003c/h2\u003e\u003ca id=\"user-content-read-the-paper\" class=\"anchor\" aria-label=\"Permalink: Read the paper\" href=\"#read-the-paper\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBenchmarks present in this repository have been published in the paper \u003ca href=\"https://doi.org/10.1109/CLUSTER51413.2022.00072\" rel=\"nofollow\"\u003eProductivity meets\nPerformance: Julia on A64FX\u003c/a\u003e, presented at\nthe 2022 IEEE International Conference on Cluster Computing (CLUSTER22), as part of the\n\u003ca href=\"https://arm-hpc-user-group.github.io/eahpc-2022/\" rel=\"nofollow\"\u003eEmbracing Arm for High Performance Computing\nWorkshop\u003c/a\u003e (pre-print available on arXiv:\n\u003ca href=\"https://arxiv.org/abs/2207.12762\" rel=\"nofollow\"\u003e\u003ccode\u003e2207.12762\u003c/code\u003e\u003c/a\u003e).  See the \u003ca href=\"./CITATION.bib\"\u003e\u003ccode\u003eCITATION.bib\u003c/code\u003e\u003c/a\u003e\nfile for a BibTeX entry to cite the paper.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eStorage\u003c/h2\u003e\u003ca id=\"user-content-storage\" class=\"anchor\" aria-label=\"Permalink: Storage\" href=\"#storage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBefore doing anything on Fugaku, be aware that there are \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20220408_01\" rel=\"nofollow\"\u003etight\nlimits\u003c/a\u003e on the size of (20 GiB)\nand the number of inodes in (200k) your home directory.  If you use many Julia Pkg\nartifacts, it\u0027s very likely you\u0027ll hit these limits.  You\u0027ll notice that you hit the limit\nbecause any disk I/O operation will result in a \u003ccode\u003eDisk quota exceeded\u003c/code\u003e error like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003e[user@fn01sv03 ~]\u003c/span\u003e$ \u003cspan class=\"pl-s1\"\u003etouch foo\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003etouch: cannot touch \u0027foo\u0027: Disk quota exceeded\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can check the quota of your home directory with \u003ccode\u003eaccountd\u003c/code\u003e for the size, and \u003ccode\u003eaccountd -i\u003c/code\u003e for the number of inodes.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUsing the data directory\u003c/h3\u003e\u003ca id=\"user-content-using-the-data-directory\" class=\"anchor\" aria-label=\"Permalink: Using the data directory\" href=\"#using-the-data-directory\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn order to avoid clogging up the home directory you may want to move the Julia depot to the\ndata directory:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eDATADIR=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/data/\u0026lt;YOUR GROUP\u0026gt;/\u003cspan class=\"pl-smi\"\u003e${USER}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e JULIA_DEPOT_PATH=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${DATADIR}\u003c/span\u003e/julia-depot\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInteractive usage\u003c/h2\u003e\u003ca id=\"user-content-interactive-usage\" class=\"anchor\" aria-label=\"Permalink: Interactive usage\" href=\"#interactive-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe login nodes you access via \u003ccode\u003elogin.fugaku.r-ccs.riken.jp\u003c/code\u003e (\u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/AccessToTheSystem/LoggingInToTheFugakuComputerWithLocalAccount.html\" rel=\"nofollow\"\u003econnection\ninstructions\u003c/a\u003e)\nhave Cascade Lake CPUs, so they aren\u0027t much useful if you want to run an aarch64 Julia.\u003c/p\u003e\n\u003cp\u003eYou can \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/Overview.html\" rel=\"nofollow\"\u003esubmit jobs to the\nqueue\u003c/a\u003e\nto run Julia code on the A64FX compute nodes, but this can be cumbersone if you need quick\nfeedback during development or debugging.  You can also request an \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/JobExecution/InteractiveJob.html\" rel=\"nofollow\"\u003einteractive\nnode\u003c/a\u003e,\nfor example with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epjsub --interact -L \"node=1\" -L \"rscgrp=int\" -L \"elapse=30:00\" --sparam \"wait-time=600\" --mpi \"max-proc-per-node=4\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAvailable software\u003c/h2\u003e\u003ca id=\"user-content-available-software\" class=\"anchor\" aria-label=\"Permalink: Available software\" href=\"#available-software\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFugaku uses the \u003ca href=\"https://spack.io/\" rel=\"nofollow\"\u003eSpack package manager\u003c/a\u003e.  For more information about how\nto use it, see the \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/FugakuSpackGuide/\" rel=\"nofollow\"\u003eFugaku Spack User\nGuide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNote that Spack is installed in \u003ccode\u003e/vol0004\u003c/code\u003e, this means that if your home directory isn\u0027t\nmounted on this volume you will have to \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/en/operation/20211130_02\" rel=\"nofollow\"\u003eexplicitly request the\npartition\u003c/a\u003e in your submission\njob scripts or commands, for example by adding \u003ccode\u003e-x PJM_LLIO_GFSCACHE=/vol0004\u003c/code\u003e to the\n\u003ccode\u003epjsub\u003c/code\u003e command, or the line\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003ePJM -x PJM_LLIO_GFSCACHE=/vol0004\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ein a job script.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsing Julia on the compute nodes\u003c/h2\u003e\u003ca id=\"user-content-using-julia-on-the-compute-nodes\" class=\"anchor\" aria-label=\"Permalink: Using Julia on the compute nodes\" href=\"#using-julia-on-the-compute-nodes\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThere is a Julia module built with Spack \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/UsingOSS/oss_e.html#packages-installed-on-the-compute-nodes\" rel=\"nofollow\"\u003eavailable on the compute\nnodes\u003c/a\u003e,\nbut as of this writing (2022-07-23) the version of Julia provided is 1.6.3, so you may want\nto download a more recent version from the \u003ca href=\"https://julialang.org/downloads/\" rel=\"nofollow\"\u003eofficial\nwebsite\u003c/a\u003e.  Use the \u003ccode\u003eaarch64\u003c/code\u003e builds for Glibc Linux,\npreferably \u003ca href=\"https://julialang.org/downloads/#current_stable_release\" rel=\"nofollow\"\u003elatest stable\u003c/a\u003e or even\nthe \u003ca href=\"https://julialang.org/downloads/nightlies/\" rel=\"nofollow\"\u003enightly build\u003c/a\u003e if you feel confident.\u003c/p\u003e\n\u003cp\u003eTo enable full vectorisation you may need to set the environment variable\n\u003ccode\u003eJULIA_LLVM_ARGS=\"-aarch64-sve-vector-bits-min=512\"\u003c/code\u003e.  Example:\n\u003ca href=\"https://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\"\u003ehttps://github.com/JuliaLang/julia/issues/40308#issuecomment-901478623\u003c/a\u003e.  However, note that\nare a couple of severe bugs when using 512-bit vectors:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/JuliaLang/julia/issues/44401\"\u003ehttps://github.com/JuliaLang/julia/issues/44401\u003c/a\u003e (may be an upstream LLVM bug:\n\u003ca href=\"https://github.com/llvm/llvm-project/issues/53331\"\u003ehttps://github.com/llvm/llvm-project/issues/53331\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/JuliaLang/julia/issues/44263\"\u003ehttps://github.com/JuliaLang/julia/issues/44263\u003c/a\u003e (only in Julia v1.8+)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote\u003c/strong\u003e\u003c/em\u003e: Julia v1.9, which is based on \u003ca href=\"https://community.arm.com/arm-community-blogs/b/tools-software-ides-blog/posts/llvm-14\" rel=\"nofollow\"\u003eLLVM\n14\u003c/a\u003e,\nis able to natively autovectorise code for A64FX \u003cem\u003ewithout\u003c/em\u003e having to set\n\u003ccode\u003eJULIA_LLVM_ARGS\u003c/code\u003e, side stepping the issues above altogether.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMPI.jl\u003c/h2\u003e\u003ca id=\"user-content-mpijl\" class=\"anchor\" aria-label=\"Permalink: MPI.jl\" href=\"#mpijl\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/JuliaParallel/MPI.jl\"\u003e\u003ccode\u003eMPI.jl\u003c/code\u003e\u003c/a\u003e with default JLL-provided MPICH works\nout of the box!  In order to\n\u003ca href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\" rel=\"nofollow\"\u003econfigure\u003c/a\u003e \u003ccode\u003eMPI.jl\u003c/code\u003e v0.19 to\nuse system-provided Fujitsu MPI (based on OpenMPI) you have to specify the \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/CompileCommands.html\" rel=\"nofollow\"\u003eMPI C\ncompiler\u003c/a\u003e\nfor A64FX with\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ejulia --project -e \u0027ENV[\"JULIA_MPI_BINARY\"]=\"system\"; ENV[\"JULIA_MPICC\"]=\"mpifcc\"; using Pkg; Pkg.build(\"MPI\"; verbose=true)\u0027\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote #1\u003c/strong\u003e\u003c/em\u003e: \u003ccode\u003empifcc\u003c/code\u003e is available only on the compute nodes.  On the login nodes that would be\n\u003ccode\u003empifccpx\u003c/code\u003e, but this is the cross compiler running on Intel architecture, it\u0027s unlikely\nyou\u0027ll run an \u003ccode\u003eaarch64\u003c/code\u003e Julia on there.  \u003ca href=\"https://github.com/JuliaParallel/MPI.jl/issues/539\"\u003ePreliminary\ntests\u003c/a\u003e show that \u003ccode\u003eMPI.jl\u003c/code\u003e should work\nmostly fine with Fujitsu MPI, but custom error handlers may not be available (read: trying\nto use them causes segmentation faults).\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote #2\u003c/strong\u003e\u003c/em\u003e: in \u003ccode\u003eMPI.jl\u003c/code\u003e v0.20 Fujitsu MPI is a known ABI (it\u0027s the same as OpenMPI) and\nthere is nothing special to do to configure it apart from \u003ca href=\"https://juliaparallel.org/MPI.jl/dev/configuration/#Configuration-2\" rel=\"nofollow\"\u003echoosing the system\nbinaries\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote #3\u003c/strong\u003e\u003c/em\u003e: we recommend using \u003ccode\u003eMPI.jl\u003c/code\u003e\u0027s wrapper of \u003ccode\u003empiexec\u003c/code\u003e to run MPI applications\nwith Julia:\n\u003ca href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Julia-wrapper-for-mpiexec\" rel=\"nofollow\"\u003e\u003ccode\u003empiexecjl\u003c/code\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eFile system latency\u003c/h3\u003e\u003ca id=\"user-content-file-system-latency\" class=\"anchor\" aria-label=\"Permalink: File system latency\" href=\"#file-system-latency\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFugaku has an advanced system to handle \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/index.html\" rel=\"nofollow\"\u003eparallel file system\nlatency\u003c/a\u003e.\nIn order.  In order to speed up parallel applications run through MPI you may want to\ndistribute it to the cache area of the second-layer storage on the first-layer storage using\n\u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/use_latest/LyeredStorageAndLLIO/TheSecondLayerStrage.html#common-file-distribution-function-llio-transfer\" rel=\"nofollow\"\u003e\u003ccode\u003ellio_transfer\u003c/code\u003e\u003c/a\u003e.\nIn particular, if you\u0027re using Julia, you likely want to distribute the \u003ccode\u003ejulia\u003c/code\u003e executable\nitself together with its installation bundle.\u003c/p\u003e\n\u003cp\u003eFor example, assuming that you are using the official binaries from the website, instead of\nthe Julia module provided by Spack, you can do the following:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Directory for log of `llio_transfer` and its wrapper `dir_transfer`\u003c/span\u003e\nLOGDIR=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${TMPDIR}\u003c/span\u003e/log\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Create the log directory if necessary\u003c/span\u003e\nmkdir -p \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${LOGDIR}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Get directory where Julia is placed\u003c/span\u003e\nJL_BUNDLE=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003edirname \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ejulia --startup-file=no -O0 --compile=min -e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003eprint(Sys.BINDIR)\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Move Julia installation to fast LLIO directory\u003c/span\u003e\n/home/system/tool/dir_transfer -l \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${LOGDIR}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${JL_BUNDLE}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Do not write empty stdout/stderr files for MPI processes.\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PLE_MPI_STD_EMPTYFILE=off\n\nmpiexecjl --project=. -np ... julia ...\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Remove Julia installation directory from the cache.\u003c/span\u003e\n/home/system/tool/dir_transfer -p -l \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${LOGDIR}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${JL_BUNDLE}\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eReverse engineering Fujitsu compiler using LLVM output\u003c/h2\u003e\u003ca id=\"user-content-reverse-engineering-fujitsu-compiler-using-llvm-output\" class=\"anchor\" aria-label=\"Permalink: Reverse engineering Fujitsu compiler using LLVM output\" href=\"#reverse-engineering-fujitsu-compiler-using-llvm-output\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Fujitsu compiler has \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/FujitsuCompiler/C/modeTradAndClangC.html\" rel=\"nofollow\"\u003etwo operation\nmodes\u003c/a\u003e:\n\"trad\" (for \"traditional\") and \"clang\" (enabled by the flag \u003ccode\u003e-Nclang\u003c/code\u003e).  In clang mode it\u0027s\nbased on LLVM (version 7 at the moment).  This means you can get it to emit LLVM IR with\n\u003ccode\u003e-emit-llvm\u003c/code\u003e.  For example, with\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003eecho\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003eint main(){}\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e|\u003c/span\u003e fcc -Nclang -x c - -S -emit-llvm -o -\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eyou get\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-llvm\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e; ModuleID = \u0027-\u0027\u003c/span\u003e\nsource_filename = \u003cspan class=\"pl-s\"\u003e\"-\"\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003etarget\u003c/span\u003e \u003cspan class=\"pl-k\"\u003edatalayout\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\"e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128\"\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003etarget\u003c/span\u003e \u003cspan class=\"pl-k\"\u003etriple\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\"aarch64-unknown-linux-gnu\"\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e; Function Attrs: norecurse nounwind readnone uwtable\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003edefine\u003c/span\u003e dso_local \u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e@main\u003c/span\u003e() \u003cspan class=\"pl-k\"\u003elocal_unnamed_addr\u003c/span\u003e #\u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e \u003cspan class=\"pl-v\"\u003e!dbg\u003c/span\u003e \u003cspan class=\"pl-v\"\u003e!8\u003c/span\u003e {\n  \u003cspan class=\"pl-k\"\u003eret\u003c/span\u003e \u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003e!dbg\u003c/span\u003e \u003cspan class=\"pl-v\"\u003e!11\u003c/span\u003e\n}\n\n\u003cspan class=\"pl-k\"\u003eattributes\u003c/span\u003e #\u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e = { \u003cspan class=\"pl-k\"\u003enorecurse\u003c/span\u003e \u003cspan class=\"pl-k\"\u003enounwind\u003c/span\u003e \u003cspan class=\"pl-k\"\u003ereadnone\u003c/span\u003e \u003cspan class=\"pl-k\"\u003euwtable\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"correctly-rounded-divide-sqrt-fp-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"disable-tail-calls\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"less-precise-fpmad\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-frame-pointer-elim\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"true\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-frame-pointer-elim-non-leaf\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-infs-fp-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-jump-tables\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-nans-fp-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-signed-zeros-fp-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"no-trapping-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"stack-protector-buffer-size\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"8\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"target-cpu\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"a64fx\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"target-features\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"+crc,+crypto,+fp-armv8,+lse,+neon,+ras,+rdm,+sve,+v8.2a\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"unsafe-fp-math\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"use-soft-float\"\u003c/span\u003e=\u003cspan class=\"pl-s\"\u003e\"false\"\u003c/span\u003e }\n\n\u003cspan class=\"pl-v\"\u003e!llvm.dbg.cu\u003c/span\u003e = !{\u003cspan class=\"pl-v\"\u003e!0\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!llvm.module.flags\u003c/span\u003e = !{\u003cspan class=\"pl-v\"\u003e!3\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003e!4\u003c/span\u003e, \u003cspan class=\"pl-v\"\u003e!5\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!llvm.ident\u003c/span\u003e = !{\u003cspan class=\"pl-v\"\u003e!6\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!llvm.compinfo\u003c/span\u003e = !{\u003cspan class=\"pl-v\"\u003e!7\u003c/span\u003e}\n\n\u003cspan class=\"pl-v\"\u003e!0\u003c/span\u003e = distinct \u003cspan class=\"pl-v\"\u003e!DICompileUnit\u003c/span\u003e(language: DW_LANG_C99, file: \u003cspan class=\"pl-v\"\u003e!1\u003c/span\u003e, producer: \u003cspan class=\"pl-s\"\u003e\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on LLVM 7.1.0)\"\u003c/span\u003e, isOptimized: \u003cspan class=\"pl-k\"\u003etrue\u003c/span\u003e, runtimeVersion: \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, emissionKind: LineTablesOnly, enums: \u003cspan class=\"pl-v\"\u003e!2\u003c/span\u003e)\n\u003cspan class=\"pl-v\"\u003e!1\u003c/span\u003e = \u003cspan class=\"pl-v\"\u003e!DIFile\u003c/span\u003e(filename: \u003cspan class=\"pl-s\"\u003e\"-\"\u003c/span\u003e, directory: \u003cspan class=\"pl-s\"\u003e\"/home/ra000019/a04463\"\u003c/span\u003e)\n\u003cspan class=\"pl-v\"\u003e!2\u003c/span\u003e = !{}\n\u003cspan class=\"pl-v\"\u003e!3\u003c/span\u003e = !{\u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, !\u003cspan class=\"pl-s\"\u003e\"Dwarf Version\"\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!4\u003c/span\u003e = !{\u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, !\u003cspan class=\"pl-s\"\u003e\"Debug Info Version\"\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e3\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!5\u003c/span\u003e = !{\u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e, !\u003cspan class=\"pl-s\"\u003e\"wchar_size\"\u003c/span\u003e, \u003cspan class=\"pl-k\"\u003ei32\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!6\u003c/span\u003e = !{!\u003cspan class=\"pl-s\"\u003e\"clang: Fujitsu C/C++ Compiler 4.7.0 (Nov  4 2021 10:55:52) (based on LLVM 7.1.0)\"\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!7\u003c/span\u003e = !{!\u003cspan class=\"pl-s\"\u003e\"C::clang\"\u003c/span\u003e}\n\u003cspan class=\"pl-v\"\u003e!8\u003c/span\u003e = distinct \u003cspan class=\"pl-v\"\u003e!DISubprogram\u003c/span\u003e(name: \u003cspan class=\"pl-s\"\u003e\"main\"\u003c/span\u003e, scope: \u003cspan class=\"pl-v\"\u003e!9\u003c/span\u003e, file: \u003cspan class=\"pl-v\"\u003e!9\u003c/span\u003e, line: \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e, type: \u003cspan class=\"pl-v\"\u003e!10\u003c/span\u003e, isLocal: \u003cspan class=\"pl-k\"\u003efalse\u003c/span\u003e, isDefinition: \u003cspan class=\"pl-k\"\u003etrue\u003c/span\u003e, scopeLine: \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e, isOptimized: \u003cspan class=\"pl-k\"\u003etrue\u003c/span\u003e, unit: \u003cspan class=\"pl-v\"\u003e!0\u003c/span\u003e, retainedNodes: \u003cspan class=\"pl-v\"\u003e!2\u003c/span\u003e)\n\u003cspan class=\"pl-v\"\u003e!9\u003c/span\u003e = \u003cspan class=\"pl-v\"\u003e!DIFile\u003c/span\u003e(filename: \u003cspan class=\"pl-s\"\u003e\"\u0026lt;stdin\u0026gt;\"\u003c/span\u003e, directory: \u003cspan class=\"pl-s\"\u003e\"/home/ra000019/a04463\"\u003c/span\u003e)\n\u003cspan class=\"pl-v\"\u003e!10\u003c/span\u003e = \u003cspan class=\"pl-v\"\u003e!DISubroutineType\u003c/span\u003e(types: \u003cspan class=\"pl-v\"\u003e!2\u003c/span\u003e)\n\u003cspan class=\"pl-v\"\u003e!11\u003c/span\u003e = \u003cspan class=\"pl-v\"\u003e!DILocation\u003c/span\u003e(line: \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e, column: \u003cspan class=\"pl-c1\"\u003e12\u003c/span\u003e, scope: \u003cspan class=\"pl-v\"\u003e!8\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSystemBenchmarks.jl\u003c/h2\u003e\u003ca id=\"user-content-systembenchmarksjl\" class=\"anchor\" aria-label=\"Permalink: SystemBenchmarks.jl\" href=\"#systembenchmarksjl\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eI ran \u003ca href=\"https://github.com/IanButterworth/SystemBenchmark.jl\"\u003e\u003ccode\u003eSystemBenchmarks.jl\u003c/code\u003e\u003c/a\u003e on a\ncompute node.  Here are the results:\n\u003ca href=\"https://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\"\u003ehttps://github.com/IanButterworth/SystemBenchmark.jl/issues/8#issuecomment-1039775968\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBLAS\u003c/h2\u003e\u003ca id=\"user-content-blas\" class=\"anchor\" aria-label=\"Permalink: BLAS\" href=\"#blas\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOpenBLAS seems to have poor performance:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-julia\"\u003e\u003cpre\u003ejulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eusing\u003c/span\u003e LinearAlgebra\n\njulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003epeakflops\u003c/span\u003e()\n\u003cspan class=\"pl-c1\"\u003e2.589865257047898e10\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUp to v1.7, Julia uses OpenBLAS v0.3.17, which actually doesn\u0027t support A64FX at all, so\nit\u0027s probably using the generic kernels.\n\u003ca href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.19\"\u003e\u003ccode\u003ev0.3.19\u003c/code\u003e\u003c/a\u003e and\n\u003ca href=\"https://github.com/xianyi/OpenBLAS/releases/tag/v0.3.20\"\u003e\u003ccode\u003ev0.3.20\u003c/code\u003e\u003c/a\u003e improved support for\nthis chip, you can find a build of 0.3.20 at\n\u003ca href=\"https://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\"\u003ehttps://github.com/JuliaBinaryWrappers/OpenBLAS_jll.jl/releases/download/OpenBLAS-v0.3.20%2B0/OpenBLAS.v0.3.20.aarch64-linux-gnu-libgfortran5.tar.gz\u003c/a\u003e,\nbut sadly there isn\u0027t a great performance improvement:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-julia\"\u003e\u003cpre\u003ejulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e BLAS\u003cspan class=\"pl-k\"\u003e.\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003elbt_forward\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003elib/libopenblas64_.so\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003e4856\u003c/span\u003e\n\njulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003epeakflops\u003c/span\u003e()\n\u003cspan class=\"pl-c1\"\u003e2.6362952057793587e10\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThere is an \u003ca href=\"https://www.fugaku.r-ccs.riken.jp/doc_root/en/user_guides/lang_latest/Library/BLASLAPACKScaLAPACKLibrary.html#how-to-dynamically-load-and-use-blas-lapack-and-scalapack\" rel=\"nofollow\"\u003eoptimised\nBLAS\u003c/a\u003e\nprovided by Fujitsu, with support for SVE (with both LP64 and ILP64).  In order to use it,\ninstall \u003ca href=\"https://github.com/giordano/FujitsuBLAS.jl\"\u003e\u003ccode\u003eFujitsuBLAS.jl\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-julia\"\u003e\u003cpre\u003ejulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eusing\u003c/span\u003e FujitsuBLAS, LinearAlgebra\n\njulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e BLAS\u003cspan class=\"pl-k\"\u003e.\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003eget_config\u003c/span\u003e()\nLinearAlgebra\u003cspan class=\"pl-k\"\u003e.\u003c/span\u003eBLAS\u003cspan class=\"pl-k\"\u003e.\u003c/span\u003eLBTConfig\nLibraries\u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e\n\u2514 [ILP64] libfjlapackexsve_ilp64\u003cspan class=\"pl-k\"\u003e.\u003c/span\u003eso\n\njulia\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003epeakflops\u003c/span\u003e()\n\u003cspan class=\"pl-c1\"\u003e4.801227630694119e10\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe package \u003ca href=\"https://github.com/carstenbauer/BLISBLAS.jl\"\u003e\u003ccode\u003eBLISBLAS.jl\u003c/code\u003e\u003c/a\u003e similarly forwards\nBLAS calls to the \u003ca href=\"https://github.com/flame/blis\"\u003eblis\u003c/a\u003e library, which has optimised kernels\nfor A64FX.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding Julia from source\u003c/h2\u003e\u003ca id=\"user-content-building-julia-from-source\" class=\"anchor\" aria-label=\"Permalink: Building Julia from source\" href=\"#building-julia-from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ewith GCC\u003c/h3\u003e\u003ca id=\"user-content-with-gcc\" class=\"anchor\" aria-label=\"Permalink: with GCC\" href=\"#with-gcc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBuilding Julia from source with GCC (which is the default if you don\u0027t set \u003ccode\u003eCC\u003c/code\u003e and \u003ccode\u003eCXX\u003c/code\u003e)\nworks fine, it\u0027s just \u003cem\u003eslow\u003c/em\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e[...]\n    JULIA usr/lib/julia/corecompiler.ji\nCore.Compiler \u2500\u2500\u2500\u2500 903.661 seconds\n[...]\nBase  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500271.257337 seconds\nArgTools  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 50.348227 seconds\nArtifacts  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.193792 seconds\nBase64  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.057241 seconds\nCRC32c  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.097865 seconds\nFileWatching  \u2500\u2500\u2500\u2500\u2500  1.169747 seconds\nLibdl  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.026215 seconds\nLogging  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.411966 seconds\nMmap  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.972844 seconds\nNetworkOptions  \u2500\u2500\u2500  1.159094 seconds\nSHA  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.067851 seconds\nSerialization  \u2500\u2500\u2500\u2500  2.942512 seconds\nSockets  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.568797 seconds\nUnicode  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.814165 seconds\nDelimitedFiles  \u2500\u2500\u2500  1.121546 seconds\nLinearAlgebra  \u2500\u2500\u2500\u2500109.560774 seconds\nMarkdown  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  7.977584 seconds\nPrintf  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  1.635409 seconds\nRandom  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 13.843395 seconds\nTar  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.146368 seconds\nDates  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 16.694863 seconds\nDistributed  \u2500\u2500\u2500\u2500\u2500\u2500  8.163152 seconds\nFuture  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.060472 seconds\nInteractiveUtils  \u2500  5.245523 seconds\nLibGit2  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 15.469061 seconds\nProfile  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  5.399918 seconds\nSparseArrays  \u2500\u2500\u2500\u2500\u2500 42.660136 seconds\nUUIDs  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.165799 seconds\nREPL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 40.149298 seconds\nSharedArrays  \u2500\u2500\u2500\u2500\u2500  5.476926 seconds\nStatistics  \u2500\u2500\u2500\u2500\u2500\u2500\u2500  2.130843 seconds\nSuiteSparse  \u2500\u2500\u2500\u2500\u2500\u2500 16.849304 seconds\nTOML  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  0.714203 seconds\nTest  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.538098 seconds\nLibCURL  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.547585 seconds\nDownloads  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  3.657012 seconds\nPkg  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 54.053634 seconds\nLazyArtifacts  \u2500\u2500\u2500\u2500  0.019103 seconds\nStdlibs total  \u2500\u2500\u2500\u2500427.178257 seconds\nSysimage built. Summary:\nTotal \u2500\u2500\u2500\u2500\u2500\u2500\u2500 698.447219 seconds\nBase: \u2500\u2500\u2500\u2500\u2500\u2500\u2500 271.257337 seconds 38.8372%\nStdlibs: \u2500\u2500\u2500\u2500 427.178257 seconds 61.1611%\n[...]\nPrecompilation complete. Summary:\nTotal \u2500\u2500\u2500\u2500\u2500\u2500\u2500 1274.714700 seconds\nGeneration \u2500\u2500 886.445205 seconds 69.5407%\nExecution \u2500\u2500\u2500 388.269495 seconds 30.4593%\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eWith Fujitsu compiler\u003c/h3\u003e\u003ca id=\"user-content-with-fujitsu-compiler\" class=\"anchor\" aria-label=\"Permalink: With Fujitsu compiler\" href=\"#with-fujitsu-compiler\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eFor reference, the version used for the last build I attempted was\n\u003ca href=\"https://github.com/JuliaLang/julia/commit/1ad2396f05fa63a71e5842c814791cd7c7715100\"\u003e\u003ccode\u003e1ad2396f\u003c/code\u003e\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eCompiling Julia from source with the Fujitsu compiler is complicated.  In particular, it\u0027s\nan absolute pain to use the Fujitsu compiler in trad mode.  You can have some more luck with\nclang mode.\u003c/p\u003e\n\u003cp\u003ePreparation.  Create the \u003ccode\u003eMake.user\u003c/code\u003e file with this content (I\u0027m not sure this file is\nactually necessary when using Clang mode, but it definitely is with trad mode):\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-makefile\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eARCH\u003c/span\u003e := aarch64\n\u003cspan class=\"pl-k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003eBUILD_MACHINE\u003c/span\u003e := aarch64-unknown-linux-gnu\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen you can compile with (\u003ccode\u003e-Nclang\u003c/code\u003e is to select clang mode)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake -j50 CC=\"fcc -Nclang\" CFLAGS=\"-Kopenmp\" CXX=\"FCC -Nclang\" CXXFLAGS=\"-Kopenmp\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe compiler in trad mode doesn\u0027t define the macro \u003ccode\u003e__SIZEOF_POINTER__\u003c/code\u003e, so compilation\nwould fail in\n\u003ca href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\"\u003ehttps://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/support/platform.h#L114-L115\u003c/a\u003e.\nThe solution is to set the macro \u003ccode\u003e-D__SIZEOF_POINTER__=8\u003c/code\u003e in the \u003ccode\u003eCFLAGS\u003c/code\u003e (or just not use\ntrad mode).  Then, you may get errors like\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2000:13: error: initializer element is not a compile-time constant\n            jl_typename_type,\n            ^~~~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from macro \u0027jl_svec\u0027\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53: note: expanded from macro \u0027_Static_assert\u0027\n      [!!sizeof (struct { int __error_if_negative: (expr) ? 2 : -1; })]\n                                                    ^~~~\n/vol0003/ra000019/a04463/repo/julia/src/jltypes.c:2025:43: error: initializer element is not a compile-time constant\n    jl_typename_type-\u0026gt;types = jl_svec(13, jl_symbol_type, jl_any_type /*jl_module_type*/,\n                                          ^~~~~~~~~~~~~~\n./julia_internal.h:437:41: note: expanded from macro \u0027jl_svec\u0027\n                n == sizeof((void *[]){ __VA_ARGS__ })/sizeof(void *),        \\\n                                        ^~~~~~~~~~~\n/usr/include/sys/cdefs.h:439:53: note: expanded from macro \u0027_Static_assert\u0027\n      [!!sizeof (struct { int __error_if_negative: (expr) ? 2 : -1; })]\n                                                    ^~~~\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is the compiler\u0027s fault, which is supposed to be able to handle this, but you can just\ndelete the assertions at lines\n\u003ca href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\"\u003ehttps://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L427-L429\u003c/a\u003e,\n\u003ca href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\"\u003ehttps://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L436-L438\u003c/a\u003e,\n\u003ca href=\"https://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\"\u003ehttps://github.com/JuliaLang/julia/blob/1ad2396f05fa63a71e5842c814791cd7c7715100/src/julia_internal.h#L444-L446\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you\u0027re lucky enough, with all these changes, you may be able to build \u003ccode\u003eusr/bin/julia\u003c/code\u003e.\nUnfortunately, last time I tried, run this executable causes a segmentation fault in\n\u003ccode\u003edl_init\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(gdb) run\nStarting program: /vol0003/ra000019/a04463/repo/julia/julia\nMissing separate debuginfos, use: yum debuginfo-install glibc-2.28-151.el8.aarch64\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\nMissing separate debuginfos, use: yum debuginfo-install FJSVxoslibmpg-2.0.0-25.14.1.el8.aarch64 elfutils-libelf-0.182-3.el8.aarch64\n(gdb) bt\n#0  0x000040000000def4 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#1  0x000040000020adb0 in _dl_catch_exception () from /lib64/libc.so.6\n#2  0x00004000000125e4 in dl_open_worker () from /lib/ld-linux-aarch64.so.1\n#3  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#4  0x0000400000011aa8 in _dl_open () from /lib/ld-linux-aarch64.so.1\n#5  0x0000400000091094 in dlopen_doit () from /lib64/libdl.so.2\n#6  0x000040000020ad54 in _dl_catch_exception () from /lib64/libc.so.6\n#7  0x000040000020ae20 in _dl_catch_error () from /lib64/libc.so.6\n#8  0x00004000000917f0 in _dlerror_run () from /lib64/libdl.so.2\n#9  0x0000400000091134 in dlopen@@GLIBC_2.17 () from /lib64/libdl.so.2\n#10 0x0000400000291f34 in load_library (rel_path=0x400001e900c6 \u0026lt;dep_libs+30\u0026gt; \"libjulia-internal.so.1\", src_dir=\u0026lt;optimized out\u0026gt;, err=1) at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:65\n#11 0x0000400000291c78 in jl_load_libjulia_internal () at /vol0003/ra000019/a04463/repo/julia/cli/loader_lib.c:200\n#12 0x000040000000de04 in call_init.part () from /lib/ld-linux-aarch64.so.1\n#13 0x000040000000df08 in _dl_init () from /lib/ld-linux-aarch64.so.1\n#14 0x0000400000001044 in _dl_start_user () from /lib/ld-linux-aarch64.so.1\nBacktrace stopped: previous frame identical to this frame (corrupt stack?)\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 10,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1690337110.0
  },
  {
    "data_format": 2,
    "description": "ARTEMIS (Adaptive mesh Refinement Time-domain ElectrodynaMIcs Solver) couples the Maxwell\u0027s equations implementation in WarpX with classical equations that describe quantum material behavior (such as, LLG equation for micromagnetics and London equation for superconducting materials) for quantifying the performance of next-generation microelectronics.",
    "filenames": [
      "Tools/machines/lxplus-cern/spack.yaml",
      "Docs/spack.yaml"
    ],
    "full_name": "AMReX-Microelectronics/artemis",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eARTEMIS\u003c/h1\u003e\u003ca id=\"user-content-artemis\" class=\"anchor\" aria-label=\"Permalink: ARTEMIS\" href=\"#artemis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 10,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1696392722.0
  },
  {
    "data_format": 2,
    "description": "Thallium is a C++14 library wrapping Margo, Mercury, and Argobots and providing an object-oriented way to use these libraries.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-thallium",
    "latest_release": "v0.12.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eThallium\u003c/h1\u003e\u003ca id=\"user-content-thallium\" class=\"anchor\" aria-label=\"Permalink: Thallium\" href=\"#thallium\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThallium is a C++ interface to \u003ca href=\"https://github.com/mochi-hpc/mochi-margo/\"\u003eMargo\u003c/a\u003e.\nIt offers a modern, object-oriented way of developing HPC data services. More\ninformation can be found on \u003ca href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003eMochi\u0027s readthedocs\u003c/a\u003e\nwebsite.\u003c/p\u003e\n",
    "stargazers_count": 10,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1685720588.0
  },
  {
    "data_format": 2,
    "description": "Repository for installation routines of the external software required by FairRoot",
    "filenames": [
      "test/env/fairlogger/spack.yaml"
    ],
    "full_name": "FairRootGroup/FairSoft",
    "latest_release": "jan24",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eFairSoft\u003c/h1\u003e\u003ca id=\"user-content-fairsoft\" class=\"anchor\" aria-label=\"Permalink: FairSoft\" href=\"#fairsoft\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe FairSoft distribution provides the software packages needed to compile and run the \u003ca href=\"https://github.com/FairRootGroup/FairRoot\"\u003eFairRoot framework\u003c/a\u003e and experiment packages based on FairRoot. FairSoft is a source distribution with recurring releases for macOS and Linux.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation from Source\u003c/h2\u003e\u003ca id=\"user-content-installation-from-source\" class=\"anchor\" aria-label=\"Permalink: Installation from Source\" href=\"#installation-from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eChoose between the classic (called \"Legacy\") installation method or the new Spack-based one:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003eLegacy (Recommended)\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eSpack (EXPERIMENTAL)\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eThis is the classic bash/cmake based setup system.\u003c/td\u003e\n\u003ctd\u003eThis is an ongoing standardization and modernization effort based on Spack (which itself is still under heavy development). Most things are already working. For early adopters.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eReleases are reflected in the git history via tags and branches, e.g.: \u003ccode\u003ejan24\u003c/code\u003e, \u003ccode\u003enov22\u003c/code\u003e, \u003ccode\u003eapr21p2\u003c/code\u003e, \u003ccode\u003eapr21_patches\u003c/code\u003e\n\u003c/td\u003e\n\u003ctd\u003eAlways use the latest \u003ccode\u003edev\u003c/code\u003e branch. Multiple releases are described within the metadata contained in the repo (read on in the Installation instructions on how to select a release).\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u25ba \u003ca href=\"legacy/README.md\"\u003econtinue\u003c/a\u003e\n\u003c/td\u003e\n\u003ctd\u003e\u25ba \u003ca href=\"docs/README.md\"\u003econtinue\u003c/a\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation of pre-compiled Binaries\u003c/h2\u003e\u003ca id=\"user-content-installation-of-pre-compiled-binaries\" class=\"anchor\" aria-label=\"Permalink: Installation of pre-compiled Binaries\" href=\"#installation-of-pre-compiled-binaries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eNote\u003c/em\u003e: FairSoft is primarily a source distribution. Availability of latest releases as pre-compiled binaries may be delayed.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eGSI Virgo Cluster\u003c/h3\u003e\u003ca id=\"user-content-gsi-virgo-cluster\" class=\"anchor\" aria-label=\"Permalink: GSI Virgo Cluster\" href=\"#gsi-virgo-cluster\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor all \u003ca href=\"https://hpc.gsi.de/virgo/platform/software.html#application-environment\" rel=\"nofollow\"\u003eVAEs\u003c/a\u003e at \u003ccode\u003e/cvmfs/fairsoft.gsi.de/\u0026lt;vae-os\u0026gt;/fairsoft/\u0026lt;release\u0026gt;\u003c/code\u003e. Use by exporting the \u003ccode\u003eSIMPATH\u003c/code\u003e environment variable pointing to one of the directories.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003emacOS (beta)\u003c/h3\u003e\u003ca id=\"user-content-macos-beta\" class=\"anchor\" aria-label=\"Permalink: macOS (beta)\" href=\"#macos-beta\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFairSoft config: \u003ca href=\"FairSoftConfig.cmake\"\u003edefault\u003c/a\u003e, no other configs planned\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eInstall \u003cem\u003eCommand Line Tools for Xcode\u003c/em\u003e from \u003ca href=\"https://developer.apple.com/downloads\" rel=\"nofollow\"\u003ehttps://developer.apple.com/downloads\u003c/a\u003e (requires Apple account)\u003c/li\u003e\n\u003cli\u003eInstall \u003ca href=\"https://brew.sh/\" rel=\"nofollow\"\u003eHomebrew\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eRun \u003ccode\u003ebrew update \u0026amp;\u0026amp; brew doctor\u003c/code\u003e and fix potential issues reported by these commands until \u003ccode\u003eYour system is ready to brew.\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eRun\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003ebrew tap fairrootgroup/fairsoft\nbrew install fairsoft\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eUse via \u003ccode\u003eexport SIMPATH=$(brew --prefix fairsoft)\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eNote\u003c/em\u003e: macOS is a fast moving target and it is possible the packages will stop working from one day to another after some system component was updated. We try our best to keep up, one great way to help is to provide detailed problem reports \u003ca href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\u003ehere on github\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOther platforms\u003c/h3\u003e\u003ca id=\"user-content-other-platforms\" class=\"anchor\" aria-label=\"Permalink: Other platforms\" href=\"#other-platforms\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBinary packages for non-GSI Linux as well as Spack binary caches and/or pre-populated install trees are planned for the future.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease ask your questions, request features, and report issues by \u003ca href=\"https://github.com/FairRootGroup/FairSoft/issues/new\"\u003ecreating a github issue\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 13,
    "subscribers_count": 14,
    "topics": [],
    "updated_at": 1705588914.0
  },
  {
    "data_format": 2,
    "description": "explore the FV3 data for parameterization",
    "filenames": [
      "docker/ufs_utils/spack.yaml"
    ],
    "full_name": "ai2cm/fv3net",
    "latest_release": "release/cyclegan_initial",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003efv3net\u003c/h1\u003e\u003ca id=\"user-content-fv3net\" class=\"anchor\" aria-label=\"Permalink: fv3net\" href=\"#fv3net\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://circleci.com/gh/ai2cm/fv3net/tree/master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b3e080c75d8b7187fbfaeb6a0e44426f4b4ce818305d3917a4334f4e5970b14c/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667\" alt=\"CircleCI\" data-canonical-src=\"https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eImproving the GFDL FV3 model physics with machine learning. See the \u003ca href=\"https://vulcanclimatemodeling.com/docs/fv3net/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e for more information on using this suite of tools.\u003c/p\u003e\n\u003cp\u003eDisclaimer: This is a work in progress.\u003c/p\u003e\n",
    "stargazers_count": 15,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1707630820.0
  },
  {
    "data_format": 2,
    "description": "Performance benchmarks and regression tests for the ExCALIBUR project",
    "filenames": [
      "benchmarks/spack/cosma8/compute-node/spack.yaml",
      "benchmarks/spack/csd3-rocky8/icelake/spack.yaml",
      "benchmarks/spack/isambard-macs/rome/spack.yaml",
      "benchmarks/spack/cosma7/rockport-openmpi-compute-node/spack.yaml",
      "benchmarks/spack/isambard-macs/volta/spack.yaml",
      "benchmarks/spack/csd3-rocky8/sapphirerapids/spack.yaml",
      "benchmarks/spack/isambard-a64fx/compute-node/spack.yaml"
    ],
    "full_name": "ukri-excalibur/excalibur-tests",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eExCALIBUR tests\u003c/h1\u003e\u003ca id=\"user-content-excalibur-tests\" class=\"anchor\" aria-label=\"Permalink: ExCALIBUR tests\" href=\"#excalibur-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePerformance benchmarks and regression tests for the ExCALIBUR project.\u003c/p\u003e\n\u003cp\u003eThese benchmarks are based on a similar project by\n\u003ca href=\"https://github.com/stackhpc/hpc-tests\"\u003eStackHPC\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFeel free to add new benchmark applications or support new systems that are part of the\nExCALIBUR benchmarking collaboration.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote\u003c/strong\u003e: at the moment the ExCALIBUR benchmarks are a work-in-progress.\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/install/\" rel=\"nofollow\"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/setup/\" rel=\"nofollow\"\u003eConfiguration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/use/\" rel=\"nofollow\"\u003eUsage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/post-processing/\" rel=\"nofollow\"\u003ePost-processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/contributing/\" rel=\"nofollow\"\u003eContributing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/apps/\" rel=\"nofollow\"\u003eSupported benchmarks\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/systems/\" rel=\"nofollow\"\u003eSupported systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ukri-excalibur.github.io/excalibur-tests/tutorial/tutorial/\" rel=\"nofollow\"\u003eARCHER2 tutorial\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgements\u003c/h2\u003e\u003ca id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink: Acknowledgements\" href=\"#acknowledgements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis work was supported by the Engineering and Physical Sciences\nResearch Council [EP/X031829/1].\u003c/p\u003e\n\u003cp\u003eThis work used the DiRAC@Durham facility managed by the Institute for Computational\nCosmology on behalf of the STFC DiRAC HPC Facility (\u003ca href=\"http://www.dirac.ac.uk\" rel=\"nofollow\"\u003ewww.dirac.ac.uk\u003c/a\u003e). The equipment\nwas funded by BEIS capital funding via STFC capital grants ST/P002293/1, ST/R002371/1\nand ST/S002502/1, Durham University and STFC operations grant ST/R000832/1.\nDiRAC is part of the National e-Infrastructure.\u003c/p\u003e\n\u003cp\u003eThe main outcomes of this work were published in a \u003ca href=\"https://dl.acm.org/doi/10.1145/3624062.3624133\" rel=\"nofollow\"\u003epaper\u003c/a\u003e in the HPCTESTS workshop in SC23.\u003c/p\u003e\n\u003cp\u003eThis work was \u003ca href=\"https://virtual.oxfordabstracts.com/#/event/4430/submission/74\" rel=\"nofollow\"\u003epresented in RSECon23\u003c/a\u003e. A \u003ca href=\"https://youtu.be/vpTD_tJqWOA?si=zl9sWvPEQYyPhJTV\" rel=\"nofollow\"\u003erecording of the talk\u003c/a\u003e is available.\u003c/p\u003e\n",
    "stargazers_count": 16,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1711383511.0
  },
  {
    "data_format": 2,
    "description": "AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes",
    "filenames": [
      "Docs/compile-notes/frontera-github/CPU/spack.yaml"
    ],
    "full_name": "jaykalinani/AsterX",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"Docs/figures/asterx.png\"\u003e\u003cimg align=\"top\" src=\"Docs/figures/asterx.png\" width=\"140\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAsterX\u003c/strong\u003e is a GPU-accelerated GRMHD code for dynamical spacetimes, written in C++. It is built upon the \u003ca href=\"https://github.com/eschnett/CarpetX\"\u003eCarpetX\u003c/a\u003e driver, which is intended for the \u003ca href=\"https://einsteintoolkit.org/\" rel=\"nofollow\"\u003eEinstein Toolkit\u003c/a\u003e. \u003cstrong\u003eCarpetX\u003c/strong\u003e is based on \u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX\u003c/a\u003e, a software framework for block-structured AMR (adaptive mesh refinement).\u003c/p\u003e\n\u003cp\u003eFull documentation will soon be available at \u003ca href=\"https://asterx.readthedocs.io/en/latest/#\" rel=\"nofollow\"\u003easterx.readthedocs.io\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jaykalinani/AsterX/actions\"\u003e\u003cimg src=\"https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg\" alt=\"GitHub CI\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e  \u003ca href=\"https://asterx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5819b92f1cc8b5c1ad3c32b04e570ab6fcd993dc8388e1821fb2d601ee2c653f/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/asterx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f944e4986dcda6a59f77a14d6f503238e4811f8c4bfef8479068d13873036548/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667\" alt=\"License: LGPL v3\" data-canonical-src=\"https://img.shields.io/badge/License-LGPL_v3-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eHeavily derived from the GRMHD code \u003ca href=\"https://zenodo.org/record/4350072\" rel=\"nofollow\"\u003eSpritz\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eSolves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes using high-resolution shock capturing (HRSC) schemes.\u003c/li\u003e\n\u003cli\u003eBased on the flux-conservative Valencia formulation.\u003c/li\u003e\n\u003cli\u003eDirectly evolves the staggered vector potential.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAvailable modules\u003c/h2\u003e\u003ca id=\"user-content-available-modules\" class=\"anchor\" aria-label=\"Permalink: Available modules\" href=\"#available-modules\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eAsterX\u003c/code\u003e - the core GRMHD module\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eAsterSeeds\u003c/code\u003e - initial data module\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eCon2PrimFactory\u003c/code\u003e - module providing different conservative-to-primitive variable recovery routines\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eEOSX\u003c/code\u003e - equation of state driver\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eReconX\u003c/code\u003e - provider of different reconstruction schemes\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eTOVSolverX\u003c/code\u003e - a modified version of the publicly available TOVSolver thorn used within the Einstein Toolkit\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstructions for downloading and building the Einstein Toolkit including\nCarpetX can be found \u003ca href=\"https://github.com/eschnett/CarpetX\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eDetails for building and running AsterX along with CarpetX will be added to \u003ca href=\"https://asterx.readthedocs.io/en/latest/#\" rel=\"nofollow\"\u003easterx.readthedocs.io\u003c/a\u003e soon..\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRelated talks and tutorials\u003c/h2\u003e\u003ca id=\"user-content-related-talks-and-tutorials\" class=\"anchor\" aria-label=\"Permalink: Related talks and tutorials\" href=\"#related-talks-and-tutorials\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\"\u003ca href=\"http://einsteintoolkit.org/seminars/2021_03_18/index.html\" rel=\"nofollow\"\u003eUsing CarpetX: A Guide for Early Adopters\u003c/a\u003e\".\nRecorded seminar talk by Erik Schnetter, providing an overview of the current capabilities of CarpetX.\u003c/li\u003e\n\u003cli\u003e\"\u003ca href=\"https://einsteintoolkit.github.io/et2022uidaho/lectures/38-Tutorial8/index.html\" rel=\"nofollow\"\u003eTutorial: GPUs and the Einstein Toolkit\u003c/a\u003e\".\nRecorded tutorial by Lorenzo Ennoggi, Jay Kalinani and Federico Lopez Armengol during the North American Einstein Toolkit workshop 2022, presenting a brief overview on AsterX, followed by a hands-on session.\u003c/li\u003e\n\u003cli\u003e\"\u003ca href=\"https://drive.google.com/file/d/1Z4i--W56mxeNIu598LQTpEEowX56FOoD/view?usp=sharing\" rel=\"nofollow\"\u003eAsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes\u003c/a\u003e\".\nSlides based on the talk by Jay Kalinani at the APS April Meeting 2023.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 17,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1698593900.0
  },
  {
    "data_format": 2,
    "description": "E4S Spack environments and container recipes",
    "filenames": [
      "docker-recipes/runner/ubuntu22.04-amd64-oneapi-2023.2.1/spack.yaml",
      "docker-recipes/runner/alinux2023-arm64-gcc-11.4/spack.yaml",
      "docker-recipes/runner/ubuntu20.04-ppc64-gcc-11.4/spack.yaml",
      "docker-recipes/runner/_archived/rhel8-ppc64le/spack.yaml",
      "docker-recipes/runner/ubuntu22.04-amd64-oneapi-2024.0.0/spack.yaml",
      "docker-recipes/archived/special/superlu-sc/spack.yaml",
      "docker-recipes/archived/minimal/ubuntu22.04-x86_64/spack.yaml",
      "docker-recipes/archived/rhel7-runner-x86_64/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.4-spack/spack.yaml",
      "docker-recipes/minimal/ubuntu20.04-ppc64le/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu22.04-ppc64le/spack.yaml",
      "docker-recipes/archived/minimal/ubuntu22.04-ppc64le/spack.yaml",
      "docker-recipes/runner/ubuntu24.04-amd64-gcc-13.2/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu20.04-x86_64-gcc-11.2/spack.yaml",
      "docker-recipes/runner/ubuntu24.04-arm64-gcc-13.2/spack.yaml",
      "docker-recipes/minimal/ubuntu20.04-aarch64/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml",
      "docker-recipes/runner/ubuntu22.04-amd64-oneapi-2024.1.0/spack.yaml",
      "docker-recipes/runner/ubuntu22.04-amd64-oneapi-2024.0.1/spack.yaml",
      "docker-recipes/runner/ubuntu20.04-amd64-clang-16/spack.yaml",
      "spack-sdk-environments/xsdk/spack.yaml"
    ],
    "full_name": "UO-OACISS/e4s",
    "latest_release": null,
    "readme": "\u003cp\u003eThis is a collection of configurations for building ECP SDK\ncontainers with combinations of packages, including the full\nE4S set.\u003c/p\u003e\n\u003cp\u003eThese are the set of stacks that are targeted for the first release:\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"figures/SDKdefinition1.png\"\u003e\u003cimg src=\"figures/SDKdefinition1.png\" alt=\"SDK definitions\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe configuration files for each container platform will be specified under each directory.  For example, the Docker configurations are under the \"docker\" subdirectory.  Each subdirectory will have a README.md file to explain how to build the container image for each stack.\u003c/p\u003e\n",
    "stargazers_count": 18,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1705236288.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "configs/templates/gsi-addon-dev/spack.yaml",
      "configs/templates/skylab-dev/spack.yaml",
      "configs/templates/ufs-weather-model/spack.yaml",
      "configs/templates/ufs-srw-public-v2/spack.yaml"
    ],
    "full_name": "JCSDA/spack-stack",
    "latest_release": "1.6.0",
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png\"\u003e\u003cimg src=\"https://user-images.githubusercontent.com/8006981/234488735-45b2c5fa-1de6-47ad-ae3b-4a6829ae49b9.png\" width=\"425\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSpack-stack is a framework for installing software libraries to support\nNOAA\u0027s Unified Forecast System (UFS) applications and the\nJoint Effort for Data assimilation Integration (JEDI) coupled to\nseveral Earth system prediction models (MPAS, NEPTUNE, UM, FV3, GEOS, UFS).\u003c/p\u003e\n\u003cp\u003eSpack-stack supports installations on a range of R\u0026amp;D and operational platforms.\nIt provides a set of installation templates (package lists), default package settings,\nsystem configurations for a range of \u003ca href=\"https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html\" rel=\"nofollow\"\u003emacOS and Linux workstation, HPC, and cloud\nplatforms\u003c/a\u003e, and Spack extensions, and uses a fork of the\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack repository\u003c/a\u003e. \u003ca href=\"https://spack.io/\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e is a\ncommunity-supported, multi-platform package manager\ndeveloped by Lawrence Livermore National Laboratory\n(LLNL). Spack is provided as a submodule to spack-stack so that a\nstable version can be referenced. For more information about Spack, see\nthe \u003ca href=\"https://computing.llnl.gov/projects/spack-hpc-package-manager\" rel=\"nofollow\"\u003eLLNL project page for Spack\u003c/a\u003e\nand the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003eSpack documentation\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTo get started with spack-stack\u003c/strong\u003e, either by using an existing\ninstallation on a \u003ca href=\"https://spack-stack.readthedocs.io/en/latest/PreConfiguredSites.html\" rel=\"nofollow\"\u003esupported platform\u003c/a\u003e\nor by \u003ca href=\"https://spack-stack.readthedocs.io/en/latest/CreatingEnvironments.html\" rel=\"nofollow\"\u003ecreating a new installation\u003c/a\u003e, see the\n\u003ca href=\"https://spack-stack.readthedocs.io/en/latest/Overview.html#getting-started\" rel=\"nofollow\"\u003eGetting Started\u003c/a\u003e documentation page.\nFull documentation with table of contents can be found at \u003ca href=\"https://spack-stack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://spack-stack.readthedocs.io/en/latest/\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSpack-stack is a collaborative effort between:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.emc.ncep.noaa.gov/emc_new.php\" rel=\"nofollow\"\u003eNOAA Environmental Modeling Center (EMC)\u003c/a\u003e: \u003ca href=\"https://www.github.com/AlexanderRichert-NOAA\"\u003eAlex Richert\u003c/a\u003e, \u003ca href=\"https://www.github.com/Hang-Lei-NOAA\"\u003eHang Lei\u003c/a\u003e, \u003ca href=\"https://www.github.com/edwardhartnett\"\u003eEd Hartnett\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.jcsda.org/\" rel=\"nofollow\"\u003eUCAR Joint Center for Satellite Data Assimilation (JCSDA)\u003c/a\u003e: \u003ca href=\"https://www.github.com/climbfuji\"\u003eDom Heinzeller\u003c/a\u003e, \u003ca href=\"https://github.com/srherbener\"\u003eSteve Herbener\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://epic.noaa.gov/\" rel=\"nofollow\"\u003eEarth Prediction Innovation Center (EPIC)\u003c/a\u003e: \u003ca href=\"https://github.com/ulmononian\"\u003eCam Book\u003c/a\u003e, \u003ca href=\"https://github.com/natalie-perlin\"\u003eNatalie Perlin\u003c/a\u003e, \u003ca href=\"https://github.com/ratkovasic-noaa\"\u003eRatko Vasic\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor more information about the organization of the spack-stack\nproject, see the \u003ca href=\"project_charter.md\"\u003eProject Charter\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 19,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1710874369.0
  },
  {
    "data_format": 2,
    "description": "Modular interface physics library featuring state-of-the-art contact physics methods.",
    "filenames": [
      "scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml",
      "scripts/spack/configs/toss_4_x86_64_ib/spack.yaml"
    ],
    "full_name": "LLNL/Tribol",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eTribol: Contact Interface Physics Library\u003c/h1\u003e\u003ca id=\"user-content-tribol-contact-interface-physics-library\" class=\"anchor\" aria-label=\"Permalink: Tribol: Contact Interface Physics Library\" href=\"#tribol-contact-interface-physics-library\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHigh fidelity simulations modeling complex interactions of moving bodies require specialized contact algorithms to\nenforce zero-interpenetration constraints between surfaces. Tribol provides a unified interface for various\ncontact algorithms, including contact search, detection and enforcement, thereby enabling the research and development\nof advanced contact algorithms.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eQuick Start Guide\u003c/h2\u003e\u003ca id=\"user-content-quick-start-guide\" class=\"anchor\" aria-label=\"Permalink: Quick Start Guide\" href=\"#quick-start-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eClone the repository\u003c/h3\u003e\u003ca id=\"user-content-clone-the-repository\" class=\"anchor\" aria-label=\"Permalink: Clone the repository\" href=\"#clone-the-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003egit clone --recursive git@github.com:LLNL/Tribol.git\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSetup for development\u003c/h3\u003e\u003ca id=\"user-content-setup-for-development\" class=\"anchor\" aria-label=\"Permalink: Setup for development\" href=\"#setup-for-development\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDevelopment tools can optionally be installed through the Spack package manager. Development tools are typically not\nneeded when using Tribol. The command to install development tools is\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 scripts/uberenv/uberenv.py --project-json=scripts/spack/devtools.json --spack-env-file=scripts/spack/configs/\u0026lt;platform\u0026gt;/spack.yaml --prefix=../tribol_devtools\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewhere \u003ccode\u003e\u0026lt;platform\u0026gt;\u003c/code\u003e is one of \u003ccode\u003eblueos_3_ppc64le_ib_p9\u003c/code\u003e, \u003ccode\u003elinux_ubuntu_20\u003c/code\u003e, \u003ccode\u003elinux_ubuntu_22\u003c/code\u003e, \u003ccode\u003etoss_4_x86_64_ib\u003c/code\u003e, or\n\u003ccode\u003etoss_4_x86_64_ib_cray\u003c/code\u003e. Please verify \u003ccode\u003escripts/spack/configs/\u0026lt;platform\u0026gt;/spack.yaml\u003c/code\u003e matches your system configuration.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstalling dependencies\u003c/h3\u003e\u003ca id=\"user-content-installing-dependencies\" class=\"anchor\" aria-label=\"Permalink: Installing dependencies\" href=\"#installing-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTribol dependency installation is managed through uberenv, which invokes a local instance of the spack package manager\nto install and manage dependencies. To install dependencies, run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 scripts/uberenv/uberenv.py --spack-env-file=scripts/spack/configs/\u0026lt;platform\u0026gt;/spack.yaml --prefix=../tribol_libs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSee additional options by running\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 scripts/uberenv/uberenv.py --help\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTribol is tested on three platforms:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUbuntu 22.04 LTS (via Windows WSL 2)\u003c/li\u003e\n\u003cli\u003eTOSS 4\u003c/li\u003e\n\u003cli\u003eBlueOS\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSee \u003ccode\u003escripts/spack/packages/tribol/package.py\u003c/code\u003e for possible variants in the spack spec. The file\n\u003ccode\u003escripts/spack/specs.json\u003c/code\u003e lists spack specs which are known to build successfully on different platforms.  Note the\ndevelopment tools can be built with dependencies using the \u003ccode\u003e+devtools\u003c/code\u003e variant.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild the code\u003c/h3\u003e\u003ca id=\"user-content-build-the-code\" class=\"anchor\" aria-label=\"Permalink: Build the code\" href=\"#build-the-code\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAfter running uberenv, a host config file is created in the tribol repo root directory.  Use the \u003ccode\u003econfig-build.py\u003c/code\u003e\nscript to create build and install directories and invoke CMake.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 ./config-build.py -hc \u0026lt;host-config\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEnter the build directory and run\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emake -j\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eto build Tribol.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Tribol contact physics library requires:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCMake 3.14 or higher\u003c/li\u003e\n\u003cli\u003eC++14 compiler\u003c/li\u003e\n\u003cli\u003eMPI\u003c/li\u003e\n\u003cli\u003emfem\u003c/li\u003e\n\u003cli\u003eaxom\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTribol has optional dependencies on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCUDA\u003c/li\u003e\n\u003cli\u003eHIP\u003c/li\u003e\n\u003cli\u003eRAJA\u003c/li\u003e\n\u003cli\u003eUmpire\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTribol is distributed under the terms of the MIT license. All new contributions must be\nmade under this license.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: MIT\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-846697\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSPDX usage\u003c/h2\u003e\u003ca id=\"user-content-spdx-usage\" class=\"anchor\" aria-label=\"Permalink: SPDX usage\" href=\"#spdx-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIndividual files contain SPDX tags instead of the full license text.\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are available here: \u003ca href=\"https://spdx.org/licenses/\" rel=\"nofollow\"\u003ehttps://spdx.org/licenses/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFiles that are licensed as MIT contain the following\ntext in the license header:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSPDX-License-Identifier: (MIT)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExternal Packages\u003c/h2\u003e\u003ca id=\"user-content-external-packages\" class=\"anchor\" aria-label=\"Permalink: External Packages\" href=\"#external-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTribol bundles some of its external dependencies in its repository.  These\npackages are covered by various permissive licenses.  A summary listing\nfollows.  See the license included with each package for full details.\u003c/p\u003e\n\u003cp\u003ePackageName: BLT\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/blt\"\u003ehttps://github.com/LLNL/blt\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: uberenv\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/uberenv\"\u003ehttps://github.com/LLNL/uberenv\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n",
    "stargazers_count": 21,
    "subscribers_count": 7,
    "topics": [
      "math-physics"
    ],
    "updated_at": 1708333690.0
  },
  {
    "data_format": 2,
    "description": "ImpactX: an s-based beam dynamics code including space charge effects",
    "filenames": [
      "docs/spack.yaml"
    ],
    "full_name": "ECP-WarpX/impactx",
    "latest_release": "24.03",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eImpactX\u003c/h1\u003e\u003ca id=\"user-content-impactx\" class=\"anchor\" aria-label=\"Permalink: ImpactX\" href=\"#impactx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml\"\u003e\u003cimg src=\"https://github.com/ECP-WarpX/impactx/actions/workflows/ubuntu.yml/badge.svg\" alt=\"CI Status\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://impactx.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/82c1a8657894c9ec3db2c95f0b6b76b54db5bf7e45791fa95a4e8b1ff5141cff/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f696d70616374782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/impactx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License ImpactX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://impactx.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.6954922\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/06f98372a5792ed51abd2d619785bacd761df421074c42b83e4d0ced15e1911d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e363935343932322d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.6954922-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.18429/JACoW-NAPAC2022-TUYE2\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5f95e3947c3a41069646d76b491600897ab8797b4fdf66579ca1bb36f439ef2a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e31383432392532464a41436f572d2d4e41504143323032322d2d54555945322d626c75652e737667\" alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.18429%2FJACoW--NAPAC2022--TUYE2-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\" alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/647bd6e78a284bf08e53bd7038f210400464c5a5ed8beedd3391512ebb2aaefb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\" alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eImpactX: an s-based beam dynamics code including space charge effects.\nThis is the next generation of the \u003ca href=\"https://github.com/impact-lbl/IMPACT-Z\"\u003eIMPACT-Z\u003c/a\u003e code.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn order to learn how to install and run the code, please see the online documentation:\n\u003ca href=\"https://impactx.readthedocs.io\" rel=\"nofollow\"\u003ehttps://impactx.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eImpactX Doxygen: \u003ca href=\"https://impactx.readthedocs.io/en/latest/_static/doxyhtml\" rel=\"nofollow\"\u003ehttps://impactx.readthedocs.io/en/latest/_static/doxyhtml\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eAMReX Doxygen: \u003ca href=\"https://amrex-codes.github.io/amrex/doxygen\" rel=\"nofollow\"\u003ehttps://amrex-codes.github.io/amrex/doxygen\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eWarpX Doxygen: \u003ca href=\"https://warpx.readthedocs.io/en/latest/_static/doxyhtml\" rel=\"nofollow\"\u003ehttps://warpx.readthedocs.io/en/latest/_static/doxyhtml\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22AMReX%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur workflow is described in \u003ca href=\"CONTRIBUTING.rst\"\u003eCONTRIBUTING.rst\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDeveloper Environment\u003c/h2\u003e\u003ca id=\"user-content-developer-environment\" class=\"anchor\" aria-label=\"Permalink: Developer Environment\" href=\"#developer-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease see our \u003ca href=\"https://impactx.readthedocs.io/en/latest/install/dependencies.html#install-dependencies\" rel=\"nofollow\"\u003edeveloper installation section\u003c/a\u003e of the documentation for an easy install of our software dependencies.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGet the Source Code\u003c/h2\u003e\u003ca id=\"user-content-get-the-source-code\" class=\"anchor\" aria-label=\"Permalink: Get the Source Code\" href=\"#get-the-source-code\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBefore you start, you will need a copy of the ImpactX source code:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone git@github.com:ECP-WarpX/impactx.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e impactx\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCompile\u003c/h2\u003e\u003ca id=\"user-content-compile\" class=\"anchor\" aria-label=\"Permalink: Compile\" href=\"#compile\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e find dependencies \u0026amp; configure\u003c/span\u003e\ncmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e compile\u003c/span\u003e\ncmake --build build -j 4\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThat\u0027s all!\nImpactX binaries are now in \u003ccode\u003ebuild/bin/\u003c/code\u003e.\nMost people execute these binaries directly or copy them out.\u003c/p\u003e\n\u003cp\u003eYou can inspect and modify build options after running \u003ccode\u003ecmake -S . -B\u003c/code\u003e build with either\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eccmake build\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor by adding arguments with \u003ccode\u003e-D\u0026lt;OPTION\u0026gt;=\u0026lt;VALUE\u0026gt;\u003c/code\u003e to the first CMake call, e.g.:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build -DImpactX_COMPUTE=CUDA -DImpactX_MPI=OFF\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePython Compile\u003c/h3\u003e\u003ca id=\"user-content-python-compile\" class=\"anchor\" aria-label=\"Permalink: Python Compile\" href=\"#python-compile\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e find dependencies \u0026amp; configure\u003c/span\u003e\ncmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build -DImpactX_PYTHON=ON\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e compile \u0026amp; install\u003c/span\u003e\ncmake --build build -j 4 --target pip_install\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRun\u003c/h2\u003e\u003ca id=\"user-content-run\" class=\"anchor\" aria-label=\"Permalink: Run\" href=\"#run\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAn executable ImpactX binary with the current compile-time options encoded in its file name will be created in \u003ccode\u003ebuild/bin/\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eAdditionally, a symbolic link named \u003ccode\u003eimpactx\u003c/code\u003e can be found in that directory, which points to the last built ImpactX executable.\u003c/p\u003e\n\u003cp\u003eThe command-line syntax for this executable is:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eUsage: impactx \u0026lt;inputs-file\u0026gt; [some.overwritten.option=value]...\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eMandatory arguments (remove the \u0026lt;\u0026gt;):\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  inputs-file     the path to an input file; can be relative to the current\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e                  working directory or absolute.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e                  Example: input_fodo.in\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eOptional arguments (remove the []):\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  options         this can overwrite any line in an inputs-file\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e                  Example: quad1.ds=0.5 sbend1.rc=1.5\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eExamples:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  In the current working directory, there is a file \"input_fodo.in\" and the\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  \"impactx\" executable.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  The line to execute would look like this:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    ./impactx input_fodo.in\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e  In the current working directory, there is a file \"input_fodo.in\" and the\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  executable \"impactx\" is in a directory that is listed in the \"PATH\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  environment variable.\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  The line to execute would look like this:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    impactx input_fodo.in\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003e  In the current working directory, there is a file \"input_fodo.in\" and the\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  \"impactx\" executable. We want to voerwrite the segment length of the beamline\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  element \"quad1\" that is already defined in it. We also want to change the\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  radius of curvature of the bending magnet \"sbend1\" to a different value than\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  in the file \"input_fodo.in\".\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  The line to execute would look like this:\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e    ./impactx input_fodo.in quad1.ds=0.5 sbend1.rc=1.5\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTest\u003c/h2\u003e\u003ca id=\"user-content-test\" class=\"anchor\" aria-label=\"Permalink: Test\" href=\"#test\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn order to run our tests, you need to have a few Python packages installed:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003epython3 -m pip install --upgrade pip\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003epython3 -m pip install --upgrade build packaging setuptools wheel pytest\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003epython3 -m pip install --upgrade -r examples/requirements.txt\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can run all our tests with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ectest --test-dir build --output-on-failure\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFurther options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ehelp: \u003ccode\u003ectest --test-dir build --help\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003elist all tests: \u003ccode\u003ectest --test-dir build -N\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eonly run tests that have \"FODO\" in their name: \u003ccode\u003ectest --test-dir build -R FODO\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgements\u003c/h2\u003e\u003ca id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink: Acknowledgements\" href=\"#acknowledgements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis work was supported by the Laboratory Directed Research and Development Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract No. DE-AC02-05CH11231.\u003c/p\u003e\n\u003cp\u003eImpactX is supported by the CAMPA collaboration, a project of the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research and Office of High Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright Notice\u003c/h2\u003e\u003ca id=\"user-content-copyright-notice\" class=\"anchor\" aria-label=\"Permalink: Copyright Notice\" href=\"#copyright-notice\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eImpactX Copyright (c) 2022, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to receipt of any required approvals from the U.S. Dept. of Energy).\nAll rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software, please contact Berkeley Lab\u0027s Intellectual Property Office at \u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE. This Software was developed under funding from the U.S. Department of Energy and the U.S. Government consequently retains certain rights. As such, the U.S. Government has been granted for itself and others acting on its behalf a paid-up, nonexclusive, irrevocable, worldwide license in the Software to reproduce, distribute copies to the public, prepare derivative works, and perform publicly and display publicly, and to permit others to do so.\u003c/p\u003e\n\u003cp\u003ePlease see the full license agreement in \u003ca href=\"LICENSE.txt\"\u003eLICENSE.txt\u003c/a\u003e. The SPDX license identifier is \u003ccode\u003eBSD-3-Clause-LBNL\u003c/code\u003e.\u003c/p\u003e\n",
    "stargazers_count": 21,
    "subscribers_count": 6,
    "topics": [
      "simulation",
      "beam-dynamics",
      "particle-in-cell",
      "gpu",
      "physics",
      "pic",
      "particle",
      "accelerator",
      "research"
    ],
    "updated_at": 1710270618.0
  },
  {
    "data_format": 2,
    "description": "A library to abstract between different lossless and lossy compressors",
    "filenames": [
      "docker/spack.yaml"
    ],
    "full_name": "robertu94/libpressio",
    "latest_release": "0.70.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLibPressio\u003c/h1\u003e\u003ca id=\"user-content-libpressio\" class=\"anchor\" aria-label=\"Permalink: LibPressio\" href=\"#libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003ethe stable version of this code is found at \u003ca href=\"https://github.com/CODARcode/libpressio\"\u003eat the CODARCode organization\u003c/a\u003e it is updated about anually\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003ePressio is latin for compression.  LibPressio is a C++ library with C compatible bindings to abstract between different lossless and lossy compressors and their configurations.  It solves the problem of having to having to write separate application level code for each lossy compressor that is developed.  Instead, users write application level code using LibPressio, and the library will make the correct underlying calls to the compressors.  It provides interfaces to represent data, compressors settings, and compressors.\u003c/p\u003e\n\u003cp\u003eDocumentation for the \u003ccode\u003emaster\u003c/code\u003e branch can be \u003ca href=\"https://robertu94.github.io/libpressio/\" rel=\"nofollow\"\u003efound here\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUsing LibPressio\u003c/h1\u003e\u003ca id=\"user-content-using-libpressio\" class=\"anchor\" aria-label=\"Permalink: Using LibPressio\" href=\"#using-libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExample using the CLI from \u003ca href=\"https://github.com/robertu94/pressio-tools\"\u003e\u003ccode\u003epressio-tools\u003c/code\u003e\u003c/a\u003e\nWe also have C, C++, Rust, Julia, and Python bindings.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epressio -i \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32 \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m \u003cspan class=\"pl-k\"\u003etime\u003c/span\u003e -m size -m error_stat -M all \\\n    -w /path/to/output.dec\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe reccomended way to learn LibPressio is with self-pased \u003ca href=\"https://github.com/robertu94/libpressio_tutorial\"\u003eLibPressio Tutorial\u003c/a\u003e.\nHere you will find examples of how to use LibPressio in a series of lessons for several common languages.\u003c/p\u003e\n\u003cp\u003eYou can also find a \u003ca href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\"\u003erecording of the tutorial on YouTube\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Started\u003c/h2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-label=\"Permalink: Getting Started\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAfter skimming the example, LibPressio has 6 major headers that you will need to use:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eType\u003c/th\u003e\n\u003cth\u003eUse\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eError reporting and aquiring handles to compressors\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_compressor.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eUsed to compress and decompress data, provided by plugins\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_data.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepresents data and associated metadata (size, type, dimentionality, memory ownership)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_options.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMaps between names and values, used for options for compressors and metrics results\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_metrics.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eA set of metrics to run while compressors run\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_io.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAn extension header that provides methods to load or store data from/to persistent storage\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eAll of these are included by the convience header \u003ccode\u003elibpressio.h\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eYou can pick up the more advanced features as you need them.\u003c/p\u003e\n\u003cp\u003eYou can also find more examples in \u003ccode\u003etest/\u003c/code\u003e or in the \u003ca href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\u003eLibPressio intresting scripts collection\u003c/a\u003e which catalogs intresting higher-level use cases.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSupported Compressors and Metrics\u003c/h2\u003e\u003ca id=\"user-content-supported-compressors-and-metrics\" class=\"anchor\" aria-label=\"Permalink: Supported Compressors and Metrics\" href=\"#supported-compressors-and-metrics\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibpressio provides a number of builtin compressor and metrics modules.\nAll of these are \u003cstrong\u003edisabled by default\u003c/strong\u003e.\nThey can be enabled by passing the corresponding \u003ccode\u003eLIBPRESSIO_HAS_*\u003c/code\u003e variable to CMake.\u003c/p\u003e\n\u003cp\u003eAdditionally, Libpressio is extensible.\nFor information on writing a compressor plugin see \u003ca href=\"docs/WritingACompressorPlugin.md\"\u003eWriting a Compressor Plugin\u003c/a\u003e\nFor information on writing a metrics plugin see \u003ca href=\"docs/WritingAMetricsPlugin.md\"\u003eWriting a Metrics Plugin\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCompressor Plugins\u003c/h3\u003e\u003ca id=\"user-content-compressor-plugins\" class=\"anchor\" aria-label=\"Permalink: Compressor Plugins\" href=\"#compressor-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\u003esrc/plugins/compressors\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"build/Compressors.md\"\u003ecompressor settings page\u003c/a\u003e for information on how to configure them.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMetrics Plugins\u003c/h3\u003e\u003ca id=\"user-content-metrics-plugins\" class=\"anchor\" aria-label=\"Permalink: Metrics Plugins\" href=\"#metrics-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\u003esrc/plugins/metrics\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"build/Metrics.md\"\u003emetrics results page\u003c/a\u003e for information on what they produce\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eIO Plugins\u003c/h3\u003e\u003ca id=\"user-content-io-plugins\" class=\"anchor\" aria-label=\"Permalink: IO Plugins\" href=\"#io-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\u003esrc/plugins/io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"build/IO.md\"\u003eio settings page\u003c/a\u003e for information on how to configure them\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eInstallation\u003c/h1\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling LibPressio using Spack\u003c/h2\u003e\u003ca id=\"user-content-installing-libpressio-using-spack\" class=\"anchor\" aria-label=\"Permalink: Installing LibPressio using Spack\" href=\"#installing-libpressio-using-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressio can be built using \u003ca href=\"https://github.com/spack/spack/\"\u003espack\u003c/a\u003e.  This example will install libpressio with only the SZ3 plugin.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/spack/spack\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh\nspack install libpressio+sz3\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMore information on spack can be found in the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack documentation\u003c/a\u003e or \u003ca href=\"https://robertu94.github.io/guides\" rel=\"nofollow\"\u003emy quick start guides for systems that I use\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can see the other available versions and compilation options by calling \u003ccode\u003espack info libpressio\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe following language bindings are in this repository.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eC\u003c/code\u003e -- (default) if you need a stable interface\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eC++\u003c/code\u003e -- (default) if you want a more productive interface, or want to extend LibPressio\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ePython\u003c/code\u003e -- (\u003ccode\u003e+python\u003c/code\u003e; BUILD_PYTHON_WRAPPER) if you know or want to intergate Python\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eHDF5\u003c/code\u003e -- (\u003ccode\u003e+hdf5+json\u003c/code\u003e; LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following bindings must be installed seperately:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eR\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/libpressio-r\"\u003er-libpressio\u003c/a\u003e if you know or want to integrate with R\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eBash/CLI\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/pressio-tools\"\u003elibpressio-tools\u003c/a\u003e  if you want to quickly prototype from the CLI\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following bindings are experimental and can be installed manually:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eJulia\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/LibPressio.jl\"\u003elibpressio-jl\u003c/a\u003e if you know or want to integrate with Julia\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eRust\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/libpressio-rs\"\u003elibpressio-rs\u003c/a\u003e if you know or want to integrate with Rust\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDoing a development build with spack\u003c/h2\u003e\u003ca id=\"user-content-doing-a-development-build-with-spack\" class=\"anchor\" aria-label=\"Permalink: Doing a development build with spack\" href=\"#doing-a-development-build-with-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe easiest way to do a development build of libpressio is to use Spack envionments.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e one time setup: create an envionment\u003c/span\u003e\nspack env create -d mydevenviroment\nspack env activate mydevenvionment\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e one time setup: tell spack to set LD_LIBRARY_PATH with the spack envionment\u0027s library paths\u003c/span\u003e\nspack config add modules:prefix_inspections:lib64:[LD_LIBRARY_PATH]\nspack config add modules:prefix_inspections:lib:[LD_LIBRARY_PATH]\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e one time setup: install libpressio-tools and checkout \u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e libpressio for development\u003c/span\u003e\nspack add libpressio-tools\nspack develop libpressio@git.master\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e compile and install (repeat as needed)\u003c/span\u003e\nspack install \u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eManual Installation\u003c/h2\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-label=\"Permalink: Manual Installation\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibpressio unconditionally requires:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecmake\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epkg-config\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/robertu94/std_compat\"\u003e\u003ccode\u003estd_compat\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eeither:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003egcc-4.8.5\u003c/code\u003e or later\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eclang-7.0.0\u003c/code\u003e or later using either \u003ccode\u003elibc++\u003c/code\u003e or \u003ccode\u003elibstdc++\u003c/code\u003e.  Beware that system libraries may need to be recompiled with \u003ccode\u003elibc++\u003c/code\u003e if using \u003ccode\u003elibc++\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDependency versions and optional dependencies are documented \u003ca href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\u003ein the spack package\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eConfiguring LibPressio Manually\u003c/h2\u003e\u003ca id=\"user-content-configuring-libpressio-manually\" class=\"anchor\" aria-label=\"Permalink: Configuring LibPressio Manually\" href=\"#configuring-libpressio-manually\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLibPressio uses a fairly standard CMake buildsystem.\nFor more information on \u003ca href=\"https://robertu94.github.io/learning/cmake\" rel=\"nofollow\"\u003eCMake refer to these docs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe set of configuration options for LibPressio can be found using \u003ccode\u003ecmake -L $BUILD_DIR\u003c/code\u003e.\nFor information on what these settings do, see the \u003ca href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\u003espack package\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eAPI Stability\u003c/h1\u003e\u003ca id=\"user-content-api-stability\" class=\"anchor\" aria-label=\"Permalink: API Stability\" href=\"#api-stability\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease refer to \u003ca href=\"docs/stability.md\"\u003edocs/stability.md\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eHow to Contribute\u003c/h1\u003e\u003ca id=\"user-content-how-to-contribute\" class=\"anchor\" aria-label=\"Permalink: How to Contribute\" href=\"#how-to-contribute\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease refer to \u003ca href=\"CONTRIBUTORS.md\"\u003eCONTRIBUTORS.md\u003c/a\u003e for a list of contributors, sponsors, and contribution guidelines.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eBug Reports\u003c/h1\u003e\u003ca id=\"user-content-bug-reports\" class=\"anchor\" aria-label=\"Permalink: Bug Reports\" href=\"#bug-reports\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease files bugs to the Github Issues page on the CODARCode libpressio repository.\u003c/p\u003e\n\u003cp\u003ePlease read this post on \u003ca href=\"https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\"\u003ehow to file a good bug report\u003c/a\u003e.\u00a0 After reading this post, please provide the following information specific to libpressio:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYour OS version and distribution information, usually this can be found in \u003ccode\u003e/etc/os-release\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe output of \u003ccode\u003ecmake -L $BUILD_DIR\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe version of each of libpressio\u0027s dependencies listed in the README that you have installed. Where possible, please provide the commit hashes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCiting LibPressio\u003c/h1\u003e\u003ca id=\"user-content-citing-libpressio\" class=\"anchor\" aria-label=\"Permalink: Citing LibPressio\" href=\"#citing-libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you find LibPressio useful, please cite this paper:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@inproceedings{underwood2021productive,\n  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di, Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n  year={2021},\n  organization={IEEE}\n}\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 22,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1709293745.0
  },
  {
    "data_format": 2,
    "description": "E4S for Spack",
    "filenames": [
      "environments/24.02/amd64-gcc-cpu-ubuntu20.04/spack.yaml",
      "environments/23.08/cuda-aarch64/spack.yaml",
      "environments/21.05/spack.yaml",
      "environments/22.05/cuda-x86_64.spack.yaml",
      "environments/23.05/cuda-x86_64/spack.yaml",
      "environments/23.05/rocm-x86_64/spack.yaml",
      "environments/24.02/arm64-gcc-cuda-ubuntu20.04/spack.yaml",
      "environments/22.05/rocm.spack.yaml",
      "environments/23.08/cuda-x86_64/spack.yaml",
      "environments/23.02/cuda-ppc64le/spack.yaml",
      "environments/22.08/cuda-x86_64.spack.yaml",
      "environments/21.08/spack.yaml",
      "environments/23.11/cuda-x86_64/spack.yaml",
      "environments/23.08/oneapi-x86_64/spack.yaml",
      "environments/23.02/cuda-x86_64/spack.yaml",
      "environments/23.11/cuda-ppc64le/spack.yaml"
    ],
    "full_name": "E4S-Project/e4s",
    "latest_release": "v24.02",
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\u003e\u003cimg src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\" width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e \n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d548c41497648f97178f367a87401d9f73f533daf22804b7fef0b85f7d8e3ee/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\" alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b8248e747ce21198bc44bfd5d4a8f9e5ec64a7a2c68b6e619cbfb5301a954f91/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1bfba11ecd687250fe889e3506d82375ddaaed674b6fd8cda2605a56dd15ad89/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\" alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e0d5e7562db6d38a29491be3391fe00bbcb5813c3a1a60a0e7bfbf4c32fa19be/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\" alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eE4S\u003c/h1\u003e\u003ca id=\"user-content-e4s\" class=\"anchor\" aria-label=\"Permalink: E4S\" href=\"#e4s\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003eExtreme-scale Scientific Software Stack (E4S)\u003c/a\u003e is a community effort to provide open source\nsoftware packages for developing, deploying and running scientific applications on high-performance\ncomputing (HPC) platforms. E4S provides from-source builds and containers of a\n\u003ca href=\"https://e4s-project.github.io/Resources/ProductInfo.html\" rel=\"nofollow\"\u003ebroad collection of HPC software packages\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eE4S is available to download in the following formats:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eContainers: Docker, Singularity, CharlieCloud, OVA\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSpack manifest (\u003ccode\u003espack.yaml\u003c/code\u003e) to install from source. These can be found in \u003ca href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\u003eenvironments\u003c/a\u003e directory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://aws.amazon.com/\" rel=\"nofollow\"\u003eAWS EC2 image\u003c/a\u003e with image name \u003ccode\u003eami-0db9d49091db1c25f\u003c/code\u003e in \u003cstrong\u003eUS-West-2 (Oregon)\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://oaciss.uoregon.edu/e4s/inventory.html\" rel=\"nofollow\"\u003eE4S Build Cache\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePlease see \u003ca href=\"https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\"\u003eE4S Product Dictionary\u003c/a\u003e for complete list of E4S products.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUseful Links\u003c/h2\u003e\u003ca id=\"user-content-useful-links\" class=\"anchor\" aria-label=\"Permalink: Useful Links\" href=\"#useful-links\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eUser Documentation: \u003ca href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\u003ehttps://e4s.readthedocs.io\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eMain Page: \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003ehttps://e4s-project.github.io/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S GitHub: \u003ca href=\"https://github.com/E4S-Project/\"\u003ehttps://github.com/E4S-Project/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S Slack Channel: \u003ca href=\"https://e4s-project.slack.com\" rel=\"nofollow\"\u003ehttps://e4s-project.slack.com\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSlack Channel Invitation: \u003ca href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\u003ehttps://communityinviter.com/apps/e4s-project/e4s\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S Dashboard: \u003ca href=\"https://dashboard.e4s.io/\" rel=\"nofollow\"\u003ehttps://dashboard.e4s.io/\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRelated Projects\u003c/h2\u003e\u003ca id=\"user-content-related-projects\" class=\"anchor\" aria-label=\"Permalink: Related Projects\" href=\"#related-projects\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\u003eE4S-Project/E4S-Project.github.io\u003c/a\u003e - E4S Documentation repo that is hosted on \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003ehttps://e4s-project.github.io/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/testsuite\"\u003eE4S-Project/testsuite\u003c/a\u003e - E4S Testsuite with collection of validation tests that can be run post-install.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/e4s-cl\"\u003eE4S-Project/e4s-cl\u003c/a\u003e - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/e4s-ci-badges\"\u003eE4S-Project/e4s-ci-badges\u003c/a\u003e - Display CI badges for E4S products that are available from \u003ca href=\"https://shields.io/\" rel=\"nofollow\"\u003eshields.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eE4S is released as MIT license for more details see \u003ca href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\u003eLICENSE\u003c/a\u003e file\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContact\u003c/h2\u003e\u003ca id=\"user-content-contact\" class=\"anchor\" aria-label=\"Permalink: Contact\" href=\"#contact\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eMike Heroux (\u003ca href=\"mailto:maherou@sandia.gov\"\u003emaherou@sandia.gov\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eSameer Shende (\u003ca href=\"mailto:sameer@cs.uoregon.edu\"\u003esameer@cs.uoregon.edu\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 23,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1711484169.0
  },
  {
    "data_format": 2,
    "description": "Simple Infrastructure for Earth System Simulations",
    "filenames": [
      "configs/spack_envs/albedo-spack.yaml"
    ],
    "full_name": "esm-tools/esm_tools",
    "latest_release": "v6.0.0",
    "stargazers_count": 23,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1711469760.0
  },
  {
    "data_format": 2,
    "description": "Training materials for setting up and using a research infrastructure based on Jupyter notebooks: https://cusy.io/en/seminars",
    "filenames": [
      "spackenvs/python-38/spack.yaml"
    ],
    "full_name": "veit/jupyter-tutorial",
    "latest_release": "v1.1.0",
    "stargazers_count": 23,
    "subscribers_count": 6,
    "topics": [
      "jupyter",
      "ipython",
      "ipython-widget",
      "ipywidget",
      "jupyter-notebook",
      "jupyterhub",
      "notebook"
    ],
    "updated_at": 1708166964.0
  },
  {
    "data_format": 2,
    "description": "An open collaborative repository for reproducible specifications of HPC benchmarks and cross site benchmarking environments",
    "filenames": [
      "configs/LLNL-Magma-Penguin-icelake-OmniPath/spack.yaml",
      "configs/nosite-AWS_PCluster_Hpc7a-zen4-EFA/spack.yaml",
      "configs/LLNL-Pascal-Penguin-broadwell-P100-OmniPath/spack.yaml",
      "configs/RCCS-Fugaku-Fujitsu-A64FX-TofuD/spack.yaml",
      "configs/LLNL-Tioga-HPECray-zen3-MI250X-Slingshot/spack.yaml",
      "configs/CSCS-Eiger-HPECray-zen2-Slingshot/spack.yaml",
      "configs/CSCS-Daint-HPECray-haswell-P100-Infiniband/spack.yaml"
    ],
    "full_name": "LLNL/benchpark",
    "latest_release": null,
    "stargazers_count": 24,
    "subscribers_count": 8,
    "topics": [
      "benchmark",
      "hpc"
    ],
    "updated_at": 1709667806.0
  },
  {
    "data_format": 2,
    "description": "Installing spack without system dependencies",
    "filenames": [
      "build/3_more_tools/spack.yaml"
    ],
    "full_name": "eth-cscs/spack-batteries-included",
    "latest_release": "develop",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml\"\u003e\u003cimg src=\"https://github.com/eth-cscs/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\" alt=\"Update spack develop version\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\ud83d\udd0b Spack with batteries included (linux/x86_64)\u003c/h1\u003e\u003ca id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\" aria-label=\"Permalink: \ud83d\udd0b Spack with batteries included (linux/x86_64)\" href=\"#-spack-with-batteries-included-linuxx86_64\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e is a package manager, and package managers should be trivial to install.\u003c/p\u003e\n\u003cp\u003eThis repo offers a single, static executable for Spack:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ewget -qO spack.x https://github.com/eth-cscs/spack-batteries-included/releases/download/develop/spack-x86_64.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003echmod +x spack.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack.x install curl tls=mbedtls\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWhat version of Spack is shipped?\u003c/h2\u003e\u003ca id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\" aria-label=\"Permalink: What version of Spack is shipped?\" href=\"#what-version-of-spack-is-shipped\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe URL above gives you a rolling release of Spack\u0027s develop branch, which is updated\nhourly. The exact commit SHA is included as a file and can be retrieved like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract spack_sha \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e cat spack/spack_sha\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e[prints the Spack commit sha]\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSupported platforms\u003c/h2\u003e\u003ca id=\"user-content-supported-platforms\" class=\"anchor\" aria-label=\"Permalink: Supported platforms\" href=\"#supported-platforms\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eCentOS 7 and above\u003c/li\u003e\n\u003cli\u003eUbuntu 14.04 and above\u003c/li\u003e\n\u003cli\u003eDebian 8 and above\u003c/li\u003e\n\u003cli\u003eFedora 20 and above\u003c/li\u003e\n\u003cli\u003eSUSE Linux 13 and above\u003c/li\u003e\n\u003cli\u003eArch Linux\u003c/li\u003e\n\u003cli\u003eGentoo\u003c/li\u003e\n\u003cli\u003eWindows Subsystem for Linux 2 with any of the above distro\u0027s.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe system dependencies are \u003ccode\u003eglibc 2.17\u003c/code\u003e and above and optionally the \u003ccode\u003efusermount\u003c/code\u003e\nexecutable. If your system supports rootless containers it likely has \u003ccode\u003efusermount\u003c/code\u003e\ninstalled already!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow does it work?\u003c/h2\u003e\u003ca id=\"user-content-how-does-it-work\" class=\"anchor\" aria-label=\"Permalink: How does it work?\" href=\"#how-does-it-work\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003espack.x\u003c/code\u003e consists of a modified version of the AppImage runtime concatenated\nwith a big squashfs file which includes \u003ccode\u003ebinutils\u003c/code\u003e, \u003ccode\u003ebzip2\u003c/code\u003e, \u003ccode\u003eclingo\u003c/code\u003e, \u003ccode\u003ecurl\u003c/code\u003e,\n\u003ccode\u003efile\u003c/code\u003e, \u003ccode\u003egit\u003c/code\u003e, \u003ccode\u003egmake\u003c/code\u003e, \u003ccode\u003egpg\u003c/code\u003e, \u003ccode\u003egzip\u003c/code\u003e, \u003ccode\u003eopenssl\u003c/code\u003e, \u003ccode\u003epatch\u003c/code\u003e, \u003ccode\u003epatchelf\u003c/code\u003e, \u003ccode\u003epython\u003c/code\u003e,\n\u003ccode\u003epy-boto3\u003c/code\u003e, \u003ccode\u003etar\u003c/code\u003e, \u003ccode\u003eunzip\u003c/code\u003e, \u003ccode\u003exz\u003c/code\u003e, \u003ccode\u003ezstd\u003c/code\u003e and their dependencies.\u003c/p\u003e\n\u003cp\u003eWhen you run \u003ccode\u003espack.x [args]\u003c/code\u003e it will use \u003ccode\u003efusermount\u003c/code\u003e to\nmount this squashfs file in a temporary directory, and then execute the\nentrypoint executable \u003ca href=\"build/6_spack/spack\"\u003espack\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003espack\u003c/code\u003e executable sets some environment variables like \u003ccode\u003ePATH\u003c/code\u003e and\n\u003ccode\u003eDL_LIBRARY_PATH\u003c/code\u003e to the bin and lib folders of the squashfs file, and then it\nexecutes \u003ccode\u003epython3 spack_src/bin/spack [args]\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWhen the command is done running, the runtime unmounts the squashfs file again.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMy system doesn\u0027t allow me to use \u003ccode\u003efusermount\u003c/code\u003e, what now?\u003c/h2\u003e\u003ca id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\" aria-label=\"Permalink: My system doesn\u0027t allow me to use fusermount, what now?\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003efusermount\u003c/code\u003e is used to mount a squashfs file included in the binary. If you\ndon\u0027t want that, you can just extract it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack.x --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebut working with the extracted \u003ccode\u003espack\u003c/code\u003e folder can come with a performance\npenalty on shared filesystems in HPC centers.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDifferences and improvements over AppImage runtime\u003c/h2\u003e\u003ca id=\"user-content-differences-and-improvements-over-appimage-runtime\" class=\"anchor\" aria-label=\"Permalink: Differences and improvements over AppImage runtime\" href=\"#differences-and-improvements-over-appimage-runtime\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003espack.x uses \u003ccode\u003ezstd\u003c/code\u003e for faster decompression;\u003c/li\u003e\n\u003cli\u003espack.x itself is an entirely static binary;\u003c/li\u003e\n\u003cli\u003espack.x does not need to dlopen libfuse.so.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTroubleshooting\u003c/h2\u003e\u003ca id=\"user-content-troubleshooting\" class=\"anchor\" aria-label=\"Permalink: Troubleshooting\" href=\"#troubleshooting\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eimmutability\u003c/strong\u003e The squashfs mountpoint is a readonly folder, meaning that\nspack can\u0027t write to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard directories, see \u003ccode\u003espack.x config blame config\u003c/code\u003e for details.\u003c/p\u003e\n\u003cp\u003eNote, spack.x applies \u003ca href=\"https://github.com/spack/spack/pull/20158/\"\u003ethis patch\u003c/a\u003e\nto ensure that log files are written to the \u003ccode\u003econfig:misc_cache\u003c/code\u003e folder.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eopenssl\u003c/strong\u003e: By default spack.x uses \u003ccode\u003eca-certificates-mozilla\u003c/code\u003e for downloading\npackage sources over https. If you somehow need to use system certificates,\nset \u003ccode\u003eSSL_CERT_DIR\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CAINFO\u003c/code\u003e or \u003ccode\u003eSSL_CERT_FILE\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CERT\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCan I run spack.x inside a container?\u003c/h2\u003e\u003ca id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" aria-label=\"Permalink: Can I run spack.x inside a container?\" href=\"#can-i-run-spackx-inside-a-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYes, but please don\u0027t! Since \u003ccode\u003efusermount\u003c/code\u003e is a setuid binary, you will need to\nrun a privileged container, which is never a good idea.\u003c/p\u003e\n\u003cp\u003eThe recommended way to run spack.x inside a container is to just extract it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack/spack --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you insist on running spack.x in Docker, this is one way to do it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esudo docker run --privileged --device /dev/fuse -it -v \u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/spack.x:/bin/spack.x ubuntu:18.04\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eapt update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt install fuse \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install fusermount\u003c/span\u003e\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003espack.x --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning an executable shipped with spack.x directly\u003c/h2\u003e\u003ca id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"anchor\" aria-label=\"Permalink: Running an executable shipped with spack.x directly\" href=\"#running-an-executable-shipped-with-spackx-directly\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you want to run an executable shipped with \u003ccode\u003espack.x\u003c/code\u003e directly instead\nof invoking spack (the default entrypoint), try this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003eNO_ENTRYPOINT= spack.x which python\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/tmp/.mount_spack.h0zr1h/view/bin/python\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow do I build spack.x myself?\u003c/h2\u003e\u003ca id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\" aria-label=\"Permalink: How do I build spack.x myself?\" href=\"#how-do-i-build-spackx-myself\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInitially you may need docker to get a rootfs filesystem for centos 7.\u003c/p\u003e\n\u003cp\u003eBuilding goes like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003emake rootfs-with-spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003emake\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou\u0027ll find the output in\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuild/output\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 24,
    "subscribers_count": 3,
    "topics": [
      "spack",
      "squashfs",
      "libfuse"
    ],
    "updated_at": 1711196251.0
  },
  {
    "data_format": 2,
    "description": "Webinars\u0026Tutorial on Containers on HPC and Cloud with Singularity",
    "filenames": [
      "demos/spack_blast/spack.yaml"
    ],
    "full_name": "PawseySC/singularity-containers",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eReadme\u003c/h1\u003e\u003ca id=\"user-content-readme\" class=\"anchor\" aria-label=\"Permalink: Readme\" href=\"#readme\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n",
    "stargazers_count": 25,
    "subscribers_count": 12,
    "topics": [],
    "updated_at": 1702984370.0
  },
  {
    "data_format": 2,
    "description": "Simplified Interface to Complex Memory",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "lanl/SICM",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSICM\u003c/h1\u003e\u003ca id=\"user-content-sicm\" class=\"anchor\" aria-label=\"Permalink: SICM\" href=\"#sicm\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSimplified Interface to Complex Memory\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/lanl/SICM/actions\"\u003e\u003cimg src=\"https://github.com/lanl/SICM/actions/workflows/sicm.yml/badge.svg\" alt=\"GitHub Actions\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIntroduction\u003c/h2\u003e\u003ca id=\"user-content-introduction\" class=\"anchor\" aria-label=\"Permalink: Introduction\" href=\"#introduction\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis project is split into two interfaces: \u003ccode\u003elow\u003c/code\u003e and \u003ccode\u003ehigh\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003elow\u003c/code\u003e interface provides a minimal interface for application wanting to\nmanage their own memory on heterogeneous memory tiers. It also provides an\narena allocator that application developers can use to create \u003ccode\u003ejemalloc\u003c/code\u003e arenas\non different memory tiers and allocate to those tiers.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003ehigh\u003c/code\u003e interface attempts to automatically manage the memory tiers for the\napplication. It provides an LLVM compiler pass (and compiler wrappers) to\nautomatically transform applications to make the appropriate \u003ccode\u003ehigh\u003c/code\u003e interface\ncalls, as well as a runtime library which provides profiling for the\napplication.  The profiling is currently meant to be used offline; that is,\nafter enabling the profiling for an application run, the results are printed\nout at the end of the run, and that information must be fed into a second run\nto make use of it. An online approach is planned.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe only dependencies that you will need for the low-level interface\nare \u003ccode\u003elibnuma\u003c/code\u003e and \u003ccode\u003ejemalloc\u003c/code\u003e. We require that \u003ccode\u003ejemalloc\u003c/code\u003e be\nconfigured with the \u003ccode\u003eje_\u003c/code\u003e prefix (using the \u003ccode\u003e--with-jemalloc-prefix\u003c/code\u003e flag).\n\u003ccode\u003eCMake\u003c/code\u003e will use \u003ccode\u003epkg-config\u003c/code\u003e to find \u003ccode\u003ejemalloc\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor the high-level interface, you need an installation of LLVM. LLVM 4.0 and\nlater have been tested, although 3.9 may possibly work. For the profiling, you\nwill also need an installation of \u003ccode\u003elibpfm\u003c/code\u003e, which is a small helper library for\n\u003ccode\u003eperf\u003c/code\u003e that is available on most distributions.\u003c/p\u003e\n\u003cp\u003eAdditionally, several other packages are required, and can be installed through a package manager:\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBinaries\u003c/h3\u003e\u003ca id=\"user-content-binaries\" class=\"anchor\" aria-label=\"Permalink: Binaries\" href=\"#binaries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eA modern C compiler\u003c/li\u003e\n\u003cli\u003eA modern C++ compiler\u003c/li\u003e\n\u003cli\u003eA modern Fortran compiler\u003c/li\u003e\n\u003cli\u003eCMake 3.0+\u003c/li\u003e\n\u003cli\u003eMake\u003c/li\u003e\n\u003cli\u003enumactl\u003c/li\u003e\n\u003cli\u003eautomake + friends (if jemalloc needs to be built)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDevelopment Libraries\u003c/h3\u003e\u003ca id=\"user-content-development-libraries\" class=\"anchor\" aria-label=\"Permalink: Development Libraries\" href=\"#development-libraries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThese packages are usually named \u003ccode\u003elib*-dev\u003c/code\u003e or \u003ccode\u003elib*-devel\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003enuma\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAdditional packages are required for the high level interface:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ehwloc\u003c/li\u003e\n\u003cli\u003ellvm\u003c/li\u003e\n\u003cli\u003eomp (if OpenMP is not available by default on your compilers)\u003c/li\u003e\n\u003cli\u003epfm4\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCompilation\u003c/h2\u003e\u003ca id=\"user-content-compilation\" class=\"anchor\" aria-label=\"Permalink: Compilation\" href=\"#compilation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode\u003eexport PKG_CONFIG_PATH=\u0026lt;jemalloc prefix\u0026gt;/lib/pkgconfig:$PKG_CONFIG_PATH\nmkdir build\ncd build\ncmake .. -DCMAKE_INSTALL_PREFIX=\u0026lt;prefix\u0026gt;\nmake\nmake install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLow-Level API\u003c/h2\u003e\u003ca id=\"user-content-low-level-api\" class=\"anchor\" aria-label=\"Permalink: Low-Level API\" href=\"#low-level-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFunction Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_init\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eDetects all memory devices on system, returns a list of them.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_fini\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eFrees up a device list and associated SICM data structures.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_find_device\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturn the first device that matches a given type and page size.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_device_alloc\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAllocates to a given device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_device_free\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eFrees memory on a device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_can_place_exact\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns whether or not a device supports exact placement.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_device_alloc_exact\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAllocate memory on a device with an exact base address.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_numa_id\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns the NUMA ID that a device is on.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_device_page_size\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns the page size of a given device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_device_eq\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns if two devices are equal or not.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_move\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMoves memory from one device to another.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_pin\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ePin the current process to a device\u0027s memory.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_capacity\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns the capacity of a given device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_avail\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns the amount of memory available on a given device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_model_distance\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns the distance of a given memory device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_is_near\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns whether or not a given memory device is nearby the current NUMA node.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_latency\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMeasures the latency of a memory device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_bandwidth_linear2\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMeasures a memory device\u0027s linear access bandwidth.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_bandwidth_random2\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMeasures random access bandwidth of a memory device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_bandwidth_linear3\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMeasures the linear bandwidth of a memory device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_bandwidth_random3\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMeasures the random access bandwidth of a memory device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eArena Allocator API\u003c/h2\u003e\u003ca id=\"user-content-arena-allocator-api\" class=\"anchor\" aria-label=\"Permalink: Arena Allocator API\" href=\"#arena-allocator-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFunction Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arenas_list\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eList all arenas created in the arena allocator.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_create\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eCreate a new arena on the given device.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_destroy\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eFrees up an arena, deleting all associated data structures.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_set_default\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eSets an arena as the default for the current thread.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_get_default\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eGets the default arena for the current thread.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_get_device\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eGets the device for a given arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_set_device\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eSets the memory device for a given arena. Moves all allocated memory already allocated to the arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_size\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eGets the size of memory allocated to the given arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_alloc\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAllocate to a given arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_alloc_aligned\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAllocate aligned memory to a given arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_realloc\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eResize allocated memory to a given arena.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003esicm_arena_lookup\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eReturns which arena a given pointer belongs to.\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHigh-Level Interface\u003c/h2\u003e\u003ca id=\"user-content-high-level-interface\" class=\"anchor\" aria-label=\"Permalink: High-Level Interface\" href=\"#high-level-interface\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe high-level interface is normally used with the compiler wrappers located in\n\u003ccode\u003ebin/\u003c/code\u003e. Users should use these wrappers to compile their applications, and a\ncompiler pass will automatically transform the code so that it calls the\nhigh-level interface with the appropriate arguments, including initialization,\ndestruction, and the proper allocation functions. Assuming the high-level\ninterface is linked to the application as a shared library, it automatically\ninitializes itself.  All heap allocation routines are replaced by calls to\n\u003ccode\u003evoid* sh_alloc(int id, size_t sz)\u003c/code\u003e, which associates an ID with a given\nallocation and allocates the memory into an arena with other allocations of\nthat ID.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProgramming Practices\u003c/h2\u003e\u003ca id=\"user-content-programming-practices\" class=\"anchor\" aria-label=\"Permalink: Programming Practices\" href=\"#programming-practices\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eAll blocks use curly braces\n\u003cul\u003e\n\u003cli\u003eEven one-line blocks\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConstants on the left side of \u003ccode\u003e==\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eif(NULL == foo) { ...\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFunctions with no arguments are \u003ccode\u003e(void)\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eNo C++-style comments in C code\u003c/li\u003e\n\u003cli\u003eNo GCC extensions except in GCC-only code\u003c/li\u003e\n\u003cli\u003eNo C++ code in libraries\n\u003cul\u003e\n\u003cli\u003eDiscouraged in components\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAlways define preprocessor macros\n\u003cul\u003e\n\u003cli\u003eDefine logicals to 0 or 1 (vs. define or not define)\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003e#if FOO\u003c/code\u003e, not \u003ccode\u003e#ifdef FOO\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
    "stargazers_count": 26,
    "subscribers_count": 24,
    "topics": [],
    "updated_at": 1702677503.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ci/spack.yaml"
    ],
    "full_name": "NOAA-EMC/fv3atm",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003efv3atm\u003c/h1\u003e\u003ca id=\"user-content-fv3atm\" class=\"anchor\" aria-label=\"Permalink: fv3atm\" href=\"#fv3atm\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis repository contains a driver and key subcomponents of the\natmospheric component of the NOAA\u0027s \u003ca href=\"https://ufscommunity.org/\" rel=\"nofollow\"\u003eUnified Forecast System\n(UFS)\u003c/a\u003e weather model.\u003c/p\u003e\n\u003cp\u003eThe subcomponents include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe Finite-Volume Cubed-Sphere (FV3) dynamical core, originally\nfrom the \u003ca href=\"https://www.gfdl.noaa.gov/\" rel=\"nofollow\"\u003eGeophysical Fluid Dynamics\nLaboratory\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eThe Common Community Physics Package (CCPP) supported by the\n\u003ca href=\"https://dtcenter.org/community-code/common-community-physics-package-ccpp\" rel=\"nofollow\"\u003eDevelopmental Testbed Center\n(DTC)\u003c/a\u003e,\nincluding:\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/NCAR/ccpp-framework\"\u003eCCPP Framework\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NCAR/ccpp-physics\"\u003eCCPP Physics\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ewrapper code to call \u003ca href=\"https://stochastic-physics.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003eUFS stochastic\nphysics\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eThe io code handles netCDF I/O.\u003c/li\u003e\n\u003cli\u003eThe cpl coupler code connects the different components and allows\nthem to communicate.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis package requires the following\n\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS\"\u003eNCEPLIBS\u003c/a\u003e packages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-w3emc\"\u003eNCEPLIBS-w3emc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-bacio\"\u003eNCEPLIBS-bacio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-nemsio\"\u003eNCEPLIBS-nemsio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-sp\"\u003eNCEPLIBS-sp\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf the INLINE_POST cmake variable is set, the upp library will be\nneeded:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/EMC_post\"\u003eUnified Post Processing Library\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis package also requires the following external packages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Unidata/netcdf-c\"\u003enetcdf-c Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Unidata/netcdf-fortran\"\u003enetcdf-fortran Library\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/esmf-org/esmf\"\u003eESMF\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-GFDL/FMS\"\u003eGFDL\u0027s Flexible Modeling System\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eObtaining fv3atm\u003c/h2\u003e\u003ca id=\"user-content-obtaining-fv3atm\" class=\"anchor\" aria-label=\"Permalink: Obtaining fv3atm\" href=\"#obtaining-fv3atm\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo obtain fv3atm, clone the git repository, and update the submodules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/NOAA-EMC/fv3atm.git\ncd fv3atm\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDisclaimer\u003c/h2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-label=\"Permalink: Disclaimer\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is\nprovided on an \"as is\" basis and the user assumes responsibility for\nits use. DOC has relinquished control of the information and no longer\nhas responsibility to protect the integrity, confidentiality, or\navailability of the information. Any claims against the Department of\nCommerce stemming from the use of its GitHub project will be governed\nby all applicable Federal law. Any reference to specific commercial\nproducts, processes, or services by service mark, trademark,\nmanufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of\nCommerce. The Department of Commerce seal and logo, or the seal and\nlogo of a DOC bureau, shall not be used in any manner to imply\nendorsement of any commercial product or activity by DOC or the United\nStates Government.\u003c/p\u003e\n",
    "stargazers_count": 28,
    "subscribers_count": 24,
    "topics": [
      "numerical-weather-prediction",
      "nwp",
      "weather"
    ],
    "updated_at": 1711373293.0
  },
  {
    "data_format": 2,
    "description": "GPU-Enabled, Zero-Copy AMReX Python Bindings including AI/ML",
    "filenames": [
      "docs/spack.yaml"
    ],
    "full_name": "AMReX-Codes/pyamrex",
    "latest_release": "24.03",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003epyAMReX\u003c/h1\u003e\u003ca id=\"user-content-pyamrex\" class=\"anchor\" aria-label=\"Permalink: pyAMReX\" href=\"#pyamrex\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://www.python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pyamrex.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a72575f4cba18887d71f6084dbe806f54cb6f8be5eedbb5e542adbb89e81e956/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f7079616d7265782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/pyamrex/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/AMReX-Codes/pyamrex/discussions\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667\" alt=\"Discussions\" data-canonical-src=\"https://img.shields.io/badge/chat-discussions-turquoise.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/ubuntu.yml/badge.svg?branch=development\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/ubuntu.yml/badge.svg?branch=development\" alt=\"Linux\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/macos.yml/badge.svg?branch=development\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/macos.yml/badge.svg?branch=development\" alt=\"macOS\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/windows.yml/badge.svg?branch=development\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/actions/workflows/windows.yml/badge.svg?branch=development\" alt=\"Windows\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License pyAMReX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.8408733\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cd9d78571166339d2799568898526d14004a42389158e25e813c645cfef06db3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e383430383733332d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.8408733-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe Python binding pyAMReX bridges the compute in AMReX block-structured codes and data science:\nit provides zero-copy application GPU data access for AI/ML, in situ analysis, application coupling and enables rapid, massively parallel prototyping.\npyAMReX enhances the \u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eBlock-Structured AMR Software Framework AMReX\u003c/a\u003e and its applications.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsers\u003c/h2\u003e\u003ca id=\"user-content-users\" class=\"anchor\" aria-label=\"Permalink: Users\" href=\"#users\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003epyAMReX \u003ca href=\"https://pyamrex.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"\u003ecan be installed\u003c/a\u003e with package managers or from source.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUsage\u003c/h3\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease see the \u003ca href=\"https://pyamrex.readthedocs.io/en/latest/usage/how_to_run.html\" rel=\"nofollow\"\u003emanual\u003c/a\u003e and our \u003ca href=\"https://github.com/AMReX-Codes/pyamrex/tree/development/tests\"\u003etest cases\u003c/a\u003e for detailed examples.\u003c/p\u003e\n\u003cp\u003eUse AMReX objects and APIs from Python:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamrex\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003espace3d\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eas\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamr\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003esmall_end\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamr\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eIntVect\u003c/span\u003e()\n\u003cspan class=\"pl-s1\"\u003ebig_end\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamr\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eIntVect\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e3\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e)\n\n\u003cspan class=\"pl-s1\"\u003eb\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamr\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eBox\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003esmall_end\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ebig_end\u003c/span\u003e)\n\u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003eb\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e# ...\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDevelopers\u003c/h2\u003e\u003ca id=\"user-content-developers\" class=\"anchor\" aria-label=\"Permalink: Developers\" href=\"#developers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you are new to CMake, \u003ca href=\"https://hsf-training.github.io/hsf-training-cmake-webpage/\" rel=\"nofollow\"\u003ethis short tutorial\u003c/a\u003e from the HEP Software foundation is the perfect place to get started with it.\u003c/p\u003e\n\u003cp\u003eIf you just want to use CMake to build the project, jump into sections \u003cem\u003e1. Introduction\u003c/em\u003e, \u003cem\u003e2. Building with CMake\u003c/em\u003e and \u003cem\u003e9. Finding Packages\u003c/em\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDependencies\u003c/h3\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003epyAMReX depends on the following popular third party software.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea mature \u003ca href=\"https://en.wikipedia.org/wiki/C%2B%2B17\" rel=\"nofollow\"\u003eC++17\u003c/a\u003e compiler, e.g., GCC 8, Clang 7, NVCC 11.0, MSVC 19.15 or newer\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003eCMake 3.20.0+\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX \u003cem\u003edevelopment\u003c/em\u003e\u003c/a\u003e: we automatically download and compile a copy of AMReX\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11/\"\u003epybind11\u003c/a\u003e 2.11.1+: we automatically download and compile a copy of pybind11 (\u003ca href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\"\u003enew BSD\u003c/a\u003e)\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://python.org\" rel=\"nofollow\"\u003ePython\u003c/a\u003e 3.8+\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://numpy.org\" rel=\"nofollow\"\u003eNumpy\u003c/a\u003e 1.15+\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOptional dependencies include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://mpi4py.readthedocs.io\" rel=\"nofollow\"\u003empi4py\u003c/a\u003e 2.1+: for multi-node and/or multi-GPU execution\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://ccache.dev\" rel=\"nofollow\"\u003eCCache\u003c/a\u003e: to speed up rebuilds (for CUDA support, needs 3.7.9+ and 4.2+ is recommended)\u003c/li\u003e\n\u003cli\u003efurther \u003ca href=\"https://github.com/AMReX-Codes/amrex/\"\u003eoptional dependencies of AMReX\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\u003epandas\u003c/a\u003e 2+: for DataFrame support\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://docs.pytest.org/en/stable/\" rel=\"nofollow\"\u003epytest\u003c/a\u003e 6.2+: for running unit tests\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOptional CUDA-capable dependencies for tests include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/cupy/cupy#installation\"\u003ecupy\u003c/a\u003e 11.2+\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://numba.readthedocs.io/en/stable/user/installing.html\" rel=\"nofollow\"\u003enumba\u003c/a\u003e 0.56+\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://pytorch.org/get-started/locally/\" rel=\"nofollow\"\u003etorch\u003c/a\u003e 1.12+\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstall Dependencies\u003c/h3\u003e\u003ca id=\"user-content-install-dependencies\" class=\"anchor\" aria-label=\"Permalink: Install Dependencies\" href=\"#install-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003emacOS/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate -d \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e spack add cuda\u003c/span\u003e\nspack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(in new terminals, re-activate the environment with \u003ccode\u003espack env activate -d .\u003c/code\u003e again)\u003c/p\u003e\n\u003cp\u003eor macOS/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ebrew update\nbrew install ccache cmake libomp mpi4py numpy open-mpi python\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow, \u003ccode\u003ecmake --version\u003c/code\u003e should be at version 3.20.0 or newer.\u003c/p\u003e\n\u003cp\u003eOr go:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epython3 -m pip install -U pip\npython3 -m pip install -U build packaging setuptools wheel\npython3 -m pip install -U cmake\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you wish to run unit tests, then please install \u003ccode\u003epytest\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epython3 -m pip install -U pytest\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eSome of our tests depend on optional third-party modules (e.g., \u003ccode\u003epandas\u003c/code\u003e, \u003ccode\u003ecupy\u003c/code\u003e, \u003ccode\u003enumba\u003c/code\u003e, and/or \u003ccode\u003epytorch\u003c/code\u003e).\nIf these are not installed then their tests will be skipped.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConfigure your compiler\u003c/h3\u003e\u003ca id=\"user-content-configure-your-compiler\" class=\"anchor\" aria-label=\"Permalink: Configure your compiler\" href=\"#configure-your-compiler\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor example, using the Clang compiler:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CC=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang++\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you also want to select a CUDA compiler:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CUDACXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich nvcc\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CUDAHOSTCXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang++\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild\u003c/h3\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFrom the base of the pyAMReX source directory, execute:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional controls (example):\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_SPACEDIM=3\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_MPI=ON\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_OMP=ON\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_GPU_BACKEND=CUDA\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_SRC=$PWD/../amrex\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport CMAKE_BUILD_PARALLEL_LEVEL=8\u003c/span\u003e\n\npython3 -m pip install -U -r requirements.txt\npython3 -m pip install -v --force-reinstall --no-deps \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you are iterating on builds, it will faster to rely on \u003ccode\u003eccache\u003c/code\u003e and to let CMake call the \u003ccode\u003epip\u003c/code\u003e install logic:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build -DAMReX_SPACEDIM=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e1;2;3\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\ncmake --build build --target pip_install -j 8\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTest\u003c/h3\u003e\u003ca id=\"user-content-test\" class=\"anchor\" aria-label=\"Permalink: Test\" href=\"#test\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAfter successful installation, you can run the unit tests (assuming \u003ccode\u003epytest\u003c/code\u003e is\ninstalled). If \u003ccode\u003eAMREX_MPI=ON\u003c/code\u003e, then please prepend the following commands with \u003ccode\u003empiexec -np \u0026lt;NUM_PROCS\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run all tests\u003c/span\u003e\npython3 -m pytest tests/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run tests from a single file\u003c/span\u003e\npython3 -m pytest tests/test_intvect.py\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run a single test (useful during debugging)\u003c/span\u003e\npython3 -m pytest tests/test_intvect.py::test_iv_conversions\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run all tests, do not capture \"print\" output and be verbose\u003c/span\u003e\npython3 -m pytest -s -vvvv tests/\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eBuild Options\u003c/h3\u003e\u003ca id=\"user-content-build-options\" class=\"anchor\" aria-label=\"Permalink: Build Options\" href=\"#build-options\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you are using the pip-driven install, selected \u003ca href=\"https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake\" rel=\"nofollow\"\u003eAMReX CMake options\u003c/a\u003e can be controlled with environment variables:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eEnvironment Variable\u003c/th\u003e\n\u003cth\u003eDefault \u0026amp; Values\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_OMP\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable OpenMP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_GPU_BACKEND\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eNONE\u003c/strong\u003e/SYCL/CUDA/HIP\u003c/td\u003e\n\u003ctd\u003eOn-node, accelerated GPU backend\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_MPI\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable MPI\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_PRECISION\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eSINGLE/\u003cstrong\u003eDOUBLE\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003ePrecision of AMReX Real type\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_SPACEDIM\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\"1;2;3\"\u003c/td\u003e\n\u003ctd\u003eDimension(s) of AMReX as a \u003ccode\u003e;\u003c/code\u003e-separated list\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_BUILD_SHARED_LIBS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eBuild the core AMReX library as shared library\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_SRC\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eAbsolute path to AMReX source directory (preferred if set)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_REPO\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ehttps://github.com/AMReX-Codes/amrex.git\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository URI to pull and build AMReX from\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_BRANCH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003edevelopment\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository branch for \u003ccode\u003eAMREX_REPO\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_INTERNAL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNeeds a pre-installed AMReX library if set to \u003ccode\u003eOFF\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePYBIND11_INTERNAL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNeeds a pre-installed pybind11 library if set to \u003ccode\u003eOFF\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eCMAKE_BUILD_PARALLEL_LEVEL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003eNumber of parallel build threads\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePYAMREX_LIBDIR\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eIf set, search for pre-built a pyAMReX library\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePYAMREX_CCACHE\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eSearch and use CCache to speed up rebuilds\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePYAMREX_IPO\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eCompile with interprocedural/link optimization (IPO/LTO)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePYINSTALLOPTIONS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eAdditional options for \u003ccode\u003epip install\u003c/code\u003e, e.g., \u003ccode\u003e-v --user\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eFurthermore, pyAMReX adds a few selected CMake build options:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eDefault \u0026amp; Values\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMReX_SPACEDIM\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003e3\u003c/strong\u003e, use \u003ccode\u003e\"1;2;3\"\u003c/code\u003e for all\u003c/td\u003e\n\u003ctd\u003eDimension(s) of AMReX as a \u003ccode\u003e;\u003c/code\u003e-separated list\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_CCACHE\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eSearch and use CCache to speed up rebuilds\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_IPO\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eCompile with interprocedural/link optimization (IPO/LTO)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_INSTALL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eEnable install targets for pyAMReX\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_amrex_src\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eAbsolute path to AMReX source directory (preferred if set)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_amrex_internal\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNeeds a pre-installed AMReX library if set to \u003ccode\u003eOFF\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_amrex_repo\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ehttps://github.com/AMReX-Codes/amrex.git\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository URI to pull and build AMReX from\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_amrex_branch\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003edevelopment\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository branch for \u003ccode\u003epyAMReX_amrex_repo\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_pybind11_src\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eAbsolute path to pybind11 source directory (preferred if set)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_pybind11_internal\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNeeds a pre-installed pybind11 library if set to \u003ccode\u003eOFF\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_pybind11_repo\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ehttps://github.com/pybind/pybind11.git\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository URI to pull and build pybind11 from\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epyAMReX_pybind11_branch\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ev2.11.1\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository branch for \u003ccode\u003epyAMReX_pybind11_repo\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePython_EXECUTABLE\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e(newest found)\u003c/td\u003e\n\u003ctd\u003ePath to Python executable\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eAs one example, one can also build against a local AMReX copy.\nAssuming AMReX\u0027 source is located in \u003ccode\u003e$HOME/src/amrex\u003c/code\u003e, then \u003ccode\u003eexport AMREX_SRC=$HOME/src/amrex\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eOr as a one-liner, assuming your AMReX source directory is located in \u003ccode\u003e../amrex\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eAMREX_SRC=\u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/../amrex python3 -m pip install -v --force-reinstall \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that you need to use absolute paths for external source trees, because pip builds in a temporary directory.\u003c/p\u003e\n\u003cp\u003eOr build against an AMReX feature branch of a colleague.\nAssuming your colleague pushed AMReX to \u003ccode\u003ehttps://github.com/WeiqunZhang/amrex/\u003c/code\u003e in a branch \u003ccode\u003enew-feature\u003c/code\u003e then\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eunset\u003c/span\u003e AMREX_SRC  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e preferred if set\u003c/span\u003e\nAMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3 -m pip install -v --force-reinstall \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can speed up the install further if you pre-install AMReX, e.g. with a package manager.\nSet \u003ccode\u003eAMREX_INTERNAL=OFF\u003c/code\u003e and add installation prefix of AMReX to the environment variable \u003ca href=\"https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html\" rel=\"nofollow\"\u003eCMAKE_PREFIX_PATH\u003c/a\u003e.\nPlease see the \u003ca href=\"#Developers\"\u003eshort CMake tutorial that we linked above\u003c/a\u003e if this sounds new to you.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgements\u003c/h2\u003e\u003ca id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink: Acknowledgements\" href=\"#acknowledgements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis work was supported by the Laboratory Directed Research and Development Program of Lawrence Berkeley National Laboratory under U.S. Department of Energy Contract No. DE-AC02-05CH11231.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright Notice\u003c/h2\u003e\u003ca id=\"user-content-copyright-notice\" class=\"anchor\" aria-label=\"Permalink: Copyright Notice\" href=\"#copyright-notice\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003epyAMReX Copyright (c) 2023, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory, National Renewable Energy\nLaboratory Alliance for Sustainable Energy, LLC and Lawrence Livermore\nNational Security, LLC (subject to receipt of any required approvals from the U.S.\nDept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Intellectual Property Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights.  As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit others to do so.\u003c/p\u003e\n\u003cp\u003eLicense for pyamrex can be found at \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 28,
    "subscribers_count": 16,
    "topics": [
      "amrex",
      "python"
    ],
    "updated_at": 1708120013.0
  },
  {
    "data_format": 2,
    "description": "The d-SEAMS C++ core engine",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "d-SEAMS/seams-core",
    "latest_release": "v1.0.1",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ed-SEAMS\u003c/h1\u003e\u003ca id=\"user-content-d-seams\" class=\"anchor\" aria-label=\"Permalink: d-SEAMS\" href=\"#d-seams\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eDeferred Structural Elucidation Analysis for Molecular Simulations\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml\"\u003e\u003cimg src=\"https://github.com/d-SEAMS/seams-core/actions/workflows/build_pkg.yml/badge.svg\" alt=\"Build Status\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://builtwithnix.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6c587786c40763574c1a811ef06e3c7aa93f0daacec04b672e12243c4b066847/68747470733a2f2f6275696c74776974686e69782e6f72672f62616467652e737667\" alt=\"built with nix\" data-canonical-src=\"https://builtwithnix.org/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCheck our build status \u003ca href=\"https://github.com/d-SEAMS/seams-core/actions/workflows/\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eThe docs themselves are \u003ca href=\"https://docs.dseams.info\" rel=\"nofollow\"\u003ehere\u003c/a\u003e and development is\nongoing \u003ca href=\"https://github.com/d-SEAMS/seams-core\"\u003eon GitHub\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eWe also have \u003ca href=\"https://zenodo.org/communities/d-seams/\" rel=\"nofollow\"\u003ea Zenodo community\u003c/a\u003e for user-contributions like reviews, testimonials\nand tutorials\u003c/li\u003e\n\u003cli\u003eTrajectories are hosted \u003ca href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\" rel=\"nofollow\"\u003eon\nfigshare\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eOur \u003ca href=\"https://wiki.dseams.info\" rel=\"nofollow\"\u003ewiki is here\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\\brief The C++ core of d-SEAMS, a molecular dynamics trajectory analysis engine.\u003c/p\u003e\n\u003cp\u003e\\note The \u003ca href=\"pages.html\"\u003erelated pages\u003c/a\u003e describe the examples and how to obtain\nthe data-sets (trajectories) \u003ca href=\"https://figshare.com/projects/d-SEAMS_Datasets/73545\" rel=\"nofollow\"\u003efrom figshare\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\\warning \u003cstrong\u003eIf\u003c/strong\u003e you are unwilling to use the \u003ccode\u003enix\u003c/code\u003e build system, then \u003cstrong\u003eplease note\u003c/strong\u003e that you must manage the dependencies MANUALLY, including the compiler versions. Optionally, use the provided \u003ccode\u003econda\u003c/code\u003e environment.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCitation\u003c/h1\u003e\u003ca id=\"user-content-citation\" class=\"anchor\" aria-label=\"Permalink: Citation\" href=\"#citation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThis has been published at the \u003ca href=\"https://doi.org/10.1021/acs.jcim.0c00031\" rel=\"nofollow\"\u003eJournal of Chemical Information and Modeling\n(JCIM)\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eYou may also read \u003ca href=\"https://arxiv.org/abs/1909.09830\" rel=\"nofollow\"\u003ethe preprint on arXiv\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you use this software please cite the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eGoswami, R., Goswami, A., \u0026amp; Singh, J. K. (2020). d-SEAMS: Deferred Structural Elucidation Analysis for Molecular Simulations. Journal of Chemical Information and Modeling. https://doi.org/10.1021/acs.jcim.0c00031\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe corresponding \u003ccode\u003ebibtex\u003c/code\u003e entry is:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@Article{Goswami2020,\nauthor={Goswami, Rohit and Goswami, Amrita and Singh, Jayant Kumar},\ntitle={d-SEAMS: Deferred Structural Elucidation Analysis for Molecular Simulations},\njournal={Journal of Chemical Information and Modeling},\nyear={2020},\nmonth={Mar},\nday={20},\npublisher={American Chemical Society},\nissn={1549-9596},\ndoi={10.1021/acs.jcim.0c00031},\nurl={https://doi.org/10.1021/acs.jcim.0c00031}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCompilation\u003c/h1\u003e\u003ca id=\"user-content-compilation\" class=\"anchor\" aria-label=\"Permalink: Compilation\" href=\"#compilation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe use a deterministic build system to generate both bug reports and uniform\nusage statistics. This also handles the \u003ccode\u003elua\u003c/code\u003e scripting engine.\u003c/p\u003e\n\u003cp\u003e\\note The lua functions are documented on the \u003ca href=\"https://docs.dseams.info/md_markdown_luafunctions\" rel=\"nofollow\"\u003eon the API Docs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWe also provide a \u003ccode\u003econda\u003c/code\u003e environment as a fallback, which is also recommended for MacOS users.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuild\u003c/h2\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-label=\"Permalink: Build\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eConda (working now)\u003c/h3\u003e\u003ca id=\"user-content-conda-working-now\" class=\"anchor\" aria-label=\"Permalink: Conda (working now)\" href=\"#conda-working-now\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAlthough we strongly suggest using \u003ccode\u003enix\u003c/code\u003e, for MacOS systems, the following\ninstructions may be more suitable. We will assume the presence of \u003ca href=\"https://mamba.readthedocs.io/en/latest/installation.html\" rel=\"nofollow\"\u003emicromamba\u003c/a\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/seams-core\nmicromamba create -f environment.yml\nmicromamba activate dseams\nluarocks install luafilesystem\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow the installation can proceed.\u003c/p\u003e\n\u003cp\u003e\\note we do not install \u003ccode\u003elua-luafilesystem\u003c/code\u003e within the \u003ccode\u003econda\u003c/code\u003e environment because it is outdated on \u003ccode\u003eosx\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emkdir build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -DCMAKE_INSTALL_PREFIX:PATH=\u003cspan class=\"pl-smi\"\u003e$CONDA_PREFIX\u003c/span\u003e ../\nmake -j\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003enproc\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\nmake install\n\u003cspan class=\"pl-smi\"\u003e$CONDA_PREFIX\u003c/span\u003e/bin/yodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe have opted to install into the \u003ccode\u003econda\u003c/code\u003e environment, if this is not the\nintended behavior, use \u003ccode\u003e/usr/local\u003c/code\u003e instead.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSpack (not working at the moment)\u003c/h3\u003e\u003ca id=\"user-content-spack-not-working-at-the-moment\" class=\"anchor\" aria-label=\"Permalink: Spack (not working at the moment)\" href=\"#spack-not-working-at-the-moment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eManually this can be done in a painful way as follows:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack install eigen@3.3.9 lua@5.2\nspack install catch2 fmt yaml-cpp openblas boost cmake ninja meson\nspack load catch2 fmt yaml-cpp openblas boost cmake ninja meson eigen@3.3.9 lua@5.2\nluarocks install luafilesystem\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOr better:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003epwd\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e After loading the packages\u003c/span\u003e\nluarocks install luafilesystem\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow we can build and install as usual.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build -DCMAKE_BUILD_TYPE=RelWithDebInfo \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=YES -GNinja \\\n -DCMAKE_INSTALL_PREFIX=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/.local \\\n -DCMAKE_CXX_FLAGS=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e-pg -fsanitize=address \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \\\n -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg \\\n -DBUILD_TESTING=NO\ncmake --build build\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOr more reasonably:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e INST_DIR=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/.local\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e src\nmeson setup bbdir --prefix \u003cspan class=\"pl-smi\"\u003e$INST_DIR\u003c/span\u003e\nmeson compile -C bbdir\nmeson install -C bbdir\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e if not done\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PATH=\u003cspan class=\"pl-smi\"\u003e$PATH\u003c/span\u003e:\u003cspan class=\"pl-smi\"\u003e$INST_DIR\u003c/span\u003e/bin\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e LD_LIBRARY_PATH=\u003cspan class=\"pl-smi\"\u003e$LD_LIBRARY_PATH\u003c/span\u003e:\u003cspan class=\"pl-smi\"\u003e$INST_DIR\u003c/span\u003e/lib\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e ../\nyodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eNix (not working at the moment)\u003c/h3\u003e\u003ca id=\"user-content-nix-not-working-at-the-moment\" class=\"anchor\" aria-label=\"Permalink: Nix (not working at the moment)\" href=\"#nix-not-working-at-the-moment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSince this project is built with \u003ccode\u003enix\u003c/code\u003e, we can simply do the following from the\nroot directory (longer method):\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Make sure there are no artifacts\u003c/span\u003e\nrm -rf build\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e This will take a long time the first time as it builds the dependencies\u003c/span\u003e\nnix-build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Optional\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install into your path\u003c/span\u003e\nnix-env -if \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Required\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run the command anywhere\u003c/span\u003e\nyodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eA faster method of building the software is by using the \u003ca href=\"https://dseams.cachix.org/\" rel=\"nofollow\"\u003ecachix binary cache\u003c/a\u003e as shown:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install cachix\u003c/span\u003e\nnix-env -iA cachix -f https://cachix.org/api/v1/install\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Use the binary cache\u003c/span\u003e\ncachix use dseams\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Faster with the cache than building from scratch\u003c/span\u003e\nnix-build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Optional\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install into your path\u003c/span\u003e\nnix-env -if \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Required\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run the command anywhere\u003c/span\u003e\nyodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUsage\u003c/h3\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHaving installed the \u003ccode\u003eyodaStruct\u003c/code\u003e binary and library, we can now use it.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eyodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\\note The paths in the \u003ccode\u003e.yml\u003c/code\u003e should be \u003cstrong\u003erelative to the folder from which the binary is called\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIf you\u0027re confused about how to handle the relative paths, run the command \u003ccode\u003eyodaStruct -c lua_inputs/config.yml\u003c/code\u003e in the top-level directory, and set the paths relative to the top-level directory. This is the convention used in the examples as well.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eLanguage Server Support\u003c/h3\u003e\u003ca id=\"user-content-language-server-support\" class=\"anchor\" aria-label=\"Permalink: Language Server Support\" href=\"#language-server-support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo generate a \u003ccode\u003ecompile_commands.json\u003c/code\u003e file for working with a language server\nlike \u003ca href=\"https://github.com/MaskRay/ccls\"\u003eccls\u003c/a\u003e use the following commands:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Pure environment\u003c/span\u003e\nnix-shell --pure\nmkdir -p build \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=YES ../\ncp compile_commands.json ../\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that there is no need to actually compile the project if you simply need to\nget the compiler database for the language server.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDo Not\u003c/strong\u003e commit the \u003ccode\u003e.json\u003c/code\u003e file.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDevelopment\u003c/h2\u003e\u003ca id=\"user-content-development\" class=\"anchor\" aria-label=\"Permalink: Development\" href=\"#development\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe can simply use the \u003ccode\u003enix\u003c/code\u003e environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e From the project root\u003c/span\u003e\nnix-shell --pure\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eRunning\u003c/h1\u003e\u003ca id=\"user-content-running\" class=\"anchor\" aria-label=\"Permalink: Running\" href=\"#running\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is built completely with nix:\u003c/p\u003e\n\u003cpre lang=\"{bash}\"\u003e\u003ccode\u003e# Install systemwide\nnix-env -if .\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo run the sample inputs, simply install the software, and ensure that \u003ccode\u003einput/\u003c/code\u003e is a child directory.\u003c/p\u003e\n\u003cpre lang=\"{bash}\"\u003e\u003ccode\u003e# Assuming you are in the src directory\n# Check help with -h\nyodaStruct -c lua_inputs/config.yml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTests\u003c/h2\u003e\u003ca id=\"user-content-tests\" class=\"anchor\" aria-label=\"Permalink: Tests\" href=\"#tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eApart from the \u003ca href=\"https://docs.dseams.info/pages.html\" rel=\"nofollow\"\u003eexamples\u003c/a\u003e, the test-suite\ncan be run with the \u003ccode\u003eyodaStruct_test\u003c/code\u003e binary, which will drop into the\n\u003ccode\u003enix\u003c/code\u003e environment before building and executing \u003ccode\u003egdb\u003c/code\u003e:\u003c/p\u003e\n\u003cpre lang=\"{bash}\"\u003e\u003ccode\u003e# Just run this\n./testBuild.sh\n# At this point the binary and library are copied into the root\n# One might, in a foolhardy attempt, use gdb at this point\n# Here be dragons :)\n# USE NIX\n# Anyway\ngdb --args ./yodaStruct -c lua_inputs/config.yml\n# quit gdb with quit\n# Go run the test binary\ncd shellBuild\n./yodaStruct_test\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDo note that the regular installation via \u003ccode\u003enix-env\u003c/code\u003e runs the tests before the installation\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDeveloper Documentation\u003c/h1\u003e\u003ca id=\"user-content-developer-documentation\" class=\"anchor\" aria-label=\"Permalink: Developer Documentation\" href=\"#developer-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\n\u003cp\u003eWhile developing, it is sometimes expedient to update the packages used. It is\nthen useful to note that we use \u003ca href=\"https://github.com/nmattia/niv/\"\u003eniv\u003c/a\u003e to handle our pinned packages (apart from\nthe ones built from Github). Thus, one might need, say:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eniv update nixpkgs -b nixpkgs-unstable\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTest the build with nix:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003enix-build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Outputs are in ./result\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e If you get a CMake error\u003c/span\u003e\nrm -rf build\nnix-store --delete /nix/store/\u003cspan class=\"pl-smi\"\u003e$whatever\u003c/span\u003e \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e $whatever is the derivation complaining\u003c/span\u003e\nnix-collect-garbage \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e then try again [worst case scenario]\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLeaks and performance\u003c/h2\u003e\u003ca id=\"user-content-leaks-and-performance\" class=\"anchor\" aria-label=\"Permalink: Leaks and performance\" href=\"#leaks-and-performance\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWhile testing for leaks, use \u003ccode\u003eclang\u003c/code\u003e (for\n\u003ca href=\"https://github.com/google/sanitizers/wiki/AddressSanitizer\"\u003eAddressSanitizer\u003c/a\u003e\nand\n\u003ca href=\"https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer\"\u003eLeakSanitizer\u003c/a\u003e)\nand the following:\u003c/p\u003e\n\u003cpre lang=\"{bash}\"\u003e\u003ccode\u003e# From the developer shell\nexport CXX=/usr/bin/clang++ \u0026amp;\u0026amp; export CC=/usr/bin/clang\ncmake .. -DCMAKE_CXX_FLAGS=\"-pg -fsanitize=address \" -DCMAKE_EXE_LINKER_FLAGS=-pg -DCMAKE_SHARED_LINKER_FLAGS=-pg\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eOverview\u003c/h1\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAs of Mon Jan 20 15:57:18 2020, the lines of code calculated by\n\u003ca href=\"http://cloc.sourceforge.net/\" rel=\"nofollow\"\u003ecloc\u003c/a\u003e are as follows:\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"images/cloc-2020-01-20_15-56.png\"\u003e\u003cimg src=\"images/cloc-2020-01-20_15-56.png\" alt=\"Cloc Lines\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eContributing\u003c/h1\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease ensure that all contributions are formatted according to the\n\u003ca href=\"./clang-format\"\u003eclang-format\u003c/a\u003e configuration file.\u003c/p\u003e\n\u003cp\u003eSpecifically, consider using the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/rosshemsley/SublimeClangFormat\"\u003eSublime Plugin\u003c/a\u003e for users\nof Sublime Text\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/lassik/emacs-format-all-the-code\"\u003eformat-all\u003c/a\u003e for Emacs\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/rhysd/vim-clang-format\"\u003evim-clang-format\u003c/a\u003e for Vim\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eVisual Studio: \u003ca href=\"http://llvm.org/builds/\" rel=\"nofollow\"\u003ehttp://llvm.org/builds/\u003c/a\u003e, or use the \u003ca href=\"https://blogs.msdn.microsoft.com/vcblog/2018/03/13/clangformat-support-in-visual-studio-2017-15-7-preview-1/\" rel=\"nofollow\"\u003eintegrated support in Visual Studio 2017\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eXcode: \u003ca href=\"https://github.com/travisjeffery/ClangFormat-Xcode\"\u003ehttps://github.com/travisjeffery/ClangFormat-Xcode\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhere some of the above suggestions are derived from \u003ca href=\"https://github.com/andrewseidl/githook-clang-format\"\u003ethis depreciated githook\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAlso, do note that we have a \u003ccode\u003eCONTRIBUTING\u003c/code\u003e file you \u003cstrong\u003eneed to read\u003c/strong\u003e to\ncontribute, for certain reasons, like, common sense.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCommit Hook\u003c/h2\u003e\u003ca id=\"user-content-commit-hook\" class=\"anchor\" aria-label=\"Permalink: Commit Hook\" href=\"#commit-hook\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eNote that we expect compliance with the \u003ccode\u003eclang-format\u003c/code\u003e as mentioned above, and this may be enforced by using the provided scripts for a pre-commit hook:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./scripts/git-pre-commit-format install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis will ensure that new commits are in accordance to the \u003ccode\u003eclang-format\u003c/code\u003e file.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDevelopment Builds\u003c/h2\u003e\u003ca id=\"user-content-development-builds\" class=\"anchor\" aria-label=\"Permalink: Development Builds\" href=\"#development-builds\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe general idea is to drop into an interactive shell with the dependencies and then use \u003ccode\u003ecmake\u003c/code\u003e as usual.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003enix-shell --pure --run bash --show-trace --verbose\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake .. -DCMAKE_BUILD_TYPE=Debug -DNO_WARN=TRUE \\\n -DFIND_EIGEN=TRUE \\\n -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \\\n -G \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eNinja\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\nninja\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Test\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e ../\nyodaStruct -c lua_inputs/config.yml\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Debug\u003c/span\u003e\ngdb --args yodaStruct -c lua_inputs/config.yml\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo load debugging symbols from the shared library, when you are inside \u003ccode\u003egdb\u003c/code\u003e (from the top-level directory, for instance), use the following command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eadd-symbol-file build/libyodaLib.so\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen you can set breakpoints in the C++ code; for instance:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eb seams_input.cpp:408\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eAcknowledgements\u003c/h1\u003e\u003ca id=\"user-content-acknowledgements\" class=\"anchor\" aria-label=\"Permalink: Acknowledgements\" href=\"#acknowledgements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe following tools are used in this project:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://cmake.org/\" rel=\"nofollow\"\u003eCMake\u003c/a\u003e for compilation (\u003ca href=\"https://github.com/cginternals/cmake-init\"\u003ecmake-init\u003c/a\u003e was used as a reference)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://clang.llvm.org/\" rel=\"nofollow\"\u003eClang\u003c/a\u003e because it is more descriptive with better tools\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.doxygen.org\" rel=\"nofollow\"\u003eDoxygen\u003c/a\u003e for the developer API\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://clang.llvm.org/docs/ClangFormat.html\" rel=\"nofollow\"\u003eclang-format\u003c/a\u003e for code formatting\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/barisione/clang-format-hooks\"\u003eclang-format-hooks\u003c/a\u003e for \u003ccode\u003egit\u003c/code\u003e hooks to enforce formatting\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.lua.org\" rel=\"nofollow\"\u003elua\u003c/a\u003e for the scripting engine\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"http://yaml.org/\" rel=\"nofollow\"\u003eyaml\u003c/a\u003e for the configuration\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eThird Party Libraries\u003c/h2\u003e\u003ca id=\"user-content-third-party-libraries\" class=\"anchor\" aria-label=\"Permalink: Third Party Libraries\" href=\"#third-party-libraries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe libraries used are:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/bombela/backward-cpp\"\u003ebackward-cpp\u003c/a\u003e for better stacktraces without \u003ccode\u003egdb\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jarro2783/cxxopts\"\u003ecxxopts\u003c/a\u003e for parsing command line options\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/agauniyal/rang\"\u003erang\u003c/a\u003e for terminal styles (ANSI)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ThePhD/sol2\"\u003esol2\u003c/a\u003e for interfacing with lua\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jbeder/yaml-cpp\"\u003eyaml-cpp\u003c/a\u003e for working with \u003ccode\u003eyaml\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/fmtlib/fmt\"\u003efmt\u003c/a\u003e for safe and fast formatting\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.netlib.org/lapack/\" rel=\"nofollow\"\u003eLinear Algebra PACKage (LAPACK)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.netlib.org/blas/\" rel=\"nofollow\"\u003eBasic Linear Algebra Subprograms (BLAS)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/yixuan/spectra/\"\u003eSpectra\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.boost.org/doc/libs/1_68_0/libs/geometry/doc/html/index.html\" rel=\"nofollow\"\u003eBoost Geometry\u003c/a\u003e for working with different coordinates\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.boost.org/doc/libs/?view=category_math\" rel=\"nofollow\"\u003eBoost Math\u003c/a\u003e for spherical harmonics\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://bitbucket.org/blaze-lib/blaze/\" rel=\"nofollow\"\u003eBlaze\u003c/a\u003e for very fast modern linear algebra\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jlblancoc/nanoflann\"\u003enanoflann\u003c/a\u003e to calculate nearest neighbors\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/renatoGarcia/icecream-cpp\"\u003eicecream-cpp\u003c/a\u003e for pretty-printing and debugging\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 32,
    "subscribers_count": 5,
    "topics": [
      "molecular-dynamics-simulation",
      "molecular-dynamics",
      "trajectory-analysis",
      "lua",
      "nix",
      "d-seams",
      "analysis-framework",
      "trajectories"
    ],
    "updated_at": 1708730598.0
  },
  {
    "data_format": 2,
    "description": "A multi-platform experimentation framework written in python.",
    "filenames": [
      "etc/ramble/defaults/spack.yaml"
    ],
    "full_name": "GoogleCloudPlatform/ramble",
    "latest_release": "v0.4.0",
    "readme": "\u003cp\u003eRamble is a multi-platform experimentation framework to increase exploration\nproductivity and improve reproducibility. Ramble is capable of driving software\ninstallation, acquire input files, configure experiments, and extract results.\nIt works on Linux, macOS, and many supercomputers.\u003c/p\u003e\n\u003cp\u003eRamble can be used to configure a variety of experiments for applications.\nThese can include anything from:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eScientific parameter sweeps\u003c/li\u003e\n\u003cli\u003ePerformance focused scalaing studies\u003c/li\u003e\n\u003cli\u003eCompiler flag sweeps\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo install ramble and configure your experiment workspace, make sure you have\nPython, and Ramble\u2019s dependencies are installed as per the dependency section\nbelow.\nThen:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone -c feature.manyFiles=true https://github.com/GoogleCloudPlatform/ramble.git\n$ cd ramble/bin\n$ ./ramble workspace create -d test_workspace -c ../examples/basic_hostname_config.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRamble\u2019s python dependencies can be installed using the included requirements.txt file.\u003c/p\u003e\n\u003cp\u003ee.g.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ pip install -r requirements.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe recommend Python \u0026gt;= 3.7 for Ramble, but a best effort attempt is made to\nsupport Python 3.6 as it is used by older operating systems such as Centos7.\nSpecifically, you might need to update \u003ccode\u003epip\u003c/code\u003e and downgrade \u003ccode\u003eprotobuf\u003c/code\u003e when\nusing Python 3.6.\u003c/p\u003e\n\u003cp\u003eOutside of these requirements, ramble requires an existing installation of\nspack for some application definition. See\n\u003ca href=\"https://github.com/spack/spack#-spack\"\u003eSpack\u2019s documentation\u003c/a\u003e to install Spack.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRamble\u2019s documentation can be viewed at\n\u003ca href=\"https://googlecloudplatform.github.io/ramble/\" rel=\"nofollow\"\u003ehttps://googlecloudplatform.github.io/ramble/\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor help with Ramble\u2019s commands, run \u003ccode\u003eramble help\u003c/code\u003e or \u003ccode\u003eramble help --all\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor more information on concepts in Ramble, see Ramble\u2019s\n\u003ca href=\"./lib/ramble/docs/getting_started.rst\"\u003eGetting Started\u003c/a\u003e guide.\u003c/p\u003e\n\u003cp\u003eExample configuration files are also contained in the\n\u003ca href=\"./examples\"\u003eexamples\u003c/a\u003e directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCommunity\u003c/h2\u003e\u003ca id=\"user-content-community\" class=\"anchor\" aria-label=\"Permalink: Community\" href=\"#community\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRamble is an open source project.  Questions, discussion, and\ncontributions are welcome. Contributions can be anything from new\npackages to bugfixes, documentation, or even new core features.\u003c/p\u003e\n\u003cp\u003eResources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/GoogleCloudPlatform/ramble/discussions\"\u003e\u003cstrong\u003eGithub Discussions\u003c/strong\u003e\u003c/a\u003e: not just for discussions, also Q\u0026amp;A.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eContributing to Ramble is relatively easy.  Just send us a\n\u003ca href=\"https://help.github.com/articles/using-pull-requests/\"\u003epull request\u003c/a\u003e.\nWhen you send your request, make \u003ccode\u003edevelop\u003c/code\u003e the destination branch on the\n\u003ca href=\"https://github.com/GoogleCloudPlatform/ramble\"\u003eRamble repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eYour PR must pass Ramble\u0027s unit tests and documentation tests, and must be\n\u003ca href=\"https://www.python.org/dev/peps/pep-0008/\" rel=\"nofollow\"\u003ePEP 8\u003c/a\u003e compliant.  We enforce\nthese guidelines with our CI process.\u003c/p\u003e\n\u003cp\u003eThese tests can be run locally through test runners in the share/ramble/qa/\ndirectory. Alternatively, \u003ca href=\"https://pre-commit.com/#install\" rel=\"nofollow\"\u003epre-commit\u003c/a\u003e can be\nused to manage our git hooks. To install the hooks, simply run:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epre-commit install\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor additional requirements about contributing, including Google\u2019s CLA, see our\n\u003ca href=\".github/CONTRIBUTING.md\"\u003eContribution Guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eRamble\u0027s \u003ccode\u003edevelop\u003c/code\u003e branch has the latest contributions. Pull requests\nshould target \u003ccode\u003edevelop\u003c/code\u003e, and users who want the latest package versions,\nfeatures, etc. can use \u003ccode\u003edevelop\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eReleases\u003c/h2\u003e\u003ca id=\"user-content-releases\" class=\"anchor\" aria-label=\"Permalink: Releases\" href=\"#releases\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eEach Ramble release series also has a corresponding branch, e.g.\n\u003ccode\u003ereleases/v0.1\u003c/code\u003e has \u003ccode\u003e0.1.x\u003c/code\u003e versions of Ramble, and \u003ccode\u003ereleases/v0.2\u003c/code\u003e has\n\u003ccode\u003e0.2.x\u003c/code\u003e versions. We backport important bug fixes to these branches but\nwe do not advance the application definitions or make other changes that would\nchange the way experiments Ramble would create within a release branch.\nSo, you can base your Ramble deployment on a release branch subsequent updates\ncan be considered non-breaking.\u003c/p\u003e\n\u003cp\u003eThe latest release is always available with the \u003ccode\u003ereleases/latest\u003c/code\u003e tag.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCode of Conduct\u003c/h2\u003e\u003ca id=\"user-content-code-of-conduct\" class=\"anchor\" aria-label=\"Permalink: Code of Conduct\" href=\"#code-of-conduct\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease note that Ramble has a\n\u003ca href=\".github/CODE_OF_CONDUCT.md\"\u003e\u003cstrong\u003eCode of Conduct\u003c/strong\u003e\u003c/a\u003e. By participating in\nthe Ramble community, you agree to abide by its rules.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMany thanks go to Ramble\u0027s \u003ca href=\"https://github.com/GoogleCloudPlatform/ramble/graphs/contributors\"\u003econtributors\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eRamble was created by Doug Jacobsen, \u003ca href=\"mailto:dwjacobsen@google.com\"\u003edwjacobsen@google.com\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis software is distributed under the terms of both the MIT license and the\nApache License (Version 2.0).\u003c/p\u003e\n\u003cp\u003eSee LICENSE for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n",
    "stargazers_count": 33,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1712008588.0
  },
  {
    "data_format": 2,
    "description": "The Canadian Hydrological Model",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "Chrismarsh/CHM",
    "latest_release": "1.3.0",
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/dev/docs/images/mesh.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eThe Canadian Hydrological Model\u003c/h1\u003e\u003ca id=\"user-content-the-canadian-hydrological-model\" class=\"anchor\" aria-label=\"Permalink: The Canadian Hydrological Model\" href=\"#the-canadian-hydrological-model\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Canadian Hydrological Model (CHM) is a novel modular unstructured mesh based approach for hydrological modelling. It can move between spatial scale, temporal scale, and spatial extents. It is designed for developing and testing process representations for hydrological models.\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#motivation\"\u003eMotivation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#design-goals\"\u003eDesign goals\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#publications\"\u003ePublications\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#features\"\u003eFeatures\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#spatial-scales\"\u003eSpatial Scales\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#visualization\"\u003eVisualization\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#netcdf-support\"\u003enetCDF support\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#process-representations\"\u003eProcess representations\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#unstructured-mesh\"\u003eUnstructured mesh\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#parallel-computing\"\u003eParallel computing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#uncertainty-analysis\"\u003eUncertainty analysis\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#demonstration\"\u003eDemonstration\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#snowcast\"\u003eSnowCast\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#large-extent\"\u003eLarge extent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#point-scale\"\u003ePoint scale\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#blowing-snow\"\u003eBlowing snow\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUsage\u003c/h1\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDetails on how to use CHM, as well as more implimentation details, can be found in the \u003ca href=\"https://chm.readthedocs.io/en/dev/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eMotivation\u003c/h1\u003e\u003ca id=\"user-content-motivation\" class=\"anchor\" aria-label=\"Permalink: Motivation\" href=\"#motivation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eModelling of hydrological processes at any scale is hampered by large uncertainties in parameters and forcing data, incomplete process representations (the scientific conceptualization of a phenomena codified numerically), and arbitrary process representation selections and linkages (collectively \u2018model structure\u2019). There is also consistent difficulty or an inability to easily test and estimate the uncertainty due to variations in model structure, parameter values, number of parameters, forcing data requirements, and spatial discretization requirements (collectively \u2018model complexity\u2019).\u003c/p\u003e\n\u003cp\u003eIn this work, a new distributed model framework is presented that can examine a variety of process representations, process linkages and levels of model complexity. Algorithms can be easily interchanged, removed, and decoupled while preserving the underlying model framework. Thus, uncertainty propagation and subsequent feedbacks within the model structure can be quantified. Unstructured meshes represent the spatial heterogeneity of surface and sub-surface features in a computationally efficient manner and also decreases number of parameters and initial conditions. The parallel architecture allows for efficient uncertainty testing of parameter ranges. By utilizing unstructured meshes, fewer than 5% of the computational elements of high-resolution structured (raster) grids are usually necessary.  This preserves surface and sub-surface heterogeneity but results in fewer parameters and initial conditions.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDesign goals\u003c/h1\u003e\u003ca id=\"user-content-design-goals\" class=\"anchor\" aria-label=\"Permalink: Design goals\" href=\"#design-goals\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eMulti-scale, multi-physics, variable complexity and domain model\u003c/li\u003e\n\u003cli\u003eAssessment of model structural, parameter, and data uncertainty\u003c/li\u003e\n\u003cli\u003eEasily test multiple hypotheses, avoid rigid model structures\u003c/li\u003e\n\u003cli\u003eIncorporate existing code\u003c/li\u003e\n\u003cli\u003eContribute to decision support systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003ePublications\u003c/h1\u003e\u003ca id=\"user-content-publications\" class=\"anchor\" aria-label=\"Permalink: Publications\" href=\"#publications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe following publications provide an overview of CHM and its capabilities\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eV. Vionnet, Marsh, C.B., B. Menounos, S. Gascoin, N.E. Wayand, J. Shea, K. Mukherjee, and J.W. Pomeroy. Multi-scale snowdrift-permitting modelling of mountain snowpack. The Cryosphere Discussions, 2020:1--43, 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B., J.W. Pomeroy, and H.S. Wheater. The Canadian Hydrological Model (CHM) v1.0: a multi-scale, multi-extent, variable-complexity hydrological model \u2013 design and overview. Geoscientific Model Development, 13(1):225--247, 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B, J. W. Pomeroy, R.J. Spiteri, and H.S Wheater. A Finite Volume Blowing Snow Model for Use With Variable Resolution Meshes. Water Resources Research, 56(2), 2020.\u003c/li\u003e\n\u003cli\u003eMarsh, C.B, R. J. Spiteri, J.W. Pomeroy, and H.S. Wheater. Multi-objective unstructured triangular mesh generation for use in hydrological and land surface models. Computers \u0026amp; Geosciences, 119:49--67, 2018.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eFeatures\u003c/h1\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink: Features\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSpatial Scales\u003c/h2\u003e\u003ca id=\"user-content-spatial-scales\" class=\"anchor\" aria-label=\"Permalink: Spatial Scales\" href=\"#spatial-scales\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCHM is applicable to multiple scales from the basin scale, to the provincial/state scale and beyond. It may also be applied at a single point-scale.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/scale.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVisualization\u003c/h2\u003e\u003ca id=\"user-content-visualization\" class=\"anchor\" aria-label=\"Permalink: Visualization\" href=\"#visualization\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOutput is in the vtu file format, allowing for visualization, analysis, and timeseries animation in \u003ca href=\"https://www.paraview.org/\" rel=\"nofollow\"\u003eParaView\u003c/a\u003e. Date-time support has been added to ParaView via an filter \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\"\u003e\u003cimg src=\"https://github.com/Chrismarsh/vtk-paraview-datetimefilter\" alt=\"vtk-paraview-datetimefilter\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/paraview.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003enetCDF support\u003c/h2\u003e\u003ca id=\"user-content-netcdf-support\" class=\"anchor\" aria-label=\"Permalink: netCDF support\" href=\"#netcdf-support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInput meterology may be either in a standard ASCII file, or as a netCDF file allowing for ease of use when using climate model outputs.\u003c/p\u003e\n\u003cp\u003eThe below figure shows virtual stations that correspond to the center of the 2.5 km GEM numerical weather prediction output in netCDF format.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/netcdf.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eProcess representations\u003c/h2\u003e\u003ca id=\"user-content-process-representations\" class=\"anchor\" aria-label=\"Permalink: Process representations\" href=\"#process-representations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eProcess represetenation will be extented to include the entirety of the hydrological cycle. However, current representation includes mostly surface and cold regions processes\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eProcess\u003c/th\u003e\n\u003cth\u003eModule\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCanopy\u003c/td\u003e\n\u003ctd\u003eOpen/forest (exp/log) (Pomeroy et al., 1998; Ellis et al., 2010)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSnowpack\u003c/td\u003e\n\u003ctd\u003e2-layer Snobal (Marks et al, 1999); Multi-layer Snowpack (Lehning et al., 1999); Various albedo e.g., CLASS (Verseghy 1991)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSoil\u003c/td\u003e\n\u003ctd\u003eFrozen soil infiltration (Gray et al., 2001)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMass redistribution\u003c/td\u003e\n\u003ctd\u003ePBSM3D (Marsh et al, 2018 in review); Snowslide (Bernhardt 2010)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eInput meterology is spatially interpolated and down-scaled from the input station or virtual-station (e.g., from numerical weather prediction) to produce a spatially distributed driving dataset. There are a number of ways to downscale these meterology.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eVariable\u003c/th\u003e\n\u003cth\u003eType\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eAir temperature\u003c/td\u003e\n\u003ctd\u003eLinear lapse rates (measured, seasonal, constant, neutral stability) (Kunkel, 1989, Dodson et al., 1997)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRelative humidity\u003c/td\u003e\n\u003ctd\u003eLinear lapse rates (measured, seasonal, constant) (Kunkel, 1989)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHorizontal wind\u003c/td\u003e\n\u003ctd\u003eTopographic curvature (Liston, et al., 2006); Mason-Sykes (Mason and Sykes, 1979); uniform wind\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePrecipitation\u003c/td\u003e\n\u003ctd\u003eElevation based lapse (Thornton, 1997)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePrecipitation Phase\u003c/td\u003e\n\u003ctd\u003eLinear; Psychometric (Harder and Pomeroy, 2013); Threshold\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSolar radiation\u003c/td\u003e\n\u003ctd\u003eTerrain shadows (Marsh et al., 2011, Dozier and Frew, 1990); Clear sky transmittance (Burridge, 1975); Transmittance from observations; Cloud fraction estimates (Walcek, 1994); Direct/diffuse splitting (Iqbal, 19xx)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLongwave\u003c/td\u003e\n\u003ctd\u003eT, RH based (Sicart et al., 2006); Constant (Marty et al., 2002)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUnstructured mesh\u003c/h2\u003e\u003ca id=\"user-content-unstructured-mesh\" class=\"anchor\" aria-label=\"Permalink: Unstructured mesh\" href=\"#unstructured-mesh\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCHM uses an unstructured triangular mesh to representent the terrain. This mesh is generated by \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/Chrismarsh/mesher\"\u003e\u003cimg src=\"https://github.com/Chrismarsh/mesher\" alt=\"Mesher\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e, a novel multi-objective unstructured mesh generation software that allows mesh generation to be generated from an arbitrary number of hydrologically important features while maintaining a variable spatial resolution. Triangle quality is guaranteed as well as a smooth graduation from small to large triangles. Including these additional features resulted in a better representation of spatial heterogeneity versus classic topography-only mesh generation while significantly reducing the total number of computational elements.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/mesher/master/images/mesh.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eParallel computing\u003c/h2\u003e\u003ca id=\"user-content-parallel-computing\" class=\"anchor\" aria-label=\"Permalink: Parallel computing\" href=\"#parallel-computing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIn CHM, parallelism is currently implemented via the shared memory API OpenMP. As described above, modules may either be point-scale models that are applied to each triangle independently or require knowledge of the surrounding triangles. Mixing these two types of parallelism complicates the implementation of parallel code. To provide as much seamless parallelism as possible to the modules, each module declares the type of algorithm it is: data parallel or domain parallel. Data parallel modules are point-scale models that are applied to every triangle. Domain parallel modules are modules that require knowledge of surrounding mesh points. Thus, after the topological sort is performed to determine module execution order, the modules are scheduled together into groups that share a parallelism type\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUncertainty analysis\u003c/h2\u003e\u003ca id=\"user-content-uncertainty-analysis\" class=\"anchor\" aria-label=\"Permalink: Uncertainty analysis\" href=\"#uncertainty-analysis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA key feature of CHM is the ability to, on the command line, change any value specified by a configuration parameter. CHM provides a seamless mechanism to easily allow modules to obtain parameter data from configuration files.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003esubprocess\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eshutil\u003c/span\u003e\n\n\n\u003cspan class=\"pl-s1\"\u003eprj_path\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"CHM.config\"\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003ecf1\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.VistaView.file:vv_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf2\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.UpperClearing.file:uc_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf3\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"-c output.FiserraRidge.file:fr_dodson.txt\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003ecf4\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\"--add-module Dodson_NSA_ta\"\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003esubprocess\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003echeck_call\u003c/span\u003e([\u003cspan class=\"pl-s\"\u003e\u0027./CHM %s %s %s %s %s\u0027\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e%\u003c/span\u003e (\u003cspan class=\"pl-s1\"\u003eprj_path\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf1\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf2\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ecf3\u003c/span\u003e,\u003cspan class=\"pl-s1\"\u003ecf4\u003c/span\u003e)], \u003cspan class=\"pl-s1\"\u003eshell\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e\u003cspan class=\"pl-c1\"\u003eTrue\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDemonstration\u003c/h1\u003e\u003ca id=\"user-content-demonstration\" class=\"anchor\" aria-label=\"Permalink: Demonstration\" href=\"#demonstration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSnowCast\u003c/h2\u003e\u003ca id=\"user-content-snowcast\" class=\"anchor\" aria-label=\"Permalink: SnowCast\" href=\"#snowcast\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"http://www.snowcast.ca\" rel=\"nofollow\"\u003eSnowCast\u003c/a\u003e is an experimental, daily data product that uses the Global Environmental Multiscale (GEM) model forecasts from Environment and Climate Change Canada (ECCC) to drive the Canadian Hydrological Model (CHM). Estimates of snowpack are provided over the a Bow River Basin, centered over Banff, Canada.\u003c/p\u003e\n\u003cp\u003eSnowCast is developed as part of \u003ca href=\"https://gwf.usask.ca/\" rel=\"nofollow\"\u003eGlobal Water Futures\u003c/a\u003e and the \u003ca href=\"https://www.usask.ca/hydrology/\" rel=\"nofollow\"\u003eCentre for Hydrology\u003c/a\u003e, University of Saskatchewan.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLarge extent\u003c/h2\u003e\u003ca id=\"user-content-large-extent\" class=\"anchor\" aria-label=\"Permalink: Large extent\" href=\"#large-extent\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHourly solar radiation modelling for the territory of Yukon, Canada.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/yk_solar.gif\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePoint scale\u003c/h2\u003e\u003ca id=\"user-content-point-scale\" class=\"anchor\" aria-label=\"Permalink: Point scale\" href=\"#point-scale\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eComparison of CHM driving Snobal and Snowpack at the Upper Clearing site at Marmot Creek Research Basin in Alberta, Canada\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/CHM_crhm_v_chm_v_obs_swe.png\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBlowing snow\u003c/h2\u003e\u003ca id=\"user-content-blowing-snow\" class=\"anchor\" aria-label=\"Permalink: Blowing snow\" href=\"#blowing-snow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBlowing snow for a small sub-basin of Wolf Creek Reserach Basin, located in the Yukon, Canada.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/Chrismarsh/CHM/master/wiki/output_small.gif\" alt=\"\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 36,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1710834006.0
  },
  {
    "data_format": 2,
    "description": "Standalone Spack Tutorial Repository",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "spack/spack-tutorial",
    "latest_release": "sc23",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/47a9107684d07b99a6f0bd5faae9666346330a6555e2a08271979b6f4b9c677f/68747470733a2f2f63646e2e7261776769742e636f6d2f737061636b2f737061636b2f646576656c6f702f73686172652f737061636b2f6c6f676f2f737061636b2d6c6f676f2e737667\" width=\"64\" valign=\"middle\" alt=\"Spack\" data-canonical-src=\"https://cdn.rawgit.com/spack/spack/develop/share/spack/logo/spack-logo.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e Spack Tutorial\u003c/h1\u003e\u003ca id=\"user-content--spack-tutorial\" class=\"anchor\" aria-label=\"Permalink:  Spack Tutorial\" href=\"#-spack-tutorial\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://spack-tutorial.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cc15a98bdbe77c2664a8d15480c99dd7372c06ce4afabe1571236cb260e94717/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f737061636b2d7475746f7269616c2f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/spack-tutorial/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSpack is a multi-platform package manager that builds and installs multiple versions and configurations of software. It works on Linux, macOS, and many supercomputers. Spack is non-destructive: installing a new version of a package does not break existing installations, so many configurations of the same package can coexist.\u003c/p\u003e\n\u003cp\u003eThis repository houses Spack\u0027s \u003ca href=\"https://spack-tutorial.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003e\u003cstrong\u003ehands-on tutorial\u003c/strong\u003e\u003c/a\u003e, which is a subset of Spack\u0027s \u003ca href=\"https://spack.readthedocs.io/\" rel=\"nofollow\"\u003e\u003cstrong\u003efull documentation\u003c/strong\u003e\u003c/a\u003e (or you can run \u003ccode\u003espack help\u003c/code\u003e or \u003ccode\u003espack help --all\u003c/code\u003e).\u003c/p\u003e\n\u003cp\u003eThis tutorial covers basic to advanced usage, packaging, developer features, and large HPC deployments.  You can do all of the exercises on your own laptop using a Docker container. Feel free to use these materials to teach users at your organization about Spack.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUpdating the tutorial\u003c/h2\u003e\u003ca id=\"user-content-updating-the-tutorial\" class=\"anchor\" aria-label=\"Permalink: Updating the tutorial\" href=\"#updating-the-tutorial\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eCreate a new branch named for the event/milestone that corresponds to the new version you want to create.\u003c/li\u003e\n\u003cli\u003eUpload screen shot of first slide (244px wide, .png) to \u003ca href=\"https://github.com/spack/spack-tutorial/tree/master/tutorial/images\"\u003eimages directory\u003c/a\u003e following existing file-naming convention.\u003c/li\u003e\n\u003cli\u003eUpload PDF of slide deck to \u003ca href=\"https://github.com/spack/spack-tutorial/tree/master/_static/slides\"\u003eslides directory\u003c/a\u003e following existing file-naming convention.\u003c/li\u003e\n\u003cli\u003eUpdate \u003ca href=\"https://github.com/spack/spack-tutorial/blob/master/index.rst\"\u003eindex.rst\u003c/a\u003e with event name and date; full citation; and file paths for image and PDF.\u003c/li\u003e\n\u003cli\u003eUpdate this README (lines 3 and 7) with link to new version\u0027s URL.\u003c/li\u003e\n\u003cli\u003eBuild docs locally.\u003c/li\u003e\n\u003cli\u003ePush changes to GitHub and active new tag/version on Read the Docs.\u003c/li\u003e\n\u003cli\u003eBuild new version on Read the Docs.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUpdating the tutorial container\u003c/h2\u003e\u003ca id=\"user-content-updating-the-tutorial-container\" class=\"anchor\" aria-label=\"Permalink: Updating the tutorial container\" href=\"#updating-the-tutorial-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Spack tutorial container is automatically built from \u003ca href=\"docker/Dockerfile\"\u003erepository\u003c/a\u003e by \u003ca href=\".github/workflows/containers.yaml\"\u003ethis GitHub action\u003c/a\u003e. The latest version is available at\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eghcr.io/spack/tutorial:latest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand is rebuilt on a schedule. It can also be \u003ca href=\"https://github.com/spack/spack-tutorial/actions\"\u003etriggered manually\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe tutorial image builds on top of the container image that runs in Spack CI, which is built in a different repository at \u003ca href=\"https://github.com/spack/gitlab-runners/\"\u003espack/gitlab-runners\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAutomatically generating command ouputs\u003c/h2\u003e\u003ca id=\"user-content-automatically-generating-command-ouputs\" class=\"anchor\" aria-label=\"Permalink: Automatically generating command ouputs\" href=\"#automatically-generating-command-ouputs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe tutorial \u003ccode\u003erst\u003c/code\u003e files include output from Spack commands. This process is automated, and it is\nrecommended not to run commands manually.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote:\u003c/strong\u003e as a preliminary step, check your terminal width. All current outputs\nare generated on a fixed terminal width \u003cstrong\u003e94\u003c/strong\u003e; deviating from that can cause\nunnecessarily large diffs:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003etput cols\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e94\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo regenerate the outputs, run:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emake -C outputs -j \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eN\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis runs each \u003ccode\u003eoutputs/\u0026lt;section\u0026gt;.sh\u003c/code\u003e script in parallel in a container, and collects outputs in\n\u003ccode\u003eoutputs/raw/*\u003c/code\u003e. When all complete succesfully, the outputs are post-processed and put in\n\u003ccode\u003eoutputs/\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIn case you want to restrict to particular sections, or if you need to modify the container\nexecutable and flags, specify those as variables in \u003ccode\u003eoutputs/Make.user\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-makefile\"\u003e\u003cpre\u003e\u003cspan class=\"pl-smi\"\u003esections\u003c/span\u003e := basics scripting\n\u003cspan class=\"pl-smi\"\u003eDOCKER\u003c/span\u003e := sudo docker\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003emake\u003c/code\u003e will regenerate the relevant outputs when \u003ccode\u003eoutputs/\u0026lt;section\u0026gt;.sh\u003c/code\u003e files are modified.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eTo start from scratch, run \u003ccode\u003emake clean\u003c/code\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003emake run-\u0026lt;tab\u0026gt;\u003c/code\u003e can also be used to regenerate a particular section, but notice it will only\ncreate raw outputs.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the Apache License (Version 2.0). Users may choose either license, at their option.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0 licenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack/blob/develop/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack/blob/develop/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack/blob/develop/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack/blob/develop/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 40,
    "subscribers_count": 38,
    "topics": [
      "tutorial"
    ],
    "updated_at": 1710667031.0
  },
  {
    "data_format": 2,
    "description": "Software interfaces for interacting with brain atlases - Python client",
    "filenames": [
      ".ebrains/spack/siibra-spack.yaml"
    ],
    "full_name": "FZJ-INM1-BDA/siibra-python",
    "latest_release": null,
    "stargazers_count": 44,
    "subscribers_count": 8,
    "topics": [
      "brain",
      "atlas",
      "neuroscience",
      "bigbrain",
      "bigbrainproject",
      "humanbrainproject"
    ],
    "updated_at": 1699439990.0
  },
  {
    "data_format": 2,
    "description": "High-performance power grid optimization for stochastic, security-constrained, and multi-period ACOPF problems.",
    "filenames": [
      "buildsystem/spack/ascent/spack.yaml",
      "buildsystem/spack/summit/spack.yaml",
      "buildsystem/container/spack.yaml"
    ],
    "full_name": "pnnl/ExaGO",
    "latest_release": "v1.6.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003cb\u003eExa\u003c/b\u003escale \u003cb\u003eG\u003c/b\u003erid \u003cb\u003eO\u003c/b\u003eptimization toolkit (ExaGO\u003csup\u003eTM\u003c/sup\u003e) \u003ca href=\"https://github.com/pre-commit/pre-commit\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a8cba9888a55d8a038324b73da057a30a40f34b0eae64c2f93196d5d837df1bd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7072652d2d636f6d6d69742d656e61626c65642d627269676874677265656e3f6c6f676f3d7072652d636f6d6d6974\" alt=\"pre-commit\" data-canonical-src=\"https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\"\u003e\u003cimg src=\"https://github.com/pnnl/ExaGO/actions/workflows/pnnl_mirror.yaml/badge.svg\" alt=\"PNNL GitLab Push Mirror\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\"\u003e\u003cimg src=\"https://github.com/pnnl/ExaGO/actions/workflows/ornl_ascent_mirror.yaml/badge.svg\" alt=\"ORNL Ascent GitLab Push Mirror\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\"\u003e\u003cimg src=\"https://github.com/pnnl/ExaGO/actions/workflows/pre_commit.yaml/badge.svg?event=pull_request\" alt=\"pre-commit GitHub Action\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\"\u003e\u003cimg src=\"https://github.com/pnnl/ExaGO/actions/workflows/spack_cpu_build.yaml/badge.svg?event=pull_request\" alt=\"Spack CPU Build\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/h1\u003e\u003ca id=\"user-content-exascale-grid-optimization-toolkit-exagotm-----\" class=\"anchor\" aria-label=\"Permalink: Exascale Grid Optimization toolkit (ExaGO) \" href=\"#exascale-grid-optimization-toolkit-exagotm-----\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"viz/images/network_gen_load_us.png\"\u003e\u003cimg src=\"viz/images/network_gen_load_us.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"docs/manual/figures/three_in_one.png\"\u003e\u003cimg src=\"docs/manual/figures/three_in_one.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eExaGO\u003csup\u003eTM\u003c/sup\u003e is a package for solving large-scale  power grid optimization problems on parallel and distributed architectures, particularly targeted for exascale machines with heteregenous architectures (GPU). Combinations of stochastic, contingency-constrained, multiperiod ACOPF problems can be solved with ExaGO. The package is written in C/C++ with python bindings available for python-based applications. An overview of the package is given on this page. For extended information, including the modeling details and formulations, see the \u003ca href=\"docs/manual/manual.pdf\"\u003eExaGO manual\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eExaGO\u003csup\u003eTM\u003c/sup\u003e includes the following applications for solving different power grid optimization problems:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/opflow.md\"\u003eOPFLOW\u003c/a\u003e solves an AC optimal power flow either on CPU and GPU\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/tcopflow.md\"\u003eTCOPFLOW\u003c/a\u003e solves a multi-period optimal power flow\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/scopflow.md\"\u003eSCOPFLOW\u003c/a\u003e solves a security-constrained (contingency-constrained) optimal power. Both single-period and multi-period problems can be solved.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/sopflow.md\"\u003eSOPFLOW\u003c/a\u003e solves a stochastic optimal power flow with (optional) security constraints for single and multiple periods.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExaGO\u003csup\u003eTM\u003c/sup\u003e applications are interfaced with the following optimization solver packaages:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/coin-or/Ipopt\"\u003eIpopt\u003c/a\u003e is a popular optimization package for solving nonlinear optimization problems that uses an interior-point algorithm.\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/LLNL/hiop\"\u003eHiOp\u003c/a\u003e is a HPC package for optimization. ExaGO interfaces with two of its solvers -- a mixed sparse-dense interior-point solver (NewtonMDS) and a sparse interior-point solver (HiOPSparse). NewtonMDS  allows execution of the optimization either on CPU and GPU. The sparse HiOp solver is currently supported on CPU only.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNote that not all applications can utilize all solvers yet. The following table lists the solver-application compatibility.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"center\"\u003eSolver\u003c/th\u003e\n\u003cth align=\"center\"\u003eOPFLOW\u003c/th\u003e\n\u003cth align=\"center\"\u003eTCOPFLOW\u003c/th\u003e\n\u003cth align=\"center\"\u003eSCOPLOW\u003c/th\u003e\n\u003cth align=\"center\"\u003eSOPFLOW\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003eIpopt\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"center\"\u003eHiOp\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003ctd align=\"center\"\u003eY\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eAdditionally, note that SCOPFLOW and SOPFLOW with HiOp solver use Ipopt to solve a portion of the problem (base problem). So one must also configure with Ipopt when using HiOp solver for these applications.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstalling\u003c/h2\u003e\u003ca id=\"user-content-installing\" class=\"anchor\" aria-label=\"Permalink: Installing\" href=\"#installing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eDetails installation instructions are given at \u003ca href=\"./INSTALL.md\"\u003eINSTALL.md\u003c/a\u003e for information on acquiring, building and installing ExaGO.\u003c/p\u003e\n\u003cp\u003eIf you are a developer with access to the project, we also provide public binaries that are generated through our GitHub actions workflows documented in \u003ca href=\".github/workflows/README.md\"\u003eREADME.md\u003c/a\u003e, and with documentation about usage in the packages section of our repository. Check out a short (\u0026lt; 60s demo) of pulling down a version of ExaGO:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/036a31e6b78284e2773e8c365f25415ca9f4d6c5bf012a91311694943e2c6cda/68747470733a2f2f61736369696e656d612e6f72672f612f4b436935546d555863367a57446a374a59487a665346786d772e706e67\" alt=\"asciicast\" data-canonical-src=\"https://asciinema.org/a/KCi5TmUXc6zWDj7JYHzfSFxmw.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDeveloper Guide\u003c/h2\u003e\u003ca id=\"user-content-developer-guide\" class=\"anchor\" aria-label=\"Permalink: Developer Guide\" href=\"#developer-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can view the following helpful documentation sources:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/test_add.md\"\u003etest_add.md\u003c/a\u003e markdown file for information on adding tets (outdated)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"buildsystem/README.md\"\u003eREADME.md\u003c/a\u003e for our bash / spack buildsystem used in GitHub/GitLab CI/CD\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"buildsystem/spack/README.md\"\u003eREADME.md\u003c/a\u003e for our spack specific build scripts that support CI tcl modules on HPC target platforms\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/devcontainer/README.md\"\u003eREADME.md\u003c/a\u003e for our devcontianer configuration information (codespace support coming soon)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/exago_policy_compatibility.md\"\u003eexago_policy_compatiblility\u003c/a\u003e for xSDK compatibility guidelines, and ways to enforce compliance\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/python_bindings.md\"\u003epython_bindings.md\u003c/a\u003e for documentation about or Python bindings\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"performance_analysis/README.md\"\u003eREADME.md\u003c/a\u003e for information about profiling ExaGO with spack\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\".github/workflows/README.md\"\u003eREADME.md\u003c/a\u003e for details about our GitHub actions\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/README.ci_clusters.md\"\u003eREADME.ci_clusters.md\u003c/a\u003e for CI cluster workflow documentation\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/web/README.summit.md\"\u003eREADME.summit.md\u003c/a\u003e for ORNL\u0027s Summit specific configuration\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVizualisation\u003c/h2\u003e\u003ca id=\"user-content-vizualisation\" class=\"anchor\" aria-label=\"Permalink: Vizualisation\" href=\"#vizualisation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOur ChatGrid frontend deployed with React, PSQL and LangChain has documentation in \u003ca href=\"viz/README.md\"\u003eREADME.md\u003c/a\u003e as well as a pdf \u003ca href=\"viz/README.pdf\"\u003eREADME.pdf\u003c/a\u003e in the \u003ccode\u003eviz\u003c/code\u003e subdirectory. Several of our tutorials install this through commands in Jupyter Notebooks as well.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eInstructions for executing the different ExaGO\u003csup\u003eTM\u003c/sup\u003e applications is given below.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"docs/web/opflow.md\"\u003eOPFLOW\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/web/tcopflow.md\"\u003eTCOPFLOW\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/web/sopflow.md\"\u003eSOPFLOW\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/web/scopflow.md\"\u003eSCOPFLOW\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/web/pflow.md\"\u003ePFLOW\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe also provide our user manual as a pdf \u003ca href=\"docs/manual/manual.pdf\"\u003emanual.pdf\u003c/a\u003e -\u0026gt; need to update this regularly with CI / move to quarto docs.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTutorials\u003c/h2\u003e\u003ca id=\"user-content-tutorials\" class=\"anchor\" aria-label=\"Permalink: Tutorials\" href=\"#tutorials\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eIf you are using a devcontainer with VSCode, the following tutorials are provided:\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"docs/devcontainer/tutorial.ipynb\"\u003etutorial.ipynb\u003c/a\u003e for basic configuration infromation and I/O\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/devcontainer/mpi4py-tutorial.ipynb\"\u003empi4py-tutorial.ipynb\u003c/a\u003e for mpi4py pointers and best practices\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/devcontainer/viz-tutorial.ipynb\"\u003eviz-tutorial.ipynb\u003c/a\u003e for spinning up our frontend visualization with ChatGrid integration\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOtherwise, you can check out our more in depth application tutorials in the \u003ccode\u003etutorials\u003c/code\u003esubdirectory:\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"tutorials/demo1.ipynb\"\u003edemo1.ipynb\u003c/a\u003e run OPFLOW, SCOPFLOW and visualize your output\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"tutorials/demo2.ipynb\"\u003edemo2.ipynb\u003c/a\u003e run SOPFLOW on many ranks using MPI, and visualize outpu\n\u003cul\u003e\n\u003cli\u003eTODO - add fixes from \u003ccode\u003empi4py\u003c/code\u003e devcontainer example into this notebook to show working MPI workflow\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOptions\u003c/h3\u003e\u003ca id=\"user-content-options\" class=\"anchor\" aria-label=\"Permalink: Options\" href=\"#options\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eEach application has a different set of options that are described in depth in the usage notes. These options can be passed optionally through an options file (\u003ccode\u003e-optionsfile \u0026lt;option_file\u0026gt;\u003c/code\u003e), or directly on the command line.\u003c/p\u003e\n\u003cp\u003eSince options may be specified in more than one location (on the command line, and through an options file), it is worth noting that the option specified on the command line supersede those in the options file. For example, if \u003ccode\u003eopflowoptions\u003c/code\u003e options file set the network file via the option \u003ccode\u003e-netfile case9mod.m\u003c/code\u003e, the following behavior occurs:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e This uses case9mod.m\u003c/span\u003e\n./opflow -optionsfile opflowoptions\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e This uses case118.m\u003c/span\u003e\n./opflow -netfile case118.m -options_file opflowoptions\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVisualization (experimental)\u003c/h2\u003e\u003ca id=\"user-content-visualization-experimental\" class=\"anchor\" aria-label=\"Permalink: Visualization (experimental)\" href=\"#visualization-experimental\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eExaGO has an experimental visualization to display the results of \u003ccode\u003eOPFLOW\u003c/code\u003e application on a map. See the \u003ca href=\"viz/README.md\"\u003evisualization README\u003c/a\u003e for more information.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease see \u003ca href=\"docs/developer_guidelines.md\"\u003ethe developer guidelines\u003c/a\u003e before attempting to contribute.\nFeel free to raise an issue or contact the team if the guidelines are ambiguous or you have a particular question.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eShrirang Abhyankar\u003c/li\u003e\n\u003cli\u003eSlaven Peles\u003c/li\u003e\n\u003cli\u003eAsher Mancinelli\u003c/li\u003e\n\u003cli\u003eCameron Rutherford\u003c/li\u003e\n\u003cli\u003eBruce Palmer\u003c/li\u003e\n\u003cli\u003eJaelyn Litzinger\u003c/li\u003e\n\u003cli\u003eWilliam Perkins\u003c/li\u003e\n\u003cli\u003eSayef Azad Sakin\u003c/li\u003e\n\u003cli\u003eJoseph Macam\u003c/li\u003e\n\u003cli\u003eRyan Danehy\u003c/li\u003e\n\u003cli\u003eNicholson Koukpaizan\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgement\u003c/h2\u003e\u003ca id=\"user-content-acknowledgement\" class=\"anchor\" aria-label=\"Permalink: Acknowledgement\" href=\"#acknowledgement\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis package is developed as a part of \u003ca href=\"https://www.exascaleproject.org/research-project/exasgd/\" rel=\"nofollow\"\u003eExaSGD\u003c/a\u003e project under the \u003ca href=\"https://www.exascaleproject.org/\" rel=\"nofollow\"\u003eExascale computing project\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright\u003c/h2\u003e\u003ca id=\"user-content-copyright\" class=\"anchor\" aria-label=\"Permalink: Copyright\" href=\"#copyright\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCopyright \u00a9 2020, Battelle Memorial Institute.\u003c/p\u003e\n\u003cp\u003eExaGO\u003csup\u003eTM\u003c/sup\u003e is a free software distributed under a BSD 2-clause license. You may reuse, modify, and redistribute the software. See the \u003ca href=\"LICENSE\"\u003elicense\u003c/a\u003e file for details.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDisclaimer\u003c/h2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-label=\"Permalink: Disclaimer\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis material was prepared as an account of work sponsored by an agency of the United States Government.  Neither the United States Government nor the United States Department of Energy, nor Battelle, nor any of their employees, nor any jurisdiction or organization that has cooperated in the development of these materials, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness or any information, apparatus, product, software, or process disclosed, or represents that its use would not infringe privately owned rights.\nReference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof, or Battelle Memorial Institute. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof.\u003c/p\u003e\n",
    "stargazers_count": 45,
    "subscribers_count": 11,
    "topics": [],
    "updated_at": 1711971039.0
  },
  {
    "data_format": 2,
    "description": "Celeritas is a new Monte Carlo transport code designed to accelerate scientific discovery in high energy physics by improving detector simulation throughput and energy efficiency using GPUs.",
    "filenames": [
      "scripts/spack.yaml"
    ],
    "full_name": "celeritas-project/celeritas",
    "latest_release": "v0.4.2",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCeleritas\u003c/h1\u003e\u003ca id=\"user-content-celeritas\" class=\"anchor\" aria-label=\"Permalink: Celeritas\" href=\"#celeritas\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Celeritas project implements HEP detector physics on GPU accelerator\nhardware with the ultimate goal of supporting the massive computational\nrequirements of the \u003ca href=\"https://home.cern/science/accelerators/high-luminosity-lhc\" rel=\"nofollow\"\u003eHL-LHC upgrade\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDocumentation\u003c/h1\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMost of the Celeritas documentation is readable through the codebase through a\ncombination of \u003ca href=\"doc/index.rst\"\u003estatic RST documentation\u003c/a\u003e and Doxygen-markup\ncomments in the source code itself. The full \u003ca href=\"https://celeritas-project.github.io/celeritas/user/index.html\" rel=\"nofollow\"\u003eCeleritas user\ndocumentation\u003c/a\u003e (including selected code documentation incorporated\nby Breathe) and the \u003ca href=\"https://celeritas-project.github.io/celeritas/dev/index.html\" rel=\"nofollow\"\u003eCeleritas code documentation\u003c/a\u003e are mirrored on\nour GitHub pages site. You can generate these yourself (if the necessary\nprerequisites are installed) by\nsetting the \u003ccode\u003eCELERITAS_BUILD_DOCS=ON\u003c/code\u003e configuration option and running \u003ccode\u003eninja doc\u003c/code\u003e (user) or \u003ccode\u003eninja doxygen\u003c/code\u003e (developer). A continuously updated version of\nthe \u003ca href=\"https://celeritas.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003estatic Celeritas user documentation\u003c/a\u003e (without API documentation) is\nhosted on \u003ccode\u003ereadthedocs.io\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eInstallation for applications\u003c/h1\u003e\u003ca id=\"user-content-installation-for-applications\" class=\"anchor\" aria-label=\"Permalink: Installation for applications\" href=\"#installation-for-applications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe easiest way to install Celeritas as a library/app is with Spack:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFollow the first two steps above to install \u003ca href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e and set up its CUDA usage.\u003c/li\u003e\n\u003cli\u003eInstall Celeritas with \u003ccode\u003espack install celeritas\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003espack load celeritas\u003c/code\u003e to add the installation to your \u003ccode\u003ePATH\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThen see the \"Downstream usage as a library\" section of the \u003ca href=\"doc/main/installation.rst\"\u003einstallation\ndocumentation\u003c/a\u003e for how to use Celeritas in your application or framework.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eInstallation for developers\u003c/h1\u003e\u003ca id=\"user-content-installation-for-developers\" class=\"anchor\" aria-label=\"Permalink: Installation for developers\" href=\"#installation-for-developers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSince Celeritas is still under heavy development and is not yet full-featured\nfor downstream integration, you are likely installing it for development\npurposes. The \u003ca href=\"doc/main/installation.rst\"\u003einstallation documentation\u003c/a\u003e has a\ncomplete description of the code\u0027s dependencies and installation process for\ndevelopment.\u003c/p\u003e\n\u003cp\u003eAs an example, if you have the \u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package manager\ninstalled and want to do development on a CUDA system with Volta-class graphics\ncards, execute the following steps from within the cloned Celeritas source\ndirectory:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e# \u003cspan class=\"pl-s1\"\u003eSet up CUDA (optional)\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack external find cuda\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eInstall celeritas dependencies\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack env create celeritas scripts/spack.yaml\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack env activate celeritas\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack config add packages:all:variants:\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ecxxstd=17 +cuda cuda_arch=70\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack install\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eConfigure, build, and \u003cspan class=\"pl-c1\"\u003etest\u003c/span\u003e\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./build.sh base\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you don\u0027t use Spack but have all the dependencies you want (Geant4,\ngoogletest, VecGeom, etc.) in your \u003ccode\u003eCMAKE_PREFIX_PATH\u003c/code\u003e, you can configure and\nbuild Celeritas as you would any other project:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003emkdir build \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003ecmake ..\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003emake \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e ctest\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eCeleritas guarantees full compatibility and correctness only on the\ncombinations of compilers and dependencies tested under continuous integration:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCompilers:\n\u003cul\u003e\n\u003cli\u003eGCC 8.4, 12.3\u003c/li\u003e\n\u003cli\u003eClang 10.0, 15.0\u003c/li\u003e\n\u003cli\u003eGCC 11.3 + NVCC 11.8\u003c/li\u003e\n\u003cli\u003eHIP-Clang 15.0\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDependencies:\n\u003cul\u003e\n\u003cli\u003eGeant4 11.0.3\u003c/li\u003e\n\u003cli\u003eVecGeom 1.2.5\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePartial compatibility and correctness is available for an extended range of\nGeant4:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e10.5-10.7: no support for tracking manager offload\u003c/li\u003e\n\u003cli\u003e11.0: no support for fast simulation offload\u003c/li\u003e\n\u003cli\u003e11.1-11.2: [no support for default Rayleigh scattering cross section](see\n\u003ca href=\"https://github.com/celeritas-project/celeritas/issues/1091\"\u003ehttps://github.com/celeritas-project/celeritas/issues/1091\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSince we compile with extra warning flags and avoid non-portable code, most\nother compilers \u003cem\u003eshould\u003c/em\u003e work.\nThe full set of configurations is viewable on CI platforms (\u003ca href=\"https://cloud.cees.ornl.gov/jenkins-ci/job/celeritas/job/develop\" rel=\"nofollow\"\u003eJenkins\u003c/a\u003e and \u003ca href=\"https://github.com/celeritas-project/celeritas/actions\"\u003eGitHub Actions\u003c/a\u003e).\nCompatibility fixes that do not cause newer versions to fail are welcome.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDevelopment\u003c/h1\u003e\u003ca id=\"user-content-development\" class=\"anchor\" aria-label=\"Permalink: Development\" href=\"#development\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSee the \u003ca href=\"CONTRIBUTING.rst\"\u003econtribution guide\u003c/a\u003e for the contribution process,\n\u003ca href=\"doc/appendix/development.rst\"\u003ethe development guidelines\u003c/a\u003e for further\ndetails on coding in Celeritas, and \u003ca href=\"doc/appendix/administration.rst\"\u003ethe administration guidelines\u003c/a\u003e for community standards and roles.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDirectory structure\u003c/h1\u003e\u003ca id=\"user-content-directory-structure\" class=\"anchor\" aria-label=\"Permalink: Directory structure\" href=\"#directory-structure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003eDirectory\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eDescription\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eapp\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eSource code for installed executable applications\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003ecmake\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eImplementation code for CMake build configuration\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003edoc\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eCode documentation and manual\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eexample\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eExample applications and input files\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003einterface\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eWrapper interfaces to Celeritas library functions\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003escripts\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eDevelopment and continuous integration helper scripts\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003esrc\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eLibrary source code\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003etest\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eUnit tests\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCiting Celeritas\u003c/h1\u003e\u003ca id=\"user-content-citing-celeritas\" class=\"anchor\" aria-label=\"Permalink: Citing Celeritas\" href=\"#citing-celeritas\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf using Celeritas in your work, we ask that you cite the code using its\n\u003ca href=\"https://www.osti.gov/doecode/biblio/94866\" rel=\"nofollow\"\u003eDOECode\u003c/a\u003e registration:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSeth R. Johnson, Amanda Lund, Soon Yung Jun, Stefano Tognini, Guilherme Lima, Paul Romano, Philippe Canal, Ben Morgan, and Tom Evans. \u201cCeleritas,\u201d July 2022. \u003ca href=\"https://doi.org/10.11578/dc.20221011.1\" rel=\"nofollow\"\u003ehttps://doi.org/10.11578/dc.20221011.1\u003c/a\u003e.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA continually evolving list of works authored by (or with content authored by)\ncore team members is available in our \u003ca href=\"doc/_static/celeritas.bib\"\u003ecitation file\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 51,
    "subscribers_count": 10,
    "topics": [
      "hep",
      "cuda",
      "computational-physics",
      "monte-carlo",
      "detector-simulation",
      "particle-transport"
    ],
    "updated_at": 1708096313.0
  },
  {
    "data_format": 2,
    "description": "Share Spack configuration files with other HPC sites",
    "filenames": [
      "NERSC/cori/e4s-21.02/prod/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/nvhpc/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-22.05/spack.yaml",
      "NERSC/perlmutter/e4s-23.08/gcc/spack.yaml",
      "NERSC/perlmutter/e4s-23.08/prod/gcc/spack.yaml",
      "OLCF/andes/spack.yaml",
      "NERSC/perlmutter/e4s-22.11/prod/gcc/spack.yaml",
      "NREL/configs/rhodes/utilities/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/gcc/spack.yaml",
      "OLCF/summit/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-21.11/spack.yaml",
      "BOISESTATE/borah/applications/gromacs/_spack.yaml",
      "NREL/configs/eagle/utilities/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/cce/spack.yaml",
      "NREL/configs/eagle/compilers/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-21.11/prod/spack.yaml",
      "NERSC/perlmutter/e4s-23.08/nvhpc/spack.yaml",
      "BOISESTATE/borah/environments/base/_spack.yaml",
      "NREL/configs/rhodes/compilers/spack.yaml",
      "NERSC/perlmutter/e4s-22.05/prod/gcc/spack.yaml",
      "NERSC/perlmutter/e4s-22.11/cuda/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-21.05/spack.yaml",
      "NERSC/perlmutter/e4s-22.05/nvhpc/spack.yaml",
      "NERSC/perlmutter/e4s-22.11/gcc/spack.yaml",
      "NREL/configs/eagle/base/spack.yaml",
      "OLCF/frontier/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/prod/tools/spack.yaml",
      "NERSC/perlmutter/e4s-22.05/cuda/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-22.02/spack.yaml",
      "NERSC/perlmutter/e4s-22.05/prod/cce/spack.yaml",
      "ANL/JLSE/Arcticus/E4S-22.08/spack.yaml",
      "BOISESTATE/borah/environments/b4s/_spack.yaml",
      "NERSC/perlmutter/e4s-23.05/data/spack.yaml",
      "NREL/configs/eagle/software/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/cuda/spack.yaml",
      "NERSC/perlmutter/e4s-23.05/prod/nvhpc/spack.yaml",
      "UOREGON/E4S-21.05-Facility-Examples/Frank-Jupiter/spack.yaml"
    ],
    "full_name": "spack/spack-configs",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSpack Configs\u003c/h1\u003e\u003ca id=\"user-content-spack-configs\" class=\"anchor\" aria-label=\"Permalink: Spack Configs\" href=\"#spack-configs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis is a repository that sites can use to share their configuration\nfiles for Spack.  You can contribute your own configuration files, or\nbrowse around and look at what others have done.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 56,
    "subscribers_count": 31,
    "topics": [],
    "updated_at": 1711548572.0
  },
  {
    "data_format": 2,
    "description": "C++ Message Queuing Library and Framework",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "FairRootGroup/FairMQ",
    "latest_release": "v1.8.4",
    "readme": "\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eFairMQ\u003c/h1\u003e\u003ca id=\"user-content-fairmq\" class=\"anchor\" aria-label=\"Permalink: FairMQ\" href=\"#fairmq\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"COPYRIGHT\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f1b04dc9744be18d2e4a57e93eb675e9d34c7fd88dd2af920a23cbf2b6126c9b/68747470733a2f2f616c66612d63692e6773692e64652f736869656c64732f62616467652f6c6963656e73652d4c47504c2d2d332e302d6f72616e67652e737667\" alt=\"license\" data-canonical-src=\"https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.1689985\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/61eb705b099605db7fd32ca363bc81333685424ab3d43368fb9eb92d2d20fcf8/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e313638393938352e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://bestpractices.coreinfrastructure.org/projects/6915\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1f8dec075c5bd5f9939e67adf475385a6ef6f10683061f1192c191ea31d3ffc3/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363931352f6261646765\" alt=\"OpenSSF Best Practices\" data-canonical-src=\"https://bestpractices.coreinfrastructure.org/projects/6915/badge\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cf9de53206b2701f8f690c12ded388c94ec29b8b4366cc55a64f1442b196ae01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666169722d2d736f6674776172652e65752d2545322539372538462532302532302545322539372538462532302532302545322539372538422532302532302545322539372538462532302532302545322539372538462d79656c6c6f77\" alt=\"fair-software.eu\" data-canonical-src=\"https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://repology.org/project/fairmq/versions\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a986833bc26fb382ffb3173c4f42c00cc0953f0b09ee7fc10e5c97df7f86c5a2/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f76657273696f6e2d666f722d7265706f2f737061636b2f666169726d712e737667\" alt=\"Spack package\" data-canonical-src=\"https://repology.org/badge/version-for-repo/spack/fairmq.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eC++ Message Queuing Library and Framework\u003c/p\u003e\n\u003cp\u003eDocs: \u003ca href=\"https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation\"\u003eBook\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFind all FairMQ releases \u003ca href=\"https://github.com/FairRootGroup/FairMQ/releases\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eIntroduction\u003c/h2\u003e\u003ca id=\"user-content-introduction\" class=\"anchor\" aria-label=\"Permalink: Introduction\" href=\"#introduction\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFairMQ is designed to help implementing large-scale data processing workflows needed in next-generation Particle Physics experiments. FairMQ is written in C++ and aims to\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eprovide \u003cstrong\u003ean asynchronous message passing abstraction\u003c/strong\u003e of different data transport technologies,\u003c/li\u003e\n\u003cli\u003eprovide a reasonably \u003cstrong\u003eefficient data transport\u003c/strong\u003e service (zero-copy, high throughput),\u003c/li\u003e\n\u003cli\u003ebe \u003cstrong\u003edata format agnostic\u003c/strong\u003e, and\u003c/li\u003e\n\u003cli\u003eprovide \u003cstrong\u003ebasic building blocks\u003c/strong\u003e that can be used to implement higher level data processing workflows.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe core of FairMQ provides an abstract asynchronous message passing API with scalability protocols\ninspired by \u003ca href=\"https://github.com/zeromq/libzmq\"\u003eZeroMQ\u003c/a\u003e (e.g. PUSH/PULL, PUB/SUB).\nFairMQ provides multiple implementations for its API (so-called \"transports\",\ne.g. \u003ccode\u003ezeromq\u003c/code\u003e and \u003ccode\u003eshmem\u003c/code\u003e (latest release of the \u003ccode\u003eofi\u003c/code\u003e transport in v1.4.56, removed since v1.5+)) to cover\na variety of use cases\n(e.g. inter-thread, inter-process, inter-node communication) and machines (e.g. Ethernet, Infiniband).\nIn addition to this core functionality FairMQ provides a framework for creating \"devices\" - actors which\nare communicating through message passing. FairMQ does not only allow the user to use different transport\nbut also to mix them; i.e: A Device can communicate using different transport on different channels at the\nsame time. Device execution is modelled as a simple state machine that shapes the integration points for\nthe user task. Devices also incorporate a plugin system for runtime configuration and control.\nNext to the provided \u003ca href=\"https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices\"\u003edevices\u003c/a\u003e and\n\u003ca href=\"https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins\"\u003eplugins\u003c/a\u003e the user can extend FairMQ\nby developing his own plugins to integrate his devices with external configuration and control services.\u003c/p\u003e\n\u003cp\u003eFairMQ has been developed in the context of its mother project \u003ca href=\"https://github.com/FairRootGroup/FairRoot\"\u003eFairRoot\u003c/a\u003e -\na simulation, reconstruction and analysis framework.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation from Source\u003c/h2\u003e\u003ca id=\"user-content-installation-from-source\" class=\"anchor\" aria-label=\"Permalink: Installation from Source\" href=\"#installation-from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRecommended:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/FairRootGroup/FairMQ fairmq_source\ncmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release\ncmake --build fairmq_build\nctest --test-dir fairmq_build --output-on-failure --schedule-random -j\u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003encpus\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\ncmake --install fairmq_build --prefix \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003epwd\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e/fairmq_install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ePlease consult the \u003ca href=\"https://cmake.org/cmake/help/latest/manual/cmake.1.html\" rel=\"nofollow\"\u003emanpages of your CMake version\u003c/a\u003e for more options.\u003c/p\u003e\n\u003cp\u003eIf dependencies are not installed in standard system directories, you can hint the installation location via\n\u003ccode\u003e-DCMAKE_PREFIX_PATH=...\u003c/code\u003e or per dependency via \u003ccode\u003e-D{DEPENDENCY}_ROOT=...\u003c/code\u003e (\u003ccode\u003e*_ROOT\u003c/code\u003e variables can also be environment variables).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFairMQ ships as a CMake package, so in your \u003ccode\u003eCMakeLists.txt\u003c/code\u003e you can discover it like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003efind_package\u003c/span\u003e(FairCMakeModules 1.0 \u003cspan class=\"pl-k\"\u003eREQUIRED\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003einclude\u003c/span\u003e(FairFindPackage2)\nfind_package2(FairMQ)\nfind_package2_implicit_dependencies()\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe \u003ca href=\"https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html\" rel=\"nofollow\"\u003e\u003ccode\u003eFairFindPackage2\u003c/code\u003e module\u003c/a\u003e is part of the \u003ca href=\"https://fairrootgroup.github.io/FairCMakeModules\" rel=\"nofollow\"\u003e\u003ccode\u003eFairCMakeModules\u003c/code\u003e package\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf FairMQ is not installed in system directories, you can hint the installation:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003elist\u003c/span\u003e(PREPEND CMAKE_PREFIX_PATH /path/to/fairmq_install)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.boost.org/\" rel=\"nofollow\"\u003eBoost\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cmake.org/\" rel=\"nofollow\"\u003eCMake\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.doxygen.org/\" rel=\"nofollow\"\u003eDoxygen\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/FairRootGroup/FairCMakeModules\"\u003eFairCMakeModules\u003c/a\u003e (optionally bundled)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/FairRootGroup/FairLogger\"\u003eFairLogger\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/google/googletest\"\u003eGTest\u003c/a\u003e (optionally bundled)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://zeromq.org/\" rel=\"nofollow\"\u003eZeroMQ\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhich dependencies are required depends on which components are built.\u003c/p\u003e\n\u003cp\u003eSupported platform is Linux. macOS is supported on a best-effort basis.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCMake options\u003c/h2\u003e\u003ca id=\"user-content-cmake-options\" class=\"anchor\" aria-label=\"Permalink: CMake options\" href=\"#cmake-options\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOn command line:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-DDISABLE_COLOR=ON\u003c/code\u003e disables coloured console output.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-DBUILD_TESTING=OFF\u003c/code\u003e disables building of tests.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-DBUILD_EXAMPLES=OFF\u003c/code\u003e disables building of examples.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-DBUILD_DOCS=ON\u003c/code\u003e enables building of API docs.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF\u003c/code\u003e disable channel \u003ccode\u003eautoBind\u003c/code\u003e by default\u003c/li\u003e\n\u003cli\u003eYou can hint non-system installations for dependent packages, see the #installation-from-source section above\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAfter the \u003ccode\u003efind_package(FairMQ)\u003c/code\u003e call the following CMake variables are defined:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eVariable\u003c/th\u003e\n\u003cth\u003eInfo\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_PACKAGE_DEPENDENCIES}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe list of public package dependencies\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_\u0026lt;dep\u0026gt;_VERSION}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe minimum \u003ccode\u003e\u0026lt;dep\u0026gt;\u003c/code\u003e version FairMQ requires\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_\u0026lt;dep\u0026gt;_COMPONENTS}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe list of \u003ccode\u003e\u0026lt;dep\u0026gt;\u003c/code\u003e components FairMQ depends on\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_PACKAGE_COMPONENTS}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe list of components FairMQ consists of\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_#COMPONENT#_FOUND}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003eTRUE\u003c/code\u003e if this component was built\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_VERSION}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe version in format \u003ccode\u003eMAJOR.MINOR.PATCH\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_GIT_VERSION}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe version in the format returned by \u003ccode\u003egit describe --tags --dirty --match \"v*\"\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_PREFIX}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe actual installation prefix\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_BINDIR}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe installation bin directory\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_INCDIR}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe installation include directory\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_LIBDIR}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe installation lib directory\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_DATADIR}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe installation data directory (\u003ccode\u003e../share/fairmq\u003c/code\u003e)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_CMAKEMODDIR}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe installation directory of shipped CMake find modules\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_BUILD_TYPE}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe value of \u003ccode\u003eCMAKE_BUILD_TYPE\u003c/code\u003e at build-time\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003e${FairMQ_CXX_FLAGS}\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003ethe values of \u003ccode\u003eCMAKE_CXX_FLAGS\u003c/code\u003e and \u003ccode\u003eCMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}\u003c/code\u003e at build-time\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Device.md#1-device\"\u003eDevice\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Device.md#11-topology\"\u003eTopology\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Device.md#12-communication-patterns\"\u003eCommunication Patterns\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Device.md#13-state-machine\"\u003eState Machine\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Device.md#15-multiple-devices-in-the-same-process\"\u003eMultiple devices in the same process\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Transport.md#2-transport-interface\"\u003eTransport Interface\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Transport.md#21-message\"\u003eMessage\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Transport.md#211-ownership\"\u003eOwnership\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Transport.md#22-channel\"\u003eChannel\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Transport.md#23-poller\"\u003ePoller\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Configuration.md#3-configuration\"\u003eConfiguration\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Configuration.md#31-device-configuration\"\u003eDevice Configuration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Configuration.md#32-communication-channels-configuration\"\u003eCommunication Channels Configuration\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Configuration.md#321-json-parser\"\u003eJSON Parser\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Configuration.md#322-suboptparser\"\u003eSuboptParser\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Configuration.md#33-introspection\"\u003eIntrospection\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Development.md#4-development\"\u003eDevelopment\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Development.md#41-testing\"\u003eTesting\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Development.md#42-static-analysis\"\u003eStatic Analysis\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Development.md#421-cmake-integration\"\u003eCMake Integration\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Development.md#422-extra-compiler-arguments\"\u003eExtra Compiler Arguments\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Logging.md#5-logging\"\u003eLogging\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Logging.md#51-log-severity\"\u003eLog severity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Logging.md#52-log-verbosity\"\u003eLog verbosity\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Logging.md#53-color\"\u003eColor for console output\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Logging.md#54-file-output\"\u003eFile output\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Logging.md#55-custom-sinks\"\u003eCustom sinks\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Examples.md#6-examples\"\u003eExamples\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Plugins.md#7-plugins\"\u003ePlugins\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Plugins.md#71-usage\"\u003eUsage\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"docs/Plugins.md#72-development\"\u003eDevelopment\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"docs/Plugins.md#73-provided-plugins\"\u003eProvided Plugins\u003c/a\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"docs/Plugins.md#731-pmix\"\u003ePMIx\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n",
    "stargazers_count": 81,
    "subscribers_count": 12,
    "topics": [
      "fairroot",
      "fairmq",
      "zeromq",
      "shmem",
      "c-plus-plus"
    ],
    "updated_at": 1709540936.0
  },
  {
    "data_format": 2,
    "description": "UnifyFS: A file system for burst buffers",
    "filenames": [
      ".spack-env/unifyfs-lsf-gcc4_9_3/spack.yaml",
      ".spack-env/unifyfs-slurm-gcc12_1_1/spack.yaml"
    ],
    "full_name": "LLNL/UnifyFS",
    "latest_release": "v2.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eUnifyFS: A Distributed Burst Buffer File System\u003c/h1\u003e\u003ca id=\"user-content-unifyfs-a-distributed-burst-buffer-file-system\" class=\"anchor\" aria-label=\"Permalink: UnifyFS: A Distributed Burst Buffer File System\" href=\"#unifyfs-a-distributed-burst-buffer-file-system\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eNode-local burst buffers are becoming an indispensable hardware resource on\nlarge-scale supercomputers to buffer the bursty I/O from scientific\napplications. However, there is a lack of software support for burst buffers to\nbe efficiently shared by applications within a batch-submitted job and recycled\nacross different batch jobs. In addition, burst buffers need to cope with a\nvariety of challenging I/O patterns from data-intensive scientific\napplications.\u003c/p\u003e\n\u003cp\u003eUnifyFS is a user-level burst buffer file system under active development.\nUnifyFS supports scalable and efficient aggregation of I/O bandwidth from burst\nbuffers while having the same life cycle as a batch-submitted job. While UnifyFS\nis designed for N-N write/read, UnifyFS compliments its functionality with the\nsupport for N-1 write/read. It efficiently accelerates scientific I/O based on\nscalable metadata indexing, co-located I/O delegation, and server-side read\nclustering and pipelining.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUnifyFS documentation is at \u003ca href=\"https://unifyfs.readthedocs.io\" rel=\"nofollow\"\u003ehttps://unifyfs.readthedocs.io\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor instructions on how to build and install UnifyFS,\nsee \u003ca href=\"http://unifyfs.readthedocs.io/en/dev/build.html\" rel=\"nofollow\"\u003eBuild UnifyFS\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuild Status\u003c/h2\u003e\u003ca id=\"user-content-build-status\" class=\"anchor\" aria-label=\"Permalink: Build Status\" href=\"#build-status\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eStatus of UnifyFS development branch (dev):\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\"\u003e\u003cimg src=\"https://github.com/LLNL/UnifyFS/actions/workflows/build-and-test.yml/badge.svg?branch=dev\" alt=\"Build Status\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://unifyfs.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/32daa6ee48d97cb528194d1ea7f20969e697b70bcd7fc76a159c9c10a5ed371b/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756e69667966732f62616467652f3f76657273696f6e3d646576\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/unifyfs/badge/?version=dev\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUnifyFS Citation\u003c/h2\u003e\u003ca id=\"user-content-unifyfs-citation\" class=\"anchor\" aria-label=\"Permalink: UnifyFS Citation\" href=\"#unifyfs-citation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe recommend that you use this citation for UnifyFS:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMichael Brim, Adam Moody, Seung-Hwan Lim, Ross Miller, Swen Boehm, Cameron Stanavige, Kathryn Mohror, Sarp Oral, \u201cUnifyFS: A User-level Shared File System for Unified Access to Distributed Local Storage,\u201d 37th IEEE International Parallel \u0026amp; Distributed Processing Symposium (IPDPS 2023), St. Petersburg, FL, May 2023.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContribute and Develop\u003c/h2\u003e\u003ca id=\"user-content-contribute-and-develop\" class=\"anchor\" aria-label=\"Permalink: Contribute and Develop\" href=\"#contribute-and-develop\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you would like to help, please see our \u003ca href=\"https://unifyfs.readthedocs.io/en/dev/contribute-ways.html\" rel=\"nofollow\"\u003econtributing guidelines\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 95,
    "subscribers_count": 20,
    "topics": [
      "system-software",
      "burst-buffers",
      "file-system"
    ],
    "updated_at": 1708741604.0
  },
  {
    "data_format": 2,
    "description": ":floppy_disk: C++ \u0026 Python API for Scientific I/O",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "openPMD/openPMD-api",
    "latest_release": "0.15.2",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eC++ \u0026amp; Python API for Scientific I/O with openPMD\u003c/h1\u003e\u003ca id=\"user-content-c--python-api-for-scientific-io-with-openpmd\" class=\"anchor\" aria-label=\"Permalink: C++ \u0026amp; Python API for Scientific I/O with openPMD\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/openPMD/openPMD-standard/releases\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d13f841c93684a76b33b3bfea77f0972f8d14291c5180eac269e1cad9dc341c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\" alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openpmd.org/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d0fc2114159b7b68214de4f99a704161635ae9a5f2500903a0735598634331a5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\" alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://gitter.im/openPMD/API\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ff7083cc261bcd9f3693e400b5c5ab2bc0c7e24d7b0b456ffe7b34ee19af0e1f/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\" alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.gnu.org/licenses/lgpl-3.0.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/20a8ccdee703984a1e590f3213ce07587f7467115d7742291cd7d77b254707bf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.14278/rodare.27\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b7df96f0665c4aeee252301c6cdaf28fa395ee36730464abaa93956ccf5544f4/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\" alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/66b24447775c3b5b6d1fb8a72efa1a837bd07012711189a76c944b2943a1d83b/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\" alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/openPMD/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a4d2f864cd8cc403a0a9af3b8a008fccdbe8b3476c8d39a02ecda3097212cdcb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/502c10b6946e49f3d3a5758800dc5e01cb40a0c4cc5ea8bb17a9e2471c98e327/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://travis-ci.com/openPMD/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f687ccda5d5e831448209e00847229d69a109d4d0c9d0f24ef2c19fd1c50fe7/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\" alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c4197235edfc513c73649de993970af6f8067123ce78821c0249dd0c6747ed9c/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\" alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\u003e\u003cimg src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels\u0026amp;event=push\" alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1\u0026amp;branchName=azure_install\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5420d1b718d3805a368c5cd2a9c33e294819c7235e8e533d3b8f1b2b2bc6c4b4/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install\u0026amp;label=nightly%20packages\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5348e1f24701566268367aea654dee73cbea5ea91b3d94819085fd552dff34b5/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\" alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eopenPMD is an open meta-data schema that provides meaning and self-description for data sets in science and engineering.\nSee \u003ca href=\"https://github.com/openPMD/openPMD-standard\"\u003ethe openPMD standard\u003c/a\u003e for details of this schema.\u003c/p\u003e\n\u003cp\u003eThis library provides a reference API for openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable, hierarchical file formats, this library implements various backends such as HDF5, ADIOS2 and JSON.\nWriting \u0026amp; reading through those backends and their associated files are supported for serial and \u003ca href=\"https://www.mpi-forum.org/docs/\" rel=\"nofollow\"\u003eMPI-parallel\u003c/a\u003e workflows.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eUsage\u003c/h2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-label=\"Permalink: Usage\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eC++\u003c/h3\u003e\u003ca id=\"user-content-c\" class=\"anchor\" aria-label=\"Permalink: C++\" href=\"#c\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4039af8871849eff8d3350af5ac6e8f02048d6dc71ce1e941b5ab9f219325ea/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\" alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003eopenPMD/openPMD.hpp\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003eiostream\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e ...\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e s = openPMD::Series(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003esamples/git-sample/data%T.h5\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, openPMD::Access::READ_ONLY);\n\n\u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [step, it] : s.iterations ) {\n    std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eIteration: \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; step \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [name, mesh] : it.\u003cspan class=\"pl-smi\"\u003emeshes\u003c/span\u003e ) {\n        std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e  Mesh \u0027\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0027 attributes:\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e\u0026amp; val : mesh.\u003cspan class=\"pl-c1\"\u003eattributes\u003c/span\u003e() )\n            std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e    \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e;\n    }\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [name, species] : it.\u003cspan class=\"pl-smi\"\u003eparticles\u003c/span\u003e ) {\n        std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e  Particle species \u0027\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0027 attributes:\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e\u0026amp; val : species.\u003cspan class=\"pl-c1\"\u003eattributes\u003c/span\u003e() )\n            std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e    \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e;\n    }\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003ePython\u003c/h3\u003e\u003ca id=\"user-content-python\" class=\"anchor\" aria-label=\"Permalink: Python\" href=\"#python\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://www.python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e751dc39d18bc7613b561655f2f3551a2c999fc64fb85aeda826e0351492e168/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e08047faf15af7ed30138bc35fd09dc954afe88590bec56604d757725ec9aa9d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eopenpmd_api\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eas\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e# ...\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003eseries\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eSeries\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"samples/git-sample/data%T.h5\"\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eAccess\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eread_only\u003c/span\u003e)\n\n\u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_i\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eseries\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eiterations\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n    \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"Iteration: {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_i\u003c/span\u003e))\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_m\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003em\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003emeshes\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n        \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"  Mesh \u0027{0}\u0027 attributes:\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_m\u003c/span\u003e))\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003em\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eattributes\u003c/span\u003e:\n            \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"    {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e))\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_p\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ep\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eparticles\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n        \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"  Particle species \u0027{0}\u0027 attributes:\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_p\u003c/span\u003e))\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ep\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eattributes\u003c/span\u003e:\n            \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"    {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e))\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eMore!\u003c/h3\u003e\u003ca id=\"user-content-more\" class=\"anchor\" aria-label=\"Permalink: More!\" href=\"#more\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCurious?\nOur manual shows full \u003ca href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\" rel=\"nofollow\"\u003eread \u0026amp; write examples\u003c/a\u003e, both serial and MPI-parallel!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDependencies\u003c/h2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eRequired:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCMake 3.15.0+\u003c/li\u003e\n\u003cli\u003eC++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eShipped internally in \u003ccode\u003eshare/openPMD/thirdParty/\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/catchorg/Catch2\"\u003eCatch2\u003c/a\u003e 2.13.10+ (\u003ca href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\"\u003eBSL-1.0\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11\"\u003epybind11\u003c/a\u003e 2.11.1+ (\u003ca href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\"\u003enew BSD\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/nlohmann/json\"\u003eNLohmann-JSON\u003c/a\u003e 3.9.1+ (\u003ca href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\"\u003eMIT\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ToruNiina/toml11\"\u003etoml11\u003c/a\u003e 3.7.1+ (\u003ca href=\"https://github.com/ToruNiina/toml11/blob/master/LICENSE\"\u003eMIT\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI/O backends:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"nofollow\"\u003eJSON\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://support.hdfgroup.org/HDF5\" rel=\"nofollow\"\u003eHDF5\u003c/a\u003e 1.8.13+ (optional)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ornladios/ADIOS2\"\u003eADIOS2\u003c/a\u003e 2.7.0+ (optional)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ewhile those can be built either with or without:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOptional language bindings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePython:\n\u003cul\u003e\n\u003cli\u003ePython 3.8 - 3.12\u003c/li\u003e\n\u003cli\u003epybind11 2.11.1+\u003c/li\u003e\n\u003cli\u003enumpy 1.15+\u003c/li\u003e\n\u003cli\u003empi4py 2.1+ (optional, for MPI)\u003c/li\u003e\n\u003cli\u003epandas 1.0+ (optional, for dataframes)\u003c/li\u003e\n\u003cli\u003edask 2021+ (optional, for dask dataframes)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCUDA C++ (optional, currently used only in tests)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/132ae648808a03cbf50ea3f9834f3e797f087ad259ebdc21b8d94804f9f57700/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fd019b54503cfc07bcb5b636086070bf8a09e73e1f88653a551cd3f47231df28/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/openPMD/homebrew-openPMD\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c10ad19fca3dd28135f3b21f3e7a9950dad57fbb3d4c9f90d8d369aafd757e1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d5db8554037acd8a410130359282ed8e0ba8e5c6d4ec232b6898667459d763b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/33b82ea6e40ffa2127d4e4e0fcd64e8aa96692b222c51bf6f93e1996dac79b21/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\" alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur community loves to help each other.\nPlease \u003ca href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install\u0026amp;template=install_problem.md\"\u003ereport installation problems\u003c/a\u003e in case you should get stuck.\u003c/p\u003e\n\u003cp\u003eChoose \u003cem\u003eone\u003c/em\u003e of the install methods below to get started:\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003e\u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e\u003c/h3\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-label=\"Permalink: Spack\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/942d8d86fcbe5f3670631c12617a3d205a84acb9304609abfa364280d96d8588/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b376c2ae3f321777bb8b0dd09bce8bf2340611f6c0eb2ce8207323e0fab04f20/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\" alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:               +python -adios2 -hdf5 -mpi\u003c/span\u003e\nspack install openpmd-api\nspack load openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003e\u003ca href=\"https://conda.io\" rel=\"nofollow\"\u003eConda\u003c/a\u003e\u003c/h3\u003e\u003ca id=\"user-content-conda\" class=\"anchor\" aria-label=\"Permalink: Conda\" href=\"#conda\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6fe3005c57558bc59b43aa7228a48663428f0dd49c264d35af536f6d052b12b3/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/502a7a44785416f67a8fb94dbc02547a993fb42195f308e821661c28319060ad/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                      OpenMPI support  =*=mpi_openmpi*\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                        MPICH support  =*=mpi_mpich*\u003c/span\u003e\nconda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003e\u003ca href=\"https://brew.sh\" rel=\"nofollow\"\u003eBrew\u003c/a\u003e\u003c/h3\u003e\u003ca id=\"user-content-brew\" class=\"anchor\" aria-label=\"Permalink: Brew\" href=\"#brew\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/openPMD/homebrew-openPMD\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5ef9bc9e32e5b1966642b44b62543b570d72da9d2583fea7b32cae6fce75495d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\" alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://docs.brew.sh/Homebrew-on-Linux\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b52f21df7ad363012112cd9c32c25dd554bd25cac3c84c92a04c6207274acd8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://brew.sh\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d44878e96acfad216c259071aaeb3dc3a3abc44a9cdf5d12c5fce6d07e4c1762/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\" alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ebrew tap openpmd/openpmd\nbrew install openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003e\u003ca href=\"https://pypi.org\" rel=\"nofollow\"\u003ePyPI\u003c/a\u003e\u003c/h3\u003e\u003ca id=\"user-content-pypi\" class=\"anchor\" aria-label=\"Permalink: PyPI\" href=\"#pypi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9401a82878058d507a0199407fc2722229b0bf78eb31fdeaa054bd881d0bc769/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\" alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api/#files\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6445f5e527792585ad3b382fce8128892407ba1bb5af6508af00abd8ccf08cfd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8feb288d963f4caa697d0b3b5182e71edbf4106ae4bcc66ce0dd1921cba5c6f6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\" alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/24f7c205d4b2824ef9506cc27543baa4d040b9a7c0e91355d7da11fc17b74c17/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\" alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOn very old macOS versions (\u0026lt;10.9) or on exotic processor architectures, this install method \u003cem\u003ecompiles from source\u003c/em\u003e against the found installations of HDF5, ADIOS2, and/or MPI (in system paths, from other package managers, or loaded via a module system, ...).\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e we need pip 19 or newer\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                   --user\u003c/span\u003e\npython3 -m pip install -U pip\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                        --user\u003c/span\u003e\npython3 -m pip install openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf MPI-support shall be enabled, we always have to recompile:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                    --user\u003c/span\u003e\npython3 -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U cmake\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                                                   --user\u003c/span\u003e\nopenPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor some exotic architectures and compilers, you might need to disable a compiler feature called \u003ca href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\" rel=\"nofollow\"\u003elink-time/interprocedural optimization\u003c/a\u003e if you encounter linking problems:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                                --user\u003c/span\u003e\npython3 -m pip install openpmd-api --no-binary openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdditional CMake options can be passed via individual environment variables, which need to be prefixed with \u003ccode\u003eopenPMD_CMAKE_\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eFrom Source\u003c/h3\u003e\u003ca id=\"user-content-from-source\" class=\"anchor\" aria-label=\"Permalink: From Source\" href=\"#from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e35be8f08546231b86c7e9290cb559ec981380d6cb27512296820d120f233eeb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\" alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eopenPMD-api can also be built and installed from source using \u003ca href=\"https://cmake.org/\" rel=\"nofollow\"\u003eCMake\u003c/a\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/openPMD/openPMD-api.git\n\nmkdir openPMD-api-build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e openPMD-api-build\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: for full tests, with unzip\u003c/span\u003e\n../openPMD-api/share/openPMD/download_samples.sh\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e for own install prefix append:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DCMAKE_INSTALL_PREFIX=$HOME/somepath\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e for options append:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DopenPMD_USE_...=...\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e e.g. for python support add:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which python3)\u003c/span\u003e\ncmake ../openPMD-api\n\ncmake --build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional\u003c/span\u003e\nctest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e sudo might be required for system paths\u003c/span\u003e\ncmake --build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e --target install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe following options can be added to the \u003ccode\u003ecmake\u003c/code\u003e call to control features.\nCMake controls options with prefixed \u003ccode\u003e-D\u003c/code\u003e, e.g. \u003ccode\u003e-DopenPMD_USE_MPI=OFF\u003c/code\u003e:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_MPI\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eParallel, Multi-Node I/O for clusters\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_HDF5\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eHDF5 backend (\u003ccode\u003e.h5\u003c/code\u003e files)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_ADIOS2\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eADIOS2 backend (\u003ccode\u003e.bp\u003c/code\u003e files in BP3, BP4 or higher)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_PYTHON\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eEnable Python bindings\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INVASIVE_TESTS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable unit tests that modify source code \u003csup\u003e1\u003c/sup\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_VERIFY\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eEnable internal VERIFY (assert) macro independent of build type \u003csup\u003e2\u003c/sup\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_INSTALL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eAdd installation targets\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_INSTALL_RPATH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eAdd RPATHs to installed binaries\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePython_EXECUTABLE\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e(newest found)\u003c/td\u003e\n\u003ctd\u003ePath to Python executable\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003csup\u003e1\u003c/sup\u003e \u003cem\u003ee.g. changes C++ visibility keywords, breaks MSVC\u003c/em\u003e\n\u003csup\u003e2\u003c/sup\u003e \u003cem\u003ethis includes most pre-/post-condition checks, disabling without specific cause is highly discouraged\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAdditionally, the following libraries are shipped internally.\nThe following options allow to switch to external installs:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eLibrary\u003c/th\u003e\n\u003cth\u003eVersion\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_CATCH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eCatch2\u003c/td\u003e\n\u003ctd\u003e2.13.10+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_PYBIND11\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003epybind11\u003c/td\u003e\n\u003ctd\u003e2.11.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_JSON\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNLohmann-JSON\u003c/td\u003e\n\u003ctd\u003e3.9.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_TOML11\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003etoml11\u003c/td\u003e\n\u003ctd\u003e3.7.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eBy default, this will build as a shared library (\u003ccode\u003elibopenPMD.[so|dylib|dll]\u003c/code\u003e) and installs also its headers.\nIn order to build a static library, append \u003ccode\u003e-DBUILD_SHARED_LIBS=OFF\u003c/code\u003e to the \u003ccode\u003ecmake\u003c/code\u003e command.\nYou can only build a static or a shared library at a time.\u003c/p\u003e\n\u003cp\u003eBy default, the \u003ccode\u003eRelease\u003c/code\u003e version is built.\nIn order to build with debug symbols, pass \u003ccode\u003e-DCMAKE_BUILD_TYPE=Debug\u003c/code\u003e to your \u003ccode\u003ecmake\u003c/code\u003e command.\u003c/p\u003e\n\u003cp\u003eBy default, tests, examples and command line tools are built.\nIn order to skip building those, pass \u003ccode\u003eOFF\u003c/code\u003e to these \u003ccode\u003ecmake\u003c/code\u003e options:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_TESTING\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild tests\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_EXAMPLES\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild examples\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_CLI_TOOLS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild command-line tools\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_CUDA_EXAMPLES\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eUse CUDA in examples\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLinking to your project\u003c/h2\u003e\u003ca id=\"user-content-linking-to-your-project\" class=\"anchor\" aria-label=\"Permalink: Linking to your project\" href=\"#linking-to-your-project\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe install will contain header files and libraries in the path set with \u003ccode\u003e-DCMAKE_INSTALL_PREFIX\u003c/code\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCMake\u003c/h3\u003e\u003ca id=\"user-content-cmake\" class=\"anchor\" aria-label=\"Permalink: CMake\" href=\"#cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf your project is using CMake for its build, one can conveniently use our provided \u003ccode\u003eopenPMDConfig.cmake\u003c/code\u003e package, which is installed alongside the library.\u003c/p\u003e\n\u003cp\u003eFirst set the following environment hint if openPMD-api was \u003cem\u003enot\u003c/em\u003e installed in a system path:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: only needed if installed outside of system paths\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CMAKE_PREFIX_PATH=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/somepath:\u003cspan class=\"pl-smi\"\u003e$CMAKE_PREFIX_PATH\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUse the following lines in your project\u0027s \u003ccode\u003eCMakeLists.txt\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS2\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003efind_package\u003c/span\u003e(openPMD 0.15.0 \u003cspan class=\"pl-k\"\u003eCONFIG\u003c/span\u003e)\n\n\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(openPMD_FOUND)\n    \u003cspan class=\"pl-c1\"\u003etarget_link_libraries\u003c/span\u003e(YourTarget \u003cspan class=\"pl-k\"\u003ePRIVATE\u003c/span\u003e openPMD::openPMD)\n\u003cspan class=\"pl-k\"\u003eendif\u003c/span\u003e()\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eAlternatively\u003c/em\u003e, add the openPMD-api repository source directly to your project and use it via:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eadd_subdirectory\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"path/to/source/of/openPMD-api\"\u003c/span\u003e)\n\n\u003cspan class=\"pl-c1\"\u003etarget_link_libraries\u003c/span\u003e(YourTarget \u003cspan class=\"pl-k\"\u003ePRIVATE\u003c/span\u003e openPMD::openPMD)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor development workflows, you can even automatically download and build openPMD-api from within a depending CMake project.\nJust replace the \u003ccode\u003eadd_subdirectory\u003c/code\u003e call with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003einclude\u003c/span\u003e(FetchContent)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(CMAKE_POLICY_DEFAULT_CMP0077 \u003cspan class=\"pl-k\"\u003eNEW\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_CLI_TOOLS \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_EXAMPLES \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_TESTING \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_SHARED_LIBS \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e precedence over BUILD_SHARED_LIBS if needed\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_INSTALL \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)            \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e or instead use:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e set(openPMD_INSTALL ${BUILD_SHARED_LIBS})  # only install if used as a shared library\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_USE_PYTHON \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY \u003cspan class=\"pl-s\"\u003e\"https://github.com/openPMD/openPMD-api.git\"\u003c/span\u003e\n  GIT_TAG        \u003cspan class=\"pl-s\"\u003e\"0.15.0\"\u003c/span\u003e)\nFetchContent_MakeAvailable(openPMD)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eManually\u003c/h3\u003e\u003ca id=\"user-content-manually\" class=\"anchor\" aria-label=\"Permalink: Manually\" href=\"#manually\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf your (Linux/OSX) project is build by calling the compiler directly or uses a manually written \u003ccode\u003eMakefile\u003c/code\u003e, consider using our \u003ccode\u003eopenPMD.pc\u003c/code\u003e helper file for \u003ccode\u003epkg-config\u003c/code\u003e, which are installed alongside the library.\u003c/p\u003e\n\u003cp\u003eFirst set the following environment hint if openPMD-api was \u003cem\u003enot\u003c/em\u003e installed in a system path:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: only needed if installed outside of system paths\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PKG_CONFIG_PATH=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/somepath/lib/pkgconfig:\u003cspan class=\"pl-smi\"\u003e$PKG_CONFIG_PATH\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdditional linker and compiler flags for your project are available via:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e switch to check if openPMD-api was build as static library\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e (via BUILD_SHARED_LIBS=OFF) or as shared library (default)\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e [ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003epkg-config --variable=static openPMD\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e==\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etrue\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e ]\n\u003cspan class=\"pl-k\"\u003ethen\u003c/span\u003e\n    pkg-config --libs --static openPMD\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eelse\u003c/span\u003e\n    pkg-config --libs openPMD\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -L${HOME}/somepath/lib -lopenPMD\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003efi\u003c/span\u003e\n\npkg-config --cflags openPMD\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -I${HOME}/somepath/include\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthor Contributions\u003c/h2\u003e\u003ca id=\"user-content-author-contributions\" class=\"anchor\" aria-label=\"Permalink: Author Contributions\" href=\"#author-contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eopenPMD-api is developed by many people.\nIt was initially started by the \u003ca href=\"https://hzdr.de/crp\" rel=\"nofollow\"\u003eComputational Radiation Physics Group\u003c/a\u003e at \u003ca href=\"https://www.hzdr.de/\" rel=\"nofollow\"\u003eHZDR\u003c/a\u003e as successor to \u003ca href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\u003elibSplash\u003c/a\u003e, generalizing the \u003ca href=\"https://arxiv.org/abs/1706.00522\" rel=\"nofollow\"\u003esuccessful HDF5 \u0026amp; ADIOS1 implementations\u003c/a\u003e in \u003ca href=\"https://github.com/ComputationalRadiationPhysics/picongpu\"\u003ePIConGPU\u003c/a\u003e.\nThe following people and institutions \u003ca href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\u003econtributed\u003c/a\u003e to openPMD-api:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ax3l\"\u003eAxel Huebl (LBNL, previously HZDR)\u003c/a\u003e:\nproject lead, releases, documentation, automated CI/CD, Python bindings, Dask, installation \u0026amp; packaging, prior reference implementations\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/franzpoeschel\"\u003eFranz Poeschel (CASUS)\u003c/a\u003e:\nJSON \u0026amp; ADIOS2 backend, data staging/streaming, reworked class design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/C0nsultant\"\u003eFabian Koller (HZDR)\u003c/a\u003e:\ninitial library design and implementation with HDF5 \u0026amp; ADIOS1 backend\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/guj\"\u003eJunmin Gu (LBNL)\u003c/a\u003e:\nnon-collective parallel I/O fixes, ADIOS improvements, benchmarks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eMaintained by the following research groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.casus.science/casus/team/\" rel=\"nofollow\"\u003eComputational Radiation Physics (CRD)\u003c/a\u003e at CASUS/HZDR, led by \u003ca href=\"https://github.com/bussmann\"\u003eMichael Bussmann\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://atap.lbl.gov/accelerator-modeling-program/\" rel=\"nofollow\"\u003eAccelerator Modeling Program (AMP)\u003c/a\u003e at LBNL, led by \u003ca href=\"https://github.com/jlvay\"\u003eJean-Luc Vay\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://crd.lbl.gov/divisions/scidata/sdm/\" rel=\"nofollow\"\u003eScientific Data Management (SDM)\u003c/a\u003e at LBNL, led by \u003ca href=\"https://github.com/john18\"\u003eKesheng (John) Wu\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFurther thanks go to improvements and contributions from:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/CFGrote\"\u003eCarsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)\u003c/a\u003e:\ndraft of our Python unit tests\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/StanczakDominik\"\u003eDominik Sta\u0144czak (Warsaw University of Technology)\u003c/a\u003e:\ndocumentation improvements\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mingwandroid\"\u003eRay Donnelly (Anaconda, Inc.)\u003c/a\u003e:\nsupport on conda packaging and libc++ quirks\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/amundson\"\u003eJames Amundson (FNAL)\u003c/a\u003e:\ncompile fix for newer compilers\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/psychocoderHPC\"\u003eRen\u00e9 Widera (HZDR)\u003c/a\u003e:\ndesign improvements for initial API design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/erikzenker\"\u003eErik Zenker (HZDR)\u003c/a\u003e:\ndesign improvements for initial API design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/sbastrakov\"\u003eSergei Bastrakov (HZDR)\u003c/a\u003e:\ndocumentation improvements (windows)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/RemiLehe\"\u003eR\u00e9mi Lehe (LBNL)\u003c/a\u003e:\npackage integration testing on macOS and Linux\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/LDAmorim\"\u003eL\u00edgia Diana Amorim (LBNL)\u003c/a\u003e:\npackage integration testing on macOS\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/KseniaBastrakova\"\u003eKseniia Bastrakova (HZDR)\u003c/a\u003e:\ncompatibility testing\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/PrometheusPi\"\u003eRichard Pausch (HZDR)\u003c/a\u003e:\ncompatibility testing, documentation improvements\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pordyna\"\u003ePawe\u0142 Ordyna (HZDR)\u003c/a\u003e:\nreport on NVCC warnings\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/dmitry-ganyushin\"\u003eDmitry Ganyushin (ORNL)\u003c/a\u003e:\nDask prototyping \u0026amp; ADIOS2 benchmarking\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jakirkham\"\u003eJohn Kirkham (NVIDIA)\u003c/a\u003e:\nDask guidance \u0026amp; reviews\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/eschnett\"\u003eErik Schnetter (PITP)\u003c/a\u003e:\nC++ API bug fixes\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jeanbez\"\u003eJean Luca Bez (LBNL)\u003c/a\u003e:\nHDF5 performance tuning\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/bernhardmgruber\"\u003eBernhard Manfred Gruber (CERN)\u003c/a\u003e:\nCMake fix for parallel HDF5\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/DerNils-git\"\u003eNils Schild (IPP)\u003c/a\u003e:\nCMake improvements for subprojects\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eGrants\u003c/h3\u003e\u003ca id=\"user-content-grants\" class=\"anchor\" aria-label=\"Permalink: Grants\" href=\"#grants\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe openPMD-api authors acknowledge support via the following programs.\nSupported by the CAMPA collaboration, a project of the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research and Office of High Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\nPreviously supported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration).\nThis project has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 654220.\nThis work was partially funded by the Center of Advanced Systems Understanding (CASUS), which is financed by Germany\u0027s Federal Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism (SMWK) with tax funds on the basis of the budget approved by the Saxon State Parliament.\nSupported by the HElmholtz Laser Plasma Metadata Initiative (HELPMI) project (ZT-I-PF-3-066), funded by the \"Initiative and Networking Fund\" of the Helmholtz Association in the framework of the \"Helmholtz Metadata Collaboration\" project call 2022.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eTransitive Contributions\u003c/h3\u003e\u003ca id=\"user-content-transitive-contributions\" class=\"anchor\" aria-label=\"Permalink: Transitive Contributions\" href=\"#transitive-contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eopenPMD-api stands on the shoulders of giants and we are grateful for the following projects included as direct dependencies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ornladios/ADIOS2\"\u003eADIOS2\u003c/a\u003e by \u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003eS. Klasky, N. Podhorszki, W.F. Godoy (ORNL), team, collaborators\u003c/a\u003e and \u003ca href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/catchorg/Catch2\"\u003eCatch2\u003c/a\u003e by \u003ca href=\"https://github.com/philsquared\"\u003ePhil Nash\u003c/a\u003e, \u003ca href=\"https://github.com/horenmar\"\u003eMartin Ho\u0159e\u0148ovsk\u00fd\u003c/a\u003e and \u003ca href=\"https://github.com/catchorg/Catch2/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eHDF5 by \u003ca href=\"https://www.hdfgroup.org\" rel=\"nofollow\"\u003ethe HDF group\u003c/a\u003e and community\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/nlohmann/json\"\u003ejson\u003c/a\u003e by \u003ca href=\"https://github.com/nlohmann\"\u003eNiels Lohmann\u003c/a\u003e and \u003ca href=\"https://github.com/nlohmann/json/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ToruNiina/toml11\"\u003etoml11\u003c/a\u003e by \u003ca href=\"https://github.com/ToruNiina\"\u003eToru Niina\u003c/a\u003e and \u003ca href=\"https://github.com/ToruNiina/toml11#Contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11\"\u003epybind11\u003c/a\u003e by \u003ca href=\"https://github.com/wjakob\"\u003eWenzel Jakob (EPFL)\u003c/a\u003e and \u003ca href=\"https://github.com/pybind/pybind11/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eall contributors to the evolution of modern C++ and early library preview developers, e.g. \u003ca href=\"https://github.com/mpark\"\u003eMichael Park (Facebook)\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ethe \u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003eCMake build system\u003c/a\u003e and \u003ca href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003epackaging support by the \u003ca href=\"https://conda-forge.org\" rel=\"nofollow\"\u003econda-forge\u003c/a\u003e, \u003ca href=\"https://pypi.org\" rel=\"nofollow\"\u003ePyPI\u003c/a\u003e and \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e communities, among others\u003c/li\u003e\n\u003cli\u003ethe \u003ca href=\"https://github.com/openPMD/openPMD-standard\"\u003eopenPMD-standard\u003c/a\u003e by \u003ca href=\"https://github.com/ax3l\"\u003eAxel Huebl (HZDR, now LBNL)\u003c/a\u003e and \u003ca href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 132,
    "subscribers_count": 11,
    "topics": [
      "openpmd",
      "openscience",
      "hdf5",
      "adios",
      "mpi",
      "hpc",
      "research",
      "file-handling",
      "python3",
      "opendata",
      "metadata",
      "cpp17"
    ],
    "updated_at": 1710013090.0
  },
  {
    "data_format": 2,
    "description": "CS infrastructure components for HPC applications",
    "filenames": [
      "scripts/spack/devtools_configs/blueos_3_ppc64le_ib_p9/spack.yaml",
      "scripts/spack/configs/toss_4_x86_64_ib_cray/spack.yaml",
      "scripts/spack/configs/docker/ubuntu20_cuda/spack.yaml",
      "scripts/spack/configs/darwin/spack.yaml",
      "scripts/spack/configs/docker/ubuntu20/spack.yaml",
      "scripts/spack/configs/blueos_3_ppc64le_ib_p9/spack.yaml",
      "scripts/spack/configs/linux_ubuntu_20/spack.yaml",
      "scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml"
    ],
    "full_name": "LLNL/axom",
    "latest_release": "v0.9.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/share/axom/logo/axom_logo_transparent.png?raw=true\"\u003e\u003cimg src=\"/share/axom/logo/axom_logo_transparent.png?raw=true\" width=\"250\" valign=\"middle\" alt=\"Axom\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/h1\u003e\u003ca id=\"\" class=\"anchor\" aria-label=\"Permalink: \" href=\"#\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://dev.azure.com/axom/axom/_build/latest?definitionId=1\u0026amp;branchName=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2e86a2917fe6af2683654deb988253bb0643de772d9b144c44792e0dee8267c5/68747470733a2f2f6465762e617a7572652e636f6d2f61786f6d2f61786f6d2f5f617069732f6275696c642f7374617475732f4c4c4e4c2e61786f6d3f6272616e63684e616d653d646576656c6f70\" alt=\"Azure Pipelines Build Status\" data-canonical-src=\"https://dev.azure.com/axom/axom/_apis/build/status/LLNL.axom?branchName=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://axom.readthedocs.io/en/develop/?badge=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8723959c981c1cd7fa64e597cc73c149d9a423922f12dcaa572a9ddf30bb689c/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f61786f6d2f62616467652f3f76657273696f6e3d646576656c6f70\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/axom/badge/?version=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/LLNL/axom/blob/develop/LICENSE\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/aa27bfae9200ad81b9c64e82edafa3aef061e2b59e4089eb0841297d510d5db9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d425344253230332d2d436c617573652d626c75652e737667\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/License-BSD%203--Clause-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/LLNL/axom/releases/latest\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6532c8239e2f1f30a988264904337c2f4904be4b6867e704eb39e6c48a4b6f0f/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f4c4c4e4c2f61786f6d2e737667\" alt=\"GitHub release\" data-canonical-src=\"https://img.shields.io/github/release/LLNL/axom.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAxom provides robust, flexible software infrastructure for the development of multi-physics applications and computational tools.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLatest docs on Develop branch: \u003ca href=\"https://axom.readthedocs.io\" rel=\"nofollow\"\u003ehttps://axom.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTo access docs for other versions: \u003ca href=\"https://readthedocs.org/projects/axom/\" rel=\"nofollow\"\u003ehttps://readthedocs.org/projects/axom/\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eGetting Involved\u003c/h2\u003e\u003ca id=\"user-content-getting-involved\" class=\"anchor\" aria-label=\"Permalink: Getting Involved\" href=\"#getting-involved\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAxom is an open-source project and we welcome contributions from the community.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMailing List\u003c/h2\u003e\u003ca id=\"user-content-mailing-list\" class=\"anchor\" aria-label=\"Permalink: Mailing List\" href=\"#mailing-list\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe project maintains two email lists:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0027\u003ca href=\"mailto:axom-users@llnl.gov\"\u003eaxom-users@llnl.gov\u003c/a\u003e\u0027 is how Axom users can contact developers for questions, report issues, etc.\u003c/li\u003e\n\u003cli\u003e\u0027\u003ca href=\"mailto:axom-dev@llnl.gov\"\u003eaxom-dev@llnl.gov\u003c/a\u003e\u0027 is for communication among team members.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributions\u003c/h2\u003e\u003ca id=\"user-content-contributions\" class=\"anchor\" aria-label=\"Permalink: Contributions\" href=\"#contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe welcome all kinds of contributions: new features, bug fixes, documentation edits.\u003c/p\u003e\n\u003cp\u003eTo contribute, make a \u003ca href=\"https://github.com/llnl/axom/compare\"\u003epull request\u003c/a\u003e, with \u003ccode\u003edevelop\u003c/code\u003e\nas the destination branch. We use CI testing and your branch must pass these tests before\nbeing merged.\u003c/p\u003e\n\u003cp\u003eFor more information, see the \u003ca href=\"https://github.com/llnl/axom/blob/develop/CONTRIBUTING.md\"\u003econtributing guide\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThanks to all of Axom\u0027s\n\u003ca href=\"https://github.com/llnl/axom/graphs/contributors\"\u003econtributors\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCopyright (c) 2017-2024, Lawrence Livermore National Security, LLC.\nProduced at the Lawrence Livermore National Laboratory.\u003c/p\u003e\n\u003cp\u003eCopyrights and patents in the Axom project are retained by contributors.\nNo copyright assignment is required to contribute to Axom.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"./LICENSE\"\u003eLICENSE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eUnlimited Open Source - BSD 3-clause Distribution\n\u003ccode\u003eLLNL-CODE-741217\u003c/code\u003e \u003ccode\u003eOCEC-17-187\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSPDX usage\u003c/h2\u003e\u003ca id=\"user-content-spdx-usage\" class=\"anchor\" aria-label=\"Permalink: SPDX usage\" href=\"#spdx-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIndividual files contain SPDX tags instead of the full license text.\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are available here: \u003ca href=\"https://spdx.org/licenses/\" rel=\"nofollow\"\u003ehttps://spdx.org/licenses/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFiles that are licensed as BSD 3-Clause contain the following\ntext in the license header:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSPDX-License-Identifier: (BSD-3-Clause)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExternal Packages\u003c/h2\u003e\u003ca id=\"user-content-external-packages\" class=\"anchor\" aria-label=\"Permalink: External Packages\" href=\"#external-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAxom bundles some of its external dependencies in its repository.  These\npackages are covered by various permissive licenses.  A summary listing\nfollows.  See the license included with each package for full details.\u003c/p\u003e\n\u003cp\u003ePackageName: BLT\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/blt\"\u003ehttps://github.com/LLNL/blt\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: CLI11\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/CLIUtils/CLI11\"\u003ehttps://github.com/CLIUtils/CLI11\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: fmt\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/fmtlib/fmt\"\u003ehttps://github.com/fmtlib/fmt\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: MIT License\u003c/p\u003e\n\u003cp\u003ePackageName: radiuss-spack-configs\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/radiuss-spack-configs\"\u003ehttps://github.com/LLNL/radiuss-spack-configs\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: MIT License\u003c/p\u003e\n\u003cp\u003ePackageName: sol\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/ThePhD/sol2\"\u003ehttps://github.com/ThePhD/sol2\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: MIT License\u003c/p\u003e\n\u003cp\u003ePackageName: sparsehash\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/sparsehash/sparsehash\"\u003ehttps://github.com/sparsehash/sparsehash\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: uberenv\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/uberenv\"\u003ehttps://github.com/LLNL/uberenv\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n",
    "stargazers_count": 137,
    "subscribers_count": 23,
    "topics": [
      "hpc",
      "parallel-computing",
      "llnl",
      "cpp",
      "c-plus-plus",
      "app-infrastructure",
      "radiuss",
      "fortran"
    ],
    "updated_at": 1710280076.0
  },
  {
    "data_format": 2,
    "description": "SpECTRE is a code for multi-scale, multi-physics problems in astrophysics and gravitational physics.",
    "filenames": [
      "support/DevEnvironments/spack.yaml"
    ],
    "full_name": "sxs-collaboration/spectre",
    "latest_release": "v2024.03.19",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2bb6ac78e5a9f4f688a6a066cc71b62012101802fcdb478e6e4c6b6ec75dc694/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\" alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/df0b1027d8e161884d7089c2577d4b43a35b394555a9517f5de6ae0e20bf7162/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d32302d626c75652e737667\" alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-20-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/sxs-collaboration/spectre/actions\"\u003e\u003cimg src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\" alt=\"Build Status\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/cdc7257a23f3adea0c43ac91edd0780291ab8375e99198bfe972bce4934c9b61/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/sxs-collaboration/spectre\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/424f1f41d024411d8bd1fe155067d6e555c47bd1e69a71fd0936d8f10a9e0447/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2024.03.19\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/07542c17acaf28c9e4c3f980cc52917a236bdde2d32cf06a7c8262eb4f659e48/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032342e30332e31392d696e666f726d6174696f6e616c\" alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2024.03.19-informational\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.10841324\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/202934bc5070a708e03afc32c33b9b1a3fdce089a3b0f12d6e07e50d54f37cbe/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e31303834313332342e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.10841324.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWhat is SpECTRE?\u003c/h2\u003e\u003ca id=\"user-content-what-is-spectre\" class=\"anchor\" aria-label=\"Permalink: What is SpECTRE?\" href=\"#what-is-spectre\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSpECTRE is an open-source code for multi-scale, multi-physics problems\nin astrophysics and gravitational physics. In the future, we hope that\nit can be applied to problems across discipline boundaries in fluid\ndynamics, geoscience, plasma physics, nuclear physics, and\nengineering. It runs at petascale and is designed for future exascale\ncomputers.\u003c/p\u003e\n\u003cp\u003eSpECTRE is being developed in support of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae, and\ngamma-ray bursts.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCiting SpECTRE\u003c/h2\u003e\u003ca id=\"user-content-citing-spectre\" class=\"anchor\" aria-label=\"Permalink: Citing SpECTRE\" href=\"#citing-spectre\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease cite SpECTRE in any publications that make use of its code or data. Cite\nthe latest version that you use in your publication. The DOI for this version\nis:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDOI: \u003ca href=\"https://doi.org/10.5281/zenodo.10841324\" rel=\"nofollow\"\u003e10.5281/zenodo.10841324\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can cite this BibTeX entry in your publication:\u003c/p\u003e\n\n\n\u003cdiv class=\"highlight highlight-text-bibtex\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e@software\u003c/span\u003e{\u003cspan class=\"pl-en\"\u003espectrecode\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eauthor\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eDeppe, Nils and Throwe, William and Kidder, Lawrence E. and Vu,\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eNils L. and Nelli, Kyle C. and Armaza, Crist\\\u0027obal and Bonilla, Marceline S. and\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eH\\\u0027ebert, Fran\\c{c}ois and Kim, Yoonsoo and Kumar, Prayush and Lovelace,\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eGeoffrey and Macedo, Alexandra and Moxon, Jordan and O\u0027Shea, Eamonn and\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003ePfeiffer, Harald P. and Scheel, Mark A. and Teukolsky, Saul A. and Wittek,\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eNikolas A. and others\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003etitle\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\\texttt{SpECTRE v2024.03.19}\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eversion\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e2024.03.19\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003epublisher\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZenodo\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003edoi\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e10.5281/zenodo.10841324\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eurl\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ehttps://spectre-code.org\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003ehowpublished\u003c/span\u003e =\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\\href{https://doi.org/10.5281/zenodo.10841324}{10.5281/zenodo.10841324}\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003elicense\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eMIT\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eyear\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e2024\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003emonth\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e3\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n}\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eTo aid reproducibility of your scientific results with SpECTRE, we recommend you\nkeep track of the version(s) you used and report this information in your\npublication. We also recommend you supply the YAML input files and, if\nappropriate, any additional C++ code you wrote to compile SpECTRE executables as\nsupplemental material to the publication.\u003c/p\u003e\n\u003cp\u003eSee our \u003ca href=\"https://spectre-code.org/publication_policies.html\" rel=\"nofollow\"\u003epublication policy\u003c/a\u003e\nfor more information.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eViewing Documentation\u003c/h2\u003e\u003ca id=\"user-content-viewing-documentation\" class=\"anchor\" aria-label=\"Permalink: Viewing Documentation\" href=\"#viewing-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe documentation can be viewed at \u003ca href=\"https://spectre-code.org/\" rel=\"nofollow\"\u003ehttps://spectre-code.org/\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 139,
    "subscribers_count": 16,
    "topics": [],
    "updated_at": 1711680509.0
  },
  {
    "data_format": 2,
    "description": "Serac is a high order nonlinear thermomechanical simulation code",
    "filenames": [
      "scripts/spack/devtools_configs/blueos_3_ppc64le_ib_p9/spack.yaml",
      "scripts/spack/configs/docker/ubuntu20/spack.yaml",
      "scripts/spack/configs/linux_ubuntu_22/spack.yaml",
      "scripts/spack/configs/linux_ubuntu_20/spack.yaml",
      "scripts/spack/devtools_configs/toss_4_x86_64_ib/spack.yaml"
    ],
    "full_name": "LLNL/serac",
    "latest_release": null,
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/share/serac/logo/serac-logo-blue.png?raw=true\"\u003e\u003cimg src=\"/share/serac/logo/serac-logo-blue.png?raw=true\" width=\"150\" alt=\"Serac\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/h1\u003e\u003ca id=\"\" class=\"anchor\" aria-label=\"Permalink: \" href=\"#\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://dev.azure.com/llnl-serac/serac/_build/latest?definitionId=1\u0026amp;branchName=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/037c40c18167c2f51c531cab7f2ecc11128fd35f9de4f86069791798bc097f0a/68747470733a2f2f6465762e617a7572652e636f6d2f6c6c6e6c2d73657261632f73657261632f5f617069732f6275696c642f7374617475732f4c4c4e4c2e73657261633f6272616e63684e616d653d646576656c6f70\" alt=\"Build Status\" data-canonical-src=\"https://dev.azure.com/llnl-serac/serac/_apis/build/status/LLNL.serac?branchName=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://serac.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00fb910871e6439ba9db142b3d74c89f026b9fcc43c7d2c2e3a8aba22f0f47f0/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f73657261632f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/serac/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/LLNL/serac\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6024e4752532a6f5e3c2922749432d9a05441d39d538e4817c32971a0b65cac8/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f73657261632f6272616e63682f646576656c6f702f67726170682f62616467652e7376673f746f6b656e3d444f344b464d504e4d30\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/LLNL/serac/branch/develop/graph/badge.svg?token=DO4KFMPNM0\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"./LICENSE\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/46ab19c2c0af8a73620c60806fe8512ebe91f6db426ef8cf0855c60f04c4e5dd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d425344253230332d2d436c617573652d626c75652e737667\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-BSD%203--Clause-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSerac is a 3D implicit nonlinear thermal-structural simulation code. Its primary purpose is to investigate multiphysics\nabstraction strategies and implicit finite element-based algorithm development for emerging computing architectures.\nIt also serves as a proxy-app for LLNL\u0027s Smith code and heavily leverages the \u003ca href=\"https://mfem.org/\" rel=\"nofollow\"\u003eMFEM finite element library\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThis project is under heavy development and is currently a pre-alpha release. Functionality and interfaces may change rapidly\nas development progresses.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBuild, run, and design documentation can be found at \u003ca href=\"https://serac.readthedocs.io\" rel=\"nofollow\"\u003ereadthedocs\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSource documentation can be found \u003ca href=\"https://serac.readthedocs.io/en/latest/doxygen/html/index.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributions\u003c/h2\u003e\u003ca id=\"user-content-contributions\" class=\"anchor\" aria-label=\"Permalink: Contributions\" href=\"#contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe welcome all kinds of contributions: new features, bug fixes, and documentation edits.\u003c/p\u003e\n\u003cp\u003eFor more information, see the \u003ca href=\"./CONTRIBUTING.md\"\u003econtributing guide\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCopyright (c) 2019-2023, Lawrence Livermore National Security, LLC.\nProduced at the Lawrence Livermore National Laboratory.\u003c/p\u003e\n\u003cp\u003eCopyrights and patents in the Serac project are retained by contributors.\nNo copyright assignment is required to contribute to Serac.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"./LICENSE\"\u003eLICENSE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eUnlimited Open Source - BSD 3-clause Distribution\u003cbr\u003e\n\u003ccode\u003eLLNL-CODE-805541\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSPDX usage\u003c/h2\u003e\u003ca id=\"user-content-spdx-usage\" class=\"anchor\" aria-label=\"Permalink: SPDX usage\" href=\"#spdx-usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIndividual files contain SPDX tags instead of the full license text.\nThis enables machine processing of license information based on the SPDX\nLicense Identifiers that are available here: \u003ca href=\"https://spdx.org/licenses/\" rel=\"nofollow\"\u003ehttps://spdx.org/licenses/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eFiles that are licensed as BSD 3-Clause contain the following\ntext in the license header:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSPDX-License-Identifier: (BSD-3-Clause)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExternal Packages\u003c/h2\u003e\u003ca id=\"user-content-external-packages\" class=\"anchor\" aria-label=\"Permalink: External Packages\" href=\"#external-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSerac bundles some of its external dependencies in its repository.  These\npackages are covered by various permissive licenses.  A summary listing\nfollows.  See the license included with each package for full details.\u003c/p\u003e\n\u003cp\u003ePackageName: Axom\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/axom\"\u003ehttps://github.com/LLNL/axom\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: BLT\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/blt\"\u003ehttps://github.com/LLNL/blt\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: MFEM\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/mfem/mfem\"\u003ehttps://github.com/mfem/mfem\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n\u003cp\u003ePackageName: radiuss-spack-configs\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/radiuss-spack-configs\"\u003ehttps://github.com/LLNL/radiuss-spack-configs\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: MIT License\u003c/p\u003e\n\u003cp\u003ePackageName: uberenv\u003cbr\u003e\nPackageHomePage: \u003ca href=\"https://github.com/LLNL/uberenv\"\u003ehttps://github.com/LLNL/uberenv\u003c/a\u003e\u003cbr\u003e\nPackageLicenseDeclared: BSD-3-Clause\u003c/p\u003e\n",
    "stargazers_count": 163,
    "subscribers_count": 12,
    "topics": [
      "math-physics",
      "finite-elements",
      "proxy-application",
      "simulation",
      "cpp"
    ],
    "updated_at": 1711967169.0
  },
  {
    "data_format": 2,
    "description": "Simplified Data Exchange for HPC Simulations",
    "filenames": [
      "scripts/uberenv_configs/old_configs/spack_envs/llnl/quartz/spack.yaml"
    ],
    "full_name": "LLNL/conduit",
    "latest_release": "v0.9.1",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eConduit\u003c/h1\u003e\u003ca id=\"user-content-conduit\" class=\"anchor\" aria-label=\"Permalink: Conduit\" href=\"#conduit\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eConduit: Simplified Data Exchange for HPC Simulations\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eConduit is an open source project from Lawrence Livermore National Laboratory that provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. It is used for data coupling between packages in-core, serialization, and I/O tasks.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://travis-ci.org/LLNL/conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4ddb4916bd808b8f77cba61d4a4cd362a21cdf555317057bb16cf3da3f753c5/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67\" alt=\"Travis CI Build Status\" data-canonical-src=\"https://travis-ci.org/LLNL/conduit.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://ci.appveyor.com/project/cyrush/conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4db6fd786cd4661ce078846f65bcf387639c4d7a4df8e96f31d5ea7a92ccedd1/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565\" alt=\"Appveyor Build Status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop\u0026amp;svg=true\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/LLNL/conduit?branch=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/85653a998250a89385c38ab30cd69a0863fb3ce4ab51acfea5f00dba6a9fbfdb/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://scan.coverity.com/projects/llnl-conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3a960144de3b74d3b847bc708a61395b4ee0e3c6ad64de7835bccb4a0e31d9e0/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31\" alt=\"Static Analysis Status\" data-canonical-src=\"https://scan.coverity.com/projects/8426/badge.svg?flat=1\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDocumentation\u003c/h1\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo get started building and using Conduit, check out the full documentation:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://llnl-conduit.readthedocs.io/\" rel=\"nofollow\"\u003ehttp://llnl-conduit.readthedocs.io/\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSource Repo\u003c/h1\u003e\u003ca id=\"user-content-source-repo\" class=\"anchor\" aria-label=\"Permalink: Source Repo\" href=\"#source-repo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eConduit\u0027s source is hosted on GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/llnl/conduit\"\u003ehttps://github.com/llnl/conduit\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLicense\u003c/h1\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eConduit is released under a BSD-style license - for detailed license info, refer to:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://llnl-conduit.readthedocs.io/en/latest/licenses.html\" rel=\"nofollow\"\u003ehttps://llnl-conduit.readthedocs.io/en/latest/licenses.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eor the following files in the Conduit source tree:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/LICENSE\"\u003eLICENSE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/thirdparty_licenses.md\"\u003ethirdparty_licenses.md\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eChangelog\u003c/h1\u003e\u003ca id=\"user-content-changelog\" class=\"anchor\" aria-label=\"Permalink: Changelog\" href=\"#changelog\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/CHANGELOG.md\"\u003eChangelog\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 191,
    "subscribers_count": 22,
    "topics": [
      "hpc",
      "scientific-computing",
      "cpp",
      "fortran",
      "python",
      "llnl",
      "json",
      "yaml",
      "hdf5",
      "radiuss",
      "data-management"
    ],
    "updated_at": 1711757214.0
  },
  {
    "data_format": 2,
    "description": "GEOS Simulation Framework",
    "filenames": [
      "scripts/pygeosx_configs/toss_4_x86_64_ib/spack.yaml",
      "scripts/pygeosx_configs/blueos_3_ppc64le_ib_p9/spack.yaml"
    ],
    "full_name": "GEOS-DEV/GEOS",
    "latest_release": "v1.0.1",
    "readme": "\u003cp\u003e\u003ca href=\"https://zenodo.org/badge/latestdoi/131810578\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9c0760932d168b68bde7fb1623f1727acad25f306fc5609a1b38d392888ae7dd/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f3133313831303537382e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/131810578.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/github/GEOS-DEV/GEOS\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1c8900c4ee778b688be56b9a8e1618325ce04dbe7f3db14f033e4af735640493/68747470733a2f2f636f6465636f762e696f2f6769746875622f47454f532d4445562f47454f532f67726170682f62616467652e7376673f746f6b656e3d30565445485051473538\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/github/GEOS-DEV/GEOS/graph/badge.svg?token=0VTEHPQG58\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg\"\u003e\u003cimg src=\"https://github.com/GEOS-DEV/GEOS/actions/workflows/ci_tests.yml/badge.svg\" alt=\"CI\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://geosx-geosx.readthedocs-hosted.com/en/latest/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b6c2fc0d68b06cb042bb53ee5bcc4f8d55169fc19297eeff32d0cf3ca8b9b91/68747470733a2f2f72656164746865646f63732e636f6d2f70726f6a656374732f67656f73782d67656f73782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"docs\" data-canonical-src=\"https://readthedocs.com/projects/geosx-geosx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWelcome to the GEOS project!\u003c/h2\u003e\u003ca id=\"user-content-welcome-to-the-geos-project\" class=\"anchor\" aria-label=\"Permalink: Welcome to the GEOS project!\" href=\"#welcome-to-the-geos-project\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eGEOS is a simulation framework for modeling coupled flow, transport, and geomechanics\nin the subsurface.  The code provides advanced solvers for a number of target applications,\nincluding\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecarbon sequestration,\u003c/li\u003e\n\u003cli\u003egeothermal energy,\u003c/li\u003e\n\u003cli\u003eand similar systems.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eA key focus of the project is achieving scalable performance on current and next-generation\nhigh performance computing systems.  We do this through a portable programming model and research into scalable algorithms.\u003c/p\u003e\n\u003cp\u003eYou may want to browse our\n\u003ca href=\"https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Publications.html\" rel=\"nofollow\"\u003epublications\u003c/a\u003e\npage for more details on the HPC, numerics,\nand applied engineering components of this effort.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eOur documentation is hosted \u003ca href=\"https://geosx-geosx.readthedocs-hosted.com/en/latest/?\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eWho develops GEOS?\u003c/h2\u003e\u003ca id=\"user-content-who-develops-geos\" class=\"anchor\" aria-label=\"Permalink: Who develops GEOS?\" href=\"#who-develops-geos\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eGEOS is an open source project and is developed by a community of researchers at\nseveral institutions.  The bulk of the code has been written by contributors from\nfour main organizations:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLawrence Livermore National Laboratory,\u003c/li\u003e\n\u003cli\u003eStanford University,\u003c/li\u003e\n\u003cli\u003eTotalEnergies,\u003c/li\u003e\n\u003cli\u003eChevron\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSee our\n\u003ca href=\"https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Contributors.html\" rel=\"nofollow\"\u003eauthors\u003c/a\u003e\nand\n\u003ca href=\"https://geosx-geosx.readthedocs-hosted.com/en/latest/docs/sphinx/Acknowledgements.html\" rel=\"nofollow\"\u003eacknowledgements\u003c/a\u003e\npage for more details.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eHow does GEOS relate to the earlier GEOS code?\u003c/h2\u003e\u003ca id=\"user-content-how-does-geos-relate-to-the-earlier-geos-code\" class=\"anchor\" aria-label=\"Permalink: How does GEOS relate to the earlier GEOS code?\" href=\"#how-does-geos-relate-to-the-earlier-geos-code\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eGEOS is the offshoot of an earlier code developed at LLNL also called GEOS.  The new\ncode differs from our previous efforts in two important ways:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThis new code GEOS uses a fundamentally different programming model to achieve\nhigh performance on the complicated chip architectures common on today\u0027s\nHPC systems.  This code is ready for exascale-class systems as they are delivered.\u003c/li\u003e\n\u003cli\u003eThe new code has been released as an open-source effort to encourage collaboration\nwithin the research and industrial community.  See the release notes below\nfor details of the \u003ca href=\"./LICENSE\"\u003eLGPL 2.1 License\u003c/a\u003e that has been adopted.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRelease\u003c/h2\u003e\u003ca id=\"user-content-release\" class=\"anchor\" aria-label=\"Permalink: Release\" href=\"#release\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor release details and restrictions, please read the \u003ca href=\"./LICENSE\"\u003eLICENSE\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003eFor copyrights, please read the \u003ca href=\"./COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003eFor contributors, please read the \u003ca href=\"./CONTRIBUTORS\"\u003eCONTRIBUTORS\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003eFor acknowledgements, please read the \u003ca href=\"./ACKNOWLEDGEMENTS\"\u003eACKNOWLEDGEMENTS\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003eFor notice, please read the \u003ca href=\"./NOTICE\"\u003eNOTICE\u003c/a\u003e file.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eLLNL-CODE-812638\u003c/code\u003e  \u003ccode\u003eOCEC-18-021\u003c/code\u003e\u003c/p\u003e\n",
    "stargazers_count": 194,
    "subscribers_count": 31,
    "topics": [
      "hpc",
      "reservoir-simulation",
      "geomechanics",
      "gpu",
      "carbon-storage",
      "llnl"
    ],
    "updated_at": 1710717902.0
  },
  {
    "data_format": 2,
    "description": "HPC solver for nonlinear optimization problems",
    "filenames": [
      "scripts/platforms/newell/spack.yaml",
      "scripts/platforms/marianas/spack.yaml",
      "scripts/platforms/summit/spack.yaml"
    ],
    "full_name": "LLNL/hiop",
    "latest_release": "v1.0.3",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eHiOp - HPC solver for optimization\u003c/h1\u003e\u003ca id=\"user-content-hiop---hpc-solver-for-optimization\" class=\"anchor\" aria-label=\"Permalink: HiOp - HPC solver for optimization\" href=\"#hiop---hpc-solver-for-optimization\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\"\u003e\u003cimg src=\"https://github.com/LLNL/hiop/workflows/tests/badge.svg\" alt=\"tests\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHiOp is an optimization solver for solving certain mathematical optimization problems expressed as nonlinear programming problems. HiOp is a lightweight HPC solver that leverages application\u0027s existing data parallelism to parallelize the optimization iterations by using specialized parallel linear algebra kernels.\u003c/p\u003e\n\u003cp\u003ePlease cite the user manual whenever HiOp is used:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@TECHREPORT{hiop_techrep,\n  title={{HiOp} -- {U}ser {G}uide},\n  author={Petra, Cosmin G. and Chiang, NaiYuan and Jingyi Wang},\n  year={2018},\n  institution = {Center for Applied Scientific Computing, Lawrence Livermore National Laboratory},\n  number = {LLNL-SM-743591}\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn addition, when using the quasi-Newton solver please cite:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@ARTICLE{Petra_18_hiopdecomp,\ntitle = {A memory-distributed quasi-Newton solver for nonlinear programming problems with a small number of general constraints},\njournal = {Journal of Parallel and Distributed Computing},\nvolume = {133},\npages = {337-348},\nyear = {2019},\nissn = {0743-7315},\ndoi = {https://doi.org/10.1016/j.jpdc.2018.10.009},\nurl = {https://www.sciencedirect.com/science/article/pii/S0743731518307731},\nauthor = {Cosmin G. Petra},\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand when using the the PriDec solver please cite:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@article{wang2023,\n  archivePrefix = {arXiv},\n  author = {J. Wang and C. G. Petra},\n  title = {A Sequential Quadratic Programming Algorithm for Nonsmooth Problems with Upper-$\\mathcal{C}^2$ Objective},\n  journal = {SIAM Journal on Optimization},\n  volume = {33},\n  number = {3},\n  pages = {2379-2405},\n  year = {2023},\n  doi = {10.1137/22M1490995}\n}\n@INPROCEEDINGS{wang2021,\n  author={J. Wang and N. Chiang and C. G. Petra},\n  booktitle={2021 20th International Symposium on Parallel and Distributed Computing (ISPDC)}, \n  title={An asynchronous distributed-memory optimization solver for two-stage stochastic programming problems}, \n  year={2021},\n  volume={},\n  number={},\n  pages={33-40},\n  doi={10.1109/ISPDC52870.2021.9521613}}\n }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuild/install instructions\u003c/h2\u003e\u003ca id=\"user-content-buildinstall-instructions\" class=\"anchor\" aria-label=\"Permalink: Build/install instructions\" href=\"#buildinstall-instructions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHiOp uses a CMake-based build system. A standard build can be done by invoking in the \u0027build\u0027 directory the following\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake ..\n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make \n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make \u003cspan class=\"pl-c1\"\u003etest\u003c/span\u003e\n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis sequence will build HiOp, run integrity and correctness tests, and install the headers and the library in the directory \u0027_dist-default-build\u0027 in HiOp\u0027s root directory.\u003c/p\u003e\n\u003cp\u003eCommand \u003ccode\u003emake test\u003c/code\u003e runs extensive tests of the various modules of HiOp to check integrity and correctness. The tests suite range from unit testing to solving concrete optimization problems and checking the performance of HiOp solvers on these problems against known solutions. By default \u003ccode\u003emake test\u003c/code\u003e runs \u003ccode\u003empirun\u003c/code\u003e locally, which may not work on some HPC machines. For these HiOp allows using \u003ccode\u003ebsub\u003c/code\u003e to schedule \u003ccode\u003emake test\u003c/code\u003e on the compute nodes; to enable this, the use should use \u003cem\u003e-DHIOP_TEST_WITH_BSUB=ON\u003c/em\u003e with cmake when building and run \u003ccode\u003emake test\u003c/code\u003e in a bsub shell session, for example,\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebsub -P your_proj_name -nnodes 1 -W 30\nmake test\nCTRL+D\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe installation can be customized using the standard CMake options. For example, one can provide an alternative installation directory for HiOp by using\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake -DCMAKE_INSTALL_PREFIX=/usr/lib/hiop ..\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSelected HiOp-specific build options\u003c/h3\u003e\u003ca id=\"user-content-selected-hiop-specific-build-options\" class=\"anchor\" aria-label=\"Permalink: Selected HiOp-specific build options\" href=\"#selected-hiop-specific-build-options\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eEnable/disable MPI: \u003cem\u003e-DHIOP_USE_MPI=[ON/OFF]\u003c/em\u003e (by default ON)\u003c/li\u003e\n\u003cli\u003eGPU support: \u003cem\u003e-DHIOP_USE_GPU=ON\u003c/em\u003e. MPI can be either off or on. For more build system options related to GPUs, see \"Dependencies\" section below.\u003c/li\u003e\n\u003cli\u003eEnable/disable \"developer mode\" build that enforces more restrictive compiler rules and guidelines: \u003cem\u003e-DHIOP_DEVELOPER_MODE=ON\u003c/em\u003e. This option is by default off.\u003c/li\u003e\n\u003cli\u003eAdditional checks and self-diagnostics inside HiOp meant to detect abnormalities and help to detect bugs and/or troubleshoot problematic instances: \u003cem\u003e-DHIOP_DEEPCHECKS=[ON/OFF]\u003c/em\u003e (by default ON). Disabling HIOP_DEEPCHECKS usually provides 30-40% execution speedup in HiOp. For full strength, it is recommended to use HIOP_DEEPCHECKS with debug builds. With non-debug builds, in particular the ones that disable the assert macro, HIOP_DEEPCHECKS does not perform all checks and, thus, may overlook potential issues.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake -DHIOP_USE_MPI=ON -DHIOP_DEEPCHECKS=ON ..\n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make \n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make \u003cspan class=\"pl-c1\"\u003etest\u003c/span\u003e\n$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e make install\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eOther useful options to use with CMake\u003c/h3\u003e\u003ca id=\"user-content-other-useful-options-to-use-with-cmake\" class=\"anchor\" aria-label=\"Permalink: Other useful options to use with CMake\" href=\"#other-useful-options-to-use-with-cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cem\u003e-DCMAKE_BUILD_TYPE=Release\u003c/em\u003e will build the code with the optimization flags on\u003c/li\u003e\n\u003cli\u003e\n\u003cem\u003e-DCMAKE_CXX_FLAGS=\"-O3\"\u003c/em\u003e will enable a high level of compiler code optimization\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eDependencies\u003c/h3\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-label=\"Permalink: Dependencies\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eA complete list of dependencies is maintained \u003ca href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/hiop/package.py\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor a minimal build, HiOp requires LAPACK and BLAS. These dependencies are automatically detected by the build system. MPI is optional and by default enabled. To disable use cmake option \u0027-DHIOP_USE_MPI=OFF\u0027.\u003c/p\u003e\n\u003cp\u003eHiOp has support for NVIDIA \u003cstrong\u003eGPU-based computations\u003c/strong\u003e via CUDA and Magma. To enable the use of GPUs, use cmake with \u0027-DHIOP_USE_GPU=ON\u0027. The build system will automatically search for CUDA Toolkit. For non-standard CUDA Toolkit installations, use \u0027-DHIOP_CUDA_LIB_DIR=/path\u0027 and \u0027-DHIOP_CUDA_INCLUDE_DIR=/path\u0027. For \"very\" non-standard CUDA Toolkit installations, one can specify the directory of cuBlas libraries as well with \u0027-DHIOP_CUBLAS_LIB_DIR=/path\u0027.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eUsing RAJA and Umpire portability libraries\u003c/h3\u003e\u003ca id=\"user-content-using-raja-and-umpire-portability-libraries\" class=\"anchor\" aria-label=\"Permalink: Using RAJA and Umpire portability libraries\" href=\"#using-raja-and-umpire-portability-libraries\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePortability libraries allow running HiOp\u0027s linear algebra either on host (CPU) or a device (GPU). RAJA and Umpire are disabled by default. You can turn them on together by passing \u003ccode\u003e-DHIOP_USE_RAJA=ON\u003c/code\u003e to CMake. If the two libraries are not automatically found, specify their installation directories like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake -DHIOP_USE_RAJA=ON -DRAJA_DIR=/path/to/raja/dir -Dumpire_DIR=/path/to/umpire/dir\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf the GPU support is enabled, RAJA will run all HiOp linear algebra kernels on GPU, otherwise RAJA will run the kernels on CPU using an OpenMP execution policy.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSupport for GPU computations\u003c/h3\u003e\u003ca id=\"user-content-support-for-gpu-computations\" class=\"anchor\" aria-label=\"Permalink: Support for GPU computations\" href=\"#support-for-gpu-computations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWhen GPU support is on, HiOp requires Magma linear solver library and CUDA Toolkit. Both are detected automatically in most cases. The typical cmake command to enable GPU support in HiOp is\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake -DHIOP_USE_GPU=ON ..\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWhen Magma is not detected, one can specify its location by passing \u003ccode\u003e-DHIOP_MAGMA_DIR=/path/to/magma/dir\u003c/code\u003e to cmake.\u003c/p\u003e\n\u003cp\u003eFor custom CUDA Toolkit installations, the locations to the (missing/not found) CUDA libraries can be specified to cmake via \u003ccode\u003e-DNAME=/path/cuda/directory/lib\u003c/code\u003e, where \u003ccode\u003eNAME\u003c/code\u003e can be any of\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eCUDA_cublas_LIBRARY\nCUDA_CUDART_LIBRARY\nCUDA_cudadevrt_LIBRARY\nCUDA_cusparse_LIBRARY\nCUDA_cublasLt_LIBRARY\nCUDA_nvblas_LIBRARY\nCUDA_culibos_LIBRARY\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBelow is an example for specifiying \u003ccode\u003ecuBlas\u003c/code\u003e, \u003ccode\u003ecuBlasLt\u003c/code\u003e, and \u003ccode\u003envblas\u003c/code\u003e libraries, which were \u003ccode\u003eNOT_FOUND\u003c/code\u003e because of a non-standard CUDA Toolkit instalation:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e cmake -DHIOP_USE_GPU=ON -DCUDA_cublas_LIBRARY=/usr/local/cuda-10.2/targets/x86_64-linux/lib/lib64 -DCUDA_cublasLt_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/ -DCUDA_nvblas_LIBRARY=/export/home/petra1/work/installs/cuda10.2.89/targets/x86_64-linux/lib/ .. \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make -j \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eA detailed example on how to compile HiOp straight of the box on \u003ccode\u003esummit.olcf.ornl.gov\u003c/code\u003e is available \u003ca href=\"README_summit.md\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eRAJA and UMPIRE dependencies are usually detected by HiOp\u0027s cmake build system.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eKron reduction\u003c/h3\u003e\u003ca id=\"user-content-kron-reduction\" class=\"anchor\" aria-label=\"Permalink: Kron reduction\" href=\"#kron-reduction\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eKron reduction functionality of HiOp is disabled by default. One can enable it by using\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e rm -rf \u003cspan class=\"pl-k\"\u003e*\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e cmake -DHIOP_WITH_KRON_REDUCTION=ON -DUMFPACK_DIR=/Users/petra1/work/installs/SuiteSparse-5.7.1 -DMETIS_DIR=/Users/petra1/work/installs/metis-4.0.3 .. \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make -j \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e make install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMetis is usually detected automatically and needs not be specified under normal circumstances.\u003c/p\u003e\n\u003cp\u003eUMFPACK (part of SuiteSparse) and METIS need to be provided as shown above.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eInterfacing with HiOp\u003c/h1\u003e\u003ca id=\"user-content-interfacing-with-hiop\" class=\"anchor\" aria-label=\"Permalink: Interfacing with HiOp\" href=\"#interfacing-with-hiop\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHiOp supports three types of optimization problems, each with a separate input formats in the form of the C++ interfaces \u003ccode\u003ehiopInterfaceDenseConstraints\u003c/code\u003e,\u003ccode\u003ehiopInterfaceSparse\u003c/code\u003e and \u003ccode\u003ehiopInterfaceMDS\u003c/code\u003e. These interfaces are specified in \u003ca href=\"src/Interface/hiopInterface.hpp\"\u003ehiopInterface.hpp\u003c/a\u003e and documented and discussed as well in the \u003ca href=\"doc/hiop_usermanual.pdf\"\u003euser manual\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003ccode\u003ehiopInterfaceDenseConstraints\u003c/code\u003e interface\u003c/em\u003e supports NLPs with \u003cstrong\u003ebillions\u003c/strong\u003e of variables with and without bounds but only limited number (\u0026lt;100) of general, equality and inequality constraints. The underlying algorithm is a limited-memory quasi-Newton interior-point method and generally scales well computationally (but it may not algorithmically) on thousands of cores. This interface uses MPI for parallelization\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003ccode\u003ehiopInterfaceSparse\u003c/code\u003e interface\u003c/em\u003e supports general sparse and large-scale NLPs. This functionality is similar to that of the state-of-the-art \u003ca href=\"https://github.com/coin-or/Ipopt\"\u003eIpopt\u003c/a\u003e (without being as robust and flexible as Ipopt is). Acceleration for this class of problems can be achieved via OpenMP or CUDA, however, this is work in progress and you are encouraged to contact HiOp\u0027s developers for up-to-date information.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003ccode\u003ehiopInterfaceMDS\u003c/code\u003e interface\u003c/em\u003e supports mixed dense-sparse NLPs and achives parallelization using GPUs and RAJA portability abstraction layer.\u003c/p\u003e\n\u003cp\u003eMore information on the HiOp interfaces are \u003ca href=\"src/Interface/README.md\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eRunning HiOp tests and applications\u003c/h2\u003e\u003ca id=\"user-content-running-hiop-tests-and-applications\" class=\"anchor\" aria-label=\"Permalink: Running HiOp tests and applications\" href=\"#running-hiop-tests-and-applications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHiOp is using NVBlas library when built with CUDA support. If you don\u0027t specify\nlocation of the \u003ccode\u003envblas.conf\u003c/code\u003e configuration file, you may get an annoying\nwarnings. HiOp provides default \u003ccode\u003envblas.conf\u003c/code\u003e file and installs it at the same\nlocation as HiOp libraries. To use it, set environment variable as\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e NVBLAS_CONFIG_FILE=\u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003ehiop install dir\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e/lib/nvblas.conf\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor, if you are using C-shell, as\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ setenv NVBLAS_CONFIG_FILE \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003ehiop install dir\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e/lib/nvblas.conf\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eExisting issues\u003c/h2\u003e\u003ca id=\"user-content-existing-issues\" class=\"anchor\" aria-label=\"Permalink: Existing issues\" href=\"#existing-issues\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUsers are highly encouraged to report any issues they found from using HiOp.\nOne known issue is that there is some minor inconsistence between HiOp and linear package STRUMPACK.\nWhen STRUMPACK is compiled with MPI (and Scalapack), user must set flag \u003ccode\u003eHIOP_USE_MPI\u003c/code\u003e to \u003ccode\u003eON\u003c/code\u003e when compiling HiOp.\nOtherwise HiOp won\u0027t load MPI module and will return an error when links to STRUMPACK, since the later one requires a valid MPI module.\nSimilarly, if both Magma and STRUMPACK are linked to HiOp, user must guarantee the all the packages are compiled by the same CUDA compiler.\nUser can check other issues and their existing status from \u003ca href=\"https://github.com/LLNL/hiop\"\u003ehttps://github.com/LLNL/hiop\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAcknowledgments\u003c/h2\u003e\u003ca id=\"user-content-acknowledgments\" class=\"anchor\" aria-label=\"Permalink: Acknowledgments\" href=\"#acknowledgments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHiOp has been developed under the financial support of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDepartment of Energy, Office of Advanced Scientific Computing Research (ASCR): Exascale Computing Program (ECP) and Applied Math Program.\u003c/li\u003e\n\u003cli\u003eDepartment of Energy, Advanced Research Projects Agency-Energy (ARPA\u2011E)\u003c/li\u003e\n\u003cli\u003eLawrence Livermore National Laboratory Institutional Scientific Capability Portfolio (ISCP)\u003c/li\u003e\n\u003cli\u003eLawrence Livermore National Laboratory, through the LDRD program\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eContributors\u003c/h1\u003e\u003ca id=\"user-content-contributors\" class=\"anchor\" aria-label=\"Permalink: Contributors\" href=\"#contributors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eHiOp is written by Cosmin G. Petra (\u003ca href=\"mailto:petra1@llnl.gov\"\u003epetra1@llnl.gov\u003c/a\u003e), Nai-Yuan Chiang (\u003ca href=\"mailto:chiang7@llnl.gov\"\u003echiang7@llnl.gov\u003c/a\u003e), and Jingyi \"Frank\" Wang (\u003ca href=\"mailto:wang125@llnl.gov\"\u003ewang125@llnl.gov\u003c/a\u003e) from LLNL and has received important contributions from Asher Mancinelli (PNNL), Slaven Peles (ORNL), Cameron Rutherford (PNNL), Jake K. Ryan (PNNL), and Michel Schanen (ANL).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eCopyright\u003c/h1\u003e\u003ca id=\"user-content-copyright\" class=\"anchor\" aria-label=\"Permalink: Copyright\" href=\"#copyright\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eCopyright (c) 2017-2021, Lawrence Livermore National Security, LLC. All rights reserved. Produced at the Lawrence Livermore National Laboratory. LLNL-CODE-742473. HiOp is free software; you can modify it and/or redistribute it under the terms of the BSD 3-clause license. See \u003ca href=\"/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e and \u003ca href=\"/LICENSE\"\u003eLICENSE\u003c/a\u003e for complete copyright and license information.\u003c/p\u003e\n",
    "stargazers_count": 204,
    "subscribers_count": 17,
    "topics": [
      "hpc",
      "nonlinear-optimization",
      "nonlinear-programming",
      "nonlinear-programming-algorithms",
      "interior-point-method",
      "parallel-programming",
      "mpi",
      "bfgs",
      "quasi-newton",
      "constrained-optimization",
      "solver",
      "optimization",
      "acopf",
      "gpu-support",
      "cuda",
      "math-physics",
      "radiuss",
      "interior-point-optimizer",
      "nonsmooth-optimization",
      "rocm"
    ],
    "updated_at": 1709694068.0
  },
  {
    "data_format": 2,
    "description": "WarpX is an advanced, time-based electromagnetic \u0026 electrostatic Particle-In-Cell code.",
    "filenames": [
      "Tools/machines/lxplus-cern/spack.yaml"
    ],
    "full_name": "ECP-WarpX/WarpX",
    "latest_release": "24.03",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eWarpX\u003c/h1\u003e\u003ca id=\"user-content-warpx\" class=\"anchor\" aria-label=\"Permalink: WarpX\" href=\"#warpx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1\u0026amp;branchName=development\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9322d48a1ef1d4949f877013f47676310b6774d0e750615ed2cecf4ec2d7eca3/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74\" alt=\"Code Status development\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3f9d8b15b61c55052071805cafa2f278fb4a2dd4372acb0b7ee63620a65d15e7/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Installation Tests\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly\u0026amp;label=nightly%20packages\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://warpx.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0beb5ef504dfacd71832068b9c4531e7dd837a2f801f3bd55ff8b36d89aa6951/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/warpx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/86f588e641d33c0f54e4fe9494235aea0398003a5d5eac847133d2da8b9fccea/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a1d9ef8a9eb8118b83cc146955af7c9fc3721e5d80e4eed459eb558c6f596b73/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/ECP-WarpX/WarpX/discussions\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1160c9b83b0d3a01df9f7384cf556f0cc92a304b6496afd616efe2ca068089b0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d64697363757373696f6e732d74757271756f6973652e737667\" alt=\"Discussions\" data-canonical-src=\"https://img.shields.io/badge/chat-discussions-turquoise.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://warpx.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7c6c831719f56e623098e7f1f2b33ddb6a2631cf671cea4be57880273b2af16c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/ECP-WarpX/WarpX/compare/development\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1a6f861e33c8f14a8e4119adb07d24668e8d2fc773bf9e83829fa62732251df0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667\" alt=\"GitHub commits since last release\" data-canonical-src=\"https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.exascaleproject.org/research/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3d90ef357e4a9590dd0cf06c730de1b41c601ebe7ca2eb10beee42fd406053e0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765\" alt=\"Exascale Computing Project\" data-canonical-src=\"https://img.shields.io/badge/supported%20by-ECP-orange\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e7fb0089d24cbec0919fda1a3406c2bb3ddfc5e6e70c69420c4d6b59e4136f37/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\" alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/647bd6e78a284bf08e53bd7038f210400464c5a5ed8beedd3391512ebb2aaefb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\" alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/deef4595319047065a3c59d5ff7692b42be5957ed2bf39e6b690d9c5a13f1e7e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License WarpX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.4571577\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/65fec93ca7f0122e02994a743ea08ff139c085192a9e94ac627b966b8058e3b4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.1109/SC41404.2022.00008\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c5d3f4fb049eab48f59d6f9bb6e34570ad406e2691f5dcda65167dec4ad0d08a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667\" alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWarpX is an advanced \u003cstrong\u003eelectromagnetic \u0026amp; electrostatic Particle-In-Cell\u003c/strong\u003e code.\nIt supports many features including Perfectly-Matched Layers (PML), mesh refinement, and the boosted-frame technique.\u003c/p\u003e\n\u003cp\u003eWarpX is a \u003cem\u003ehighly-parallel and highly-optimized code\u003c/em\u003e, which can run on GPUs and multi-core CPUs, and includes load balancing capabilities.\nWarpX scales to the world\u0027s largest supercomputers and was awarded the \u003ca href=\"https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/\" rel=\"nofollow\"\u003e2022 ACM Gordon Bell Prize\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://picmi-standard.github.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92c92f18fa93aab19301f6c1d609d4dbba6d2833f441adfc8aba95635e8a1186/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICMI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22PICMI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openPMD.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d8faa5dd5c10a3a416f5b36feb83f7d0b22a040a13c4becf398c5660b4c94ccb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22openPMD%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://yt-project.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/532de0ea13712920c2b2f644fe425c87090486691a9b3de2bdc0a121552707ad/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"yt-project\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22yt%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn order to learn how to install and run the code, please see the online documentation:\n\u003ca href=\"https://warpx.readthedocs.io\" rel=\"nofollow\"\u003ehttps://warpx.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTo contact the developers, feel free to open an issue on this repo, or visit our discussions page at \u003ca href=\"https://github.com/ECP-WarpX/WarpX/discussions\"\u003ehttps://github.com/ECP-WarpX/WarpX/discussions\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/68712ecce18e982a6a11d855fdcb3fd647bee2a05e6e550581d66f1c78e58b89/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22AMReX%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://picsar.net\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4c0961a0bcc2c026f3f3a20ea7dbd4f24c13f21991a145baf86385a18d2c408a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICSAR\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22PICSAR%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe112996993c23975e07c48ba70423ea5c9b716b2d60fbdcd8dfa620bd282ec3/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD-api\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22openPMD-api%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c6a0dd9275b2fd160addee7f2d74ef088bb97a1598c29eab5bee1e9f153ae44a/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"ADIOS\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22ADIOS%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.hdfgroup.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/27d0f337e406f972927563ea93742777c7ce42cd1e4f5d204f9aa14b4e2e52d6/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"HDF5\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22HDF5%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"http://www.ascent-dav.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0f2432f4678daa26dd446599ac3b93b3f25aa44d69c4d5e7db4fced70fe7a34/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"Ascent\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22Ascent%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://sensei-insitu.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/648674b11909d214d16a356f6a8c4f7d7d5578185f95afcc4e23327c5e4cff63/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"SENSEI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22SENSEI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur workflow is described in \u003ca href=\"CONTRIBUTING.rst\"\u003eCONTRIBUTING.rst\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCopyright Notice\u003c/h2\u003e\u003ca id=\"user-content-copyright-notice\" class=\"anchor\" aria-label=\"Permalink: Copyright Notice\" href=\"#copyright-notice\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWarpX Copyright (c) 2018, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Innovation \u0026amp; Partnerships Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.\u003c/p\u003e\n\u003cp\u003ePlease see the full license agreement in \u003ca href=\"LICENSE.txt\"\u003eLICENSE.txt\u003c/a\u003e.\nThe SPDX license identifier is \u003ccode\u003eBSD-3-Clause-LBNL\u003c/code\u003e.\u003c/p\u003e\n",
    "stargazers_count": 248,
    "subscribers_count": 14,
    "topics": [
      "laser",
      "plasma",
      "physics",
      "gpu",
      "simulation",
      "particle-in-cell",
      "pic",
      "research"
    ],
    "updated_at": 1711749495.0
  },
  {
    "data_format": 2,
    "description": "An application-focused API for memory management on NUMA \u0026 GPU architectures",
    "filenames": [
      ".spack_env/darwin/spack.yaml"
    ],
    "full_name": "LLNL/Umpire",
    "latest_release": "v2024.02.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/16f93148e0fba6da82ea7e29bc163792e4adfa6d97964ef301f27bb5804fe1ce/68747470733a2f2f63646e2e7261776769742e636f6d2f4c4c4e4c2f556d706972652f646576656c6f702f73686172652f756d706972652f6c6f676f2f756d706972652d6c6f676f2e706e67\" width=\"128\" valign=\"middle\" alt=\"Umpire\" data-canonical-src=\"https://cdn.rawgit.com/LLNL/Umpire/develop/share/umpire/logo/umpire-logo.png\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e  Umpire v2024.02.0\u003c/h1\u003e\u003ca id=\"user-content---umpire-v2024020\" class=\"anchor\" aria-label=\"Permalink:   Umpire v2024.02.0\" href=\"#--umpire-v2024020\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://travis-ci.com/LLNL/Umpire\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b035b6565b7e96277667acd970a34d855ba58259be899a270de459ba1a42393/68747470733a2f2f7472617669732d63692e636f6d2f4c4c4e4c2f556d706972652e7376673f6272616e63683d646576656c6f70\" alt=\"Travis Build Status\" data-canonical-src=\"https://travis-ci.com/LLNL/Umpire.svg?branch=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/davidbeckingsale/Umpire/_build/latest?definitionId=1\u0026amp;branchName=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67d5cb2c08560bb4582131e7ab385863faee5e7f89266ef73c47bdc7c0ff4544/68747470733a2f2f6465762e617a7572652e636f6d2f64617669646265636b696e6773616c652f556d706972652f5f617069732f6275696c642f7374617475732f4c4c4e4c2e556d706972653f6272616e63684e616d653d646576656c6f70\" alt=\"Azure Pipelines Build Status\" data-canonical-src=\"https://dev.azure.com/davidbeckingsale/Umpire/_apis/build/status/LLNL.Umpire?branchName=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://umpire.readthedocs.io/en/develop/?badge=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c43adcc35db9b22246733d2caaad138c624a56e87031c1e8e5f72f0c3752d0f5/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f756d706972652f62616467652f3f76657273696f6e3d646576656c6f70\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/umpire/badge/?version=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/LLNL/Umpire\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/dec8e40b05ba312fc266977dc2ea2803d478e338856c3b8838437a8c72cf7264/68747470733a2f2f636f6465636f762e696f2f67682f4c4c4e4c2f556d706972652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/LLNL/Umpire/branch/develop/graph/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://gitter.im/LLNL/Umpire?utm_source=badge\u0026amp;utm_medium=badge\u0026amp;utm_campaign=pr-badge\u0026amp;utm_content=badge\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b97e5039e17f725e41c4f915579646596c1bee4d17b93bcd958360b41c38c4d8/68747470733a2f2f6261646765732e6769747465722e696d2f4c4c4e4c2f556d706972652e737667\" alt=\"Join the chat at https://gitter.im/LLNL/Umpire\" data-canonical-src=\"https://badges.gitter.im/LLNL/Umpire.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUmpire is a resource management library that allows the discovery, provision,\nand management of memory on machines with multiple memory devices like NUMA and GPUs.\u003c/p\u003e\n\u003cp\u003eUmpire uses CMake and BLT to handle builds. Since BLT is included as a\nsubmodule, first make sure you run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git submodule init \u0026amp;\u0026amp; git submodule update\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen, make sure that you have a modern compiler loaded, and the configuration is as\nsimple as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ mkdir build \u0026amp;\u0026amp; cd build\n$ cmake ..\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCMake will provide output about which compiler is being used. Once CMake has\ncompleted, Umpire can be built with Make:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ make\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor more advanced configuration you can use standard CMake variables.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDocumentation\u003c/h1\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBoth user and code documentation is available \u003ca href=\"http://umpire.readthedocs.io/\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe Umpire \u003ca href=\"https://umpire.readthedocs.io/en/develop/sphinx/tutorial.html\" rel=\"nofollow\"\u003etutorial\u003c/a\u003e provides a step by step introduction to Umpire features.\u003c/p\u003e\n\u003cp\u003eIf you have build problems, we have comprehensive \u003ca href=\"https://umpire.readthedocs.io/en/develop/sphinx/advanced_configuration.html\" rel=\"nofollow\"\u003ebuild system documentation\u003c/a\u003e too!\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eGetting Involved\u003c/h1\u003e\u003ca id=\"user-content-getting-involved\" class=\"anchor\" aria-label=\"Permalink: Getting Involved\" href=\"#getting-involved\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUmpire is an open-source project, and we welcome contributions from the community.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eMailing List\u003c/h2\u003e\u003ca id=\"user-content-mailing-list\" class=\"anchor\" aria-label=\"Permalink: Mailing List\" href=\"#mailing-list\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe Umpire mailing list is hosted on Google Groups, and is a great place to ask questions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://groups.google.com/forum/#!forum/umpire-users\" rel=\"nofollow\"\u003eUmpire Users Google Group\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributions\u003c/h2\u003e\u003ca id=\"user-content-contributions\" class=\"anchor\" aria-label=\"Permalink: Contributions\" href=\"#contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe welcome all kinds of contributions: new features, bug fixes, documentation edits; it\u0027s all great!\u003c/p\u003e\n\u003cp\u003eTo contribute, make a \u003ca href=\"https://github.com/LLNL/Umpire/compare\"\u003epull request\u003c/a\u003e, with \u003ccode\u003edevelop\u003c/code\u003e as the destination branch.\nWe use Travis to run CI tests, and your branch must pass these tests before being merged.\u003c/p\u003e\n\u003cp\u003eFor more information, see the \u003ca href=\"https://github.com/LLNL/Umpire/blob/develop/CONTRIBUTING.md\"\u003econtributing guide\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eAuthors\u003c/h1\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThanks to all of Umpire\u0027s\n\u003ca href=\"https://github.com/LLNL/Umpire/graphs/contributors\"\u003econtributors\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUmpire was created by David Beckingsale (\u003ca href=\"mailto:david@llnl.gov\"\u003edavid@llnl.gov\u003c/a\u003e).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCiting Umpire\u003c/h2\u003e\u003ca id=\"user-content-citing-umpire\" class=\"anchor\" aria-label=\"Permalink: Citing Umpire\" href=\"#citing-umpire\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eIf you are referencing Umpire in a publication, please use the following citation:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eD. Beckingsale, M. Mcfadden, J. Dahm, R. Pankajakshan and R. Hornung, \u003ca href=\"https://ieeexplore.ieee.org/document/8907404\" rel=\"nofollow\"\u003e\"Umpire: Application-Focused Management and Coordination of Complex Hierarchical Memory,\"\u003c/a\u003e in IBM Journal of Research and Development. 2019. doi: 10.1147/JRD.2019.2954403\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eRelease\u003c/h1\u003e\u003ca id=\"user-content-release\" class=\"anchor\" aria-label=\"Permalink: Release\" href=\"#release\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eUmpire is released under an MIT license. For more details, please see the\n\u003ca href=\"./LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"./RELEASE\"\u003eRELEASE\u003c/a\u003e files.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eLLNL-CODE-747640\u003c/code\u003e\n\u003ccode\u003eOCEC-18-031\u003c/code\u003e\u003c/p\u003e\n",
    "stargazers_count": 298,
    "subscribers_count": 16,
    "topics": [
      "hpc",
      "memory-management",
      "gpu",
      "blt",
      "portability",
      "radiuss",
      "cpp"
    ],
    "updated_at": 1711934119.0
  },
  {
    "data_format": 2,
    "description": "Modular C++ Toolkit for Performance Analysis and Logging. Profiling API and Tools for C, C++, CUDA, Fortran, and Python. The C++ template API is essentially a framework to creating tools: it is designed to provide a unifying interface for recording various performance measurements alongside data logging and interfaces to other tools.",
    "filenames": [
      "docker/cpu/spack.yaml"
    ],
    "full_name": "NERSC/timemory",
    "latest_release": "v3.2.3",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003etimemory\u003c/h1\u003e\u003ca id=\"user-content-timemory\" class=\"anchor\" aria-label=\"Permalink: timemory\" href=\"#timemory\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eTiming + Memory + Hardware Counter Utilities for C / C++ / CUDA / Python\u003c/h2\u003e\u003ca id=\"user-content-timing--memory--hardware-counter-utilities-for-c--c--cuda--python\" class=\"anchor\" aria-label=\"Permalink: Timing + Memory + Hardware Counter Utilities for C / C++ / CUDA / Python\" href=\"#timing--memory--hardware-counter-utilities-for-c--c--cuda--python\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://travis-ci.org/NERSC/timemory\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e771c5877a01c9ad3c5f9ac404fafcbb19d8f1647e63f72448851af6753c1d9c/68747470733a2f2f7472617669732d63692e6f72672f4e455253432f74696d656d6f72792e7376673f6272616e63683d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://travis-ci.org/NERSC/timemory.svg?branch=master\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://ci.appveyor.com/project/jrmadsen/timemory/branch/master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/310167bff27e3bfcff0843c04e63901359e8ed7672b1dabbe55d9fb4378d3ba7/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f38786b37326f6f7477736566693863312f6272616e63682f6d61737465723f7376673d74727565\" alt=\"Build status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/8xk72ootwsefi8c1/branch/master?svg=true\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/NERSC/timemory\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d4fac988b58c397453b2f2631379b0e47366ef6750df318103caabf9b65ca0c/68747470733a2f2f636f6465636f762e696f2f67682f4e455253432f74696d656d6f72792f6272616e63682f6d61737465722f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/NERSC/timemory/branch/master/graph/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/NERSC/timemory\"\u003etimemory on GitHub (Source code)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://timemory.readthedocs.io\" rel=\"nofollow\"\u003etimemory General Documentation (ReadTheDocs)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\u003etimemory Source Code Documentation (Doxygen)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://cdash.nersc.gov/index.php?project=TiMemory\" rel=\"nofollow\"\u003etimemory Testing Dashboard (CDash)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/NERSC/timemory-tutorials\"\u003etimemory Tutorials\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=K1Pazcw7zVo\" rel=\"nofollow\"\u003eECP 2021 Tutorial Day 1 (YouTube)\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=-zIpZDiwrmI\" rel=\"nofollow\"\u003eECP 2021 Tutorial Day 2 (YouTube)\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/NERSC/timemory/wiki\"\u003etimemory Wiki\u003c/a\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eGitHub\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003egit clone https://github.com/NERSC/timemory.git\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ePyPi\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003epip install timemory\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack install timemory\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003econda-forge\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003econda install -c conda-forge timemory\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://anaconda.org/conda-forge/timemory\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/13d88311b8a3ad78d2eef315c0144a27a104d75e9a610a215d6fc1251318275d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7265636970652d74696d656d6f72792d677265656e2e737667\" alt=\"Conda Recipe\" data-canonical-src=\"https://img.shields.io/badge/recipe-timemory-green.svg\" style=\"max-width: 100%;\"\u003e \u003cimg src=\"https://camo.githubusercontent.com/533b6f62d054e5318ac8873adf8b287aee649fa0b56ac1c1de77b09f4e00b2aa/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f74696d656d6f72792e737667\" alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/timemory.svg\" style=\"max-width: 100%;\"\u003e \u003cimg src=\"https://camo.githubusercontent.com/bafca219a0c269a4ab94502e87e4a06788840125f4b0bf838158aaf5eb141c18/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f74696d656d6f72792e737667\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/timemory.svg\" style=\"max-width: 100%;\"\u003e \u003cimg src=\"https://camo.githubusercontent.com/978fa080053b7937c5fb17a7bd59e5be69923086146a430e861f1dda4cb0eb9e/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f706e2f636f6e64612d666f7267652f74696d656d6f72792e737667\" alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/conda/pn/conda-forge/timemory.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePurpose\u003c/h2\u003e\u003ca id=\"user-content-purpose\" class=\"anchor\" aria-label=\"Permalink: Purpose\" href=\"#purpose\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe goal of timemory is to create an open-source performance measurement and analyis package\nwith modular and reusable components which can be used to adapt to any existing C/C++\nperformance measurement and analysis API and is arbitrarily extendable by users within their\napplication.\nTimemory is not just another profiling tool, it is a profling \u003cem\u003etoolkit\u003c/em\u003e which streamlines building custom\nprofiling tools through modularity and then utilizes the toolkit to provides several pre-built tools.\u003c/p\u003e\n\u003cp\u003eIn other words, timemory provides many pre-built tools, libraries, and interfaces but, due to it\u0027s modularity,\ncodes can re-use only individual pieces -- such as the classes for measuring different timing intervals, memory usage,\nand hardware counters -- without the timemory \"runtime management\".\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding and Installing\u003c/h2\u003e\u003ca id=\"user-content-building-and-installing\" class=\"anchor\" aria-label=\"Permalink: Building and Installing\" href=\"#building-and-installing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTimemory uses a standard CMake installation.\nSeveral installation examples can be found in the \u003ca href=\"https://github.com/NERSC/timemory/wiki/Installation-Examples\"\u003eWiki\u003c/a\u003e. See the \u003ca href=\"https://timemory.readthedocs.io/en/develop/installation.html\" rel=\"nofollow\"\u003einstallation documentation\u003c/a\u003e for detailed information on the CMake options.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eDocumentation\u003c/h2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe full documentation is available at \u003ca href=\"https://timemory.readthedocs.io\" rel=\"nofollow\"\u003etimemory.readthedocs.io\u003c/a\u003e.\nDetailed source documentation is provided in the \u003ca href=\"https://timemory.readthedocs.io/en/latest/doxygen-docs/\" rel=\"nofollow\"\u003edoygen\u003c/a\u003e\nsection of the full documentation.\nTutorials are available in the \u003ca href=\"https://github.com/NERSC/timemory-tutorials\"\u003egithub.com/NERSC/timemory-tutorials\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eOverview\u003c/h2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-label=\"Permalink: Overview\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003e\u003cem\u003eThe primary objective of the timemory is the development of a common framework for binding together software\nmonitoring code (i.e. performance analysis, debugging, logging) into a compact and highly-efficient interface.\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTimemory arose out of the need for a universal adapator kit for the various APIs provided several existing tools\nand a straight-forward and intuitive method for creating new tools. Timemory makes it possible to bundle\ntogether deterministic performance measurements, statistical performance\nmeasurements (i.e. sampling), debug messages, data logging, and data validation into the same interface for\ncustom application-specific software monitoring interfaces, easily building tools like \u003ccode\u003etime\u003c/code\u003e,\n\u003ccode\u003enetstat\u003c/code\u003e, instrumentation profilers, sampling profilers, and writing implementations for MPI-P, MPI-T, OMPT,\nKokkosP, etc. Furthermore, timemory can forward its markers to several third-party profilers such as\n\u003ca href=\"https://github.com/RRZE-HPC/likwid\"\u003eLIKWID\u003c/a\u003e, \u003ca href=\"https://github.com/LLNL/Caliper\"\u003eCaliper\u003c/a\u003e,\n\u003ca href=\"https://www.cs.uoregon.edu/research/tau/home.php\" rel=\"nofollow\"\u003eTAU\u003c/a\u003e, \u003ca href=\"https://github.com/gperftools/gperftools\"\u003egperftools\u003c/a\u003e,\n\u003ca href=\"https://perfetto.dev/docs/\" rel=\"nofollow\"\u003ePerfetto\u003c/a\u003e, VTune, Allinea-MAP, CrayPAT, Nsight-Systems, Nsight-Compute, and NVProf.\u003c/p\u003e\n\u003cp\u003eTimemory provides a front-end \u003ca href=\"https://timemory.readthedocs.io/en/develop/api/library.html\" rel=\"nofollow\"\u003eC/C++/Fortran API\u003c/a\u003e\nand \u003ca href=\"https://timemory.readthedocs.io/en/develop/api/python.html\" rel=\"nofollow\"\u003ePython API\u003c/a\u003e which allows arbitrary selection\nof 50+ different components from timers to hardware counters to interfaces with third-party tools. This is all\nbuilt generically from the toolkit API with type-safe bundles of tools such as:\n\u003ccode\u003ecomponent_tuple\u0026lt;wall_clock, papi_vector, nvtx_marker, user_bundle\u0026gt;\u003c/code\u003e\nwhere \u003ccode\u003ewall_clock\u003c/code\u003e is a wall-clock timer,\n\u003ccode\u003epapi_vector\u003c/code\u003e is a handle for hardware counters,\n\u003ccode\u003envxt_marker\u003c/code\u003e creates notations in the NVIDIA CUDA profilers, and\n\u003ccode\u003euser_bundle\u003c/code\u003e is a generic component which downstream users can insert more components into at runtime.\u003c/p\u003e\n\u003cp\u003ePerformance measurement components written with timemory are arbitrarily scalable up to any number of threads and\nprocesses and fully support intermixing different measurements at different locations within the program -- this\nuniquely enables timemory to be deployed to collect performance data at scale in HPC because highly detailed collection can\noccur at specific locations within the program where ubiquitous collection would simulatenously degrade performance\nsignificantly and require a prohibitive amount of memory.\u003c/p\u003e\n\u003cp\u003eTimemory can be used as a backend to bundle instrumentation and sampling tools together, support serialization to JSON/XML,\nand provide statistics among other uses. It can also be utilized as a front-end to invoke\ncustom instrumentation and sampling tools. Timemory uses the abstract term \"component\" for a structure\nwhich encapsulates some performance analysis operation. The structure might encapsulate function\ncalls to another tool, record timestamps for timing, log values provided by the application,\nprovide a operator for replacing a function in the code dynamically, audit the incoming arguments\nand/or outgoing return value from function, or just provide stubs which can be overloaded by the linker.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eVisualization and Analysis\u003c/h3\u003e\u003ca id=\"user-content-visualization-and-analysis\" class=\"anchor\" aria-label=\"Permalink: Visualization and Analysis\" href=\"#visualization-and-analysis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe native output format of timemory is JSON and text; other output formats such as XML are also supported.\nThe text format is intended to be human readable. The JSON data\nis intended for analysis and comes in two flavors: hierarchical and flat. Basic plotting capabilities are\navailable via \u003ccode\u003etimemory-plotting\u003c/code\u003e but users are highly encouraged to use \u003ca href=\"https://github.com/hatchet/hatchet\"\u003ehatchet\u003c/a\u003e\nfor analyzing the heirarchical JSON data in pandas dataframes. \u003ca href=\"https://github.com/hatchet/hatchet\"\u003eHatchet\u003c/a\u003e supports\nfiltering, unions, addition, subtractions, output to \u003ccode\u003edot\u003c/code\u003e and flamegraph formats, and an interactive Jupyter notebook.\nAt present, timemory supports 45+ metric types for analysis in Hatchet.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eCategories\u003c/h3\u003e\u003ca id=\"user-content-categories\" class=\"anchor\" aria-label=\"Permalink: Categories\" href=\"#categories\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThere are 4 primary categories in timemory: components, operations, bundlers, and storage. Components provide\nthe specifics of how to perform a particular behavior, operations provide the scaffold for requesting that\na component perform an operation in complex scenarios, bundlers group components into a single generic handle,\nand storage manages data collection over the lifetime of the application. When all four categories are combined,\ntimemory effectively resembles a standard performance analysis tool which passively collects data and provides\nreports and analysis at the termination of the application. Timemory, however, makes it \u003cem\u003every easy\u003c/em\u003e to subtract\nstorage from the equation and, in doing so, transforms timemory into a toolkit for customized data collection.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cstrong\u003e\u003cem\u003eComponents\u003c/em\u003e\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eIndividual classes which encapsulate one or more measurement, analysis, logging, or third-party library action(s)\u003c/li\u003e\n\u003cli\u003eAny data specific to one instance of performing the action is stored within the instance of the class\u003c/li\u003e\n\u003cli\u003eAny configuration data specific to that type is typically stored within static member functions which return a reference to the configuration data\u003c/li\u003e\n\u003cli\u003eThese classes are designed to support direct usage within other tools, libraries, etc.\u003c/li\u003e\n\u003cli\u003eExamples include:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003etim::component::wall_clock\u003c/code\u003e : a simple wall-clock timer\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::component::vtune_profiler\u003c/code\u003e : a simple component which turns the VTune Profiler on and off (when VTune is actively profiling application)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::component::data_tracker_integer\u003c/code\u003e : associates an integer values with a label as the application executes (e.g. number of loop iterations used somewhere)\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::component::papi_vector\u003c/code\u003e : uses the PAPI library to collect hardware-counters values\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::component::user_bundle\u003c/code\u003e : encapsulates an array of components which the user can dynamically manipulate during runtime\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e\u003cem\u003eOperations\u003c/em\u003e\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eTemplated classes whose primary purpose is to provide the implementation for performing some action on a component, e.g. \u003ccode\u003etim::operation::start\u0026lt;wall_clock\u0026gt;\u003c/code\u003e will attempt to call the \u003ccode\u003estart()\u003c/code\u003e member function on a \u003ccode\u003ewall_clock\u003c/code\u003e component instance\u003c/li\u003e\n\u003cli\u003eDefault implementations generally have one or two public functions: a constructor and/or a function call operator\n\u003cul\u003e\n\u003cli\u003eThese generally accept any/all arguments and use SFINAE to determine whether the operation can be performed with or without the given arguments (i.e. does \u003ccode\u003ewall_clock\u003c/code\u003e have a \u003ccode\u003estore(int)\u003c/code\u003e function? \u003ccode\u003estore()\u003c/code\u003e?)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOperations are (generally) not directly utilized by the user and are typically optimized out of the binary\u003c/li\u003e\n\u003cli\u003eExamples include:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003etim::operation::start\u003c/code\u003e : instruct a component to start collection\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::operation::sample\u003c/code\u003e : instruct a component to take individual measurement\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etim::operation::derive\u003c/code\u003e : extra data from other components if it is available\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e\u003cem\u003eBundlers\u003c/em\u003e\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eProvide a generic handle for multiple components\u003c/li\u003e\n\u003cli\u003eMember functions generally accept any/all arguments and use operations classes to correctly to handle differences between different capabilities of the components it is bundling\u003c/li\u003e\n\u003cli\u003eExamples include:\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003etim::auto_tuple\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etim::component_tuple\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etim::component_list\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etim::lightweight_tuple\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eVarious flavors provide different implicit behaviors and allocate memory differently\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eauto_tuple\u003c/code\u003e starts all components when constructed and stops all components when destructed whereas \u003ccode\u003ecomponent_tuple\u003c/code\u003e requires an explicit start\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ecomponent_tuple\u003c/code\u003e allocates all components on the stack and components are \"always on\" whereas \u003ccode\u003ecomponent_list\u003c/code\u003e allocates components on the heap and thus components can be activated/deactivated at runtime\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003elightweight_tuple\u003c/code\u003e does not implicitly perform any expensive actions, such as call-stack tracking in \"Storage\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e\u003cem\u003eStorage\u003c/em\u003e\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eProvides persistent storage for multiple instances of components over the lifetime of a thread in the application\u003c/li\u003e\n\u003cli\u003eResponsible for maintaining the hierarchy and order of component measurements, i.e. call-stack tracking\u003c/li\u003e\n\u003cli\u003eResponsible for combining component data from multiple threads and/or processes and outputting the results\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNOTE: \u003ccode\u003etim::lightweight_tuple\u003c/code\u003e is the recommended bundle for those seeking to use timemory as a toolkit for implementing custom tools and interfaces\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eFeatures\u003c/h2\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-label=\"Permalink: Features\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eC++ Template API\n\u003cul\u003e\n\u003cli\u003eModular and fully-customizable\u003c/li\u003e\n\u003cli\u003eAdheres to C++ standard template library paradigm of \"you don\u0027t pay for what you don\u0027t use\"\u003c/li\u003e\n\u003cli\u003eSimplifies and facilitates creation and implementation of performance measurement tools\n\u003cul\u003e\n\u003cli\u003eCreate your own instrumentation profiler\u003c/li\u003e\n\u003cli\u003eCreate your own instrumentation library\u003c/li\u003e\n\u003cli\u003eCreate your own sampling profiler\u003c/li\u003e\n\u003cli\u003eCreate your own sampling library\u003c/li\u003e\n\u003cli\u003eCreate your own execution wrappers\u003c/li\u003e\n\u003cli\u003eSupplement timemory-provided tools with your own custom component(s)\u003c/li\u003e\n\u003cli\u003eThread-safe data aggregation\u003c/li\u003e\n\u003cli\u003eAggregate collection over multiple processes (MPI and UPC++ support)\u003c/li\u003e\n\u003cli\u003eSerialization to text, JSON, XML\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eComponents are composable with other components\u003c/li\u003e\n\u003cli\u003eVariadic component bundlers which maintain complete type-safety\n\u003cul\u003e\n\u003cli\u003eComponents can be bundled together into a single handle without abstractions\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eComponents can store data in any valid C++ data type\u003c/li\u003e\n\u003cli\u003eComponents can return data in any valid C++ data type\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eC / C++ / CUDA / Fortran Library API\n\u003cul\u003e\n\u003cli\u003eStraight-forward collection of functions and macros for creating built-in performance analysis to your code\u003c/li\u003e\n\u003cli\u003eComponent collection can be arbitrarily inter-mixed\n\u003cul\u003e\n\u003cli\u003eE.g. collect \"A\" and \"B\" in one region, \"A\" and \"C\" in another region\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eComponent collection can be dynamically manipulated at runtime\n\u003cul\u003e\n\u003cli\u003eE.g. add/remove \"A\" at any point, on any thread, on any process\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePython API\n\u003cul\u003e\n\u003cli\u003eDecorators and context-managers for functions or regions in code\u003c/li\u003e\n\u003cli\u003ePython function profiling\u003c/li\u003e\n\u003cli\u003ePython line-by-line profiling\u003c/li\u003e\n\u003cli\u003eEvery component in \u003ccode\u003etimemory-avail\u003c/code\u003e is provided as a stand-alone Python class\n\u003cul\u003e\n\u003cli\u003eProvide low-overhead measurements for building your own Python profiling tools\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePython Analysis via \u003ca href=\"https://pandas.pydata.org/\" rel=\"nofollow\"\u003epandas\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eCommand-line Tools\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-avail/README.md\"\u003etimemory-avail\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eProvides available components, settings, and hardware counters\u003c/li\u003e\n\u003cli\u003eQuick API reference tool\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timem/README.md\"\u003etimem\u003c/a\u003e (UNIX)\n\u003cul\u003e\n\u003cli\u003eExtended version of UNIX \u003ccode\u003etime\u003c/code\u003e command-line tool that includes additional information on memory usage, context switches, and hardware counters\u003c/li\u003e\n\u003cli\u003eSupport collecting hardware counters (Linux-only, requires PAPI)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-run/README.md\"\u003etimemory-run\u003c/a\u003e (Linux)\n\u003cul\u003e\n\u003cli\u003eDynamic instrumentation profiling tool\u003c/li\u003e\n\u003cli\u003eSupports runtime instrumentation and binary re-writing\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-nvml/README.md\"\u003etimemory-nvml\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eData collection similar to \u003ccode\u003envidia-smi\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etimemory-python-profiler\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003ePython function profiler supporting all timemory components\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efrom timemory.profiler import Profile\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etimemory-python-trace\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003ePython line-by-line profiler supporting all timemory components\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efrom timemory.trace import Trace\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etimemory-python-line-profiler\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003ePython line-by-line profiler based on \u003ca href=\"https://pypi.org/project/line-profiler/\" rel=\"nofollow\"\u003eline-profiler\u003c/a\u003e package\u003c/li\u003e\n\u003cli\u003eExtended to use components: cpu-clock, memory-usage, context-switches, etc. (all components which collect scalar values)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003efrom timemory.line_profiler import LineProfiler\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eInstrumentation Libraries\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-mpip/README.md\"\u003etimemory-mpip\u003c/a\u003e: MPI Profiling Library (Linux-only)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-ncclp/README.md\"\u003etimemory-ncclp\u003c/a\u003e: NCCL Profiling Library (Linux-only)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-ompt/README.md\"\u003etimemory-ompt\u003c/a\u003e: OpenMP Profiling Library\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/timemory-compiler-instrument/README.md\"\u003etimemory-compiler-instrument\u003c/a\u003e: Compiler instrumentation Library\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"source/tools/kokkos-connector/README.md\"\u003ekokkos-connector\u003c/a\u003e: Kokkos Profiling Libraries\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSamples\u003c/h2\u003e\u003ca id=\"user-content-samples\" class=\"anchor\" aria-label=\"Permalink: Samples\" href=\"#samples\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eVarious macros are defined for C in \u003ca href=\"source/timemory/timemory.h\"\u003esource/timemory/compat/timemory_c.h\u003c/a\u003e\nand \u003ca href=\"source/timemory/variadic/macros.hpp\"\u003esource/timemory/variadic/macros.hpp\u003c/a\u003e. Numerous samples of\ntheir usage can be found in the examples.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSample C++ Template API\u003c/h3\u003e\u003ca id=\"user-content-sample-c-template-api\" class=\"anchor\" aria-label=\"Permalink: Sample C++ Template API\" href=\"#sample-c-template-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etimemory/timemory.hpp\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003enamespace\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ecomp\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e tim::component;\n\u003cspan class=\"pl-k\"\u003eusing\u003c/span\u003e \u003cspan class=\"pl-k\"\u003enamespace\u003c/span\u003e \u003cspan class=\"pl-en\"\u003etim\u003c/span\u003e\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e specific set of components\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eusing\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003especific_t\u003c/span\u003e = component_tuple\u0026lt;comp::wall_clock, comp::cpu_clock\u0026gt;;\n\u003cspan class=\"pl-k\"\u003eusing\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003egeneric_t\u003c/span\u003e  = component_tuple\u0026lt;comp::user_global_bundle\u0026gt;;\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e** argv)\n{\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e configure default settings\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003esettings::flat_profile\u003c/span\u003e() = \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e;\n    \u003cspan class=\"pl-c1\"\u003esettings::timing_units\u003c/span\u003e() = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emsec\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e initialize with cmd-line\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_init\u003c/span\u003e(argc, argv);\n    \n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e add argparse support\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_argparse\u003c/span\u003e(\u0026amp;argc, \u0026amp;argv);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e create a region \"main\"\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003especific_t\u003c/span\u003e m{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e };\n    m.\u003cspan class=\"pl-c1\"\u003estart\u003c/span\u003e();\n    m.\u003cspan class=\"pl-c1\"\u003estop\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e pause and resume collection globally\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003esettings::enabled\u003c/span\u003e() = \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e;\n    \u003cspan class=\"pl-c1\"\u003especific_t\u003c/span\u003e h{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ehidden\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e };\n    h.\u003cspan class=\"pl-c1\"\u003estart\u003c/span\u003e().\u003cspan class=\"pl-c1\"\u003estop\u003c/span\u003e();\n    \u003cspan class=\"pl-c1\"\u003esettings::enabled\u003c/span\u003e() = \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e;\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Add peak_rss component to specific_t\u003c/span\u003e\n    mpl::\u003cspan class=\"pl-c1\"\u003epush_back_t\u003c/span\u003e\u0026lt;\u003cspan class=\"pl-c1\"\u003especific_t\u003c/span\u003e, comp::peak_rss\u0026gt; wprss{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ewith peak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e };\n    \n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e create region collecting only peak_rss\u003c/span\u003e\n    component_tuple\u0026lt;comp::peak_rss\u0026gt; oprss{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eonly peak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e };\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e convert component_tuple to a type that starts/stops upon construction/destruction\u003c/span\u003e\n    {\n        scope::config _scope{};\n        \u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e)  _scope += scope::flat{};\n        \u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e) _scope += scope::timeline{};\n        \u003cspan class=\"pl-c1\"\u003econvert_t\u003c/span\u003e\u0026lt;\u003cspan class=\"pl-c1\"\u003especific_t\u003c/span\u003e, auto_tuple\u0026lt;\u0026gt;\u0026gt; scoped{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003escoped start/stop + flat\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, _scope };\n        \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e will yield auto_tuple\u0026lt;comp::wall_clock, comp::cpu_clock\u0026gt;\u003c/span\u003e\n    }\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e configure the generic bundle via set of strings\u003c/span\u003e\n    runtime::configure\u0026lt;comp::user_global_bundle\u0026gt;({ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ewall_clock\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e });\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e configure the generic bundle via set of enumeration ids\u003c/span\u003e\n    runtime::configure\u0026lt;comp::user_global_bundle\u0026gt;({ TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK });\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e configure the generic bundle via component instances\u003c/span\u003e\n    comp::user_global_bundle::configure\u0026lt;comp::page_rss, comp::papi_vector\u0026gt;();\n    \n    \u003cspan class=\"pl-c1\"\u003egeneric_t\u003c/span\u003e g{ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003egeneric\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, quirk::config\u0026lt;quirk::auto_start\u0026gt;{} };\n    g.\u003cspan class=\"pl-c1\"\u003estop\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Output the results\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_finalize\u003c/span\u003e();\n    \u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSample C / C++ Library API\u003c/h3\u003e\u003ca id=\"user-content-sample-c--c-library-api\" class=\"anchor\" aria-label=\"Permalink: Sample C / C++ Library API\" href=\"#sample-c--c-library-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etimemory/library.h\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etimemory/timemory.h\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e** argv)\n{\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e configure settings\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e overwrite       = \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n    \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e update_settings = \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e;\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e default to flat-profile\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_set_environ\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eTIMEMORY_FLAT_PROFILE\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eON\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, overwrite, update_settings);\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e force timing units\u003c/span\u003e\n    overwrite = \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e;\n    \u003cspan class=\"pl-c1\"\u003etimemory_set_environ\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eTIMEMORY_TIMING_UNITS\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emsec\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, overwrite, update_settings);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e initialize with cmd-line\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_init_library\u003c/span\u003e(argc, argv);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e check if inited, init with name\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(!\u003cspan class=\"pl-c1\"\u003etimemory_library_is_initialized\u003c/span\u003e())\n        \u003cspan class=\"pl-c1\"\u003etimemory_named_init_library\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eex-c\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e define the default set of components\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_set_default\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ewall_clock, cpu_clock\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e create a region \"main\"\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_push_region\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_pop_region\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e pause and resume collection globally\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_pause\u003c/span\u003e();\n    \u003cspan class=\"pl-c1\"\u003etimemory_push_region\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ehidden\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_pop_region\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ehidden\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_resume\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Add/remove component(s) to the current set of components\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_add_components\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_remove_components\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e get an identifier for a region and end it\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003euint64_t\u003c/span\u003e idx = \u003cspan class=\"pl-c1\"\u003etimemory_get_begin_record\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eindexed\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_end_record\u003c/span\u003e(idx);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e assign an existing identifier for a region\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_begin_record\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eindexed/2\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u0026amp;idx);\n    \u003cspan class=\"pl-c1\"\u003etimemory_end_record\u003c/span\u003e(idx);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e create region collecting a specific set of data\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_begin_record_enum\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eenum\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u0026amp;idx, TIMEMORY_PEAK_RSS, TIMEMORY_COMPONENTS_END);\n    \u003cspan class=\"pl-c1\"\u003etimemory_end_record\u003c/span\u003e(idx);\n\n    \u003cspan class=\"pl-c1\"\u003etimemory_begin_record_types\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etypes\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, \u0026amp;idx, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_end_record\u003c/span\u003e(idx);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e replace current set of components and then restore previous set\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_push_components\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epage_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003etimemory_pop_components\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c1\"\u003etimemory_push_components_enum\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, TIMEMORY_WALL_CLOCK, TIMEMORY_CPU_CLOCK);\n    \u003cspan class=\"pl-c1\"\u003etimemory_pop_components\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Output the results\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003etimemory_finalize_library\u003c/span\u003e();\n    \u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSample Fortran API\u003c/h3\u003e\u003ca id=\"user-content-sample-fortran-api\" class=\"anchor\" aria-label=\"Permalink: Sample Fortran API\" href=\"#sample-fortran-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-fortran\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eprogram\u003c/span\u003e fortran_example\n    use timemory\n    use iso_c_binding, only : C_INT64_T\n    \u003cspan class=\"pl-k\"\u003eimplicit none\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003einteger\u003c/span\u003e(C_INT64_T) \u003cspan class=\"pl-k\"\u003e::\u003c/span\u003e idx\n\n    ! initialize with explicit name\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_init_library(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eex-fortran\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! initialize with name extracted from get_command_argument(\u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, ...)\n    ! \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_init_library(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! define the default set of components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_set_default(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ewall_clock, cpu_clock\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! Start region \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_push_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! Add peak_rss \u003cspan class=\"pl-k\"\u003eto\u003c/span\u003e the current set of components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_add_components(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! Nested region \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e nested under \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_push_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! End the \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e region\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_pop_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! remove peak_rss\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_remove_components(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epeak_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! begin a region and get an identifier\n    idx \u003cspan class=\"pl-k\"\u003e=\u003c/span\u003e timemory_get_begin_record(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eindexed\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! replace current set of components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_push_components(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epage_rss\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! Nested region \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e with only page_rss components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_push_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner (pushed)\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! \u003cspan class=\"pl-k\"\u003eStop\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e region with only page_rss components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_pop_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003einner (pushed)\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! restore previous set of components\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_pop_components()\n\n    ! end the \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eindexed\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e region\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_end_record(idx)\n\n    ! End \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_pop_region(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emain\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e)\n\n    ! Output the results\n    \u003cspan class=\"pl-k\"\u003ecall\u003c/span\u003e timemory_finalize_library()\n\n\u003cspan class=\"pl-k\"\u003eend program\u003c/span\u003e fortran_example\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSample Python API\u003c/h3\u003e\u003ca id=\"user-content-sample-python-api\" class=\"anchor\" aria-label=\"Permalink: Sample Python API\" href=\"#sample-python-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eDecorator\u003c/h4\u003e\u003ca id=\"user-content-decorator\" class=\"anchor\" aria-label=\"Permalink: Decorator\" href=\"#decorator\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003efrom\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etimemory\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003ebundle\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003emarker\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003e@\u003cspan class=\"pl-en\"\u003emarker\u003c/span\u003e([\u003cspan class=\"pl-s\"\u003e\"cpu_clock\"\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\"peak_rss\"\u003c/span\u003e])\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003edef\u003c/span\u003e \u003cspan class=\"pl-en\"\u003efoo\u003c/span\u003e():\n    \u003cspan class=\"pl-k\"\u003epass\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eContext Manager\u003c/h4\u003e\u003ca id=\"user-content-context-manager\" class=\"anchor\" aria-label=\"Permalink: Context Manager\" href=\"#context-manager\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003efrom\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etimemory\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eprofiler\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eprofile\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003edef\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebar\u003c/span\u003e():\n    \u003cspan class=\"pl-k\"\u003ewith\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eprofile\u003c/span\u003e([\u003cspan class=\"pl-s\"\u003e\"wall_clock\"\u003c/span\u003e, \u003cspan class=\"pl-s\"\u003e\"cpu_util\"\u003c/span\u003e]):\n        \u003cspan class=\"pl-en\"\u003efoo\u003c/span\u003e()\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eIndividual Components\u003c/h4\u003e\u003ca id=\"user-content-individual-components\" class=\"anchor\" aria-label=\"Permalink: Individual Components\" href=\"#individual-components\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003efrom\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etimemory\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003ecomponent\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-v\"\u003eWallClock\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003edef\u003c/span\u003e \u003cspan class=\"pl-en\"\u003espam\u003c/span\u003e():\n\n    \u003cspan class=\"pl-s1\"\u003ewc\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-v\"\u003eWallClock\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"spam\"\u003c/span\u003e)\n    \u003cspan class=\"pl-s1\"\u003ewc\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003estart\u003c/span\u003e()\n\n    \u003cspan class=\"pl-en\"\u003ebar\u003c/span\u003e()\n\n    \u003cspan class=\"pl-s1\"\u003ewc\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003estop\u003c/span\u003e()\n    \u003cspan class=\"pl-s1\"\u003edata\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ewc\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eget\u003c/span\u003e()\n    \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003edata\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eArgparse Support\u003c/h4\u003e\u003ca id=\"user-content-argparse-support\" class=\"anchor\" aria-label=\"Permalink: Argparse Support\" href=\"#argparse-support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eargparse\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003eparser\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eargparse\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eArgumentParser\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"example\"\u003c/span\u003e)\n\u003cspan class=\"pl-c\"\u003e# ...\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003etimemory\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eadd_arguments\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003eparser\u003c/span\u003e)\n\n\u003cspan class=\"pl-s1\"\u003eargs\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eparser\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eparse_args\u003c/span\u003e()\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch4 class=\"heading-element\"\u003eComponent Storage\u003c/h4\u003e\u003ca id=\"user-content-component-storage\" class=\"anchor\" aria-label=\"Permalink: Component Storage\" href=\"#component-storage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003efrom\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003etimemory\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003estorage\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-v\"\u003eWallClockStorage\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e# data for current rank\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003edata\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-v\"\u003eWallClockStorage\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eget\u003c/span\u003e()\n\u003cspan class=\"pl-c\"\u003e# combined data on rank zero but all ranks must call it\u003c/span\u003e\n\u003cspan class=\"pl-s1\"\u003edmp_data\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-v\"\u003eWallClockStorage\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003edmp_get\u003c/span\u003e()\u003c/pre\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eVersioning\u003c/h2\u003e\u003ca id=\"user-content-versioning\" class=\"anchor\" aria-label=\"Permalink: Versioning\" href=\"#versioning\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTimemory originated as a very simple tool for recording timing and memory measurements (hence the name) in C, C++, and Python and only supported\nthree modes prior to the 3.0.0 release: a fixed set of timers, a pair of memory measurements, and the combination of the two.\n\u003cstrong\u003ePrior to the 3.0.0 release, timemory was almost completely rewritten from scratch\u003c/strong\u003e with the sole exceptions of some C/C++ macro, e.g.\n\u003ccode\u003eTIMEMORY_AUTO_TIMER\u003c/code\u003e, and some Python decorators and context-manager, e.g. \u003ccode\u003etimemory.util.auto_timer\u003c/code\u003e, whose behavior were\nable to be fully replicated in the new release. Thus, while it may appear that timemory is a mature project at v3.0+, it\nis essentially still in it\u0027s first major release.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCiting timemory\u003c/h2\u003e\u003ca id=\"user-content-citing-timemory\" class=\"anchor\" aria-label=\"Permalink: Citing timemory\" href=\"#citing-timemory\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eTo reference timemory in a publication, please cite the following paper:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMadsen, J.R. et al. (2020) Timemory: Modular Performance Analysis for HPC. In: Sadayappan P., Chamberlain B., Juckeland G., Ltaief H. (eds) High Performance Computing. ISC High Performance 2020. Lecture Notes in Computer Science, vol 12151. Springer, Cham\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAdditional Information\u003c/h2\u003e\u003ca id=\"user-content-additional-information\" class=\"anchor\" aria-label=\"Permalink: Additional Information\" href=\"#additional-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor more information, refer to the \u003ca href=\"https://timemory.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 341,
    "subscribers_count": 16,
    "topics": [
      "python",
      "cpp",
      "cplusplus",
      "performance",
      "c",
      "cross-platform",
      "cross-language",
      "memory-measurements",
      "mpi",
      "cuda",
      "papi",
      "hardware-counters",
      "analysis",
      "roofline",
      "performance-measurement",
      "instrumentation-api",
      "gotcha",
      "cupti",
      "modular-design"
    ],
    "updated_at": 1711455387.0
  },
  {
    "data_format": 2,
    "description": "Official development repository for SUNDIALS - a SUite of Nonlinear and DIfferential/ALgebraic equation Solvers. Pull requests are welcome for bug fixes and minor changes.",
    "filenames": [
      "docker/sundials-ci/e4s-quarterly/int64-single/spack.yaml",
      "docker/sundials-ci/spack-nightly/int64-double/spack.yaml",
      "docker/sundials-ci/spack-nightly/int32-double/spack.yaml"
    ],
    "full_name": "LLNL/sundials",
    "latest_release": "v7.0.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSUNDIALS: SUite of Nonlinear and DIfferential/ALgebraic equation Solvers\u003c/h1\u003e\u003ca id=\"user-content-sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers\" class=\"anchor\" aria-label=\"Permalink: SUNDIALS: SUite of Nonlinear and DIfferential/ALgebraic equation Solvers\" href=\"#sundials-suite-of-nonlinear-and-differentialalgebraic-equation-solvers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eVersion 7.0.0 (Feb 2024)\u003c/h3\u003e\u003ca id=\"user-content-version-700-feb-2024\" class=\"anchor\" aria-label=\"Permalink: Version 7.0.0 (Feb 2024)\" href=\"#version-700-feb-2024\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003eCenter for Applied Scientific Computing, Lawrence Livermore National Laboratory\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eSUNDIALS is a family of software packages providing robust and efficient time\nintegrators and nonlinear solvers that can easily be incorporated into existing\nsimulation codes. The packages are designed to require minimal information from\nthe user, allow users to supply their own data structures underneath the\npackages, and enable interfacing with user-supplied or third-party algebraic\nsolvers and preconditioners.\u003c/p\u003e\n\u003cp\u003eThe SUNDIALS suite consists of the following packages for ordinary differential\nequation (ODE) systems, differential-algebraic equation (DAE) systems, and\nnonlinear algebraic systems:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eARKODE - for integrating stiff, nonstiff, and multirate ODEs of the form\n$$M(t) \\, y\u0027 = f_1(t,y) + f_2(t,y), \\quad y(t_0) = y_0$$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCVODE - for integrating stiff and nonstiff ODEs of the form\n$$y\u0027 = f(t,y), \\quad y(t_0) = y_0$$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCVODES - for integrating and sensitivity analysis (forward and adjoint) of\nODEs of the form\n$$y\u0027 = f(t,y,p), \\quad y(t_0) = y_0(p)$$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIDA - for integrating DAEs of the form\n$$F(t,y,y\u0027) = 0, \\quad y(t_0) = y_0, \\quad y\u0027(t_0) = y_0\u0027$$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIDAS - for integrating and sensitivity analysis (forward and adjoint) of DAEs\nof the form\n$$F(t,y,y\u0027,p) = 0, \\quad y(t_0) = y_0(p), \\quad y\u0027(t_0) = y_0\u0027(p)$$\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eKINSOL - for solving nonlinear algebraic systems of the form\n$$F(u) = 0 \\quad \\text{or} \\quad G(u) = u$$\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eInstallation\u003c/h2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFor installation directions see the \u003ca href=\"https://sundials.readthedocs.io/en/latest/Install_link.html\" rel=\"nofollow\"\u003eonline install guide\u003c/a\u003e,\nthe installation chapter in any of the package user guides, or INSTALL_GUIDE.pdf.\u003c/p\u003e\n\u003cp\u003eWarning to users who receive more than one of the individual packages at\ndifferent times: Mixing old and new versions of SUNDIALS may fail. To avoid\nsuch failures, obtain all desired package at the same time.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eSupport\u003c/h2\u003e\u003ca id=\"user-content-support\" class=\"anchor\" aria-label=\"Permalink: Support\" href=\"#support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFull user guides for all of the SUNDIALS packages are available \u003ca href=\"https://sundials.readthedocs.io\" rel=\"nofollow\"\u003eonline\u003c/a\u003e\nand in the \u003ca href=\"./doc\"\u003edoc\u003c/a\u003e directory. Additionally, the \u003ca href=\"./doc\"\u003edoc\u003c/a\u003e directory\ncontains documentation for the package example programs.\u003c/p\u003e\n\u003cp\u003eFor information on recent changes to SUNDIALS see the \u003ca href=\"./CHANGELOG.md\"\u003eCHANGELOG\u003c/a\u003e\nor the introduction chapter of any package user guide.\u003c/p\u003e\n\u003cp\u003eA list of Frequently Asked Questions on build and installation procedures as\nwell as common usage issues is available on the SUNDIALS \u003ca href=\"https://computing.llnl.gov/projects/sundials/faq\" rel=\"nofollow\"\u003eFAQ\u003c/a\u003e.\nFor dealing with systems with unphysical solutions or discontinuities see the\nSUNDIALS \u003ca href=\"https://computing.llnl.gov/projects/sundials/usage-notes\" rel=\"nofollow\"\u003eusage notes\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you have a question not covered in the FAQ or usage notes, please submit\nyour question to the SUNDIALS \u003ca href=\"https://computing.llnl.gov/projects/sundials/mailing-list\" rel=\"nofollow\"\u003emailing list\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eBug fixes or minor changes are preferred via a pull request to the\n\u003ca href=\"https://github.com/LLNL/sundials\"\u003eSUNDIALS GitHub repository\u003c/a\u003e. For more\ninformation on contributing see the \u003ca href=\"./CONTRIBUTING.md\"\u003eCONTRIBUTING\u003c/a\u003e file.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eCiting\u003c/h2\u003e\u003ca id=\"user-content-citing\" class=\"anchor\" aria-label=\"Permalink: Citing\" href=\"#citing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSee the \u003ca href=\"https://sundials.readthedocs.io/en/latest/index.html#citing\" rel=\"nofollow\"\u003eonline documentation\u003c/a\u003e\nor \u003ca href=\"./CITATIONS.md\"\u003eCITATIONS\u003c/a\u003e file for information on how to cite SUNDIALS in\nany publications reporting work done using SUNDIALS packages.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eAuthors\u003c/h2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-label=\"Permalink: Authors\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThe SUNDIALS library has been developed over many years by a number of\ncontributors. The current SUNDIALS team consists of Cody J. Balos,\nDavid J. Gardner, Alan C. Hindmarsh, Daniel R. Reynolds, and Carol S. Woodward.\nWe thank Radu Serban for significant and critical past contributions.\u003c/p\u003e\n\u003cp\u003eOther contributors to SUNDIALS include: James Almgren-Bell, Lawrence E. Banks,\nPeter N. Brown, George Byrne, Rujeko Chinomona, Scott D. Cohen, Aaron Collier,\nKeith E. Grant, Steven L. Lee, Shelby L. Lockhart, John Loffeld, Daniel McGreer,\nYu Pan, Slaven Peles, Cosmin Petra, Steven B. Roberts, H. Hunter Schwartz,\nJean M. Sexton, Dan Shumaker, Steve G. Smith, Shahbaj Sohal, Allan G. Taylor,\nHilari C. Tiedeman, Chris White, Ting Yan, and Ulrike M. Yang.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eSUNDIALS is released under the BSD 3-clause license. See the \u003ca href=\"./LICENSE\"\u003eLICENSE\u003c/a\u003e\nand \u003ca href=\"./NOTICE\"\u003eNOTICE\u003c/a\u003e files for details. All new contributions must be made\nunder the BSD 3-clause license.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePlease Note\u003c/strong\u003e If you are using SUNDIALS with any third party libraries linked\nin (e.g., LAPACK, KLU, SuperLU_MT, PETSc, or \u003cem\u003ehypre\u003c/em\u003e), be sure to review the\nrespective license of the package as that license may have more restrictive\nterms than the SUNDIALS license.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eSPDX-License-Identifier: BSD-3-Clause\n\nLLNL-CODE-667205  (ARKODE)\nUCRL-CODE-155951  (CVODE)\nUCRL-CODE-155950  (CVODES)\nUCRL-CODE-155952  (IDA)\nUCRL-CODE-237203  (IDAS)\nLLNL-CODE-665877  (KINSOL)\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 450,
    "subscribers_count": 35,
    "topics": [
      "ode-solver",
      "dae-solver",
      "nonlinear-equation-solver",
      "sensitivity-analysis",
      "time-integration",
      "scientific-computing",
      "parallel-computing",
      "hpc",
      "math-physics",
      "radiuss",
      "solver",
      "high-performance-computing"
    ],
    "updated_at": 1712002057.0
  },
  {
    "data_format": 2,
    "description": "Official main repository for LFortran",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "lfortran/lfortran",
    "latest_release": "v0.34.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLFortran\u003c/h1\u003e\u003ca id=\"user-content-lfortran\" class=\"anchor\" aria-label=\"Permalink: LFortran\" href=\"#lfortran\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f075ed3a1bcc7bc6d681d5b1b96c7235827bcfa73790e55a1c98bf969736b4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\" alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLFortran is a modern open-source (BSD licensed) interactive Fortran compiler\nbuilt on top of LLVM. It can execute user\u0027s code interactively to allow\nexploratory work (much like Python, MATLAB or Julia) as well as compile to\nbinaries with the goal to run user\u0027s code on modern architectures such as\nmulti-core CPUs and GPUs.\u003c/p\u003e\n\u003cp\u003eWebsite: \u003ca href=\"https://lfortran.org/\" rel=\"nofollow\"\u003ehttps://lfortran.org/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTry online: \u003ca href=\"https://dev.lfortran.org/\" rel=\"nofollow\"\u003ehttps://dev.lfortran.org/\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDocumentation\u003c/h1\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-label=\"Permalink: Documentation\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eAll documentation, installation instructions, motivation, design, ... is\navailable at:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://docs.lfortran.org/\" rel=\"nofollow\"\u003ehttps://docs.lfortran.org/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eWhich is generated using the files in the \u003ccode\u003edoc\u003c/code\u003e directory.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDevelopment\u003c/h1\u003e\u003ca id=\"user-content-development\" class=\"anchor\" aria-label=\"Permalink: Development\" href=\"#development\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe welcome all contributions.\nThe main development repository is at GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/lfortran/lfortran\"\u003ehttps://github.com/lfortran/lfortran\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePlease send Pull Requests (PRs) and open issues there.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING\u003c/a\u003e document for more information.\u003c/p\u003e\n\u003cp\u003eMain mailinglist:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\u003ehttps://groups.io/g/lfortran\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can also chat with us on Zulip (\u003ca href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f075ed3a1bcc7bc6d681d5b1b96c7235827bcfa73790e55a1c98bf969736b4e9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7a756c69702d6a6f696e5f636861742d627269676874677265656e2e737667\" alt=\"project chat\" data-canonical-src=\"https://img.shields.io/badge/zulip-join_chat-brightgreen.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e).\u003c/p\u003e\n\u003cp\u003eNote: We moved to the above GitHub repository from GitLab on July 18, 2022.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eDonations\u003c/h1\u003e\u003ca id=\"user-content-donations\" class=\"anchor\" aria-label=\"Permalink: Donations\" href=\"#donations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eYou can support LFortran\u0027s development by donating to NumFOCUS or Open\nCollective as well as GitHub Sponsors:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://numfocus.org/donate-to-lfortran\" rel=\"nofollow\"\u003ehttps://numfocus.org/donate-to-lfortran\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://opencollective.com/lfortran\" rel=\"nofollow\"\u003ehttps://opencollective.com/lfortran\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/sponsors/lfortran\"\u003ehttps://github.com/sponsors/lfortran\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll donations will be used strictly to fund LFortran development, by supporting\ntasks such as paying developers to implement features, sprints, improved\ndocumentation, fixing bugs, etc.\u003c/p\u003e\n\u003cp\u003eThe donations to LFortran are managed by the NumFOCUS foundation. NumFOCUS is a\n501(c)3 non-profit foundation, so if you are subject to US Tax law, your\ncontributions will be tax-deductible.\u003c/p\u003e\n\u003cp\u003eIf you want to discuss another way to fund or help with the development, feel\nfree to contact Ond\u0159ej \u010cert\u00edk (\u003ca href=\"mailto:ondrej@certik.us\"\u003eondrej@certik.us\u003c/a\u003e).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eStar History\u003c/h1\u003e\u003ca id=\"user-content-star-history\" class=\"anchor\" aria-label=\"Permalink: Star History\" href=\"#star-history\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://star-history.com/#lfortran/lfortran\u0026amp;Date\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0d705c39c001391c1e1c00ee9eda910f1fcc337d43183467c2985974cbc2ad58/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c666f727472616e2f6c666f727472616e26747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lfortran/lfortran\u0026amp;type=Date\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 855,
    "subscribers_count": 23,
    "topics": [
      "fortran",
      "interactive",
      "compiler",
      "library",
      "repl",
      "jupyter",
      "jupyter-notebook",
      "jupyter-kernels",
      "fortran-compiler"
    ],
    "updated_at": 1711728328.0
  },
  {
    "data_format": 2,
    "description": "Python compiler",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "lcompilers/lpython",
    "latest_release": "v0.20.0",
    "readme": "\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eLPython\u003c/h1\u003e\u003ca id=\"user-content-lpython\" class=\"anchor\" aria-label=\"Permalink: LPython\" href=\"#lpython\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLPython is an ahead-of-time compiler for Python written in C++. It is currently in alpha\nstage and under heavy development. LPython works on Windows, macOS and Linux.\u003c/p\u003e\n\u003cp\u003eSome of the goals of LPython include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProviding the best possible performance for numerical and array-oriented code.\u003c/li\u003e\n\u003cli\u003eAhead-of-Time, fast compilation to binaries, plus interactive usage (Jupyter notebook).\u003c/li\u003e\n\u003cli\u003eCross-platform support.\u003c/li\u003e\n\u003cli\u003eBeing able to compile a subset of Python yet be fully compatible with it.\u003c/li\u003e\n\u003cli\u003eTransforming Python code to other programming languages like C++ and Fortran.\u003c/li\u003e\n\u003cli\u003eExploring design patterns so that LPython can eventually compile all Python code.\u003c/li\u003e\n\u003cli\u003eProviding excellent user-friendly diagnostic messages: error, warnings, hints, notes, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eamong many more.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eSponsors\u003c/h1\u003e\u003ca id=\"user-content-sponsors\" class=\"anchor\" aria-label=\"Permalink: Sponsors\" href=\"#sponsors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eLPython has been sponsored by \u003ca href=\"https://www.gsitechnology.com/\" rel=\"nofollow\"\u003eGSI Technology\u003c/a\u003e.\nOur summer students were sponsored by Google Summer of Code via Python Software\nFoundation. The intermediate representation and backends are shared with\nLFortran, see that project for a list of sponsors.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eInstallation\u003c/h1\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-label=\"Permalink: Installation\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFollow the steps below to install and run LPython on Linux, Windows or macOS.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eInstall Conda\u003c/h3\u003e\u003ca id=\"user-content-install-conda\" class=\"anchor\" aria-label=\"Permalink: Install Conda\" href=\"#install-conda\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eFollow the instructions provided \u003ca href=\"https://github.com/conda-forge/miniforge/#download\"\u003ehere\u003c/a\u003e to install Conda on your platform (Linux, macOS and Windows) using a conda-forge distribution called Miniforge.\u003c/p\u003e\n\u003cp\u003eFor Windows, these are additional requirements:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMiniforge Prompt\u003c/li\u003e\n\u003cli\u003eVisual Studio (with \"Desktop Development with C++\" workload)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eSet up your system\u003c/h3\u003e\u003ca id=\"user-content-set-up-your-system\" class=\"anchor\" aria-label=\"Permalink: Set up your system\" href=\"#set-up-your-system\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eLinux\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eRun the following command to install some global build dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esudo apt-get install build-essential binutils-dev clang zlib1g-dev\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWindows\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDownload and install \u003ca href=\"https://visualstudio.microsoft.com/downloads/\" rel=\"nofollow\"\u003eMicrosoft Visual Studio Community\u003c/a\u003e for free.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun the Visual Studio Installer. Download and install the \"Desktop Development with C++\" workload which will install the Visual C++ Compiler (MSVC).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLaunch the Miniforge prompt from the Desktop. It is recommended to use MiniForge instead of Powershell as the main terminal to build and write code for LPython. In the MiniForge Prompt, initialize the MSVC compiler using the below command:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecall \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\Common7\\Tools\\VsDevCmd\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e -arch=x64\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can optionally test MSVC via:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecl /\u003cspan class=\"pl-k\"\u003e?\u003c/span\u003e\nlink /\u003cspan class=\"pl-k\"\u003e?\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eBoth commands must print several pages of help text.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eWindows with WSL\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eInstall Miniforge Prompt and add it to path:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ewget  https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -O miniconda.sh\nbash miniconda.sh -b -p \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/conda_root\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PATH=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/conda_root/bin:\u003cspan class=\"pl-smi\"\u003e$PATH\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\nconda init bash \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e (shell name)\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOpen a new terminal window and run the following commands to install dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda create -n lp -c conda-forge llvmdev=11.0.1 bison=3.4 re2c python cmake make toml clangdev git\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOptionally, you can change the directory to a Windows location using \u003ccode\u003ecd /mnt/[drive letter]/[windows location]\u003c/code\u003e. For e.g. - \u003ccode\u003ecd mnt/c/Users/name/source/repos/\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eClone the LPython repository\u003c/h3\u003e\u003ca id=\"user-content-clone-the-lpython-repository\" class=\"anchor\" aria-label=\"Permalink: Clone the LPython repository\" href=\"#clone-the-lpython-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMake sure you have \u003ccode\u003egit\u003c/code\u003e installed. Type the following command to clone the repository:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/lcompilers/lpython.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e lpython\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou may also use GitHub Desktop to do the same.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eBuilding LPython\u003c/h2\u003e\u003ca id=\"user-content-building-lpython\" class=\"anchor\" aria-label=\"Permalink: Building LPython\" href=\"#building-lpython\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eLinux and macOS\u003c/h3\u003e\u003ca id=\"user-content-linux-and-macos\" class=\"anchor\" aria-label=\"Permalink: Linux and macOS\" href=\"#linux-and-macos\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCreate a Conda environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda env create -f environment_unix.yml\nconda activate lp\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eGenerate the prerequisite files and build in Debug Mode:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e if you are developing on top of a forked repository; please run following command first\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e ./generate_default_tag.sh\u003c/span\u003e\n\n\n./build0.sh\n./build1.sh\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eWindows\u003c/h3\u003e\u003ca id=\"user-content-windows\" class=\"anchor\" aria-label=\"Permalink: Windows\" href=\"#windows\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCreate a Conda environment using the pre-existing file:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda env create -f environment_win.yml\nconda activate lp\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eGenerate the prerequisite files and build in Release Mode:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecall build0.bat\ncall build1.bat\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch3 class=\"heading-element\"\u003eWindows with WSL\u003c/h3\u003e\u003ca id=\"user-content-windows-with-wsl\" class=\"anchor\" aria-label=\"Permalink: Windows with WSL\" href=\"#windows-with-wsl\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eActivate the Conda environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003econda activate lp\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eRun the following commands to build the project:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./build0.sh\ncmake -DCMAKE_BUILD_TYPE=Debug -DWITH_LLVM=yes -DCMAKE_INSTALL_PREFIX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e`\u003c/span\u003epwd\u003cspan class=\"pl-pds\"\u003e`\u003c/span\u003e\u003c/span\u003e/inst .\\\nmake -j8\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCheck the \u003ca href=\"./doc/src/installation.md\"\u003einstallation-docs\u003c/a\u003e for more.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eContributing\u003c/h2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-label=\"Permalink: Contributing\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eWe welcome contributions from anyone, even if you are new to compilers or open source in general.\nIt might sound daunting at first to contribute to a compiler, but do not worry, it is not that complicated.\nWe will help you with any technical issues you face and provide support so your contribution gets merged.\u003c/p\u003e\n\u003cp\u003eTo contribute, submit a Pull Request (PR) against our repository at: \u003ca href=\"https://github.com/lcompilers/lpython\"\u003ehttps://github.com/lcompilers/lpython\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDo not forget to clean your history, see \u003ca href=\"./doc/src/rebasing.md\"\u003eexample\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee the \u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING\u003c/a\u003e document for more information.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eFound a bug?\u003c/h2\u003e\u003ca id=\"user-content-found-a-bug\" class=\"anchor\" aria-label=\"Permalink: Found a bug?\" href=\"#found-a-bug\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003ePlease report any bugs you find at our issue tracker \u003ca href=\"https://github.com/lcompilers/lpython/issues\"\u003ehere\u003c/a\u003e. Or, even better, fork the repository on GitHub and create a Pull Request (PR).\u003c/p\u003e\n\u003cp\u003eWe welcome all changes, big or small. We will help you make a PR if you are new to git.\u003c/p\u003e\n\u003cp\u003eIf you have any questions or need help, please ask us at \u003ca href=\"https://lfortran.zulipchat.com/\" rel=\"nofollow\"\u003eZulip\u003c/a\u003e or on our \u003ca href=\"https://groups.io/g/lfortran\" rel=\"nofollow\"\u003emailinglist\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch1 class=\"heading-element\"\u003eStar History\u003c/h1\u003e\u003ca id=\"user-content-star-history\" class=\"anchor\" aria-label=\"Permalink: Star History\" href=\"#star-history\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://star-history.com/#lcompilers/lpython\u0026amp;Date\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/78c421eab5b4c6b49d5511402a66758420f313ca898a23fef0b6473f42f050d8/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6c636f6d70696c6572732f6c707974686f6e26747970653d44617465\" alt=\"Star History Chart\" data-canonical-src=\"https://api.star-history.com/svg?repos=lcompilers/lpython\u0026amp;type=Date\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 1247,
    "subscribers_count": 30,
    "topics": [
      "compiler",
      "high-performance",
      "python"
    ],
    "updated_at": 1712033468.0
  },
  {
    "data_format": 2,
    "description": "Lightweight, general, scalable C++ library for finite element methods",
    "filenames": [
      "config/docker/spack.yaml"
    ],
    "full_name": "mfem/mfem",
    "latest_release": "v4.6",
    "readme": "\u003cpre\u003e\u003ccode\u003e                Finite Element Discretization Library\n                               __\n                   _ __ ___   / _|  ___  _ __ ___\n                  | \u0027_ ` _ \\ | |_  / _ \\| \u0027_ ` _ \\\n                  | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_| |_| |_|\n\n                           https://mfem.org\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://mfem.org\" rel=\"nofollow\"\u003eMFEM\u003c/a\u003e is a modular parallel C++ library for finite element\nmethods. Its goal is to enable high-performance scalable finite element\ndiscretization research and application development on a wide variety of\nplatforms, ranging from laptops to supercomputers.\u003c/p\u003e\n\u003cp\u003eWe welcome contributions and feedback from the community. Please see the file\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e for additional details about our development\nprocess.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFor building instructions, see the file \u003ca href=\"INSTALL\"\u003eINSTALL\u003c/a\u003e, or type \"make help\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopyright and licensing information can be found in files \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe best starting point for new users interested in MFEM\u0027s features is to\nreview the examples and miniapps at \u003ca href=\"https://mfem.org/examples\" rel=\"nofollow\"\u003ehttps://mfem.org/examples\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstructions for learning with Docker are in \u003ca href=\"config/docker\"\u003econfig/docker\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConceptually, MFEM can be viewed as a finite element toolbox that provides the\nbuilding blocks for developing finite element algorithms in a manner similar to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\nH(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\nbilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping of various finite element discretizations, including Galerkin\nmethods, mixed finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization and Discontinuous Petrov-Galerkin (DPG) approaches.\u003c/p\u003e\n\u003cp\u003eMFEM includes classes for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral and hexahedral, as well as surface and topologically\nperiodical meshes. It has general support for mesh refinement, including local\nconforming and non-conforming (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for high-order mesh elements with curved boundaries,\nare also supported.\u003c/p\u003e\n\u003cp\u003eWhen used as a \"finite element to linear algebra translator\", MFEM can take a\nproblem described in terms of finite element-type objects, and produce the\ncorresponding linear algebra vectors and fully or partially assembled operators,\ne.g. in the form of global sparse matrices or matrix-free operators. The library\nincludes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\nwell as support for sequential sparse direct solvers from the SuiteSparse\nlibrary. Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit and implicit Runge-Kutta time integrators are also available.\u003c/p\u003e\n\u003cp\u003eMFEM supports MPI-based parallelism throughout the library, and can readily be\nused as a scalable unstructured finite element problem generator. Starting with\nversion 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal changes to switch from a serial to a highly-performant MPI-parallel\nversion of the code, where they can take advantage of the integrated linear\nsolvers from the hypre library. Comprehensive support for other external\npackages, e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional linear and nonlinear solvers, preconditioners, time integrators, etc.\u003c/p\u003e\n\u003cp\u003eFor examples of using MFEM, see the \u003ca href=\"examples\"\u003eexamples/\u003c/a\u003e and \u003ca href=\"miniapps\"\u003eminiapps/\u003c/a\u003e\ndirectories, as well as the OpenGL visualization tool GLVis which is available\nat \u003ca href=\"https://glvis.org\" rel=\"nofollow\"\u003ehttps://glvis.org\u003c/a\u003e.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\"\u003e\u003ch2 class=\"heading-element\"\u003eLicense\u003c/h2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-label=\"Permalink: License\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eMFEM is distributed under the terms of the BSD-3 license. All new contributions\nmust be made under this license. See \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e for\ndetails.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: BSD-3-Clause \u003cbr\u003e\nLLNL Release Number: LLNL-CODE-806117 \u003cbr\u003e\nDOI: 10.11578/dc.20171025.1248\u003c/p\u003e\n",
    "stargazers_count": 1513,
    "subscribers_count": 121,
    "topics": [
      "finite-elements",
      "high-order",
      "high-performance-computing",
      "parallel-computing",
      "amr",
      "computational-science",
      "fem",
      "scientific-computing",
      "hpc",
      "math-physics",
      "radiuss"
    ],
    "updated_at": 1711984227.0
  }
]
