var data =
[
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "inputs/spack/spack.yaml"
    ],
    "full_name": "cinemascienceworkflows/2021-05_ExaWind-AMRWind",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-configs\" class=\"anchor\" href=\"#spack-configs\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack Configs\u003c/h1\u003e\n\u003cp\u003eThis is a repository that sites can use to share their configuration\nfiles for Spack.  You can contribute your own configuration files, or\nbrowse around and look at what others have done.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1621478944.0
  },
  {
    "data_format": 2,
    "description": "Mobject is a prototype Mochi object storage system based on RADOS",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mobject",
    "latest_release": "v0.5",
    "readme": "",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1621277137.0
  },
  {
    "data_format": 2,
    "description": "A Tutorial for LibPressio",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "FTHPC/libpressio_tutorial",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-libpressio-tutorial\" class=\"anchor\" href=\"#libpressio-tutorial\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLibPressio Tutorial\u003c/h1\u003e\n\u003cp\u003eThis repository contains a number of example applications to help you learn how\nto use LibPressio lossy compression.  The exercises are located in \u003ccode\u003eexercises/\u003c/code\u003e\nand have their own instructions in the README.md file.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1621648529.0
  },
  {
    "data_format": 2,
    "description": "A microservice (i.e., Mochi provider) for high performance bulk storage of raw data regions",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-bake",
    "latest_release": "v0.6.3",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-bake\" class=\"anchor\" href=\"#bake\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBake\u003c/h1\u003e\n\u003cp\u003eBake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage of raw data regions.  Bake uses modular backends to store data\non persistent memory, conventional file systems, or other storage media.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\"\u003ehttps://www.mcs.anl.gov/research/projects/mochi/\u003c/a\u003e and\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/\u003c/a\u003e for more information about Mochi.\u003c/p\u003e\n\u003cp\u003eBake\u0027s scope is limited exclusively to data storage.  Capabilities such as\nindexing, name spaces, and sharding must be provided by other microservice\ncomponents.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eThe easiest way to install Bake is through spack:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install bake\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis will install BAKE and its dependencies.  Please refer to the end of the\ndocument for manual compilation instructions.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eArchitecture\u003c/h2\u003e\n\u003cp\u003eLike most Mochi services, BAKE relies on a client/provider architecture.\nA provider, identified by its \u003cem\u003eaddress\u003c/em\u003e and \u003cem\u003emultiplex id\u003c/em\u003e, manages one or more\n\u003cem\u003eBAKE targets\u003c/em\u003e, referenced externally by their \u003cem\u003etarget id\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eA target can be thought of as a storage device.  This may be (for example) a\nPMDK volume or a local file system.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" href=\"#setting-up-a-bake-target\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a BAKE target\u003c/h2\u003e\n\u003cp\u003eBAKE requires the backend storage file to be created beforehand using\n\u003ccode\u003ebake-mkpool\u003c/code\u003e. For instance:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-mkpool -s 500M /dev/shm/foo.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ecreates a 500 MB file at \u003cem\u003e/dev/shm/foo.dat\u003c/em\u003e to be used by BAKE as a target.\nBake will use the \u003ccode\u003epmem\u003c/code\u003e (persistent memory) backend by default, which means\nthat the underlying file will memory mapped for access usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as \u003ccode\u003efile:\u003c/code\u003e for the\nconventional file backend or \u003ccode\u003epmem:\u003c/code\u003e for the persistent memory backend) to\ndictate a specific target type.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStarting a daemon\u003c/h2\u003e\n\u003cp\u003eBAKE ships with a default daemon program that can setup providers and attach\nto storage targets. This daemon can be started as follows:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon [options] \u0026lt;listen_address\u0026gt; \u0026lt;bake_pool_1\u0026gt; \u0026lt;bake_pool_2\u0026gt; ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe program takes a set of options followed by an address at which to listen for\nincoming RPCs, and a list of\nBAKE targets already created using \u003ccode\u003ebake-mkpool\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234 /dev/shm/foo.dat /dev/shm/bar.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe following options are accepted:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-f\u003c/code\u003e provides the name of the file in which to write the address of the daemon.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m\u003c/code\u003e provides the mode (\u003cem\u003eproviders\u003c/em\u003e or \u003cem\u003etargets\u003c/em\u003e).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \u003cem\u003eproviders\u003c/em\u003e mode indicates that, if multiple BAKE targets are used (as above),\nthese targets should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... \u003cem\u003eN\u003c/em\u003e where \u003cem\u003eN\u003c/em\u003e is the number of storage targets\nto manage. The \u003cem\u003etargets\u003c/em\u003e mode indicates that a single provider should be used to\nmanage all the storage targets.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-integrating-bake-into-a-larger-service\" class=\"anchor\" href=\"#integrating-bake-into-a-larger-service\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntegrating Bake into a larger service\u003c/h2\u003e\n\u003cp\u003eBake is not intended to be a standalone user-facing service.  See\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/bedrock.html\u003c/a\u003e for guidance on how to\nintegrate it with other providers using Mochi\u0027s Bedrock capability.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-client-api-example\" class=\"anchor\" href=\"#client-api-example\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eClient API example\u003c/h2\u003e\n\u003cp\u003eData is stored in \u003ccode\u003eregions\u003c/code\u003e within a \u003ccode\u003etarget\u003c/code\u003e using explicit create,\nwrite, and persist operations.  The caller cannot dictate the region id\nthat will be used to reference a region; this identifier is generated\nby Bake at creation time.  The region size must be specified at creation\ntime as well; there is no mechanism for extending the size of an existing\nregion.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003ebake-client.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e **argv)\n{\n    \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e *svr_addr_str; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e string address of the BAKE server\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ehg_addr_t\u003c/span\u003e svr_addr; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Mercury address of the BAKE server\u003c/span\u003e\n    margo_instance_id mid; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Margo instance id\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_client_t\u003c/span\u003e bcl; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE client\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_provider_handle_t\u003c/span\u003e bph; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE handle to provider\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003euint8_t\u003c/span\u003e mplex_id; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e multiplex id of the provider\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003euint32_t\u003c/span\u003e target_number; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e target to use\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_region_id_t\u003c/span\u003e rid; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE region id handle\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_target_id_t\u003c/span\u003e* bti; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e array of target ids\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e ... setup variables ... \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Initialize Margo \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\tmid = \u003cspan class=\"pl-c1\"\u003emargo_init\u003c/span\u003e(..., MARGO_CLIENT_MODE, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, -\u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Lookup the server \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003emargo_addr_lookup\u003c/span\u003e(mid, svr_addr_str, \u0026amp;svr_addr);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Creates the BAKE client \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_client_init\u003c/span\u003e(mid, \u0026amp;bcl);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Creates the provider handle \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_provider_handle_create\u003c/span\u003e(bcl, svr_addr, mplex_id, \u0026amp;bph);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Asks the provider for up to target_number target ids \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003euint32_t\u003c/span\u003e num_targets = \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n\tbti = \u003cspan class=\"pl-c1\"\u003ecalloc\u003c/span\u003e(num_targets, \u003cspan class=\"pl-k\"\u003esizeof\u003c/span\u003e(*bti));\n\t\u003cspan class=\"pl-c1\"\u003ebake_probe\u003c/span\u003e(bph, target_number, bti, \u0026amp;num_targets);\n\t\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(num_targets \u0026lt; target_number) {\n\t\t\u003cspan class=\"pl-c1\"\u003efprintf\u003c/span\u003e(stderr, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eError: provider has only \u003cspan class=\"pl-c1\"\u003e%d\u003c/span\u003e storage targets\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, num_targets);\n\t}\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Create a region \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003esize_t\u003c/span\u003e size = ...; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e size of the region to create\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_create\u003c/span\u003e(bph, bti[target_number-\u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e], size, \u0026amp;rid);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Write data into the region at offset 0 \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e* buf = ...;\n\t\u003cspan class=\"pl-c1\"\u003ebake_write\u003c/span\u003e(bph, rid, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, buf, size);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Make all modifications persistent \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_persist\u003c/span\u003e(bph, rid);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Release provider handle \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_provider_handle_release\u003c/span\u003e(bph);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Release BAKE client \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_client_finalize\u003c/span\u003e(bcl);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Cleanup Margo resources \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003emargo_addr_free\u003c/span\u003e(mid, svr_addr);\n\t\u003cspan class=\"pl-c1\"\u003emargo_finalize\u003c/span\u003e(mid);\n\t\u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that a \u003ccode\u003ebake_region_id_t\u003c/code\u003e object is persistent.  It can be written\n(into a file or a socket) and stored or sent to another program. These\nregion ids are what uniquely reference a region within a given target.\u003c/p\u003e\n\u003cp\u003eThe rest of the client-side API can be found in \u003ccode\u003ebake-client.h\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProvider API\u003c/h2\u003e\n\u003cp\u003eThe bake-server-daemon source is a good example of how to create providers and\nattach storage targets to them. The provider-side API is located in\n\u003cem\u003ebake-server.h\u003c/em\u003e, and consists of mainly two functions:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_register\u003c/span\u003e(margo_instance_id                     mid,\n                           \u003cspan class=\"pl-c1\"\u003euint16_t\u003c/span\u003e                              provider_id,\n                           \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-k\"\u003estruct\u003c/span\u003e bake_provider_init_info* args,\n                           \u003cspan class=\"pl-c1\"\u003ebake_provider_t\u003c/span\u003e*                      provider);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis creates a provider at the given provider id using the specified margo\ninstance.  The \u003ccode\u003eargs\u003c/code\u003e parameter can be used to modify default settings,\nincluding passing in a fully specified json configuration block.  See\n\u003ccode\u003ebake-server.h\u003c/code\u003e for details.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_attach_target\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003ebake_provider_t\u003c/span\u003e   provider,\n                                \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e*       target_name,\n                                \u003cspan class=\"pl-c1\"\u003ebake_target_id_t\u003c/span\u003e* target_id);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis makes the provider manage the given storage target.\u003c/p\u003e\n\u003cp\u003eOther functions are available to create and detach targets from a provider.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-generic-bake-benchmark\" class=\"anchor\" href=\"#generic-bake-benchmark\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGeneric Bake benchmark\u003c/h2\u003e\n\u003cp\u003eBy using \u003ccode\u003e--enable-benchmark\u003c/code\u003e when compiling Bake (or \u003ccode\u003e+benchmark\u003c/code\u003e when using Spack),\nyou will build a \u003ccode\u003ebake-benchmark\u003c/code\u003e program that can be used as a configurable benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure Bake with\n\u003ccode\u003eCC=mpicc\u003c/code\u003e and \u003ccode\u003eCXX=mpicxx\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe benchmark is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a server, while non-zero ranks act as clients. The server will not create\na Bake target. The Bake target needs to be created (with \u003ccode\u003ebake-makepool\u003c/code\u003e) beforehand.\u003c/p\u003e\n\u003cp\u003eThe program takes as parameter the path to a JSON file containing the sequence\nof benchmarks to execute. An example of such a file is located in \u003ccode\u003esrc/benchmark.json\u003c/code\u003e.\nEach entry in the \u003ccode\u003ebenchmarks\u003c/code\u003e array corresponds to a benchmark. The \u003ccode\u003etype\u003c/code\u003e field indicates\nthe type of benchmark to execute. The \u003ccode\u003erepetitions\u003c/code\u003e field indicates how many times the\nbenchmark should be repeated.\u003c/p\u003e\n\u003cp\u003eThe following table describes each type of benchmark and their parameters.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003etype\u003c/th\u003e\n\u003cth\u003eparameter\u003c/th\u003e\n\u003cth\u003edefault\u003c/th\u003e\n\u003cth\u003edescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ewrite\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the input buffer for each write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to write to the same region\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the input buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epersist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eread\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to access the same region for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate-write-persist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create/write/persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer on clients for each operation\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-manual-installation\" class=\"anchor\" href=\"#manual-installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual installation\u003c/h2\u003e\n\u003cp\u003eBAKE depends on the following libraries:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003euuid (install uuid-dev package on ubuntu)\u003c/li\u003e\n\u003cli\u003ePMDK (see instructions below)\u003c/li\u003e\n\u003cli\u003ejson-c\u003c/li\u003e\n\u003cli\u003emochi-abt-io\u003c/li\u003e\n\u003cli\u003emochi-margo\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBake will automatically identify these dependencies at configure time using\npkg-config. To compile BAKE:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e./prepare.sh\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emkdir build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecd build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e../configure --prefix=/home/carns/working/install\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emake\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf any dependencies are installed in a nonstandard location, then\nmodify the configure step listed above to include the following argument:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ePKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1620945435.0
  },
  {
    "data_format": 2,
    "description": "Python interface for Mochi\u0027s Bedrock service.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-bedrock",
    "latest_release": "v0.1",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-py-bedrock\" class=\"anchor\" href=\"#py-bedrock\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePy-Bedrock\u003c/h1\u003e\n\u003cp\u003ePy-Bedrock providers Python utilities to configure and deploy Mochi-based\nservices using Python.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-the-jupyter-demo\" class=\"anchor\" href=\"#running-the-jupyter-demo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning the Jupyter demo\u003c/h2\u003e\n\u003cp\u003eCreate a spack environment and add the required packages in it.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env create py-bedrock-demo\nspack env activate py-bedrock-demo\nspack add py-mochi-bedrock\nspack add py-jupyterlab-server\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDeactivate and re-activate the environment for the PYTHONPATH variable to\nbe updated.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env deactivate\nspack env activate py-bedrock-demo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRun the Jupyter server.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ejupyter notebook --ip 0.0.0.0 --port 8888\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen from your browser, open the \u003ccode\u003enotebooks/Demo.ipynb\u003c/code\u003e notebook,\nand start playing!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1620857361.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "envs/chris8x/spack.yaml",
      "envs/broken-verbs-chris8x/spack.yaml",
      "envs/dev/spack.yaml"
    ],
    "full_name": "range3/spack-playground",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-playground\" class=\"anchor\" href=\"#spack-playground\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-playground\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-env\" class=\"anchor\" href=\"#env\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEnv\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e /workspaces/spack-playground\n$ spack env create -d envs/dev\n$ spack env activate -p -d envs/dev\n$ spack external find\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1620808001.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "tandem/submodules/yateto/tests/spack.yaml"
    ],
    "full_name": "le-raffael/AdaptiveTimeSteppingSEAS",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-playground\" class=\"anchor\" href=\"#spack-playground\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-playground\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-env\" class=\"anchor\" href=\"#env\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEnv\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e /workspaces/spack-playground\n$ spack env create -d envs/dev\n$ spack env activate -p -d envs/dev\n$ spack external find\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1620773652.0
  },
  {
    "data_format": 2,
    "description": "Mochi bootstrapping service.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-bedrock",
    "latest_release": "v0.3",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-bedrock\" class=\"anchor\" href=\"#bedrock\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBedrock\u003c/h1\u003e\n\u003cp\u003eBedrock is Mochi\u0027s service bootstrapping mechanism.\nFor documentations and tutorials, please see\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1620916986.0
  },
  {
    "data_format": 2,
    "description": "Spack Environments ",
    "filenames": [
      "cent8/envs/avx/lusoft/spack.yaml",
      "cent7/library/spack.yaml",
      "cent7/ece_hpc/spack.yaml",
      "cent7/library/spack.yaml~",
      "cent8/envs/x86_64/spack.yaml",
      "cent8/envs/avx512/python/spack.yaml",
      "cent7/py_376/spack.yaml",
      "cent7/bioinformatics_default/spack.yaml.bak",
      "cent7/libs_old/spack.yaml",
      "cent7/bioinformatics/spack.yaml",
      "cent7/python_376/spack.yaml",
      "compilers/envs/compilers/spack.yaml",
      "cent8/envs/avx2/lusoft/spack.yaml",
      "cent8/envs/avx512/lusoft/spack.yaml",
      "cent8/envs/avx512/rproject/spack.yaml",
      "cent8/envs/avx/python/spack.yaml",
      "cent7/library/bak/spack.yaml",
      "cent7/mpis/spack.yaml",
      "cent8/envs/avx/rproject/spack.yaml",
      "cent7/bio_old/spack.yaml",
      "cent8/envs/avx2/python/spack.yaml",
      "cent7/apps/spack.yaml",
      "cent8/envs/solhawk/spack.yaml",
      "cent8/envs/avx2/rproject/spack.yaml",
      "cent7/bioinformatics_default/spack.yaml"
    ],
    "full_name": "alexpacheco/spackenv",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-environments\" class=\"anchor\" href=\"#spack-environments\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSPACK Environments\u003c/h1\u003e\n\u003cp\u003eThis repo contains the environment definitions to deploy site-software on Lehigh University\u0027s Research Computing resources via SPACK environments.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-software-deployment-for-centos-8x\" class=\"anchor\" href=\"#software-deployment-for-centos-8x\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSoftware deployment for CentOS 8.x\u003c/h2\u003e\n\u003cp\u003eSoftware is deployed using two Spack installations.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFor compilers and module environments\u003c/li\u003e\n\u003cli\u003eSite software for general use\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-compilers\" class=\"anchor\" href=\"#compilers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompilers\u003c/h3\u003e\n\u003cp\u003eThis spack installation provides the gcc, nvhpc and cuda compilers, and lmod software for module management. In the future, this installation will also provide intel-oneapi compilers. For legacy reasons, intel@19.0.3 and intel@20.0.3 were installed in /share/Apps/intel with older intel compilers. This installation should not be used for deploying site software nor should the software provided be made available using the module environment.\u003c/p\u003e\n\u003cp\u003eTo reproduce installation\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/alexpacheco/spackenv.git\ncd spackenv/compilers/envs/compilers\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe directory \u003ccode\u003eetc/lmod\u003c/code\u003e contains the LMOD configuration to switch between avx, avx2 and avx512 enabled \u003ccode\u003eMODULEPATHS\u003c/code\u003e\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-lu-software\" class=\"anchor\" href=\"#lu-software\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLU Software\u003c/h3\u003e\n\u003cp\u003eThis spack installation provides the deployed site-software on Sol and Hawk.\u003c/p\u003e\n\u003cp\u003eTo reproduce this installation, you need to first copy the site configuration files from \u003ccode\u003eetc/spack\u003c/code\u003e to your spack install tree. This assumes that SLURM and the compiler environment above is already installed. Edit the \u003ccode\u003epackages.yaml\u003c/code\u003e file to point to the location of slurm (/usr/local), rmda-core (/usr), gcc, intel, cuda, and nvhpc. The file \u003ccode\u003erepo.yaml\u003c/code\u003e is hardwired with  location of the lubio repository and should be changed to your location. The directory \u003ccode\u003etemplates\u003c/code\u003e contains the template lua file for a few modules as defined in the \u003ccode\u003emodules.yaml\u003c/code\u003e file  and should be copied to the \u003ccode\u003eetc\u003c/code\u003e directory in your spack installation tree.\u003c/p\u003e\n\u003cp\u003eOn Sol, these files are available at \u003ccode\u003e/share/Apps/lusoft/etc/spack\u003c/code\u003e.\u003c/p\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-available-environments\" class=\"anchor\" href=\"#available-environments\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAvailable Environments\u003c/h4\u003e\n\u003ch5\u003e\n\u003ca id=\"user-content-solhawk\" class=\"anchor\" href=\"#solhawk\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esolhawk\u003c/h5\u003e\n\u003cp\u003eThis environment builds the entire software except the various python and r packages for ivybridge, haswell and skylake_avx512 architectures. This environment also builds the tcl environment modules that is not currently used. This should be build first and any new packages should be added to this environment.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/solhawk\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-avxavx2avx512\" class=\"anchor\" href=\"#avxavx2avx512\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eavx/avx2/avx512\u003c/h4\u003e\n\u003cp\u003eThese environment builds the software stack except the various python and r packages for ivybridge/haswell/skylake_avx512 architectures. If software in the \u003ccode\u003esolhawk\u003c/code\u003e environment is already built, then these environments are only setting up the installation root for the LMOD module files \u003ccode\u003e/share/Apps/lusoft/share/modules/lmod/{avx,avx2,avx512}\u003c/code\u003e. The only reason these environments exist is due to SPACK\u0027s inability to built a architecture based LMOD module tree similar to the TCL module tree.\n\u003cem\u003eNote\u003c/em\u003e: If you change the path of the installation root, make sure that you change the corresponding path in \u003ccode\u003ecompilers/etc/SitePackage.lua\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx2/lusoft\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-python-and-r-packages\" class=\"anchor\" href=\"#python-and-r-packages\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePython and R packages\u003c/h4\u003e\n\u003cp\u003eRather than building module files for various python and r packages, a single module is created for a filesystem view of all python and r packages respectively. The path to the r filesystem is setup as \u003ccode\u003eR_LIBS_SITE\u003c/code\u003e so that any application such as \u003ccode\u003etrinity\u003c/code\u003e that requires many R packages only need to load the r module. If new packages added to the above environments require a dependent R package, then that dependency should be added to the rpoject environment and concretized. The python environment uses a \u003ccode\u003econcretization: together\u003c/code\u003e and may not provide the same python package as the above software environments. The filesystem views are hardwired as \u003ccode\u003e/share/Apps/py_spack/3.8.6/{avx,avx2,avx512}\u003c/code\u003e and \u003ccode\u003e/share/Apps/r_spack/4.0.3/{avx,avx2,avx512}\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx/python\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003ecd spackenv/cent8/envs/avx512/rproject\nspack env activate -d .\nspack concretize -f # optional\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e\n\u003ca id=\"user-content-x86_64\" class=\"anchor\" href=\"#x86_64\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ex86_64\u003c/h4\u003e\n\u003cp\u003eThis environment builds unoptimized software such as anaconda python, gnu parallel, scree, tmux, etc for generic x86_64 processor.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-centos-7x-software\" class=\"anchor\" href=\"#centos-7x-software\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCentOS 7.x software\u003c/h2\u003e\n\u003cp\u003eThis just collects the various environments for building software before the CentOS 8.x upgrade.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1620234577.0
  },
  {
    "data_format": 2,
    "description": "Spack configuration files and scripts for use on machines at NREL",
    "filenames": [
      "configs/rhodes/base/spack.yaml",
      "configs/eagle/compilers/spack.yaml",
      "configs/rhodes/compilers/spack.yaml",
      "configs/rhodes/software/spack.yaml",
      "configs/eagle/base/spack.yaml",
      "configs/eagle/utilities/spack.yaml",
      "configs/eagle/software/spack.yaml",
      "envs/exawind/spack.yaml",
      "configs/rhodes/utilities/spack.yaml"
    ],
    "full_name": "jrood-nrel/spack-configs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack configuration files and scripts for use on machines at NREL\u003c/h1\u003e\n\u003cp\u003eThese software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in \u003ca href=\"modules.txt\"\u003emodules.txt\u003c/a\u003e. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.\u003c/li\u003e\n\u003cli\u003e\"binaries\" are generally the binary downloads of Paraview and Visit.\u003c/li\u003e\n\u003cli\u003e\"compilers\" are the latest set of compilers built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"utilities\" are the latest set of utility programs that don\u0027t rely on MPI and are built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.\u003c/p\u003e\n\u003cp\u003eCurrently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.\u003c/p\u003e\n\u003cp\u003eTo use these modules you can add the following to your \u003ccode\u003e~/.bashrc\u003c/code\u003e for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf \u003ccode\u003emodule avail\u003c/code\u003e does not show the modules on Eagle, try removing the LMOD cache with \u003ccode\u003erm -rf ~/.lmod.d/.cache\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eAlso included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have \u003ccode\u003eSPACK_ROOT\u003c/code\u003e set you can run \u003ccode\u003e/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh\u003c/code\u003e which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your \u003ccode\u003e${SPACK_ROOT}/etc\u003c/code\u003e directory manually. \u003ccode\u003espack compilers\u003c/code\u003e should then show you many available compilers. Source your Spack\u0027s \u003ccode\u003esetup-env.sh\u003c/code\u003e after you do the \u003ccode\u003emodule unuse ${MODULEPATH}\u003c/code\u003e in your \u003ccode\u003e.bashrc\u003c/code\u003e so that your Spack instance will add its own module path to MODULEPATH. Remove \u003ccode\u003e~/.spack/linux\u003c/code\u003e if it exists and \u003ccode\u003espack compilers\u003c/code\u003e doesn\u0027t show you the updated list of compilers. The \u003ccode\u003e~/.spack\u003c/code\u003e directory takes highest precendence in the Spack configuration.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1620946052.0
  },
  {
    "data_format": 2,
    "description": "trying to use spack in gh actions without docker images",
    "filenames": [
      "tools/environments/ci/spack.yaml"
    ],
    "full_name": "haampie-spack/ci-example-2",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack configuration files and scripts for use on machines at NREL\u003c/h1\u003e\n\u003cp\u003eThese software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in \u003ca href=\"modules.txt\"\u003emodules.txt\u003c/a\u003e. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.\u003c/li\u003e\n\u003cli\u003e\"binaries\" are generally the binary downloads of Paraview and Visit.\u003c/li\u003e\n\u003cli\u003e\"compilers\" are the latest set of compilers built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"utilities\" are the latest set of utility programs that don\u0027t rely on MPI and are built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.\u003c/p\u003e\n\u003cp\u003eCurrently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.\u003c/p\u003e\n\u003cp\u003eTo use these modules you can add the following to your \u003ccode\u003e~/.bashrc\u003c/code\u003e for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf \u003ccode\u003emodule avail\u003c/code\u003e does not show the modules on Eagle, try removing the LMOD cache with \u003ccode\u003erm -rf ~/.lmod.d/.cache\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eAlso included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have \u003ccode\u003eSPACK_ROOT\u003c/code\u003e set you can run \u003ccode\u003e/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh\u003c/code\u003e which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your \u003ccode\u003e${SPACK_ROOT}/etc\u003c/code\u003e directory manually. \u003ccode\u003espack compilers\u003c/code\u003e should then show you many available compilers. Source your Spack\u0027s \u003ccode\u003esetup-env.sh\u003c/code\u003e after you do the \u003ccode\u003emodule unuse ${MODULEPATH}\u003c/code\u003e in your \u003ccode\u003e.bashrc\u003c/code\u003e so that your Spack instance will add its own module path to MODULEPATH. Remove \u003ccode\u003e~/.spack/linux\u003c/code\u003e if it exists and \u003ccode\u003espack compilers\u003c/code\u003e doesn\u0027t show you the updated list of compilers. The \u003ccode\u003e~/.spack\u003c/code\u003e directory takes highest precendence in the Spack configuration.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1620232443.0
  },
  {
    "data_format": 2,
    "description": "Spack support for SeisSol and related tools",
    "filenames": [
      "deployment/default-env-utils-images/image-files/arm64/spack.yaml",
      "deployment/default-env-utils-images/image-files/amd64/spack.yaml"
    ],
    "full_name": "SeisSol/seissol-spack-aid",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack\u003c/h1\u003e\n\u003cp\u003eSpack support for SeisSol and related tools\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1619723394.0
  },
  {
    "data_format": 2,
    "description": "Sonata is a Mochi service for JSON document storage. It is based on UnQLite and Thallium.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-sonata",
    "latest_release": "v0.6.2",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-what-is-sonata\" class=\"anchor\" href=\"#what-is-sonata\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat is Sonata?\u003c/h1\u003e\n\u003cp\u003eSonata is a remotely-accessibl JSON document store based on UnQLite and on\nthe Mochi suit of libraries. It enables managing collections of JSON records,\nsearching through them, and running Jx9 scripts on them.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-got-some-examples\" class=\"anchor\" href=\"#got-some-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGot some examples?\u003c/h1\u003e\n\u003cp\u003eA comprehensive set of examples is available in \u003ca href=\"examples\"\u003ethis directory\u003c/a\u003e.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-how-do-i-install-sonata\" class=\"anchor\" href=\"#how-do-i-install-sonata\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow do I install Sonata?\u003c/h1\u003e\n\u003cp\u003eThe easiest way to install Sonata is to use \u003ca href=\"https://spack.readthedocs.io\" rel=\"nofollow\"\u003espack\u003c/a\u003e.\nOnce you have spack installed and setup on your machine, you need to added the\nmochi namespace to it, as follows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://xgitlab.cels.anl.gov/sds/sds-repo.git\nspack repo add sds-repo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can now install Sonata as follows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install mochi-sonata\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-and-then\" class=\"anchor\" href=\"#and-then\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAnd then?\u003c/h1\u003e\n\u003cp\u003eSonata comes in three libraries: sonata-server, sonata-client, and sonata-admin.\nThe server library contains the \u003ccode\u003esonata::Provider\u003c/code\u003e class, which allows to start\na Sonata service on a server program. The admin library contains the\n\u003ccode\u003esonata::Admin\u003c/code\u003e class, which enables creating and destroying database on a\nrunning provider. The \u003ccode\u003esonata::Client\u003c/code\u003e class is contained in the client library.\nThis class provides the main interface to open a database, and manipulat\ncollections.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1619728396.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "eugeneswalker/exawind-containers",
    "latest_release": null,
    "readme": "\u003ch2\u003e\n\u003ca id=\"user-content-working-with-the-docker-image-ecpe4sexawindlatest\" class=\"anchor\" href=\"#working-with-the-docker-image-ecpe4sexawindlatest\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorking with the Docker image (ecpe4s/exawind:latest)\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eBuild the Docker image\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-docker-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eLaunch a container from the image\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; docker run -it --rm ecpe4s/exawind\n\nroot@8df184bdac63:/# which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nroot@8df184bdac63:/# which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-working-with-the-singularity-image-exawindsif\" class=\"anchor\" href=\"#working-with-the-singularity-image-exawindsif\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorking with the Singularity image (exawind.sif)\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eBuild the Docker image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-docker-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eBuild the Singularity image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./build-singularity-image.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eRun the Singularity image:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003e$\u0026gt; ./exawind.sif\n\nExawind Singularity\u0026gt; which naluX\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/nalu-wind-master-zjlelnq6lbetgsvmpabyqe5krlwl43vq/bin/naluX\n\nExawind Singularity\u0026gt; which amr_wind\n/opt/spack/opt/spack/linux-ubuntu20.04-x86_64/gcc-9.3.0/amr-wind-main-ehzusqf26dxsz7tbjykhubyegyzvinkh/bin/amr_wind\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-run-selected-exawind-regression-tests\" class=\"anchor\" href=\"#run-selected-exawind-regression-tests\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun Selected ExaWind Regression Tests\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eLaunch a container using either the Docker or Singularity image (see above)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eClone this repository in the newly launched container and run the tests (here illustrated with Singularity)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode\u003eExawind Singularity\u0026gt; git clone https://github.com/eugeneswalker/exawind-containers ~/exawind-containers\nExawind Singularity\u0026gt; cd ~/exawind-containers/demo\n\n\nExawind Singularity\u0026gt; ./run-nonIsoEdgeOpenJet.sh\nPASS: nonIsoEdgeOpenJet.......................     6.2260s 8.1315e-19 5.7732e-15\n\n\nExawind Singularity\u0026gt; ./run-nalu-wind-tests.sh\nPASS: ablHill3d_ii............................    10.3820s 8.1955e-16 3.6451e-11\nPASS: ablHill3d_ip............................    10.0905s 2.7485e-17 2.3703e-13\n...\n\n\nExawind Singularity\u0026gt; ./run-amr-wind-tests.sh\nfinished abl_bndry_output\nfinished abl_godunov\n...\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1619816372.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "nyx/inputs/spack/spack.yaml"
    ],
    "full_name": "m-s-will/nyx",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-nyx-with-ascent-in-container\" class=\"anchor\" href=\"#nyx-with-ascent-in-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNyx with Ascent in Container\u003c/h1\u003e\n\u003cp\u003eThis project contains a Dockerfile and all necessary components to create a Docker container for Nyx.\nThe container is available on \u003ca href=\"https://hub.docker.com/repository/docker/mswill/elwe_nyx\" rel=\"nofollow\"\u003eDockerhub\u003c/a\u003e, however these versions may not always be up to date.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-the-container\" class=\"anchor\" href=\"#building-the-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the container\u003c/h2\u003e\n\u003cp\u003eThe Ascent actions can be changed by editing \u003ca href=\"https://github.com/m-s-will/nyx/blob/main/nyx/inputs/ascent/ascent_actions.yaml\"\u003eascent_actions.yaml\u003c/a\u003e.\nWhen finished with the customization, the container can be rebuilt by navigating into the source directory and executing:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ docker build -t \u0026lt;mytag\u0026gt; .\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe Nyx simulation is being run during container creation and provides a Cinema database.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-the-container\" class=\"anchor\" href=\"#running-the-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning the container\u003c/h2\u003e\n\u003cp\u003eAfter either pulling or building the container, it can be run by calling:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ docker run -p 80:80 \u0026lt;mytag\u0026gt;.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003e-p 80:80\u003c/code\u003e makes port 80 available on the outside which is needed for the Cinema viewer. We can then connect to it by visiting \u003ccode\u003elocalhost:80\u003c/code\u003e in our browser.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1619477496.0
  },
  {
    "data_format": 2,
    "description": "Singularity recipe for Octave",
    "filenames": [
      "6.2.0/spack.yaml"
    ],
    "full_name": "icaoberg/singularity-octave",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-singularity-octave\" class=\"anchor\" href=\"#singularity-octave\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003esingularity-octave\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.travis-ci.com/icaoberg/singularity-octave\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2ee2520b43fa597d24d8c42ccae9e2d15ea0e54a927d5b90207cde03bd895e9c/68747470733a2f2f7777772e7472617669732d63692e636f6d2f6963616f626572672f73696e67756c61726974792d6f63746176652e7376673f6272616e63683d6d61696e\" alt=\"Build Status\" data-canonical-src=\"https://www.travis-ci.com/icaoberg/singularity-octave.svg?branch=main\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fb797545afaa696b8fee075f0170506292bd4e6d411bac5a8358b465a6d8a87d/68747470733a2f2f7777772e676e752e6f72672f736f6674776172652f6f63746176652f696d672f474e555f4f63746176655f342d342d305f73637265656e73686f745f31363030783930302e706e67\" alt=\"Octave\" data-canonical-src=\"https://www.gnu.org/software/octave/img/GNU_Octave_4-4-0_screenshot_1600x900.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSingularity recipe for \u003ca href=\"https://www.gnu.org/software/octave/\" rel=\"nofollow\"\u003eoctave\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-the-image-using-the-recipe\" class=\"anchor\" href=\"#building-the-image-using-the-recipe\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the image using the recipe\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-to-build-the-image-locally\" class=\"anchor\" href=\"#to-build-the-image-locally\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTo build the image locally\u003c/h3\u003e\n\u003cp\u003eRun the script \u003ccode\u003ebuild.sh\u003c/code\u003e to build image locally.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebash ./build.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-to-build-the-image-remotely\" class=\"anchor\" href=\"#to-build-the-image-remotely\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTo build the image remotely\u003c/h3\u003e\n\u003cp\u003eRun the script \u003ccode\u003erbuild.sh\u003c/code\u003e to build image locally.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebash ./build.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing-the-container-on-bridges-or-similar\" class=\"anchor\" href=\"#installing-the-container-on-bridges-or-similar\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling the container on Bridges (or similar)\u003c/h2\u003e\n\u003cp\u003eCopy the\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eSIF\u003c/code\u003e file\u003c/li\u003e\n\u003cli\u003eand the \u003ccode\u003eoctave\u003c/code\u003e and \u003ccode\u003eoctave-gui\u003c/code\u003e scripts\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eto \u003ccode\u003e/opt/packages/octave/6.2.0\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eCopy the file \u003ccode\u003emodulefile.lua\u003c/code\u003e to \u003ccode\u003e/opt/modules/octave\u003c/code\u003e as \u003ccode\u003e6.2.0.lua\u003c/code\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eCopyright \u00a9 2021 Pittsburgh Supercomputing Center. All Rights Reserved.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.andrew.cmu.edu/~icaoberg\" rel=\"nofollow\"\u003eicaoberg\u003c/a\u003e at the \u003ca href=\"http://www.psc.edu\" rel=\"nofollow\"\u003ePittsburgh Supercomputing Center\u003c/a\u003e in the \u003ca href=\"https://www.cmu.edu/mcs/\" rel=\"nofollow\"\u003eMellon College of Science\u003c/a\u003e at \u003ca href=\"http://www.cmu.edu\" rel=\"nofollow\"\u003eCarnegie Mellon University\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [
      "singularity",
      "octave",
      "singularity-recipe"
    ],
    "updated_at": 1619522434.0
  },
  {
    "data_format": 2,
    "description": "simple margo-projected keyval service",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-sdskv",
    "latest_release": "v0.1.13",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-sdskv-sds-keyval\" class=\"anchor\" href=\"#sdskv-sds-keyval\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSDSKV (SDS Key/Val)\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation\" class=\"anchor\" href=\"#installation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eSDSKV can easily be installed using Spack:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install sdskeyval\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis will install SDSKV (and any required dependencies).\nAvailable backends will be \u003cem\u003eMap\u003c/em\u003e (in-memory C++ std::map, useful for testing)\nand BwTree (deprecated). To enable the BerkeleyDB and LevelDB backends,\nass \u003ccode\u003e+bdb\u003c/code\u003e and \u003ccode\u003e+leveldb\u003c/code\u003e respectively. For example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install sdskeyval+bdb+leveldb\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eNote that if you are using a system boost path in spack (in your\npackages.yaml) rather than letting spack build boost, then you must\ninstall libboost-system-dev and libboost-filesystem-dev packages on\nyour system.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-architecture\" class=\"anchor\" href=\"#architecture\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eArchitecture\u003c/h2\u003e\n\u003cp\u003eList most mochi services, SDSKV relies on a client/provider architecture.\nA provider, identified by its \u003cem\u003eaddress\u003c/em\u003e and \u003cem\u003emultiplex id\u003c/em\u003e, manages one or more\ndatabases, referenced externally by their database id.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-starting-a-daemon\" class=\"anchor\" href=\"#starting-a-daemon\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStarting a daemon\u003c/h2\u003e\n\u003cp\u003eSDSKV ships with a default daemon program that can setup providers and\ndatabases. This daemon can be started as follows:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esdskv-server-daemon [OPTIONS] \u0026lt;listen_addr\u0026gt; \u0026lt;db name 1\u0026gt;[:map|:bwt|:bdb|:ldb] \u0026lt;db name 2\u0026gt;[:map|:bwt|:bdb|:ldb] ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003esdskv-server-daemon tcp://localhost:1234 foo:bdb bar\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003elisten_addr is the address at which to listen; database names should be provided in the form\n\u003cem\u003ename:type\u003c/em\u003e where \u003cem\u003etype\u003c/em\u003e is \u003cem\u003emap\u003c/em\u003e (std::map), \u003cem\u003ebwt\u003c/em\u003e (BwTree), \u003cem\u003ebdb\u003c/em\u003e (Berkeley DB), or \u003cem\u003eldb\u003c/em\u003e (LevelDB).\u003c/p\u003e\n\u003cp\u003eFor database that are persistent like BerkeleyDB or LevelDB, the name should be a path to the\nfile where the database will be put (this file should not exist).\u003c/p\u003e\n\u003cp\u003eThe following additional options are accepted:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-f\u003c/code\u003e provides the name of the file in which to write the address of the daemon.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m\u003c/code\u003e provides the mode (providers or databases).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe providers mode indicates that, if multiple SDSKV databases are used (as above),\nthese databases should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... N where N is the number of databases\nto manage. The targets mode indicates that a single provider should be used to\nmanage all the databases. This provider will be accessible at multiplex id 1.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-client-api\" class=\"anchor\" href=\"#client-api\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eClient API\u003c/h2\u003e\n\u003cp\u003eThe client API is available in \u003cem\u003esdskv-client.h\u003c/em\u003e.\nThe codes in the \u003cem\u003etest\u003c/em\u003e folder illustrate how to use it.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-provider-api\" class=\"anchor\" href=\"#provider-api\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProvider API\u003c/h2\u003e\n\u003cp\u003eThe server-side API is available in \u003cem\u003esdskv-server.h\u003c/em\u003e.\nThe code of the daemon (\u003cem\u003esrc/sdskv-server-daemon.c\u003c/em\u003e) can be used as an example.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-custom-key-comparison-function\" class=\"anchor\" href=\"#custom-key-comparison-function\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCustom key comparison function\u003c/h3\u003e\n\u003cp\u003eIt is possible to specify a custom function for comparing/sorting keys\nwhen creating a provider. A comparison function must have the following prototype:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eint (*)(const void* key1, size_t keysize1, const void* key2, size_t keysize2)\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eIts return value must be \u0026lt; 0 if key1 \u0026lt; key2, 0 if key1 = key2, \u0026gt; 0 if key1 \u0026gt; key2.\nIt must define a total order of the key space.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-c-api\" class=\"anchor\" href=\"#c-api\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eC++ API\u003c/h2\u003e\n\u003cp\u003eAn object-oriented C++ API is available in \u003ccode\u003esdskv-client.hpp\u003c/code\u003e and \u003ccode\u003esdskv-server.hpp\u003c/code\u003e.\nOn the client side this API provides the \u003ccode\u003eclient\u003c/code\u003e, \u003ccode\u003eprovider_handle\u003c/code\u003e, and \u003ccode\u003edatabase\u003c/code\u003e objects.\nExamples of usage of these objects can be found in the \u003ccode\u003etest/sdskv-cxx-test.cc\u003c/code\u003e.\nOn the server side, this API provides a \u003ccode\u003eprovider\u003c/code\u003e object.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-benchmark\" class=\"anchor\" href=\"#benchmark\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBenchmark\u003c/h2\u003e\n\u003cp\u003eSDSKV can be compiled with \u003ccode\u003e--enable-benchmark\u003c/code\u003e (or \u003ccode\u003e+benchmark\u003c/code\u003e in Spack). In this case,\nSDSKV requires the JsonCPP and MPI dependencies (when compiling manually, use \u003ccode\u003eCXX=mpicxx\u003c/code\u003e in\nyour configure step, for example), and it will build and install the \u003ccode\u003esdskv-benchmark\u003c/code\u003e program.\u003c/p\u003e\n\u003cp\u003eThis program is an MPI program that reads a JSON file describing a series of access patterns.\nRank 0 of this MPI program acts as an SDSKV server. Other ranks act as clients, all executing\nthis access pattern.\u003c/p\u003e\n\u003cp\u003eThe following is an example of a JSON file.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-json\"\u003e\u003cpre\u003e{\n\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eprotocol\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etcp\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eseed\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e,\n\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eserver\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : {\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003euse-progress-thread\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003erpc-thread-count\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003edatabase\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : {\n\t\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etype\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003emap\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ename\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ebenchmark-db\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003epath\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/dev/shm\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\t\t}\n\t},\n\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ebenchmarks\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : [\n\t{\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etype\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eput\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003erepetitions\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e10\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003enum-entries\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e30\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ekey-sizes\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : [ \u003cspan class=\"pl-c1\"\u003e8\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e32\u003c/span\u003e ],\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eval-sizes\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : [ \u003cspan class=\"pl-c1\"\u003e24\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e48\u003c/span\u003e ],\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eerase-on-teardown\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n\t},\n\t{\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etype\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eget\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003erepetitions\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e10\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003enum-entries\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e30\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ekey-sizes\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e64\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eval-sizes\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003e128\u003c/span\u003e,\n\t\t\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eerase-on-teardown\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e : \u003cspan class=\"pl-c1\"\u003etrue\u003c/span\u003e\n\t}\n\t]\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe JSON file starts with the protocol to use, and a seed for the random-number generator (RNG).\nThe actual seed used on each rank will actually be a function of this global seed and the rank of\nthe client. The RNG will be reset with this seed after each benchmark.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003eserver\u003c/code\u003e field sets up the provider and the database. Database types can be \u003ccode\u003emap\u003c/code\u003e, \u003ccode\u003eldb\u003c/code\u003e, or \u003ccode\u003ebdb\u003c/code\u003e.\nThen follows the \u003ccode\u003ebenchmarks\u003c/code\u003e entry, which is a list of benchmarks to execute. Each benchmark is composed\nof three steps. A \u003cem\u003esetup\u003c/em\u003e phase, an \u003cem\u003eexecution\u003c/em\u003e phase, and a \u003cem\u003eteardown\u003c/em\u003e phase. The setup phase may for\nexample store a bunch of keys in the database that the execution phase will read by (in the case of a\n\u003cem\u003eget\u003c/em\u003e benchmark, for example). The teardown phase will usually remove all the keys that were written\nduring the benchmark, if \"erase-on-teardown\" is set to \u003ccode\u003etrue\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eEach benchmark entry has a \u003ccode\u003etype\u003c/code\u003e (which may be \u003ccode\u003eput\u003c/code\u003e, \u003ccode\u003eput-multi\u003c/code\u003e, \u003ccode\u003eget\u003c/code\u003e, \u003ccode\u003eget-multi\u003c/code\u003e, \u003ccode\u003elength\u003c/code\u003e,\n\u003ccode\u003elength-multi\u003c/code\u003e, \u003ccode\u003eerase\u003c/code\u003e, and \u003ccode\u003eerase-multi\u003c/code\u003e), and a number of repetitions. The benchmark will be\nexecuted as many times as requested (without resetting the RNG in between repetitions). Taking the\nexample of the \u003ccode\u003eput\u003c/code\u003e benchmark above, each repetition will put 30 key/value pairs into the database.\nThe key size will be chosen randomly in a uniform manner in the interval \u003ccode\u003e[8, 32 [\u003c/code\u003e (32 excluded).\nThe value size will be chosen randomly in a uniform manner in \u003ccode\u003e[24, 48 [\u003c/code\u003e (48 excluded). Note that\nyou may also set a specific size instead of a range.\u003c/p\u003e\n\u003cp\u003eAn MPI barrier between clients is executed in between each benchmark and in between the setup,\nexecution, and teardown phases, so that the execution phase is always executed at the same time\non all the clients. Once all the repetitions are done for a given benchmark entry, the program\nwill report statistics on the timings: average time, variance, standard deviation, mininum, maximum,\nmedian, first and third quartiles. Note that these times are for a repetition, not for single operations\nwithin a repetition. To get the timing of each individual operation, it is then necessary to divide\nthe times by the number of key/value pairs involved in the benchmark.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1620851629.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "TurbulentDynamics/tdLBCpp",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-turbulent-dynamics-lattice-boltzmann-c\" class=\"anchor\" href=\"#turbulent-dynamics-lattice-boltzmann-c\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTurbulent Dynamics Lattice Boltzmann (C++)\u003c/h1\u003e\n\u003cp\u003eThis is a basic version of the multi-node heterogeneous HPC code to run billions of cell simulation.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1619466471.0
  },
  {
    "data_format": 2,
    "description": "Raft implementation which depends on Mochi Project and Symas LMDB",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "KoyamaSohei/raft",
    "latest_release": null,
    "readme": "\u003ch2\u003e\n\u003ca id=\"user-content-raft\" class=\"anchor\" href=\"#raft\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eraft\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://raft.github.io/\" rel=\"nofollow\"\u003eRaft\u003c/a\u003e implementation which depends on \u003ca href=\"https://mochi.readthedocs.io/\" rel=\"nofollow\"\u003eMochi Project\u003c/a\u003e and \u003ca href=\"https://symas.com/lmdb/\" rel=\"nofollow\"\u003eSymas LMDB\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ethis is one of projects in \u003ca href=\"http://www.hpcs.cs.tsukuba.ac.jp/~tatebe/lecture/r02/dpro/\" rel=\"nofollow\"\u003e\u4e3b\u5c02\u653b\u5b9f\u9a13 K-16\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1612651620.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "wangzhezhe/mona-vtk",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-mona-vtk-examples\" class=\"anchor\" href=\"#mona-vtk-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMoNA-VTK examples\u003c/h1\u003e\n\u003cp\u003eThis repo shows how to implement the MonaController and use it for Paraview Catalyst to do the in-situ data analytics. The \u003ccode\u003esrc\u003c/code\u003e folder contains the implementation details of the MonaController based on the MonaCommunicator which is implemented based on \u003ca href=\"https://github.com/mochi-hpc/mochi-mona\"\u003emochi-mona\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThere are several examples in the \u003ccode\u003eexample\u003c/code\u003e folder:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ebasic: This example shows that how the MonaController can be used to execute the basic vtk parallel operations such as send and recv vtk object.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eicetExample: This exmaple shows that how the mochi-mona can be used to execute the iceT test cases based on the iceT wrapper for the mochi-mona.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMandelbulbCatalystExample: This example shows how the MonaController can be used to execute the tightly coupled in-situ analytics in distributed way.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMandelbulbColza: This example shows how the MonaController can be used to execute the loosely coupled in-situ analytics in distributed way, the \u003ca href=\"https://github.com/mochi-hpc/mochi-colza\"\u003emochi-colza\u003c/a\u003e is used as the data staging service for this example.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eGrayScottColza: This example is similar with the MandelbulbColza case but the simulation data is generated by Gray-Scott simulation.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling\u003c/h2\u003e\n\u003cp\u003eWe assume there is a new account on cori system, and we need following operations to install necessary depedencies\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSpack configuration\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThere are two ways to use the Spack to install the software packages, the first one is to init the package.yaml file and the second one is to use the spack env.\u003c/p\u003e\n\u003cp\u003eFor example, we use \u003ccode\u003espack arch -p\u003c/code\u003e to check the current architecture. If the architecture is the cray, the \u003ccode\u003epackage.yaml\u003c/code\u003e file should locate at the \u003ccode\u003e~/.spack/cray/\u003c/code\u003e. And we update the \u003ccode\u003epackage.yaml\u003c/code\u003e file as needed for installing the mochi-software stacks. One sample \u003ccode\u003epackage.yaml\u003c/code\u003e for cori system is located in \u003ccode\u003e./config/cori/packages.yaml\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe repo of the spack used by the mochi project: \u003ca href=\"https://xgitlab.cels.anl.gov/sds/sds-repo.git\" rel=\"nofollow\"\u003ehttps://xgitlab.cels.anl.gov/sds/sds-repo.git\u003c/a\u003e, we need to add this repo into the spack system by executing \u003ccode\u003espack repo add sds-repo\u003c/code\u003e at the current direactly.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBuilding ParaView patch version\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe source code of ParaView patch is located at this repo: \u003ca href=\"https://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration\" rel=\"nofollow\"\u003ehttps://gitlab.kitware.com/mdorier/paraview/-/tree/dev-icet-integration\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://gitlab.kitware.com/mdorier/paraview.git\ncd paraview\ngit checkout ecb0a075f459c9db78bdd57bf83d715a99f0fe55\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe ParaView needs the osmesa to support the capability of in-situ rendering. We use the osmesa installed by the spack on the cori system:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodule load spack\nspack load -r mesa/qozjngg\nPATH=\"/global/common/cori/software/altd/2.0/bin:$PATH\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe also need to set the compiler on the cori before building the ParaView\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# for compiling vtk on cori\nexport CRAYPE_LINK_TYPE=dynamic\n\n# let cc and CC to be the gnu compier\nmodule swap PrgEnv-intel PrgEnv-gnu\n\nmodule swap gcc/8.3.0 gcc/9.3.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAt the build direactory of the ParaView, we use cmake commands as follows (if we assume the source direactory is \u003ccode\u003e~/cworkspace/src/ParaView_patch/paraview\u003c/code\u003e):\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmake ~/cworkspace/src/ParaView_patch/paraview -DPARAVIEW_USE_QT=OFF -DPARAVIEW_USE_PYTHON=ON -DPARAVIEW_USE_MPI=ON -DVTK_OPENGL_HAS_OSMESA:BOOL=TRUE -DVTK_USE_X:BOOL=FALSE -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_PYTHON_OPTIONAL_LINK=OFF -DCMAKE_BUILD_TYPE=Release\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eBuilding and installing Colza\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis command will install the mochi-colza and other related mochi softwares\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install mochi-colza@main+drc+examples%gcc@9.3.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eBuilding all examples\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWe can load these depedencies if all packages are installed successfully. The sample commands are located in \u003ccode\u003econfig/cori/monavtkEnv.sh\u003c/code\u003e. We execute these commands before building the mona-vtk examples.\u003c/p\u003e\n\u003cp\u003eThen we can build the mona-vtk the cmake command like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecmake ~/cworkspace/src/mona-vtk/ -DCMAKE_CXX_COMPILER=CC -DCMAKE_C_COMPILER=cc -DVTK_DIR=$SCRATCH/build_paraview_patch_release/ -DENABLE_EXAMPLE=ON -DParaView_DIR=$SCRATCH/build_paraview_patch_release/ -DBUILD_SHARED_LIBS=ON \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning\u003c/h2\u003e\n\u003cp\u003eThe scripts for scale evaluation are located at the \u003ccode\u003eexample/MandelbulbColza/testScripts\u003c/code\u003e and \u003ccode\u003e./example/GrayScottColza/testScripts\u003c/code\u003e separately.\u003c/p\u003e\n\u003cp\u003eFor example, we can set the build and src dir properly at the beginning of the scripts, such as\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eBUILDDIR=/global/cscratch1/sd/zw241/build_monavtk\nSRCDIR=/global/homes/z/zw241/cworkspace/src/mona-vtk\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand then use sbatch to submit jobs with specific node configurations as needed:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esbatch ~/cworkspace/src/mona-vtk/example/MandelbulbColza/testScripts/strongscale/cori_strongscale_mona_4.scripts\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eor\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esbatch ~/cworkspace/src/mona-vtk/example/GrayScottColza/testScripts/strongscale/cori_gsstrongscale_mona_128_512.scripts\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe can check the corresponding server and log file to get the particular data put and analysing time.\u003c/p\u003e\n\u003cp\u003eFor example, the \u003ccode\u003embclient_mona_4_512.log\u003c/code\u003e records the client information when there are 4 staging processes and 512 client pracesses.\u003c/p\u003e\n\u003cp\u003eFor the \u003ccode\u003eMandelbulbColza\u003c/code\u003e example, we can set the size of the data block by updating the \u003ccode\u003eBLOCKLENW\u003c/code\u003e, \u003ccode\u003eBLOCKLENH\u003c/code\u003e and \u003ccode\u003eBLOCKLEND\u003c/code\u003e in the associated script.\u003c/p\u003e\n\u003cp\u003eFor the \u003ccode\u003eGrayScottColza\u003c/code\u003e example, we can set the size of the data block by updating the \u003ccode\u003eL\u003c/code\u003e value at the client configuration file. For example, at the \u003ccode\u003eclient_settings_monaback_408.json\u003c/code\u003e, we set the \u003ccode\u003eL\u003c/code\u003e as 408, which means there are \u003ccode\u003e408*408*408\u003c/code\u003e cells for each data block.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-other-potential-issues\" class=\"anchor\" href=\"#other-potential-issues\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOther potential issues\u003c/h2\u003e\n\u003cp\u003eWe could also try to install osmesa by spack manaully:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install mesa+osmesa~llvm swr=none\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5\" rel=\"nofollow\"\u003ehttps://discourse.paraview.org/t/undefined-symbol-pyexc-valueerror/5494/5\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e/usr/bin/ld: /global/common/sw/cray/sles15/x86_64/mesa/18.3.6/gcc/8.2.0/qozjngg/lib/libOSMesa.so: undefined reference to `del_curterm@NCURSES6_TINFO_5.0.19991023\u0027\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003etry this:\u003c/p\u003e\n\u003cp\u003eSET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -ltinfo\")\u003c/p\u003e\n\u003cp\u003erefer to\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/halide/Halide/issues/1112\"\u003ehttps://github.com/halide/Halide/issues/1112\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eif the MPICH_GNI_NDREG_ENTRIES is not set properly\n\u003ca href=\"https://github.com/mercury-hpc/mercury/issues/426\"\u003ehttps://github.com/mercury-hpc/mercury/issues/426\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003esome osmesa warning from paraview if it is built in the Debug mode for building paraview (it is ok when we use the Release mode to build the paraview)\u003c/p\u003e\n\u003cp\u003e(  44.958s) [pvbatch.3       ]vtkOpenGLFramebufferObj:356    ERR| vtkOpenGLFramebufferObject (0x10005dc58e0): failed at glGenFramebuffers 1 OpenGL errors detected\n1:   0 : (1280) Invalid enum\u003c/p\u003e\n\u003cp\u003evtkOpenGLState.cxx:505   WARN| Error glBindFramebuffer1 OpenGL errors detected\n2:   0 : (1280) Invalid enum\u003c/p\u003e\n\u003cp\u003eTry to build the paraview with the Release mode, otherwise, there are mosa related warnings\u003c/p\u003e\n\u003cp\u003eFor the python on cori, refer to this (\u003ca href=\"https://docs.nersc.gov/development/languages/python/nersc-python/\" rel=\"nofollow\"\u003ehttps://docs.nersc.gov/development/languages/python/nersc-python/\u003c/a\u003e)\nIf you only use the module option, but the python is not the default one, there are some issues\u003c/p\u003e\n\u003cp\u003eOne issue is \"unnamed python module encoding\", or other issues that have different gcc version which may cause the byte code issue\nIt is prefered to use the conda activate then the python virtual env if you not use the default python3 system on cori\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1617912788.0
  },
  {
    "data_format": 2,
    "description": "Mochi-based staging service for in situ analysis and visualization",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-colza",
    "latest_release": "v0.1",
    "readme": "",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1617665054.0
  },
  {
    "data_format": 2,
    "description": "Mochi\u0027s REsource Migration Interface",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-remi",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-resource-migration-interface\" class=\"anchor\" href=\"#resource-migration-interface\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eREsource Migration Interface\u003c/h1\u003e\n\u003cp\u003eREMI is a Mochi microservice designed to handle the migration of sets of files\nfrom a node to another. It uses RDMA and memory mapping to efficiently transfer\npotentially large groups of files at once.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-installing\" class=\"anchor\" href=\"#installing\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling\u003c/h3\u003e\n\u003cp\u003eJust like all Mochi services, REMI can be installed using Spack. Once you have\nclone the \u003ca href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\"\u003esds-repo\u003c/a\u003e package repository\nand added it to your spack installation, you can install REMI using the following\ncommand:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install mochi-remi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eREMI depends on \u003ca href=\"https://xgitlab.cels.anl.gov/sds/thallium/\" rel=\"nofollow\"\u003eThallium\u003c/a\u003e, which\nSpack will install (if needed) along with Thallium\u0027s own dependencies. It also\ndepends on Bedrock, unless the \u003ccode\u003ebedrock\u003c/code\u003e variant is disable when installing\nwith Spack (i.e. passing \u003ccode\u003e~bedrock\u003c/code\u003e to the above command).\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-overview\" class=\"anchor\" href=\"#overview\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h3\u003e\n\u003cp\u003eREMI works with \u003cem\u003efilesets\u003c/em\u003e. A fileset consists of a root directory and\na set of file paths relative to this root directory. A fileset is also characterized\nby the name of its \u003cem\u003emigration class\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eREMI clients create filesets to group files corresponding to a particular resource\n(e.g. a database\u0027s files). They can then request the migration of fileset to\na target provider.\u003c/p\u003e\n\u003cp\u003eUppon receiving a request for migration, a provider will recreate the tree of\ndirectories required to receive the files of the fileset, create the files,\nmmap them into memory, and issue an RDMA pull operation from the client\u0027s files\n(themselves mmap-ed into the client\u0027s memory).\u003c/p\u003e\n\u003cp\u003eFollowing successful migration, the provider will call a user-supplied callback\ncorresponding to the particular fileset\u0027s migration class.\u003c/p\u003e\n\u003cp\u003eFor an example of code, please see the \u003ca href=\"examples\"\u003eexamples\u003c/a\u003e\nfolder in the source tree.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1614271878.0
  },
  {
    "data_format": 2,
    "description": "Python binding to the Mochi Sonata microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/py-mochi-sonata",
    "latest_release": null,
    "readme": "\u003cp\u003ePy-Sonata is a Python interface for the \u003ca href=\"https://github.com/mochi-hpc/mochi-sonata\"\u003eSonata Mochi microservice\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1614213349.0
  },
  {
    "data_format": 2,
    "description": "Template for a thallium-based Mochi microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/thallium-microservice-template",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-thallium-microservice-template\" class=\"anchor\" href=\"#thallium-microservice-template\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThallium Microservice Template\u003c/h1\u003e\n\u003cp\u003eThis project is a template to start developing a Mochi microservice based on Thallium.\nThe complete documentation to get started using this template is available\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/templates/02_thallium.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1614210486.0
  },
  {
    "data_format": 2,
    "description": "Template for a margo-based Mochi microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/margo-microservice-template",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-margo-microservice-template\" class=\"anchor\" href=\"#margo-microservice-template\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMargo Microservice Template\u003c/h1\u003e\n\u003cp\u003eThis project is a template to start developing a Mochi microservice based on Margo.\nThe complete documentation to get started using this template is available\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/templates/01_margo.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1614210543.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mdorier/test-ssg-cori",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h1\u003e\n\u003cp\u003eSetup spack and sds-repo, clone this repository and \u003ccode\u003ecd\u003c/code\u003e in it, then:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env create ssg-test spack.yaml\nspack env activate ssg-test\nspack install\nspack env deactivate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen to build the code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport CRAYPE_LINK_TYPE=dynamic\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\nspack env activate ssg-test\nmkdir build\ncd build\ncmake ..\nmake\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning\u003c/h1\u003e\n\u003cp\u003eFrom the \u003ccode\u003ebuild\u003c/code\u003e directory:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 128 ./test-server\n# one of the server will print \"Credential: X\", copy the X\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn another terminal window, with current working directory set to \u003ccode\u003ebuild\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 1 ./test-client X # replace X with the copied value\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1614204735.0
  },
  {
    "data_format": 2,
    "description": "Benchmark exercizing the ParallelEventProcessor feature of HEPnOS.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "hepnos/HEPnOS-PEP-Benchmark",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h1\u003e\n\u003cp\u003eSetup spack and sds-repo, clone this repository and \u003ccode\u003ecd\u003c/code\u003e in it, then:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack env create ssg-test spack.yaml\nspack env activate ssg-test\nspack install\nspack env deactivate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen to build the code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport CRAYPE_LINK_TYPE=dynamic\nmodule swap PrgEnv-intel PrgEnv-gnu\nmodule swap gcc/8.3.0 gcc/9.3.0\nspack env activate ssg-test\nmkdir build\ncd build\ncmake ..\nmake\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-running\" class=\"anchor\" href=\"#running\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning\u003c/h1\u003e\n\u003cp\u003eFrom the \u003ccode\u003ebuild\u003c/code\u003e directory:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 128 ./test-server\n# one of the server will print \"Credential: X\", copy the X\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn another terminal window, with current working directory set to \u003ccode\u003ebuild\u003c/code\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eexport MPICH_GNI_NDREG_ENTRIES=1024\nexport HG_NA_LOG_LEVEL=debug\nexport ABT_THREAD_STACKSIZE=2097152\nsrun -C haswell -n 1 ./test-client X # replace X with the copied value\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1613603490.0
  },
  {
    "data_format": 2,
    "description": "HEPnOS is a distributed object store for high energy physics applications, developed at Argonne National Laboratory.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "hepnos/HEPnOS",
    "latest_release": "v0.4.2",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-hepnos\" class=\"anchor\" href=\"#hepnos\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHEPnOS\u003c/h1\u003e\n\u003cp\u003eHEPnOS is the \u003cem\u003eHigh-Energy Physics\u0027s new Object Store\u003c/em\u003e, a distributed storage\nsystem specially designed for HEP experiments and workflows for the FermiLab.\nHEPnOS relies on libraries developed at Argonne National Laboratory within the\ncontext of the Mochi project (ANL, CMU, LANL, HDF Group).\u003c/p\u003e\n\u003cp\u003eFor information on copyright and licensing, see the COPYRIGHT file.\nFor information on how to use, see the \u003ca href=\"https://xgitlab.cels.anl.gov/sds/HEPnOS/wikis/home\" rel=\"nofollow\"\u003ewiki\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1617116230.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "contrib/spack/spack.yaml"
    ],
    "full_name": "felixthieme/2020_ASPECT_IGG",
    "latest_release": null,
    "readme": "\u003cp\u003e(Cloned from ASPECT by Felix Thieme (Idaho Geodynamics Group) on 5/27/2020)\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-aspect---advanced-solver-for-problems-in-earths-convection\" class=\"anchor\" href=\"#aspect---advanced-solver-for-problems-in-earths-convection\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eASPECT - Advanced Solver for Problems in Earth\u0027s ConvecTion\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/geodynamics/aspect/blob/master/LICENSE\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6bdbfedce993ff7baeecb8c93e87eeebe79d7ae3d19002c54f87e301ec0e7cdc/68747470733a2f2f696d672e736869656c64732e696f2f6372616e2f6c2f646576746f6f6c732e737667\" alt=\"License GPL2:\" data-canonical-src=\"https://img.shields.io/cran/l/devtools.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.2653531\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/91da28a81e083b7f3b47a26fd70f2dfcf0a87a9306f2b6f0d457a65ebe089752/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e323635333533312e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.2653531.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.6084/m9.figshare.4865333\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7f17ee0a3d31869d37f8d1b1f43540d6fb99d9a8c72bcf879977682693cbe1a7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6765742d5044462d677265656e2e737667\" alt=\"pdf manual\" data-canonical-src=\"https://img.shields.io/badge/get-PDF-green.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-about\" class=\"anchor\" href=\"#about\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAbout\u003c/h2\u003e\n\u003cp\u003eASPECT is a code to simulate convection in Earth\u0027s mantle and elsewhere.\nIt has grown from a pure mantle-convection code into a tool for many\ngeodynamic applications including applications for inner core convection,\nlithospheric scale deformation, two-phase flow, and numerical methods development.\nThe project is supported by CIG (\u003ca href=\"http://geodynamics.org\" rel=\"nofollow\"\u003ehttp://geodynamics.org\u003c/a\u003e).\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-installation-instructions\" class=\"anchor\" href=\"#installation-instructions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation instructions\u003c/h2\u003e\n\u003cp\u003eThe steps to install the necessary dependencies and ASPECT itself are described\nin the Installation instructions section of the ASPECT\n\u003ca href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\"\u003emanual\u003c/a\u003e. If you encounter\nproblems during the installation, please consult our\n\u003ca href=\"https://github.com/geodynamics/aspect/wiki\"\u003ewiki\u003c/a\u003e for typical installation\nproblems or specific instructions for MacOS users, before asking your question\non the mailing list.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-and-extending-aspect\" class=\"anchor\" href=\"#running-and-extending-aspect\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning and extending ASPECT\u003c/h2\u003e\n\u003cp\u003eInstructions on how to run and extend, as well as on how to interpret the\noutput of ASPECT can also be found in the ASPECT\n\u003ca href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\"\u003emanual\u003c/a\u003e. This manual also\ndiscusses the structure of the source code.\u003c/p\u003e\n\u003cp\u003eFor getting started, you can also watch our online\n\u003ca href=\"https://geodynamics.org/cig/events/calendar/2016-cig-all-hands-meeting/aspect-tutorial/tutorial/\" rel=\"nofollow\"\u003etutorial\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-contributing-to-aspect\" class=\"anchor\" href=\"#contributing-to-aspect\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing to ASPECT\u003c/h2\u003e\n\u003cp\u003eASPECT is a community project that lives by the participation of its\nmembers \u2014 i.e., including you! It is our goal to build an inclusive\nand participatory community so we are happy that you are interested in\nparticipating! We have collected a set of guidelines and advice on how\nto get involved in the community and keep them in the\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e\nfile in ASPECT\u0027s repository.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-more-information\" class=\"anchor\" href=\"#more-information\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMore information\u003c/h2\u003e\n\u003cp\u003eFor more information see:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eThe official website at \u003ca href=\"https://aspect.geodynamics.org\" rel=\"nofollow\"\u003ehttps://aspect.geodynamics.org\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe current \u003ca href=\"http://www.math.clemson.edu/~heister/manual.pdf\" rel=\"nofollow\"\u003emanual\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://aspect.geodynamics.org/cite.html\" rel=\"nofollow\"\u003eHow to cite ASPECT\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eFor questions on the source code of ASPECT, portability, installation, new or existing features, etc., use the \u003ca href=\"https://community.geodynamics.org/c/aspect\" rel=\"nofollow\"\u003eASPECT forum\u003c/a\u003e. This forum is where the ASPECT users and developers all hang out. Archived discussions from the inactive aspect-devel mailing list can be downloaded at \u003ca href=\"http://lists.geodynamics.org/pipermail/aspect-devel\" rel=\"nofollow\"\u003easpect-devel archives\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eASPECT is primarily based on the deal.II library. If you have particular questions about deal.II, contact the \u003ca href=\"https://www.dealii.org/mail.html\" rel=\"nofollow\"\u003edeal.II discussion groups\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIn case of more general questions about mantle convection, you can contact the \u003ca href=\"http://lists.geodynamics.org/cgi-bin/mailman/listinfo/cig-MC\" rel=\"nofollow\"\u003eCIG mantle convection mailing lists\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eASPECT is being developed by a large, collaborative, and inclusive community. It is currently maintained by the following people:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWolfgang Bangerth: \u003ca href=\"mailto:bangerth@math.colostate.edu\"\u003ebangerth@math.colostate.edu\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eJuliane Dannberg: \u003ca href=\"mailto:judannberg@gmail.com\"\u003ejudannberg@gmail.com\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eRene Gassmoeller: \u003ca href=\"mailto:rene.gassmoeller@mailbox.org\"\u003erene.gassmoeller@mailbox.org\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eTimo Heister: \u003ca href=\"mailto:heister@clemson.edu\"\u003eheister@clemson.edu\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe following people have significantly contributed and furthered ASPECT\u0027s goals and are therefore Principal Developers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eJacky Austermann\u003c/li\u003e\n\u003cli\u003eWolfgang Bangerth\u003c/li\u003e\n\u003cli\u003eJuliane Dannberg\u003c/li\u003e\n\u003cli\u003eMenno Fraters\u003c/li\u003e\n\u003cli\u003eRene Gassmoeller\u003c/li\u003e\n\u003cli\u003eAnne Glerum\u003c/li\u003e\n\u003cli\u003eTimo Heister\u003c/li\u003e\n\u003cli\u003eJohn Naliboff\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eA complete and growing list of the many authors that have contributed over the years can be found at \u003ca href=\"https://github.com/geodynamics/aspect/graphs/contributors\"\u003egithub\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf you have specific questions about ASPECT that are not suitable for public and archived mailing lists, feel free to contact the maintainers or principal developers.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eASPECT is published under \u003ca href=\"LICENSE\"\u003eGPL v2 or newer\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1590632076.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "player1537/dhmem",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-dhmem-simplified-cross-workflow-communication\" class=\"anchor\" href=\"#dhmem-simplified-cross-workflow-communication\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDhmem: Simplified Cross-Workflow Communication\u003c/h1\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-buildinginstalling\" class=\"anchor\" href=\"#buildinginstalling\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding/Installing\u003c/h2\u003e\n\u003cp\u003eTo build, either vendor the source code and include with CMake\u0027s \u003ccode\u003eadd_subdirectory\u003c/code\u003e or add via \u003ccode\u003eExternalProject_Add\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-example\" class=\"anchor\" href=\"#example\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExample\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003edhmem/dhmem.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003ecstdio\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e **argv) {\n    dhmem::Dhmem \u003cspan class=\"pl-smi\"\u003edhmem\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eshared_memory_namespace\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n\n    \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u0026amp;n = dhmem.\u003cspan class=\"pl-smi\"\u003eshared\u003c/span\u003e\u0026lt;\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e\u0026gt;();\n    \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u0026amp;mutex = dhmem.\u003cspan class=\"pl-smi\"\u003eshared\u003c/span\u003e\u0026lt;dhmem::mutex\u0026gt;();\n    \n    {\n        dhmem::scoped_lock \u003cspan class=\"pl-smi\"\u003elock\u003c/span\u003e(mutex);\n        ++n;\n        \u003cspan class=\"pl-c1\"\u003estd::printf\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003en = %d\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, n);\n    }\n\n    \u003cspan class=\"pl-c1\"\u003estd::printf\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ePress Enter to quit...\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e);\n    \u003cspan class=\"pl-c1\"\u003estd::getchar\u003c/span\u003e();\n\n    \u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1614216540.0
  },
  {
    "data_format": 2,
    "description": "A random and evolving collection of ansible playbooks.",
    "filenames": [
      "roles/ronin_cluster/files/ronin_cluster-spack.yaml"
    ],
    "full_name": "smutch/playbooks",
    "latest_release": null,
    "readme": "\u003ch2\u003e\n\u003ca id=\"user-content-playbooks\" class=\"anchor\" href=\"#playbooks\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePlaybooks\u003c/h2\u003e\n\u003cp\u003eThis is a random collection of playbooks and roles as I begin my journey using\nansible to automate the tedious set up devel machines.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1612705252.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [],
    "full_name": "UCR-Research-Computing/using-nautilus-cluster",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-using-nautilus-cluster\" class=\"anchor\" href=\"#using-nautilus-cluster\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eusing-nautilus-cluster\u003c/h1\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-basic-commmands\" class=\"anchor\" href=\"#basic-commmands\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ebasic commmands\u003c/h3\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\nkubectl get pods\nkubectl create -f \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eyaml-file\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\nkubectl delete pods \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epod-name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\n\nkubectl \u003cspan class=\"pl-c1\"\u003eexec\u003c/span\u003e -it \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epod-name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e bash\nkubectl port-forward \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epod-name\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e 8888:8888\n\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-starting-jupyter\" class=\"anchor\" href=\"#starting-jupyter\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStarting Jupyter\u003c/h3\u003e\n\u003cp\u003eUse the tensorflow-cpu-pod.yaml or tensorflow-gpu-pod.yaml file to start the pod\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\nkubectl create -f tensorflow-gpu-pod.yaml\nkubectl \u003cspan class=\"pl-c1\"\u003eexec\u003c/span\u003e -it gpu-pod-example bash\n\njovyan@gpu-pod-example:\u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e$ jupyter notebook --ip=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e0.0.0.0\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e\n\nkubectl port-forward gpu-pod-example 8888:8888\n\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eopen browser to localhost:8888 and paste in the token from the jupyter notebook start command\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 0,
    "topics": [],
    "updated_at": 1607345085.0
  },
  {
    "data_format": 2,
    "description": "The Core Registry of Container Blueprints for the Autamus Build System",
    "filenames": [
      "containers/g/graphviz/spack.yaml",
      "containers/i/igraph/spack.yaml",
      "containers/m/mothur/spack.yaml",
      "containers/p/pandaseq/spack.yaml",
      "containers/c/corset/spack.yaml",
      "containers/g/go/spack.yaml",
      "containers/a/advancecomp/spack.yaml",
      "containers/p/proj/spack.yaml",
      "containers/v/valgrind/spack.yaml",
      "containers/e/eagle/spack.yaml",
      "containers/r/raxml/spack.yaml",
      "containers/g/gmp/spack.yaml",
      "containers/m/mummer/spack.yaml",
      "containers/p/poppler/spack.yaml",
      "containers/x/xrootd/spack.yaml",
      "containers/s/singularity/spack.yaml",
      "containers/v/viennarna/spack.yaml",
      "containers/b/boost/spack.yaml",
      "containers/m/meme/spack.yaml",
      "containers/p/prodigal/spack.yaml",
      "containers/j/jags/spack.yaml",
      "containers/p/plink/spack.yaml",
      "containers/c/circos/spack.yaml",
      "containers/b/beast2/spack.yaml",
      "containers/r/r-seqlogo/spack.yaml",
      "containers/a/astral/spack.yaml",
      "containers/i/iq-tree/spack.yaml",
      "containers/s/scons/spack.yaml",
      "containers/b/bedtools2/spack.yaml",
      "containers/r/ruby/spack.yaml",
      "containers/a/alps/spack.yaml",
      "containers/p/protobuf/spack.yaml",
      "containers/a/admixtools/spack.yaml",
      "containers/g/git/spack.yaml",
      "containers/g/gnuplot/spack.yaml",
      "containers/g/geant4/spack.yaml",
      "containers/g/geos/spack.yaml",
      "containers/m/mono/spack.yaml",
      "containers/b/binutils/spack.yaml",
      "containers/n/nco/spack.yaml",
      "containers/f/fastqc/spack.yaml",
      "containers/q/qhull/spack.yaml",
      "containers/p/papi/spack.yaml",
      "containers/c/cloc/spack.yaml",
      "containers/o/octave/spack.yaml",
      "containers/p/perl/spack.yaml",
      "containers/t/tcsh/spack.yaml",
      "containers/h/hypre/spack.yaml",
      "containers/c/cctools/spack.yaml",
      "containers/r/rust/spack.yaml",
      "containers/c/cdo/spack.yaml",
      "containers/o/openbabel/spack.yaml",
      "containers/s/sparsehash/spack.yaml",
      "containers/i/ior/spack.yaml",
      "containers/a/apr/spack.yaml",
      "containers/l/lmod/spack.yaml",
      "containers/s/sparse/spack.yaml",
      "containers/g/gdal/spack.yaml",
      "containers/l/libpng/spack.yaml",
      "containers/p/pcre/spack.yaml",
      "containers/b/bracken/spack.yaml",
      "containers/d/dyninst/spack.yaml",
      "containers/r/r/spack.yaml",
      "containers/o/openjdk/spack.yaml",
      "containers/c/clingo-bootstrap/spack.yaml",
      "containers/a/accumulo/spack.yaml",
      "containers/a/aria2/spack.yaml",
      "containers/m/mpc/spack.yaml",
      "containers/b/bbmap/spack.yaml",
      "containers/l/lp-solve/spack.yaml",
      "containers/c/cowsay/spack.yaml",
      "containers/a/abyss/spack.yaml",
      "containers/c/cufflinks/spack.yaml",
      "containers/g/gsl/spack.yaml",
      "containers/a/autodock-gpu/spack.yaml",
      "containers/m/mercurial/spack.yaml",
      "containers/b/bedops/spack.yaml",
      "containers/m/mafft/spack.yaml",
      "containers/i/intel-mkl/spack.yaml",
      "containers/g/gromacs/spack.yaml",
      "containers/c/cantera/spack.yaml",
      "containers/g/glpk/spack.yaml",
      "containers/m/mpfr/spack.yaml",
      "containers/b/bowtie2/spack.yaml",
      "containers/w/wget/spack.yaml",
      "containers/r/rclone/spack.yaml",
      "containers/a/apr-util/spack.yaml",
      "containers/a/ascent/spack.yaml",
      "containers/a/addrwatch/spack.yaml",
      "containers/h/htslib/spack.yaml",
      "containers/n/node-js/spack.yaml",
      "containers/a/ant/spack.yaml",
      "containers/h/hdf5/spack.yaml",
      "containers/a/argobots/spack.yaml",
      "containers/a/angsd/spack.yaml",
      "containers/s/samtools/spack.yaml",
      "containers/b/bwa/spack.yaml",
      "containers/g/gatk/spack.yaml",
      "containers/j/julia/spack.yaml",
      "containers/s/salmon/spack.yaml",
      "containers/s/spades/spack.yaml",
      "containers/d/dakota/dakota/spack.yaml",
      "containers/o/opencv/spack.yaml",
      "containers/b/bart/spack.yaml",
      "containers/l/lammps/spack.yaml",
      "containers/m/muscle/spack.yaml",
      "containers/a/alan/spack.yaml",
      "containers/b/bismark/spack.yaml",
      "containers/l/libtiff/spack.yaml",
      "containers/c/cfitsio/spack.yaml",
      "containers/s/siesta/spack.yaml",
      "containers/a/autodock-vina/spack.yaml",
      "containers/c/curl/spack.yaml",
      "containers/d/diamond/spack.yaml",
      "containers/u/unixodbc/spack.yaml",
      "containers/s/stringtie/spack.yaml",
      "containers/g/grass/spack.yaml",
      "containers/m/migrate/spack.yaml",
      "containers/f/fraggenescan/spack.yaml",
      "containers/h/hisat2/spack.yaml",
      "containers/s/snappy/spack.yaml",
      "containers/c/clhep/spack.yaml",
      "containers/l/libxpm/spack.yaml",
      "containers/h/heaptrack/spack.yaml",
      "containers/a/abi-dumper/spack.yaml",
      "containers/c/clingo/spack.yaml",
      "containers/z/zlib/spack.yaml",
      "containers/f/ffmpeg/spack.yaml",
      "containers/j/jasper/spack.yaml",
      "containers/x/xz/spack.yaml",
      "containers/u/udunits/spack.yaml",
      "containers/h/hmmer/spack.yaml",
      "containers/g/gcc/spack.yaml",
      "containers/k/kallisto/spack.yaml",
      "containers/s/sqlite/spack.yaml",
      "containers/k/kraken2/spack.yaml",
      "containers/b/bcftools/spack.yaml",
      "containers/p/python/spack.yaml",
      "containers/p/povray/spack.yaml",
      "containers/p/picard/spack.yaml"
    ],
    "full_name": "autamus/registry",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-registry\" class=\"anchor\" href=\"#registry\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRegistry\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://avatars.githubusercontent.com/u/73002963\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/73002963\" width=\"300\" height=\"300\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\nThe Core Registry of Container Blueprints for the Autamus Build System\n\u003ch2\u003e\n\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#backstory\"\u003eBackstory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#downloading-a-container\"\u003eDownloading A Container\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#submitting-a-package\"\u003eSubmitting A Package\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#container-size-comparison\"\u003eContainer Size Comparison\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-backstory\" class=\"anchor\" href=\"#backstory\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBackstory\u003c/h2\u003e\n\u003cp\u003eAt the end of my undergraduate freshman year, as my internship with the University\u0027s Research \u0026amp; HPC Computing group was finishing up, a friend (@bjoyce3) and I (@alecbcs) were talking about the software installed on our University\u0027s local HPC. In particular, how the age of many of the analysis packages (and their depedencies) were keeping us from updating the operating systems of the clusters. During that conversation, we started dreaming about \"an autonoumous build system\" for scientific containers. One that would update containers as new versions of their source code became available, rebuild containers as a package\u0027s depedencies received updates, and thoroughly test the containers before publishing them. During that following summer, I was hired on by the HPC Team and this idea became a multi-year project. Although we\u0027ve still got a ways to go handling depdencies and testing contaiers we\u0027re ready to begin building analysis packages for researchers. If this interests you as a researcher, research software engineer, or system admin check below to see how you can submit packages and pull the built containers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAutamus is an semi-autonomous build system for scientific containers. What do I mean by \"semi-autonomous\"? Well given that the source code of a package is hosted on GitHub, GitLab, Sourceforge, etc... our bot Binoc can tell when new versions of a package have been released and will submit those updates as Pull Requests to this repository and attempt to build the updated packages. Don\u0027t worry a human will always be in the loop to check over and approve an update for security. With Binoc\u0027s help however, container maintainers no longer have to spend their time remembering to check every package for updates. From the perspective of a user this also means you can spend less time submitting update requests and more time using whichever version of a container that you\u0027d like.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-downloading-a-container\" class=\"anchor\" href=\"#downloading-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDownloading A Container\u003c/h3\u003e\n\u003cp\u003eRight now all of our packages are hosted on the GitHub Container Registry.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/orgs/autamus/packages\"\u003eCheck Them Out Here!\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-submitting-a-package\" class=\"anchor\" href=\"#submitting-a-package\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubmitting a Package\u003c/h3\u003e\n\u003cp\u003e*note: At the moment we are only building single package containers although multi-package containers are coming soon!\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFork this repository (button at the top right of this page!)\u003c/li\u003e\n\u003cli\u003eCheck out the \u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html\" rel=\"nofollow\"\u003eSpack Repository\u003c/a\u003e to see if they have the package build instructions you are looking for. Or checkout the \u003ca href=\"https://spack.readthedocs.io/en/latest/packaging_guide.html\" rel=\"nofollow\"\u003eSpack Docs\u003c/a\u003e to learn how to build your very of instruction file (called a Speck).\u003c/li\u003e\n\u003cli\u003eAdd that package.py file (and any other nessiary files like patches) to a directory in your fork of this repository under \u003ccode\u003espack/FIRST-LETTER-OF-APPLICATION/NAME-OF-APPLICATION/package.py\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eCommit that new directory to your fork and open a pull request on this repository from your fork.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-container-size-comparison\" class=\"anchor\" href=\"#container-size-comparison\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainer Size Comparison\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003ePackage/Container Name\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eAutamus Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eOfficial Dockerhub Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e417MB\u003c/td\u003e\n\u003ctd\u003e885MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eR\u003c/td\u003e\n\u003ctd\u003e517.9MB\u003c/td\u003e\n\u003ctd\u003e761.2MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGCC\u003c/td\u003e\n\u003ctd\u003e1.731GB\u003c/td\u003e\n\u003ctd\u003e1.186GB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGo\u003c/td\u003e\n\u003ctd\u003e751.2MB\u003c/td\u003e\n\u003ctd\u003e861.9MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-how-are-autamus-containers-smaller\" class=\"anchor\" href=\"#how-are-autamus-containers-smaller\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow are Autamus Containers Smaller?\u003c/h3\u003e\n\u003cp\u003eAutamus uses Spack to build all packages from source before deleting no longer needed build dependencies. As a result Autamus containers only contain a minimal Linux environment and the software of the container.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1621656911.0
  },
  {
    "data_format": 2,
    "description": "The Core Registry of Container Blueprints for the Autamus Build System",
    "filenames": [
      "containers/g/graphviz/spack.yaml",
      "containers/i/igraph/spack.yaml",
      "containers/m/mothur/spack.yaml",
      "containers/p/pandaseq/spack.yaml",
      "containers/c/corset/spack.yaml",
      "containers/g/go/spack.yaml",
      "containers/a/advancecomp/spack.yaml",
      "containers/p/proj/spack.yaml",
      "containers/v/valgrind/spack.yaml",
      "containers/e/eagle/spack.yaml",
      "containers/r/raxml/spack.yaml",
      "containers/g/gmp/spack.yaml",
      "containers/m/mummer/spack.yaml",
      "containers/p/poppler/spack.yaml",
      "containers/x/xrootd/spack.yaml",
      "containers/s/singularity/spack.yaml",
      "containers/v/viennarna/spack.yaml",
      "containers/b/boost/spack.yaml",
      "containers/m/meme/spack.yaml",
      "containers/p/prodigal/spack.yaml",
      "containers/j/jags/spack.yaml",
      "containers/p/plink/spack.yaml",
      "containers/c/circos/spack.yaml",
      "containers/b/beast2/spack.yaml",
      "containers/r/r-seqlogo/spack.yaml",
      "containers/a/astral/spack.yaml",
      "containers/i/iq-tree/spack.yaml",
      "containers/s/scons/spack.yaml",
      "containers/b/bedtools2/spack.yaml",
      "containers/r/ruby/spack.yaml",
      "containers/a/alps/spack.yaml",
      "containers/p/protobuf/spack.yaml",
      "containers/a/admixtools/spack.yaml",
      "containers/g/git/spack.yaml",
      "containers/g/gnuplot/spack.yaml",
      "containers/g/geant4/spack.yaml",
      "containers/g/geos/spack.yaml",
      "containers/m/mono/spack.yaml",
      "containers/b/binutils/spack.yaml",
      "containers/n/nco/spack.yaml",
      "containers/f/fastqc/spack.yaml",
      "containers/q/qhull/spack.yaml",
      "containers/p/papi/spack.yaml",
      "containers/c/cloc/spack.yaml",
      "containers/o/octave/spack.yaml",
      "containers/p/perl/spack.yaml",
      "containers/t/tcsh/spack.yaml",
      "containers/h/hypre/spack.yaml",
      "containers/c/cctools/spack.yaml",
      "containers/r/rust/spack.yaml",
      "containers/c/cdo/spack.yaml",
      "containers/o/openbabel/spack.yaml",
      "containers/s/sparsehash/spack.yaml",
      "containers/i/ior/spack.yaml",
      "containers/a/apr/spack.yaml",
      "containers/l/lmod/spack.yaml",
      "containers/s/sparse/spack.yaml",
      "containers/g/gdal/spack.yaml",
      "containers/l/libpng/spack.yaml",
      "containers/p/pcre/spack.yaml",
      "containers/b/bracken/spack.yaml",
      "containers/d/dyninst/spack.yaml",
      "containers/r/r/spack.yaml",
      "containers/o/openjdk/spack.yaml",
      "containers/c/clingo-bootstrap/spack.yaml",
      "containers/a/accumulo/spack.yaml",
      "containers/a/aria2/spack.yaml",
      "containers/m/mpc/spack.yaml",
      "containers/b/bbmap/spack.yaml",
      "containers/l/lp-solve/spack.yaml",
      "containers/c/cowsay/spack.yaml",
      "containers/a/abyss/spack.yaml",
      "containers/c/cufflinks/spack.yaml",
      "containers/g/gsl/spack.yaml",
      "containers/a/autodock-gpu/spack.yaml",
      "containers/m/mercurial/spack.yaml",
      "containers/b/bedops/spack.yaml",
      "containers/m/mafft/spack.yaml",
      "containers/i/intel-mkl/spack.yaml",
      "containers/g/gromacs/spack.yaml",
      "containers/c/cantera/spack.yaml",
      "containers/g/glpk/spack.yaml",
      "containers/m/mpfr/spack.yaml",
      "containers/b/bowtie2/spack.yaml",
      "containers/w/wget/spack.yaml",
      "containers/r/rclone/spack.yaml",
      "containers/a/apr-util/spack.yaml",
      "containers/a/ascent/spack.yaml",
      "containers/a/addrwatch/spack.yaml",
      "containers/h/htslib/spack.yaml",
      "containers/n/node-js/spack.yaml",
      "containers/a/ant/spack.yaml",
      "containers/h/hdf5/spack.yaml",
      "containers/a/argobots/spack.yaml",
      "containers/a/angsd/spack.yaml",
      "containers/s/samtools/spack.yaml",
      "containers/b/bwa/spack.yaml",
      "containers/g/gatk/spack.yaml",
      "containers/j/julia/spack.yaml",
      "containers/s/salmon/spack.yaml",
      "containers/s/spades/spack.yaml",
      "containers/d/dakota/dakota/spack.yaml",
      "containers/o/opencv/spack.yaml",
      "containers/b/bart/spack.yaml",
      "containers/l/lammps/spack.yaml",
      "containers/m/muscle/spack.yaml",
      "containers/a/alan/spack.yaml",
      "containers/b/bismark/spack.yaml",
      "containers/l/libtiff/spack.yaml",
      "containers/c/cfitsio/spack.yaml",
      "containers/s/siesta/spack.yaml",
      "containers/a/autodock-vina/spack.yaml",
      "containers/c/curl/spack.yaml",
      "containers/d/diamond/spack.yaml",
      "containers/u/unixodbc/spack.yaml",
      "containers/s/stringtie/spack.yaml",
      "containers/g/grass/spack.yaml",
      "containers/m/migrate/spack.yaml",
      "containers/f/fraggenescan/spack.yaml",
      "containers/h/hisat2/spack.yaml",
      "containers/s/snappy/spack.yaml",
      "containers/c/clhep/spack.yaml",
      "containers/l/libxpm/spack.yaml",
      "containers/h/heaptrack/spack.yaml",
      "containers/a/abi-dumper/spack.yaml",
      "containers/c/clingo/spack.yaml",
      "containers/z/zlib/spack.yaml",
      "containers/f/ffmpeg/spack.yaml",
      "containers/j/jasper/spack.yaml",
      "containers/x/xz/spack.yaml",
      "containers/u/udunits/spack.yaml",
      "containers/h/hmmer/spack.yaml",
      "containers/g/gcc/spack.yaml",
      "containers/k/kallisto/spack.yaml",
      "containers/s/sqlite/spack.yaml",
      "containers/k/kraken2/spack.yaml",
      "containers/b/bcftools/spack.yaml",
      "containers/p/python/spack.yaml",
      "containers/p/povray/spack.yaml",
      "containers/p/picard/spack.yaml"
    ],
    "full_name": "autamus/registry",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-registry\" class=\"anchor\" href=\"#registry\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRegistry\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://avatars.githubusercontent.com/u/73002963\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/73002963\" width=\"300\" height=\"300\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\nThe Core Registry of Container Blueprints for the Autamus Build System\n\u003ch2\u003e\n\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#backstory\"\u003eBackstory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#downloading-a-container\"\u003eDownloading A Container\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#submitting-a-package\"\u003eSubmitting A Package\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#container-size-comparison\"\u003eContainer Size Comparison\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-backstory\" class=\"anchor\" href=\"#backstory\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBackstory\u003c/h2\u003e\n\u003cp\u003eAt the end of my undergraduate freshman year, as my internship with the University\u0027s Research \u0026amp; HPC Computing group was finishing up, a friend (@bjoyce3) and I (@alecbcs) were talking about the software installed on our University\u0027s local HPC. In particular, how the age of many of the analysis packages (and their depedencies) were keeping us from updating the operating systems of the clusters. During that conversation, we started dreaming about \"an autonoumous build system\" for scientific containers. One that would update containers as new versions of their source code became available, rebuild containers as a package\u0027s depedencies received updates, and thoroughly test the containers before publishing them. During that following summer, I was hired on by the HPC Team and this idea became a multi-year project. Although we\u0027ve still got a ways to go handling depdencies and testing contaiers we\u0027re ready to begin building analysis packages for researchers. If this interests you as a researcher, research software engineer, or system admin check below to see how you can submit packages and pull the built containers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAutamus is an semi-autonomous build system for scientific containers. What do I mean by \"semi-autonomous\"? Well given that the source code of a package is hosted on GitHub, GitLab, Sourceforge, etc... our bot Binoc can tell when new versions of a package have been released and will submit those updates as Pull Requests to this repository and attempt to build the updated packages. Don\u0027t worry a human will always be in the loop to check over and approve an update for security. With Binoc\u0027s help however, container maintainers no longer have to spend their time remembering to check every package for updates. From the perspective of a user this also means you can spend less time submitting update requests and more time using whichever version of a container that you\u0027d like.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-downloading-a-container\" class=\"anchor\" href=\"#downloading-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDownloading A Container\u003c/h3\u003e\n\u003cp\u003eRight now all of our packages are hosted on the GitHub Container Registry.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/orgs/autamus/packages\"\u003eCheck Them Out Here!\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-submitting-a-package\" class=\"anchor\" href=\"#submitting-a-package\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubmitting a Package\u003c/h3\u003e\n\u003cp\u003e*note: At the moment we are only building single package containers although multi-package containers are coming soon!\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFork this repository (button at the top right of this page!)\u003c/li\u003e\n\u003cli\u003eCheck out the \u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html\" rel=\"nofollow\"\u003eSpack Repository\u003c/a\u003e to see if they have the package build instructions you are looking for. Or checkout the \u003ca href=\"https://spack.readthedocs.io/en/latest/packaging_guide.html\" rel=\"nofollow\"\u003eSpack Docs\u003c/a\u003e to learn how to build your very of instruction file (called a Speck).\u003c/li\u003e\n\u003cli\u003eAdd that package.py file (and any other nessiary files like patches) to a directory in your fork of this repository under \u003ccode\u003espack/FIRST-LETTER-OF-APPLICATION/NAME-OF-APPLICATION/package.py\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eCommit that new directory to your fork and open a pull request on this repository from your fork.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-container-size-comparison\" class=\"anchor\" href=\"#container-size-comparison\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainer Size Comparison\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003ePackage/Container Name\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eAutamus Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eOfficial Dockerhub Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e417MB\u003c/td\u003e\n\u003ctd\u003e885MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eR\u003c/td\u003e\n\u003ctd\u003e517.9MB\u003c/td\u003e\n\u003ctd\u003e761.2MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGCC\u003c/td\u003e\n\u003ctd\u003e1.731GB\u003c/td\u003e\n\u003ctd\u003e1.186GB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGo\u003c/td\u003e\n\u003ctd\u003e751.2MB\u003c/td\u003e\n\u003ctd\u003e861.9MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-how-are-autamus-containers-smaller\" class=\"anchor\" href=\"#how-are-autamus-containers-smaller\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow are Autamus Containers Smaller?\u003c/h3\u003e\n\u003cp\u003eAutamus uses Spack to build all packages from source before deleting no longer needed build dependencies. As a result Autamus containers only contain a minimal Linux environment and the software of the container.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1621656911.0
  },
  {
    "data_format": 2,
    "description": "The Core Registry of Container Blueprints for the Autamus Build System",
    "filenames": [
      "containers/g/graphviz/spack.yaml",
      "containers/i/igraph/spack.yaml",
      "containers/m/mothur/spack.yaml",
      "containers/p/pandaseq/spack.yaml",
      "containers/c/corset/spack.yaml",
      "containers/g/go/spack.yaml",
      "containers/a/advancecomp/spack.yaml",
      "containers/p/proj/spack.yaml",
      "containers/v/valgrind/spack.yaml",
      "containers/e/eagle/spack.yaml",
      "containers/r/raxml/spack.yaml",
      "containers/g/gmp/spack.yaml",
      "containers/m/mummer/spack.yaml",
      "containers/p/poppler/spack.yaml",
      "containers/x/xrootd/spack.yaml",
      "containers/s/singularity/spack.yaml",
      "containers/v/viennarna/spack.yaml",
      "containers/b/boost/spack.yaml",
      "containers/m/meme/spack.yaml",
      "containers/p/prodigal/spack.yaml",
      "containers/j/jags/spack.yaml",
      "containers/p/plink/spack.yaml",
      "containers/c/circos/spack.yaml",
      "containers/b/beast2/spack.yaml",
      "containers/r/r-seqlogo/spack.yaml",
      "containers/a/astral/spack.yaml",
      "containers/i/iq-tree/spack.yaml",
      "containers/s/scons/spack.yaml",
      "containers/b/bedtools2/spack.yaml",
      "containers/r/ruby/spack.yaml",
      "containers/a/alps/spack.yaml",
      "containers/p/protobuf/spack.yaml",
      "containers/a/admixtools/spack.yaml",
      "containers/g/git/spack.yaml",
      "containers/g/gnuplot/spack.yaml",
      "containers/g/geant4/spack.yaml",
      "containers/g/geos/spack.yaml",
      "containers/m/mono/spack.yaml",
      "containers/b/binutils/spack.yaml",
      "containers/n/nco/spack.yaml",
      "containers/f/fastqc/spack.yaml",
      "containers/q/qhull/spack.yaml",
      "containers/p/papi/spack.yaml",
      "containers/c/cloc/spack.yaml",
      "containers/o/octave/spack.yaml",
      "containers/p/perl/spack.yaml",
      "containers/t/tcsh/spack.yaml",
      "containers/h/hypre/spack.yaml",
      "containers/c/cctools/spack.yaml",
      "containers/r/rust/spack.yaml",
      "containers/c/cdo/spack.yaml",
      "containers/o/openbabel/spack.yaml",
      "containers/s/sparsehash/spack.yaml",
      "containers/i/ior/spack.yaml",
      "containers/a/apr/spack.yaml",
      "containers/l/lmod/spack.yaml",
      "containers/s/sparse/spack.yaml",
      "containers/g/gdal/spack.yaml",
      "containers/l/libpng/spack.yaml",
      "containers/p/pcre/spack.yaml",
      "containers/b/bracken/spack.yaml",
      "containers/d/dyninst/spack.yaml",
      "containers/r/r/spack.yaml",
      "containers/o/openjdk/spack.yaml",
      "containers/c/clingo-bootstrap/spack.yaml",
      "containers/a/accumulo/spack.yaml",
      "containers/a/aria2/spack.yaml",
      "containers/m/mpc/spack.yaml",
      "containers/b/bbmap/spack.yaml",
      "containers/l/lp-solve/spack.yaml",
      "containers/c/cowsay/spack.yaml",
      "containers/a/abyss/spack.yaml",
      "containers/c/cufflinks/spack.yaml",
      "containers/g/gsl/spack.yaml",
      "containers/a/autodock-gpu/spack.yaml",
      "containers/m/mercurial/spack.yaml",
      "containers/b/bedops/spack.yaml",
      "containers/m/mafft/spack.yaml",
      "containers/i/intel-mkl/spack.yaml",
      "containers/g/gromacs/spack.yaml",
      "containers/c/cantera/spack.yaml",
      "containers/g/glpk/spack.yaml",
      "containers/m/mpfr/spack.yaml",
      "containers/b/bowtie2/spack.yaml",
      "containers/w/wget/spack.yaml",
      "containers/r/rclone/spack.yaml",
      "containers/a/apr-util/spack.yaml",
      "containers/a/ascent/spack.yaml",
      "containers/a/addrwatch/spack.yaml",
      "containers/h/htslib/spack.yaml",
      "containers/n/node-js/spack.yaml",
      "containers/a/ant/spack.yaml",
      "containers/h/hdf5/spack.yaml",
      "containers/a/argobots/spack.yaml",
      "containers/a/angsd/spack.yaml",
      "containers/s/samtools/spack.yaml",
      "containers/b/bwa/spack.yaml",
      "containers/g/gatk/spack.yaml",
      "containers/j/julia/spack.yaml",
      "containers/s/salmon/spack.yaml",
      "containers/s/spades/spack.yaml",
      "containers/d/dakota/dakota/spack.yaml",
      "containers/o/opencv/spack.yaml",
      "containers/b/bart/spack.yaml",
      "containers/l/lammps/spack.yaml",
      "containers/m/muscle/spack.yaml",
      "containers/a/alan/spack.yaml",
      "containers/b/bismark/spack.yaml",
      "containers/l/libtiff/spack.yaml",
      "containers/c/cfitsio/spack.yaml",
      "containers/s/siesta/spack.yaml",
      "containers/a/autodock-vina/spack.yaml",
      "containers/c/curl/spack.yaml",
      "containers/d/diamond/spack.yaml",
      "containers/u/unixodbc/spack.yaml",
      "containers/s/stringtie/spack.yaml",
      "containers/g/grass/spack.yaml",
      "containers/m/migrate/spack.yaml",
      "containers/f/fraggenescan/spack.yaml",
      "containers/h/hisat2/spack.yaml",
      "containers/s/snappy/spack.yaml",
      "containers/c/clhep/spack.yaml",
      "containers/l/libxpm/spack.yaml",
      "containers/h/heaptrack/spack.yaml",
      "containers/a/abi-dumper/spack.yaml",
      "containers/c/clingo/spack.yaml",
      "containers/z/zlib/spack.yaml",
      "containers/f/ffmpeg/spack.yaml",
      "containers/j/jasper/spack.yaml",
      "containers/x/xz/spack.yaml",
      "containers/u/udunits/spack.yaml",
      "containers/h/hmmer/spack.yaml",
      "containers/g/gcc/spack.yaml",
      "containers/k/kallisto/spack.yaml",
      "containers/s/sqlite/spack.yaml",
      "containers/k/kraken2/spack.yaml",
      "containers/b/bcftools/spack.yaml",
      "containers/p/python/spack.yaml",
      "containers/p/povray/spack.yaml",
      "containers/p/picard/spack.yaml"
    ],
    "full_name": "autamus/registry",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-registry\" class=\"anchor\" href=\"#registry\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRegistry\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://avatars.githubusercontent.com/u/73002963\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://avatars.githubusercontent.com/u/73002963\" width=\"300\" height=\"300\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\nThe Core Registry of Container Blueprints for the Autamus Build System\n\u003ch2\u003e\n\u003ca id=\"user-content-table-of-contents\" class=\"anchor\" href=\"#table-of-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#backstory\"\u003eBackstory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#introduction\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#downloading-a-container\"\u003eDownloading A Container\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#submitting-a-package\"\u003eSubmitting A Package\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#container-size-comparison\"\u003eContainer Size Comparison\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-backstory\" class=\"anchor\" href=\"#backstory\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBackstory\u003c/h2\u003e\n\u003cp\u003eAt the end of my undergraduate freshman year, as my internship with the University\u0027s Research \u0026amp; HPC Computing group was finishing up, a friend (@bjoyce3) and I (@alecbcs) were talking about the software installed on our University\u0027s local HPC. In particular, how the age of many of the analysis packages (and their depedencies) were keeping us from updating the operating systems of the clusters. During that conversation, we started dreaming about \"an autonoumous build system\" for scientific containers. One that would update containers as new versions of their source code became available, rebuild containers as a package\u0027s depedencies received updates, and thoroughly test the containers before publishing them. During that following summer, I was hired on by the HPC Team and this idea became a multi-year project. Although we\u0027ve still got a ways to go handling depdencies and testing contaiers we\u0027re ready to begin building analysis packages for researchers. If this interests you as a researcher, research software engineer, or system admin check below to see how you can submit packages and pull the built containers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-introduction\" class=\"anchor\" href=\"#introduction\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAutamus is an semi-autonomous build system for scientific containers. What do I mean by \"semi-autonomous\"? Well given that the source code of a package is hosted on GitHub, GitLab, Sourceforge, etc... our bot Binoc can tell when new versions of a package have been released and will submit those updates as Pull Requests to this repository and attempt to build the updated packages. Don\u0027t worry a human will always be in the loop to check over and approve an update for security. With Binoc\u0027s help however, container maintainers no longer have to spend their time remembering to check every package for updates. From the perspective of a user this also means you can spend less time submitting update requests and more time using whichever version of a container that you\u0027d like.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-downloading-a-container\" class=\"anchor\" href=\"#downloading-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDownloading A Container\u003c/h3\u003e\n\u003cp\u003eRight now all of our packages are hosted on the GitHub Container Registry.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/orgs/autamus/packages\"\u003eCheck Them Out Here!\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-submitting-a-package\" class=\"anchor\" href=\"#submitting-a-package\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubmitting a Package\u003c/h3\u003e\n\u003cp\u003e*note: At the moment we are only building single package containers although multi-package containers are coming soon!\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eFork this repository (button at the top right of this page!)\u003c/li\u003e\n\u003cli\u003eCheck out the \u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html\" rel=\"nofollow\"\u003eSpack Repository\u003c/a\u003e to see if they have the package build instructions you are looking for. Or checkout the \u003ca href=\"https://spack.readthedocs.io/en/latest/packaging_guide.html\" rel=\"nofollow\"\u003eSpack Docs\u003c/a\u003e to learn how to build your very of instruction file (called a Speck).\u003c/li\u003e\n\u003cli\u003eAdd that package.py file (and any other nessiary files like patches) to a directory in your fork of this repository under \u003ccode\u003espack/FIRST-LETTER-OF-APPLICATION/NAME-OF-APPLICATION/package.py\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eCommit that new directory to your fork and open a pull request on this repository from your fork.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-container-size-comparison\" class=\"anchor\" href=\"#container-size-comparison\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainer Size Comparison\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003cstrong\u003ePackage/Container Name\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eAutamus Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003cth\u003e\u003cstrong\u003eOfficial Dockerhub Container Size\u003c/strong\u003e\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e417MB\u003c/td\u003e\n\u003ctd\u003e885MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eR\u003c/td\u003e\n\u003ctd\u003e517.9MB\u003c/td\u003e\n\u003ctd\u003e761.2MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGCC\u003c/td\u003e\n\u003ctd\u003e1.731GB\u003c/td\u003e\n\u003ctd\u003e1.186GB\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGo\u003c/td\u003e\n\u003ctd\u003e751.2MB\u003c/td\u003e\n\u003ctd\u003e861.9MB\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-how-are-autamus-containers-smaller\" class=\"anchor\" href=\"#how-are-autamus-containers-smaller\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow are Autamus Containers Smaller?\u003c/h3\u003e\n\u003cp\u003eAutamus uses Spack to build all packages from source before deleting no longer needed build dependencies. As a result Autamus containers only contain a minimal Linux environment and the software of the container.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1621656911.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "hariharan-devarajan/emacs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" class=\"anchor\" href=\"#spack-configuration-files-and-scripts-for-use-on-machines-at-nrel\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack configuration files and scripts for use on machines at NREL\u003c/h1\u003e\n\u003cp\u003eThese software installations are maintained by Jon Rood for the HPACF group at NREL and are tailored to the applications our group develops. The list of available modules can be seen in \u003ca href=\"modules.txt\"\u003emodules.txt\u003c/a\u003e. They are open to anyone to use on our machines. The software installations are organized by date snapshots. The binaries, compilers, and utilties are not updated as often as the software modules, so dated symlinks might point to older dates for those. However, each date snapshot of the modules should be able to stand on its own so that older snapshots can be purged safely over time.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\"base\" is just a newer version of GCC to replace the system GCC 4.8.5 which is far too old to build many recent projects.\u003c/li\u003e\n\u003cli\u003e\"binaries\" are generally the binary downloads of Paraview and Visit.\u003c/li\u003e\n\u003cli\u003e\"compilers\" are the latest set of compilers built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"utilities\" are the latest set of utility programs that don\u0027t rely on MPI and are built using the base GCC.\u003c/li\u003e\n\u003cli\u003e\"software\" are the latest set of generally larger programs and dependencies that rely on MPI. Each date corresponds to a single MPI implementation so there is no confusion as to which MPI was used for the applications. These modules are built using a farily recent GCC, Clang, or Intel compiler provided from the \"compilers\" modules, using the highest optimization flags specific to the machine architecture.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe Spack hierarchy is linked in the following manner where each installation is based on other upstream Spack installations. \"software\" depends on \"utilities\", which both depend on \"compilers\". This hierarchy allows Spack to point to packages it needs which are already built upstream. The \"compilers\" installation exposes only the modules for compilers, while the \"utilities\" modules inherit modules from itself as well as the dependency packages in the \"compilers\" installation except the compiler modules themselves.\u003c/p\u003e\n\u003cp\u003eCurrently there is no perfect way to advertise deprecation or addition, and evolution of these modules. I have an MOTD you can cat in your login script to see updates. Generally the latest 4 sets of modules will likely be kept and new sets have been showing up around every 3 to 6 months.\u003c/p\u003e\n\u003cp\u003eTo use these modules you can add the following to your \u003ccode\u003e~/.bashrc\u003c/code\u003e for example and choose the module set (date) you prefer, and the GCC or Intel compiled software modules:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e#------------------------------------------\n\n#MPT 2.22\n#MODULES=modules-2020-07\n#COMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3.1\n#MODULES=modules-2019-10-08\n#COMPILER=gcc-7.4.0\n#COMPILER=clang-7.0.1\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-23\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-05-08\n#COMPILER=gcc-7.4.0\n#COMPILER=intel-18.0.4\n\n#MPICH 3.3\n#MODULES=modules-2019-01-10\n#COMPILER=gcc-7.3.0\n#COMPILER=intel-18.0.4\n\n#Recommended default according to where \"modules\" is currently symlinked\nMODULES=modules\nCOMPILER=gcc-8.4.0\n#COMPILER=clang-10.0.0\n#COMPILER=intel-18.0.4\n\nmodule purge\nmodule unuse ${MODULEPATH}\nmodule use /nopt/nrel/ecom/hpacf/binaries/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/compilers/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/utilities/${MODULES}\nmodule use /nopt/nrel/ecom/hpacf/software/${MODULES}/${COMPILER}\nmodule load gcc\nmodule load git\nmodule load python\n#etc...\n\n#------------------------------------------\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf \u003ccode\u003emodule avail\u003c/code\u003e does not show the modules on Eagle, try removing the LMOD cache with \u003ccode\u003erm -rf ~/.lmod.d/.cache\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eAlso included in this directory is a recommended Spack configurations you can use to build your own packages on the machines supported at NREL. Once you have \u003ccode\u003eSPACK_ROOT\u003c/code\u003e set you can run \u003ccode\u003e/nopt/nrel/ecom/hpacf/spack-configs/scripts/setup-spack.sh\u003c/code\u003e which should copy the yaml files into your instance of Spack. Or you can copy the yaml files into your \u003ccode\u003e${SPACK_ROOT}/etc\u003c/code\u003e directory manually. \u003ccode\u003espack compilers\u003c/code\u003e should then show you many available compilers. Source your Spack\u0027s \u003ccode\u003esetup-env.sh\u003c/code\u003e after you do the \u003ccode\u003emodule unuse ${MODULEPATH}\u003c/code\u003e in your \u003ccode\u003e.bashrc\u003c/code\u003e so that your Spack instance will add its own module path to MODULEPATH. Remove \u003ccode\u003e~/.spack/linux\u003c/code\u003e if it exists and \u003ccode\u003espack compilers\u003c/code\u003e doesn\u0027t show you the updated list of compilers. The \u003ccode\u003e~/.spack\u003c/code\u003e directory takes highest precendence in the Spack configuration.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1620426207.0
  },
  {
    "data_format": 2,
    "description": "The Spack-operator manages automated builds on a distributed and heterogeneus kubernetes cluster",
    "filenames": [],
    "full_name": "ArangoGutierrez/spack-operator",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-operator\" class=\"anchor\" href=\"#spack-operator\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-operator\u003c/h1\u003e\n\u003cp\u003eThe Spack-operator manages automated builds on a distributed and heterogeneus kubernetes cluster\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1613727652.0
  },
  {
    "data_format": 2,
    "description": "Documentations and tutorials for Margo, Thallium, Argobots, Mercury, and other Mochi libraries.",
    "filenames": [
      "code/spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-doc",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-mochi-documentation\" class=\"anchor\" href=\"#mochi-documentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMochi documentation\u003c/h1\u003e\n\u003cp\u003eThis repository contains a Sphinx-based documentation\nfor the Mochi libraries: Margo, Thallium, Argobots, Mercury,\nABT-IO, and SSG, as well as corresponding code examples.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-the-documentation\" class=\"anchor\" href=\"#building-the-documentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the documentation\u003c/h2\u003e\n\u003cp\u003eTo build and/orcontribute to this documentation, make sure\nthat you have Sphinx installed as well as the ReadTheDoc theme.\nThese can be installed as follows using Python\u0027s \u003ccode\u003epip\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install sphinx\npip install sphinx_rtd_theme\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you have these dependencies installed, clone this\nrepository and cd into it. You can change the documentation\nby editing the files in the source subdirectory (these files\nuse the .rst format). You can build the documentation\nusing the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd docs\nmake html\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd check the result by opening the \u003ccode\u003ebuild/index.html\u003c/code\u003e page\nthat has been created in the docs directory.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building-the-code-examples\" class=\"anchor\" href=\"#building-the-code-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the code examples\u003c/h2\u003e\n\u003cp\u003eTo build the code, you will need spack and the\n\u003ca href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\"\u003esds-repo\u003c/a\u003e setup.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd code\nspack env create mochi-doc-env spack.yaml\nspack env activate mochi-doc-env\nspack install\nmkdir build\ncd build\ncmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc\nmake\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1621119976.0
  },
  {
    "data_format": 2,
    "description": "2021 IN PROGRESS -- Getting Started with Containers on HPC",
    "filenames": [
      "files/spack_contenerize/spack.yaml",
      "exercises/spack_contenerize/spack.yaml"
    ],
    "full_name": "supercontainers/isc-tutorial",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-getting-started-with-containers-on-hpc\" class=\"anchor\" href=\"#getting-started-with-containers-on-hpc\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting Started with Containers on HPC\u003c/h1\u003e\n\u003cp\u003eView this on \u003ca href=\"https://supercontainers.github.io/isc-tutorial/\" rel=\"nofollow\"\u003eGitHub Pages\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-ecp-supercontainers-tutorial-session\" class=\"anchor\" href=\"#ecp-supercontainers-tutorial-session\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eECP Supercontainers Tutorial Session\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"fig/ecp.jpg\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"fig/ecp.jpg\" width=\"250\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003ca href=\"fig/pawsey.jpeg\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"fig/pawsey.jpeg\" width=\"250\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-details\" class=\"anchor\" href=\"#details\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDetails\u003c/h2\u003e\n\u003cp\u003eHalf-day Tutorial Session\u003c/p\u003e\n\u003cp\u003eVenue: International Supercomputing Conference (ISC21)\u003c/p\u003e\n\u003cp\u003eDate: TBD, 24 or 25 June 2021 2:00pm - 6:00pm (European Central Time)\u003c/p\u003e\n\u003cp\u003eLocation: Virtual\u003c/p\u003e\n\u003cp\u003eLink: \u003ca href=\"https://www.isc-hpc.com/\" rel=\"nofollow\"\u003eGetting Started with Containers in HPC @ ISC21\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eKeywords: Containerized HPC, System Software and Runtime Systems, Scientific Software Development, DevOps\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-ec2-login\" class=\"anchor\" href=\"#ec2-login\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEC2 Login\u003c/h2\u003e\n\u003cp\u003eThese will be provided the day of the tutorial.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-abstract\" class=\"anchor\" href=\"#abstract\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eContainer computing has revolutionized the way applications are developed and delivered. It offers opportunities that never existed before for significantly improving efficiency of scientific workflows and easily moving these workflows from the laptop to the supercomputer. Tools like Docker, Shifter, Singularity, Charliecloud and Podman enable a new paradigm for scientific and technical computing. However, to fully unlock its potential, users and administrators need to understand how to utilize these new approaches. This tutorial will introduce attendees to the basics of creating container images, explain best practices, and cover more advanced topics such as creating images to be run on HPC platforms using various container runtimes. The tutorial will also explain how research scientists can utilize container-based computing to accelerate their research and how these tools can boost the impact of their research by enabling better reproducibility and sharing of their scientific process without compromising security.\u003c/p\u003e\n\u003cp\u003eThis is an updated version of the highly successful tutorial presented at SC16-20 and ISC19.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-prerequisites\" class=\"anchor\" href=\"#prerequisites\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eThis is a hands-on tutorial. Participants should bring a laptop and load or pre-install a terminal and/or ssh client in advance to make best use of time during the tutorial.  We will be providing training user accounts to both pre-configured EC2 instances.\u003c/p\u003e\n\u003cdiv\u003e\u003ca href=\"fig/AWS_logo.png\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"fig/AWS_logo.png\" width=\"250\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp\u003eThis tutorial is supported by the Amazon AWS Machine Learning Research Awards. EC2 images and temporary login credentials will be distributed onsite at the tutorial.\u003c/p\u003e\n\u003cp\u003eAfter the tutorial, you can boot our tutorial image yourself on Amazon EC2 to run through the tutorial again. We recommend you use your own EC2 key and change the password.\u003c/p\u003e\n\u003cp\u003eUS-West-Oregon: ami-0fe12765123c6a840\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-optional-prerequisites\" class=\"anchor\" href=\"#optional-prerequisites\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOptional Prerequisites\u003c/h3\u003e\n\u003cp\u003eUsers can also install Docker and Singularity prior to attending the tutorial session. Here, it may be beneficial to create a docker and sylabs (singularity) account in advance at \u003ca href=\"https://cloud.docker.com/\" rel=\"nofollow\"\u003ehttps://cloud.docker.com/\u003c/a\u003e and \u003ca href=\"https://cloud.sylabs.io/\" rel=\"nofollow\"\u003ehttps://cloud.sylabs.io/\u003c/a\u003e This accounts will be needed to create images on docker cloud/dockerhub and sylabs cloud.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://sylabs.io/guides/3.7/user-guide/\" rel=\"nofollow\"\u003eInstall Singularity on Linux\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://repo.sylabs.io/desktop/\" rel=\"nofollow\"\u003eInstall Singualrity on Mac\u003c/a\u003e (Alpha)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\"\u003eInstall Docker for Desktop\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-questions\" class=\"anchor\" href=\"#questions\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQuestions\u003c/h2\u003e\n\u003cp\u003eYou can ask questions verbally or with this \u003ca href=\"https://docs.google.com/document/d/11gMZ-T7iA5XiRWPLYIqX7Gqv7RMb-NF9kzGYHrnOi04/edit?usp=sharing\" rel=\"nofollow\"\u003eGoogle Doc\u003c/a\u003e.\nPlease append your question below the others in the document.\u003c/p\u003e\n\u003cp\u003eWe have also created a Slack Team for this.  The invitation link is \u003ca href=\"https://join.slack.com/t/hpc-containers/shared_invite/enQtODI3NzY1NDU4OTk5LTUxOTgyOWJmYjIwOWI5YWU2MzBhZDI3Zjc1YmZmMjAxZjgzYzk4ZWEwNmFlNzlkOWI0MGNlZDNlMTBhYTBlOWY\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-schedule-tbd\" class=\"anchor\" href=\"#schedule-tbd\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSchedule (TBD)\u003c/h2\u003e\n\u003cp\u003e14:00 - 14:15 Introduction to containers in HPC (Shane)\u003cbr\u003e\nIncluding defining jargon (containers, images, registries/repos,..)\u003c/p\u003e\n\u003cp\u003e14:15 - 14:55 Build and run your first container with Podman (Shane)\u003cbr\u003e\nIncluding also minimal pull and run examples, to define these concepts\u003c/p\u003e\n\u003cp\u003e14:55 - 15:30 Deploy containers on a supercomputer (Marco)\u003c/p\u003e\n\u003cp\u003e15:30 - 16:00 High-performance containers (Marco)\u003c/p\u003e\n\u003cp\u003e16:00 - 16:30 BREAK\u003c/p\u003e\n\u003cp\u003e16:30 - 17:05 Best practices (Shane)\u003c/p\u003e\n\u003cp\u003e17:05 - 17:35 E4S containers initiative (Sameer)\u003c/p\u003e\n\u003cp\u003e17:35 - 17:55 Advanced container builds (Eduardo)\u003c/p\u003e\n\u003cp\u003e17:55 - 18:00 Wrap-up and final Q\u0026amp;A\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 8,
    "topics": [
      "hpc",
      "containers",
      "singularity-container",
      "singularity",
      "shifter",
      "docker",
      "tutorial",
      "supercomputer"
    ],
    "updated_at": 1621589992.0
  },
  {
    "data_format": 2,
    "description": "A Spack overlay repository of HEP software packaging.",
    "filenames": [
      "environments/key4hep-nightlies/spack.yaml",
      "environments/geant4-data-share/spack.yaml",
      "environments/key4hep-release-broadwell/spack.yaml",
      "environments/key4hep-release/spack.yaml",
      "environments/key4hep-release-user/spack.yaml",
      "environments/key4hep-nightlies-debug/spack.yaml",
      "environments/key4hep-debug/spack.yaml"
    ],
    "full_name": "key4hep/key4hep-spack",
    "latest_release": "2021-02-25a-opt",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-package-repo-for-key4hep-software-packaging\" class=\"anchor\" href=\"#spack-package-repo-for-key4hep-software-packaging\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package repo for Key4HEP software packaging\u003c/h1\u003e\n\u003cp\u003eThis repository holds a set of Spack recipes for key4hep software. It grew out of \u003ca href=\"https://github.com/HSF/hep-spack\"\u003ehttps://github.com/HSF/hep-spack\u003c/a\u003e, and many recipes habe been included in the upstream spack repostiory.\u003c/p\u003e\n\u003cp\u003eConsult the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack documentation\u003c/a\u003e and the \u003ca href=\"https://cern.ch/key4hep\" rel=\"nofollow\"\u003ekey4hep documentation website\u003c/a\u003e for more details.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-repository-contents\" class=\"anchor\" href=\"#repository-contents\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRepository Contents\u003c/h3\u003e\n\u003cp\u003eApart from the recipes for key4hep packages in the folder \u003ccode\u003epackages\u003c/code\u003e, the repository contains some \u003ccode\u003escripts\u003c/code\u003e used for publishing on cvmfs, and \u003ccode\u003econfig\u003c/code\u003e files for spack.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-central-installations\" class=\"anchor\" href=\"#central-installations\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCentral Installations\u003c/h3\u003e\n\u003cp\u003eInstallations of the software stack can be found under \u003ccode\u003e/cvmfs/sw.hsf.org/\u003c/code\u003e, see:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\" rel=\"nofollow\"\u003ehttps://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1621523159.0
  },
  {
    "data_format": 2,
    "description": "Argobots bindings for the Mercury RPC library",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-margo",
    "latest_release": "v0.9.4",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-margo\" class=\"anchor\" href=\"#margo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMargo\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mochi-margo/actions/workflows/test.yml/badge.svg?branch=main\" alt=\"\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/mochi-hpc/mochi-margo\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c64ae5809121f4158ced0cf46c628aca60e6db908b2639f6758b0595a6fdd779/68747470733a2f2f636f6465636f762e696f2f67682f6d6f6368692d6870632f6d6f6368692d6d6172676f2f6272616e63682f6d61696e2f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/mochi-hpc/mochi-margo/branch/main/graph/badge.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMargo provides Argobots-aware bindings to the Mercury RPC library.\u003c/p\u003e\n\u003cp\u003eMercury (\u003ca href=\"https://mercury-hpc.github.io/\" rel=\"nofollow\"\u003ehttps://mercury-hpc.github.io/\u003c/a\u003e) is a remote procedure call\nlibrary optimized for use in HPC environments.  Its native API presents a\ncallback-oriented interface to manage asynchronous operation.  Argobots\n(\u003ca href=\"https://www.argobots.org/\" rel=\"nofollow\"\u003ehttps://www.argobots.org/\u003c/a\u003e) is a user-level threading package.\u003c/p\u003e\n\u003cp\u003eMargo combines Mercury and Argobots to simplify development of distributed\nservices.  Mercury operations are presented as conventional blocking\noperations, and RPC handlers are presented as sequential threads.  This\nconfiguration enables high degree of concurrency while hiding the\ncomplexity associated with asynchronous communication progress and callback\nmanagement.\u003c/p\u003e\n\u003cp\u003eInternally, Margo suspends callers after issuing a Mercury operation, and\nautomatically resumes them when the operation completes.  This allows\nother concurrent user-level threads to make progress while Mercury\noperations are in flight without consuming operating system threads.\nThe goal of this design is to combine the performance advantages of\nMercury\u0027s native event-driven execution model with the progamming\nsimplicity of a multi-threaded execution model.\u003c/p\u003e\n\u003cp\u003eA companion library called abt-io provides similar wrappers for POSIX I/O\nfunctions: \u003ca href=\"https://github.com/mochi-hpc/mochi-abt-io\"\u003ehttps://github.com/mochi-hpc/mochi-abt-io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eNote that Margo should be compatible with any Mercury network\ntransport (NA plugin).  The documentation assumes the use of\nthe NA SM (shared memory) plugin that is built into Mercury for\nsimplicity.  This plugin is only valid for communication between\nprocesses on a single node.  See \u003ca href=\"##using-margo-with-other-mercury-na-plugins\"\u003eUsing Margo with other Mercury NA\nplugins\u003c/a\u003e for information\non other configuration options.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-spack\" class=\"anchor\" href=\"#spack\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h2\u003e\n\u003cp\u003eThe simplest way to install Margo is by installing the \"mochi-margo\" package\nin spack (\u003ca href=\"https://spack.io/\" rel=\"nofollow\"\u003ehttps://spack.io/\u003c/a\u003e).\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDependencies\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003emercury  (git clone --recurse-submodules \u003ca href=\"https://github.com/mercury-hpc/mercury.git\"\u003ehttps://github.com/mercury-hpc/mercury.git\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eargobots (git clone \u003ca href=\"https://github.com/pmodels/argobots.git\"\u003ehttps://github.com/pmodels/argobots.git\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-recommended-mercury-build-options\" class=\"anchor\" href=\"#recommended-mercury-build-options\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRecommended Mercury build options\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMercury must be compiled with -DMERCURY_USE_BOOST_PP:BOOL=ON to enable the\nBoost preprocessor macros for encoding.\u003c/li\u003e\n\u003cli\u003eMercury should be compiled with -DMERCURY_USE_SELF_FORWARD:BOOL=ON in order to enable\nfast execution path for cases in which a Mercury service is linked into the same\nexecutable as the client\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExample Mercury compilation:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir build\ncd build\ncmake -DMERCURY_USE_SELF_FORWARD:BOOL=ON \\\n -DBUILD_TESTING:BOOL=ON -DMERCURY_USE_BOOST_PP:BOOL=ON \\\n -DCMAKE_INSTALL_PREFIX=/home/pcarns/working/install \\\n -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_BUILD_TYPE:STRING=Debug ../\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-building\" class=\"anchor\" href=\"#building\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h2\u003e\n\u003cp\u003eExample configuration:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e../configure --prefix=/home/pcarns/working/install \\\n    PKG_CONFIG_PATH=/home/pcarns/working/install/lib/pkgconfig \\\n    CFLAGS=\"-g -Wall\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-examples\" class=\"anchor\" href=\"#running-examples\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning examples\u003c/h2\u003e\n\u003cp\u003eThe examples subdirectory contains:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emargo-example-client.c: an example client\u003c/li\u003e\n\u003cli\u003emargo-example-server.c: an example server\u003c/li\u003e\n\u003cli\u003emy-rpc.[ch]: an example RPC definition\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following example shows how to execute them.  Note that when the server starts it will display the address that the client can use to connect to it.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ examples/margo-example-server na+sm://\n# accepting RPCs on address \"na+sm://13367/0\"\nGot RPC request with input_val: 0\nGot RPC request with input_val: 1\nGot RPC request with input_val: 2\nGot RPC request with input_val: 3\nGot RPC request to shutdown\n\n$ examples/margo-example-client na+sm://13367/0\nULT [0] running.\nULT [1] running.\nULT [2] running.\nULT [3] running.\nGot response ret: 0\nULT [0] done.\nGot response ret: 0\nULT [1] done.\nGot response ret: 0\nULT [2] done.\nGot response ret: 0\nULT [3] done.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe client will issue 4 concurrent RPCs to the server and wait for them to\ncomplete.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-tests\" class=\"anchor\" href=\"#running-tests\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning tests\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003emake check\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-using-margo-with-the-other-na-plugins\" class=\"anchor\" href=\"#using-margo-with-the-other-na-plugins\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing Margo with the other NA plugins\u003c/h2\u003e\n\u003cp\u003eSee the \u003ca href=\"http://mercury-hpc.github.io/documentation/\" rel=\"nofollow\"\u003eMercury\ndocumentation\u003c/a\u003e for details.\nMargo is compatible with any Mercury transport and uses the same address\nformat.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-instrumentation\" class=\"anchor\" href=\"#instrumentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstrumentation\u003c/h2\u003e\n\u003cp\u003eSee the \u003ca href=\"doc/instrumentation.md\"\u003eInstrumentation documentation\u003c/a\u003e for\ninformation on how to extract diagnostic instrumentation from Margo.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-debugging\" class=\"anchor\" href=\"#debugging\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDebugging\u003c/h2\u003e\n\u003cp\u003eSee the \u003ca href=\"doc/debugging.md\"\u003eDebugging documentation\u003c/a\u003e for Margo debugging\nfeatures and strategies.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-design-details\" class=\"anchor\" href=\"#design-details\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDesign details\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"doc/fig/margo-diagram.png\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"doc/fig/margo-diagram.png\" alt=\"Margo architecture\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMargo provides Argobots-aware wrappers to common Mercury library functions\nlike HG_Forward(), HG_Addr_lookup(), and HG_Bulk_transfer().  The wrappers\nhave the same arguments as their native Mercury counterparts except that no\ncallback function is specified.  Each function blocks until the operation\nis complete.  The above diagram illustrates a typical control flow.\u003c/p\u003e\n\u003cp\u003eMargo launches a long-running user-level thread internally to drive\nprogress on Mercury and execute Mercury callback functions (labeled\n\u003ccode\u003e__margo_progress()\u003c/code\u003e above).  This thread can be assigned to a\ndedicated Argobots execution stream (i.e., an operating system thread)\nto drive network progress with a dedicated core.  Otherwise it will be\nautomatically scheduled when the caller\u0027s execution stream is blocked\nwaiting for network events as shown in the above diagram.\u003c/p\u003e\n\u003cp\u003eArgobots eventual constructs are used to suspend and resume user-level\nthreads while Mercury operations are in flight.\u003c/p\u003e\n\u003cp\u003eMargo allows several different threading/multicore configurations:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe progress loop can run on a dedicated operating system thread or not\u003c/li\u003e\n\u003cli\u003eMultiple Margo instances (and thus progress loops) can be\nexecuted on different operating system threads\u003c/li\u003e\n\u003cli\u003e(for servers) a single Margo instance can launch RPC handlers\non different operating system threads\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 7,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1621616859.0
  },
  {
    "data_format": 2,
    "description": "Installing spack without system dependencies",
    "filenames": [
      "build/5_runtime/spack.yaml",
      "build/6_spack/spack.yaml",
      "build/3_more_tools/spack.yaml",
      "build/1_ccache/spack.yaml",
      "build/2_compiler/spack.yaml"
    ],
    "full_name": "haampie/spack-batteries-included",
    "latest_release": "develop",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml\"\u003e\u003cimg src=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\" alt=\"Update spack develop version\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\" href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cg-emoji class=\"g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\u003e\ud83d\udd0b\u003c/g-emoji\u003e Spack with batteries included (linux/x86_64)\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e is a package manager, and package managers should be trivial to install.\u003c/p\u003e\n\u003cp\u003eThis repo offers a single, static executable for Spack:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ewget -qO spack.x https://github.com/haampie/spack-batteries-included/releases/download/develop/spack-x86_64.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003echmod +x spack.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack.x install zstd +programs \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003eshared build_type=Release\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\" href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat version of Spack is shipped?\u003c/h2\u003e\n\u003cp\u003eThe URL above gives you a rolling release of Spack\u0027s develop branch, which is updated\nhourly. The exact commit SHA is included as a file and can be retrieved like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract spack_sha \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e cat spack/spack_sha\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e[prints the Spack commit sha]\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-supported-platforms\" class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupported platforms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCentOS 7 and above\u003c/li\u003e\n\u003cli\u003eUbuntu 14.04 and above\u003c/li\u003e\n\u003cli\u003eDebian 8 and above\u003c/li\u003e\n\u003cli\u003eFedora 20 and above\u003c/li\u003e\n\u003cli\u003eSUSE Linux 13 and above\u003c/li\u003e\n\u003cli\u003eArch Linux\u003c/li\u003e\n\u003cli\u003eGentoo\u003c/li\u003e\n\u003cli\u003eWindows Subsystem for Linux 2 with any of the above distro\u0027s.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe system dependencies are \u003ccode\u003eglibc 2.17\u003c/code\u003e and above and optionally the \u003ccode\u003efusermount\u003c/code\u003e\nexecutable. If your system supports rootless containers it likely has \u003ccode\u003efusermount\u003c/code\u003e\ninstalled already!\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-does-it-work\" class=\"anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow does it work?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003espack.x\u003c/code\u003e consists of a modified version of the AppImage runtime concatenated\nwith a big squashfs file which includes \u003ccode\u003ebinutils\u003c/code\u003e, \u003ccode\u003ebzip2\u003c/code\u003e, \u003ccode\u003eclingo\u003c/code\u003e, \u003ccode\u003ecurl\u003c/code\u003e,\n\u003ccode\u003efile\u003c/code\u003e, \u003ccode\u003egit\u003c/code\u003e, \u003ccode\u003egmake\u003c/code\u003e, \u003ccode\u003egpg\u003c/code\u003e, \u003ccode\u003egzip\u003c/code\u003e, \u003ccode\u003eopenssl\u003c/code\u003e, \u003ccode\u003epatch\u003c/code\u003e, \u003ccode\u003epatchelf\u003c/code\u003e, \u003ccode\u003epython\u003c/code\u003e,\n\u003ccode\u003epy-boto3\u003c/code\u003e, \u003ccode\u003etar\u003c/code\u003e, \u003ccode\u003eunzip\u003c/code\u003e, \u003ccode\u003exz\u003c/code\u003e, \u003ccode\u003ezstd\u003c/code\u003e and their dependencies.\u003c/p\u003e\n\u003cp\u003eWhen you run \u003ccode\u003espack.x [args]\u003c/code\u003e it will use \u003ccode\u003efusermount\u003c/code\u003e to\nmount this squashfs file in a temporary directory, and then execute the\nentrypoint executable \u003ca href=\"build/6_spack/spack\"\u003espack\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003espack\u003c/code\u003e executable sets some environment variables like \u003ccode\u003ePATH\u003c/code\u003e and\n\u003ccode\u003eDL_LIBRARY_PATH\u003c/code\u003e to the bin and lib folders of the squashfs file, and then it\nexecutes \u003ccode\u003epython3 spack_src/bin/spack [args]\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWhen the command is done running, the runtime unmounts the squashfs file again.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMy system doesn\u0027t allow me to use \u003ccode\u003efusermount\u003c/code\u003e, what now?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003efusermount\u003c/code\u003e is used to mount a squashfs file included in the binary. If you\ndon\u0027t want that, you can just extract it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack.x --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebut working with the extracted \u003ccode\u003espack\u003c/code\u003e folder can come with a performance\npenalty on shared filesystems in HPC centers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-differences-and-improvements-over-appimage-runtime\" class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDifferences and improvements over AppImage runtime\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003espack.x uses \u003ccode\u003ezstd\u003c/code\u003e for faster decompression;\u003c/li\u003e\n\u003cli\u003espack.x itself is an entirely static binary;\u003c/li\u003e\n\u003cli\u003espack.x does not need to dlopen libfuse.so.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTroubleshooting\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eimmutability\u003c/strong\u003e The squashfs mountpoint is a readonly folder, meaning that\nspack can\u0027t write to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard directories, see \u003ccode\u003espack.x config blame config\u003c/code\u003e for details.\u003c/p\u003e\n\u003cp\u003eNote, spack.x applies \u003ca href=\"https://github.com/spack/spack/pull/20158/\"\u003ethis patch\u003c/a\u003e\nto ensure that log files are written to the \u003ccode\u003econfig:misc_cache\u003c/code\u003e folder.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eopenssl\u003c/strong\u003e: By default spack.x uses \u003ccode\u003eca-certificates-mozilla\u003c/code\u003e for downloading\npackage sources over https. If you somehow need to use system certificates,\nset \u003ccode\u003eSSL_CERT_DIR\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CAINFO\u003c/code\u003e or \u003ccode\u003eSSL_CERT_FILE\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CERT\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCan I run spack.x inside a container?\u003c/h2\u003e\n\u003cp\u003eYes, but please don\u0027t! Since \u003ccode\u003efusermount\u003c/code\u003e is a setuid binary, you will need to\nrun a privileged container, which is never a good idea.\u003c/p\u003e\n\u003cp\u003eThe recommended way to run spack.x inside a container is to just extract it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack/spack --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you insist on running spack.x in Docker, this is one way to do it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esudo docker run --privileged --device /dev/fuse -it -v \u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/spack.x:/bin/spack.x ubuntu:18.04\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eapt update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt install fuse \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install fusermount\u003c/span\u003e\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003espack.x --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning an executable shipped with spack.x directly\u003c/h2\u003e\n\u003cp\u003eIf you want to run an executable shipped with \u003ccode\u003espack.x\u003c/code\u003e directly instead\nof invoking spack (the default entrypoint), try this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003eNO_ENTRYPOINT= spack.x which python\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/tmp/.mount_spack.h0zr1h/view/bin/python\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\" href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow do I build spack.x myself?\u003c/h2\u003e\n\u003cp\u003eInitially you may need docker to get a rootfs filesystem for centos 7.\u003c/p\u003e\n\u003cp\u003eBuilding goes like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003emake rootfs-with-spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003emake\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou\u0027ll find the output in\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuild/output\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 1,
    "topics": [
      "spack",
      "squashfs",
      "libfuse"
    ],
    "updated_at": 1621575407.0
  },
  {
    "data_format": 2,
    "description": "Installing spack without system dependencies",
    "filenames": [
      "build/5_runtime/spack.yaml",
      "build/6_spack/spack.yaml",
      "build/3_more_tools/spack.yaml",
      "build/1_ccache/spack.yaml",
      "build/2_compiler/spack.yaml"
    ],
    "full_name": "haampie/spack-batteries-included",
    "latest_release": "develop",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml\"\u003e\u003cimg src=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\" alt=\"Update spack develop version\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\" href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cg-emoji class=\"g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\u003e\ud83d\udd0b\u003c/g-emoji\u003e Spack with batteries included (linux/x86_64)\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e is a package manager, and package managers should be trivial to install.\u003c/p\u003e\n\u003cp\u003eThis repo offers a single, static executable for Spack:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ewget -qO spack.x https://github.com/haampie/spack-batteries-included/releases/download/develop/spack-x86_64.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003echmod +x spack.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack.x install zstd +programs \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003eshared build_type=Release\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\" href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat version of Spack is shipped?\u003c/h2\u003e\n\u003cp\u003eThe URL above gives you a rolling release of Spack\u0027s develop branch, which is updated\nhourly. The exact commit SHA is included as a file and can be retrieved like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract spack_sha \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e cat spack/spack_sha\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e[prints the Spack commit sha]\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-supported-platforms\" class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupported platforms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCentOS 7 and above\u003c/li\u003e\n\u003cli\u003eUbuntu 14.04 and above\u003c/li\u003e\n\u003cli\u003eDebian 8 and above\u003c/li\u003e\n\u003cli\u003eFedora 20 and above\u003c/li\u003e\n\u003cli\u003eSUSE Linux 13 and above\u003c/li\u003e\n\u003cli\u003eArch Linux\u003c/li\u003e\n\u003cli\u003eGentoo\u003c/li\u003e\n\u003cli\u003eWindows Subsystem for Linux 2 with any of the above distro\u0027s.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe system dependencies are \u003ccode\u003eglibc 2.17\u003c/code\u003e and above and optionally the \u003ccode\u003efusermount\u003c/code\u003e\nexecutable. If your system supports rootless containers it likely has \u003ccode\u003efusermount\u003c/code\u003e\ninstalled already!\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-does-it-work\" class=\"anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow does it work?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003espack.x\u003c/code\u003e consists of a modified version of the AppImage runtime concatenated\nwith a big squashfs file which includes \u003ccode\u003ebinutils\u003c/code\u003e, \u003ccode\u003ebzip2\u003c/code\u003e, \u003ccode\u003eclingo\u003c/code\u003e, \u003ccode\u003ecurl\u003c/code\u003e,\n\u003ccode\u003efile\u003c/code\u003e, \u003ccode\u003egit\u003c/code\u003e, \u003ccode\u003egmake\u003c/code\u003e, \u003ccode\u003egpg\u003c/code\u003e, \u003ccode\u003egzip\u003c/code\u003e, \u003ccode\u003eopenssl\u003c/code\u003e, \u003ccode\u003epatch\u003c/code\u003e, \u003ccode\u003epatchelf\u003c/code\u003e, \u003ccode\u003epython\u003c/code\u003e,\n\u003ccode\u003epy-boto3\u003c/code\u003e, \u003ccode\u003etar\u003c/code\u003e, \u003ccode\u003eunzip\u003c/code\u003e, \u003ccode\u003exz\u003c/code\u003e, \u003ccode\u003ezstd\u003c/code\u003e and their dependencies.\u003c/p\u003e\n\u003cp\u003eWhen you run \u003ccode\u003espack.x [args]\u003c/code\u003e it will use \u003ccode\u003efusermount\u003c/code\u003e to\nmount this squashfs file in a temporary directory, and then execute the\nentrypoint executable \u003ca href=\"build/6_spack/spack\"\u003espack\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003espack\u003c/code\u003e executable sets some environment variables like \u003ccode\u003ePATH\u003c/code\u003e and\n\u003ccode\u003eDL_LIBRARY_PATH\u003c/code\u003e to the bin and lib folders of the squashfs file, and then it\nexecutes \u003ccode\u003epython3 spack_src/bin/spack [args]\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWhen the command is done running, the runtime unmounts the squashfs file again.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMy system doesn\u0027t allow me to use \u003ccode\u003efusermount\u003c/code\u003e, what now?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003efusermount\u003c/code\u003e is used to mount a squashfs file included in the binary. If you\ndon\u0027t want that, you can just extract it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack.x --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebut working with the extracted \u003ccode\u003espack\u003c/code\u003e folder can come with a performance\npenalty on shared filesystems in HPC centers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-differences-and-improvements-over-appimage-runtime\" class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDifferences and improvements over AppImage runtime\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003espack.x uses \u003ccode\u003ezstd\u003c/code\u003e for faster decompression;\u003c/li\u003e\n\u003cli\u003espack.x itself is an entirely static binary;\u003c/li\u003e\n\u003cli\u003espack.x does not need to dlopen libfuse.so.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTroubleshooting\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eimmutability\u003c/strong\u003e The squashfs mountpoint is a readonly folder, meaning that\nspack can\u0027t write to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard directories, see \u003ccode\u003espack.x config blame config\u003c/code\u003e for details.\u003c/p\u003e\n\u003cp\u003eNote, spack.x applies \u003ca href=\"https://github.com/spack/spack/pull/20158/\"\u003ethis patch\u003c/a\u003e\nto ensure that log files are written to the \u003ccode\u003econfig:misc_cache\u003c/code\u003e folder.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eopenssl\u003c/strong\u003e: By default spack.x uses \u003ccode\u003eca-certificates-mozilla\u003c/code\u003e for downloading\npackage sources over https. If you somehow need to use system certificates,\nset \u003ccode\u003eSSL_CERT_DIR\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CAINFO\u003c/code\u003e or \u003ccode\u003eSSL_CERT_FILE\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CERT\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCan I run spack.x inside a container?\u003c/h2\u003e\n\u003cp\u003eYes, but please don\u0027t! Since \u003ccode\u003efusermount\u003c/code\u003e is a setuid binary, you will need to\nrun a privileged container, which is never a good idea.\u003c/p\u003e\n\u003cp\u003eThe recommended way to run spack.x inside a container is to just extract it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack/spack --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you insist on running spack.x in Docker, this is one way to do it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esudo docker run --privileged --device /dev/fuse -it -v \u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/spack.x:/bin/spack.x ubuntu:18.04\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eapt update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt install fuse \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install fusermount\u003c/span\u003e\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003espack.x --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning an executable shipped with spack.x directly\u003c/h2\u003e\n\u003cp\u003eIf you want to run an executable shipped with \u003ccode\u003espack.x\u003c/code\u003e directly instead\nof invoking spack (the default entrypoint), try this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003eNO_ENTRYPOINT= spack.x which python\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/tmp/.mount_spack.h0zr1h/view/bin/python\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\" href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow do I build spack.x myself?\u003c/h2\u003e\n\u003cp\u003eInitially you may need docker to get a rootfs filesystem for centos 7.\u003c/p\u003e\n\u003cp\u003eBuilding goes like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003emake rootfs-with-spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003emake\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou\u0027ll find the output in\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuild/output\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 1,
    "topics": [
      "spack",
      "squashfs",
      "libfuse"
    ],
    "updated_at": 1621575407.0
  },
  {
    "data_format": 2,
    "description": "Installing spack without system dependencies",
    "filenames": [
      "build/5_runtime/spack.yaml",
      "build/6_spack/spack.yaml",
      "build/3_more_tools/spack.yaml",
      "build/1_ccache/spack.yaml",
      "build/2_compiler/spack.yaml"
    ],
    "full_name": "haampie/spack-batteries-included",
    "latest_release": "develop",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml\"\u003e\u003cimg src=\"https://github.com/haampie/spack-batteries-included/actions/workflows/update-spack.yaml/badge.svg?branch=master\" alt=\"Update spack develop version\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content--spack-with-batteries-included-linuxx86_64\" class=\"anchor\" href=\"#-spack-with-batteries-included-linuxx86_64\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003cg-emoji class=\"g-emoji\" alias=\"battery\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/1f50b.png\"\u003e\ud83d\udd0b\u003c/g-emoji\u003e Spack with batteries included (linux/x86_64)\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e is a package manager, and package managers should be trivial to install.\u003c/p\u003e\n\u003cp\u003eThis repo offers a single, static executable for Spack:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ewget -qO spack.x https://github.com/haampie/spack-batteries-included/releases/download/develop/spack-x86_64.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003echmod +x spack.x\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack.x install zstd +programs \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003eshared build_type=Release\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-what-version-of-spack-is-shipped\" class=\"anchor\" href=\"#what-version-of-spack-is-shipped\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat version of Spack is shipped?\u003c/h2\u003e\n\u003cp\u003eThe URL above gives you a rolling release of Spack\u0027s develop branch, which is updated\nhourly. The exact commit SHA is included as a file and can be retrieved like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract spack_sha \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e cat spack/spack_sha\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e[prints the Spack commit sha]\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-supported-platforms\" class=\"anchor\" href=\"#supported-platforms\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupported platforms\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCentOS 7 and above\u003c/li\u003e\n\u003cli\u003eUbuntu 14.04 and above\u003c/li\u003e\n\u003cli\u003eDebian 8 and above\u003c/li\u003e\n\u003cli\u003eFedora 20 and above\u003c/li\u003e\n\u003cli\u003eSUSE Linux 13 and above\u003c/li\u003e\n\u003cli\u003eArch Linux\u003c/li\u003e\n\u003cli\u003eGentoo\u003c/li\u003e\n\u003cli\u003eWindows Subsystem for Linux 2 with any of the above distro\u0027s.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe system dependencies are \u003ccode\u003eglibc 2.17\u003c/code\u003e and above and optionally the \u003ccode\u003efusermount\u003c/code\u003e\nexecutable. If your system supports rootless containers it likely has \u003ccode\u003efusermount\u003c/code\u003e\ninstalled already!\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-does-it-work\" class=\"anchor\" href=\"#how-does-it-work\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow does it work?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003espack.x\u003c/code\u003e consists of a modified version of the AppImage runtime concatenated\nwith a big squashfs file which includes \u003ccode\u003ebinutils\u003c/code\u003e, \u003ccode\u003ebzip2\u003c/code\u003e, \u003ccode\u003eclingo\u003c/code\u003e, \u003ccode\u003ecurl\u003c/code\u003e,\n\u003ccode\u003efile\u003c/code\u003e, \u003ccode\u003egit\u003c/code\u003e, \u003ccode\u003egmake\u003c/code\u003e, \u003ccode\u003egpg\u003c/code\u003e, \u003ccode\u003egzip\u003c/code\u003e, \u003ccode\u003eopenssl\u003c/code\u003e, \u003ccode\u003epatch\u003c/code\u003e, \u003ccode\u003epatchelf\u003c/code\u003e, \u003ccode\u003epython\u003c/code\u003e,\n\u003ccode\u003epy-boto3\u003c/code\u003e, \u003ccode\u003etar\u003c/code\u003e, \u003ccode\u003eunzip\u003c/code\u003e, \u003ccode\u003exz\u003c/code\u003e, \u003ccode\u003ezstd\u003c/code\u003e and their dependencies.\u003c/p\u003e\n\u003cp\u003eWhen you run \u003ccode\u003espack.x [args]\u003c/code\u003e it will use \u003ccode\u003efusermount\u003c/code\u003e to\nmount this squashfs file in a temporary directory, and then execute the\nentrypoint executable \u003ca href=\"build/6_spack/spack\"\u003espack\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003espack\u003c/code\u003e executable sets some environment variables like \u003ccode\u003ePATH\u003c/code\u003e and\n\u003ccode\u003eDL_LIBRARY_PATH\u003c/code\u003e to the bin and lib folders of the squashfs file, and then it\nexecutes \u003ccode\u003epython3 spack_src/bin/spack [args]\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWhen the command is done running, the runtime unmounts the squashfs file again.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-my-system-doesnt-allow-me-to-use-fusermount-what-now\" class=\"anchor\" href=\"#my-system-doesnt-allow-me-to-use-fusermount-what-now\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMy system doesn\u0027t allow me to use \u003ccode\u003efusermount\u003c/code\u003e, what now?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003efusermount\u003c/code\u003e is used to mount a squashfs file included in the binary. If you\ndon\u0027t want that, you can just extract it:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack.x --squashfs-extract\n$ ./spack/spack\nusage: spack [-hkV] [--color {always,never,auto}] COMMAND ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebut working with the extracted \u003ccode\u003espack\u003c/code\u003e folder can come with a performance\npenalty on shared filesystems in HPC centers.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-differences-and-improvements-over-appimage-runtime\" class=\"anchor\" href=\"#differences-and-improvements-over-appimage-runtime\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDifferences and improvements over AppImage runtime\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003espack.x uses \u003ccode\u003ezstd\u003c/code\u003e for faster decompression;\u003c/li\u003e\n\u003cli\u003espack.x itself is an entirely static binary;\u003c/li\u003e\n\u003cli\u003espack.x does not need to dlopen libfuse.so.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-troubleshooting\" class=\"anchor\" href=\"#troubleshooting\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTroubleshooting\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eimmutability\u003c/strong\u003e The squashfs mountpoint is a readonly folder, meaning that\nspack can\u0027t write to spack/{var,opt} folders. spack.x is configured to use some\nnon-standard directories, see \u003ccode\u003espack.x config blame config\u003c/code\u003e for details.\u003c/p\u003e\n\u003cp\u003eNote, spack.x applies \u003ca href=\"https://github.com/spack/spack/pull/20158/\"\u003ethis patch\u003c/a\u003e\nto ensure that log files are written to the \u003ccode\u003econfig:misc_cache\u003c/code\u003e folder.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eopenssl\u003c/strong\u003e: By default spack.x uses \u003ccode\u003eca-certificates-mozilla\u003c/code\u003e for downloading\npackage sources over https. If you somehow need to use system certificates,\nset \u003ccode\u003eSSL_CERT_DIR\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CAINFO\u003c/code\u003e or \u003ccode\u003eSSL_CERT_FILE\u003c/code\u003e and \u003ccode\u003eGIT_SSL_CERT\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-can-i-run-spackx-inside-a-container\" class=\"anchor\" href=\"#can-i-run-spackx-inside-a-container\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCan I run spack.x inside a container?\u003c/h2\u003e\n\u003cp\u003eYes, but please don\u0027t! Since \u003ccode\u003efusermount\u003c/code\u003e is a setuid binary, you will need to\nrun a privileged container, which is never a good idea.\u003c/p\u003e\n\u003cp\u003eThe recommended way to run spack.x inside a container is to just extract it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack.x --squashfs-extract\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e./spack/spack --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you insist on running spack.x in Docker, this is one way to do it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003esudo docker run --privileged --device /dev/fuse -it -v \u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/spack.x:/bin/spack.x ubuntu:18.04\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003eapt update \u003cspan class=\"pl-k\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e apt install fuse \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install fusermount\u003c/span\u003e\u003c/span\u003e\n# \u003cspan class=\"pl-s1\"\u003espack.x --version\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-running-an-executable-shipped-with-spackx-directly\" class=\"anchor\" href=\"#running-an-executable-shipped-with-spackx-directly\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning an executable shipped with spack.x directly\u003c/h2\u003e\n\u003cp\u003eIf you want to run an executable shipped with \u003ccode\u003espack.x\u003c/code\u003e directly instead\nof invoking spack (the default entrypoint), try this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003eNO_ENTRYPOINT= spack.x which python\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/tmp/.mount_spack.h0zr1h/view/bin/python\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-how-do-i-build-spackx-myself\" class=\"anchor\" href=\"#how-do-i-build-spackx-myself\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow do I build spack.x myself?\u003c/h2\u003e\n\u003cp\u003eInitially you may need docker to get a rootfs filesystem for centos 7.\u003c/p\u003e\n\u003cp\u003eBuilding goes like this:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003emake rootfs-with-spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003emake\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou\u0027ll find the output in\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuild/output\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 1,
    "topics": [
      "spack",
      "squashfs",
      "libfuse"
    ],
    "updated_at": 1621575407.0
  },
  {
    "data_format": 2,
    "description": "[Experimental] AMReX Python Bindings",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "AMReX-Codes/pyamrex",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-pyamrex\" class=\"anchor\" href=\"#pyamrex\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003epyAMReX\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width:100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e\" target=\"_blank\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b4bbc2488e2de908b64d4a3c99de80e3b0842cc33e938283b89433bf1193a072/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d7072652d2d616c7068612d79656c6c6f77677265656e\" alt=\"Python3 API: Pre-Alpha\" title=\"Status: Pre-Alpha\" data-canonical-src=\"https://img.shields.io/badge/phase-pre--alpha-yellowgreen\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License AMReX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/workflows/linux/badge.svg?branch=development\" alt=\"linux\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/workflows/macos/badge.svg?branch=development\" alt=\"macos\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"https://github.com/AMReX-Codes/pyamrex/workflows/windows/badge.svg?branch=development\" alt=\"windows\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003epyAMReX is part of AMReX.\u003c/p\u003e\n\u003cp\u003eDue to its \u003cstrong\u003ehighly experimental\u003c/strong\u003e nature, we develop it currently in a separate respository.\u003c/p\u003e\n\u003cp\u003eWe will add further information here once first development versions are ready for testing.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-users\" class=\"anchor\" href=\"#users\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsers\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003eto do\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epip/pypa\u003c/li\u003e\n\u003cli\u003econda-forge\u003c/li\u003e\n\u003cli\u003espack\u003c/li\u003e\n\u003cli\u003ebrew\u003c/li\u003e\n\u003cli\u003e...\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-usage\" class=\"anchor\" href=\"#usage\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h3\u003e\n\u003cp\u003e\u003cem\u003eto do\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamrex\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003esmall_end\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamrex\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eInt_Vect\u003c/span\u003e()\n\u003cspan class=\"pl-s1\"\u003ebig_end\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamrex\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eInt_Vect\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003e2\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e3\u003c/span\u003e, \u003cspan class=\"pl-c1\"\u003e4\u003c/span\u003e)\n\n\u003cspan class=\"pl-s1\"\u003eb\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eamrex\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eBox\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003esmall_end\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ebig_end\u003c/span\u003e)\n\u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003eb\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e# ...\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-developers\" class=\"anchor\" href=\"#developers\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDevelopers\u003c/h2\u003e\n\u003cp\u003eIf you are new to CMake, \u003ca href=\"https://hsf-training.github.io/hsf-training-cmake-webpage/\" rel=\"nofollow\"\u003ethis short tutorial\u003c/a\u003e from the HEP Software foundation is the perfect place to get started with it.\u003c/p\u003e\n\u003cp\u003eIf you just want to use CMake to build the project, jump into sections \u003cem\u003e1. Introduction\u003c/em\u003e, \u003cem\u003e2. Building with CMake\u003c/em\u003e and \u003cem\u003e9. Finding Packages\u003c/em\u003e.\u003c/p\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-dependencies\" class=\"anchor\" href=\"#dependencies\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDependencies\u003c/h3\u003e\n\u003cp\u003epyAMReX depends on the following popular third party software.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea mature \u003ca href=\"https://en.wikipedia.org/wiki/C%2B%2B14\" rel=\"nofollow\"\u003eC++14\u003c/a\u003e compiler: e.g. g++ 5.0+, clang 5.0+, VS 2017+\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003eCMake 3.18.0+\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX \u003cem\u003edevelopment\u003c/em\u003e\u003c/a\u003e: we automatically download and compile a copy of AMReX\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11/\"\u003epybind11\u003c/a\u003e 2.6.2+: we automatically download and compile a copy of pybind11 (\u003ca href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\"\u003enew BSD\u003c/a\u003e)\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://python.org\" rel=\"nofollow\"\u003ePython\u003c/a\u003e 3.6+\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://numpy.org\" rel=\"nofollow\"\u003eNumpy\u003c/a\u003e 1.15+\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOptional dependencies include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.openmp.org\" rel=\"nofollow\"\u003empi4py\u003c/a\u003e 2.1+: for multi-node and/or multi-GPU execution\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://ccache.dev\" rel=\"nofollow\"\u003eCCache\u003c/a\u003e: to speed up rebuilds (needs 3.7.9+ for CUDA)\u003c/li\u003e\n\u003cli\u003efurther \u003ca href=\"https://github.com/AMReX-Codes/amrex/\"\u003eoptional dependencies of AMReX\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://docs.pytest.org/en/stable/\" rel=\"nofollow\"\u003epytest\u003c/a\u003e 6.2+: for running unit tests\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-install-dependencies\" class=\"anchor\" href=\"#install-dependencies\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall Dependencies\u003c/h3\u003e\n\u003cp\u003emacOS/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate -d \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e spack add cuda\u003c/span\u003e\nspack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e(in new terminals, re-activate the environment with \u003ccode\u003espack env activate -d .\u003c/code\u003e again)\u003c/p\u003e\n\u003cp\u003eor macOS/Linux:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ebrew update\nbrew install ccache cmake libomp mpi4py numpy open-mpi python\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow, \u003ccode\u003ecmake --version\u003c/code\u003e should be at version 3.18.0 or newer.\u003c/p\u003e\n\u003cp\u003eOr go:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                    --user\u003c/span\u003e\npython3 -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you wish to run unit tests, then please install \u003ccode\u003epytest\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epython3 -m pip install -U pytest\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-configure-your-compiler\" class=\"anchor\" href=\"#configure-your-compiler\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfigure your compiler\u003c/h3\u003e\n\u003cp\u003eFor example, using the Clang compiler:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CC=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang++\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you also want to select a CUDA compiler:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CUDACXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich nvcc\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CUDAHOSTCXX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003ewhich clang++\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-build--test\" class=\"anchor\" href=\"#build--test\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild \u0026amp; Test\u003c/h3\u003e\n\u003cp\u003eFrom the base of the pyAMReX source directory, execute:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional controls (example):\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_SPACEDIM=3\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_MPI=ON\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_OMP=ON\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_GPU_BACKEND=CUDA\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport AMREX_SRC=$PWD/../amrex\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eexport CMAKE_BUILD_PARALLEL_LEVEL=8\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                 --force-reinstall --user\u003c/span\u003e\npython3 -m pip install -v \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOn successful installation, you can run the unit tests (assuming \u003ccode\u003epytest\u003c/code\u003e is\ninstalled). If \u003ccode\u003eAMREX_MPI=ON\u003c/code\u003e, then please prepend the following commands with \u003ccode\u003empiexec -np \u0026lt;NUM_PROCS\u0026gt;\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run all tests \u003c/span\u003e\npython -m pytest tests/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run tests from a single file\u003c/span\u003e\npython -m pytest tests/test_intvect.py\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Run a single test (useful during debugging)\u003c/span\u003e\npython -m pytest tests/test_intvect.py::test_iv_conversions\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you are iterating on C++ builds, it might be faster to just call CMake:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecmake -S \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -B build\ncmake --build build -j 8  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e repeat this step to fix compile errors\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\n\u003ca id=\"user-content-build-options\" class=\"anchor\" href=\"#build-options\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild Options\u003c/h3\u003e\n\u003cp\u003eIf you are using the pip-driven install, selected \u003ca href=\"https://amrex-codes.github.io/amrex/docs_html/BuildingAMReX.html#building-with-cmake\" rel=\"nofollow\"\u003eAMReX CMake options\u003c/a\u003e can be controlled with environment variables:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eEnvironment Variable\u003c/th\u003e\n\u003cth\u003eDefault \u0026amp; Values\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_OMP\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable OpenMP\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_GPU_BACKEND\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eNONE\u003c/strong\u003e/SYCL/CUDA/HIP\u003c/td\u003e\n\u003ctd\u003eOn-node, accelerated GPU backend\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_MPI\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable MPI\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_PRECISION\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eSINGLE/\u003cstrong\u003eDOUBLE\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003ePrecision of AMReX Real type\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_SPACEDIM\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e1/2/\u003cstrong\u003e3\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eDimension of AMReX\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_BUILD_SHARED_LIBS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eBuild the core AMReX library as shared library\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_SRC\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003cem\u003eNone\u003c/em\u003e\u003c/td\u003e\n\u003ctd\u003eAbsolute path to AMReX source directory (preferred if set)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_REPO\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ehttps://github.com/AMReX-Codes/amrex.git\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository URI to pull and build AMReX from\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_BRANCH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003edevelopment\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepository branch for \u003ccode\u003eAMREX_REPO\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_INTERNAL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNeeds a pre-installed AMReX library if set to \u003ccode\u003eOFF\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eAMREX_LIBDIR\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cem\u003eNone\u003c/em\u003e         (note: not yet implemented)\u003c/td\u003e\n\u003ctd\u003eIf set, search for pre-built AMReX C++ libraries (see below)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eCMAKE_BUILD_PARALLEL_LEVEL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e2\u003c/td\u003e\n\u003ctd\u003eNumber of parallel build threads\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eFor example, one can also build against a local AMReX copy.\nAssuming AMReX\u0027 source is located in \u003ccode\u003e$HOME/src/amrex\u003c/code\u003e, then \u003ccode\u003eexport AMREX_SRC=$HOME/src/amrex\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eOr as a one-liner, assuming your AMReX source directory is located in \u003ccode\u003e../amrex\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eAMREX_SRC=\u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/../amrex python3 -m pip install -v --force-reinstall \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that you need to use absolute paths for external source trees, because pip builds in a temporary directory.\u003c/p\u003e\n\u003cp\u003eOr build against an AMReX feature branch of a colleague.\nAssuming your colleague pushed AMReX to \u003ccode\u003ehttps://github.com/WeiqunZhang/amrex/\u003c/code\u003e in a branch \u003ccode\u003enew-feature\u003c/code\u003e then\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eunset\u003c/span\u003e AMREX_SRC  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e preferred if set\u003c/span\u003e\nAMREX_REPO=https://github.com/WeiqunZhang/amrex.git AMREX_BRANCH=new-feature python3 -m pip install -v --force-reinstall \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou can speed up the install further if you pre-install AMReX, e.g. with a package manager.\nSet \u003ccode\u003eAMREX_INTERNAL=OFF\u003c/code\u003e and add installation prefix of AMReX to the environment variable \u003ca href=\"https://cmake.org/cmake/help/latest/envvar/CMAKE_PREFIX_PATH.html\" rel=\"nofollow\"\u003eCMAKE_PREFIX_PATH\u003c/a\u003e.\nPlease see the \u003ca href=\"#Developers\"\u003eshort CMake tutorial that we linked above\u003c/a\u003e if this sounds new to you.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003epyAMReX Copyright (c) 2021, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Innovation \u0026amp; Partnerships Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.\u003c/p\u003e\n\u003cp\u003eLicense for pyamrex can be found at \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 15,
    "topics": [
      "amrex",
      "python"
    ],
    "updated_at": 1618453857.0
  },
  {
    "data_format": 2,
    "description": "E4S Spack environments and container recipes",
    "filenames": [
      "docker-recipes/rhel8-runner-ppc64le/spack.yaml",
      "spack-sdk-environments/e4s_ecosystem/spack.yaml",
      "spack-sdk-environments/xsdk/spack.yaml",
      "docker-recipes/rhel7-runner-ppc64le/spack.yaml",
      "spack-sdk-environments/compilers_and_support/spack.yaml",
      "spack-sdk-environments/data-mgmt_io-services_checkpoint-restart/spack.yaml",
      "spack-sdk-environments/visualization_analysis_reduction/spack.yaml",
      "docker-recipes/rhel8-runner-x86_64/spack.yaml",
      "spack-sdk-environments/pmr_core/spack.yaml",
      "docker-recipes/superlu-sc/spack.yaml",
      "docker-recipes/rhel7-runner-x86_64/spack.yaml",
      "spack-sdk-environments/tools_and_technology/spack.yaml"
    ],
    "full_name": "UO-OACISS/e4s",
    "latest_release": null,
    "readme": "\u003cp\u003eThis is a collection of configurations for building ECP SDK\ncontainers with combinations of packages, including the full\nE4S set.\u003c/p\u003e\n\u003cp\u003eThese are the set of stacks that are targeted for the first release:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"figures/SDKdefinition1.png\" target=\"_blank\" rel=\"noopener noreferrer\"\u003e\u003cimg src=\"figures/SDKdefinition1.png\" alt=\"SDK definitions\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe configuration files for each container platform will be specified under each directory.  For example, the Docker configurations are under the \"docker\" subdirectory.  Each subdirectory will have a README.md file to explain how to build the container image for each stack.\u003c/p\u003e\n",
    "stargazers_count": 11,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1621369941.0
  },
  {
    "data_format": 2,
    "description": "Share Spack configuration files with other HPC sites",
    "filenames": [
      "UOREGON/E4S-Develop/spack-ubuntu18.04-ppc64le.yaml",
      "NERSC/cori/e4s-20.10/spack.yaml",
      "NERSC/cori/e4s-stacks/hsw/spack.yaml",
      "NREL/configs/rhodes/software/spack.yaml",
      "UOREGON/E4S-Develop/spack-ubuntu20.04-ppc64le.yaml",
      "UOREGON/E4S-Develop/spack-rhel8-x86_64.yaml",
      "UOREGON/E4S-Develop/spack-ubuntu18.04-x86_64.yaml",
      "NERSC/cori/e4s-20.10/prod/spack.yaml",
      "NERSC/cori/e4s-stacks/knl/spack.yaml",
      "NREL/configs/eagle/base/spack.yaml",
      "NREL/configs/rhodes/compilers/spack.yaml",
      "UOREGON/E4S-Develop/spack-rhel7-ppc64le.yaml",
      "NREL/configs/rhodes/utilities/spack.yaml",
      "UOREGON/E4S-Develop/spack-rhel8-ppc64le.yaml",
      "NREL/configs/eagle/software/spack.yaml",
      "OLCF/e4s-stacks/etc/spack.yaml",
      "UOREGON/E4S-Develop/spack-ubuntu20.04-x86_64.yaml",
      "UOREGON/E4S-Develop/spack-rhel7-x86_64.yaml",
      "NREL/configs/eagle/compilers/spack.yaml",
      "NERSC/cori/e4s-stacks/x86/spack.yaml",
      "OLCF/e4s-stacks/spack/var/spack/environments/test/spack.yaml",
      "NREL/configs/rhodes/base/spack.yaml",
      "NREL/configs/eagle/utilities/spack.yaml"
    ],
    "full_name": "spack/spack-configs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-spack-configs\" class=\"anchor\" href=\"#spack-configs\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack Configs\u003c/h1\u003e\n\u003cp\u003eThis is a repository that sites can use to share their configuration\nfiles for Spack.  You can contribute your own configuration files, or\nbrowse around and look at what others have done.\u003c/p\u003e\n\u003ch2\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eSpack is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). Users may choose either license, at their\noption.\u003c/p\u003e\n\u003cp\u003eAll new contributions must be made under both the MIT and Apache-2.0\nlicenses.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-MIT\"\u003eLICENSE-MIT\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/LICENSE-APACHE\"\u003eLICENSE-APACHE\u003c/a\u003e,\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/COPYRIGHT\"\u003eCOPYRIGHT\u003c/a\u003e, and\n\u003ca href=\"https://github.com/spack/spack-configs/blob/master/NOTICE\"\u003eNOTICE\u003c/a\u003e for details.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: (Apache-2.0 OR MIT)\u003c/p\u003e\n\u003cp\u003eLLNL-CODE-811652\u003c/p\u003e\n",
    "stargazers_count": 28,
    "subscribers_count": 22,
    "topics": [],
    "updated_at": 1621550978.0
  },
  {
    "data_format": 2,
    "description": "A flyweight in situ visualization and analysis runtime for multi-physics HPC simulations",
    "filenames": [
      "scripts/uberenv/spack_envs/llnl/pascal-cuda/spack.yaml",
      "scripts/uberenv/spack_envs/ci/ubuntu_18_cuda_10.1_devel/spack.yaml",
      "scripts/uberenv/spack_envs/llnl/quartz/spack.yaml",
      "scripts/uberenv/spack_envs/olcf/summit/spack.yaml",
      "scripts/uberenv/spack_envs/ci/ubuntu_18_devel/spack.yaml"
    ],
    "full_name": "Alpine-DAV/ascent",
    "latest_release": "v0.7.1",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-ascent\" class=\"anchor\" href=\"#ascent\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAscent\u003c/h1\u003e\n\u003cp\u003eAscent is an open source many-core capable lightweight in situ visualization and analysis infrastructure for multi-physics HPC simulations.\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentation\u003c/h1\u003e\n\u003cp\u003eTo get started building and using Ascent, check out the full documentation:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://alpine-dav.github.io/ascent/\" rel=\"nofollow\"\u003ehttps://alpine-dav.github.io/ascent/\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSource Repo\u003c/h1\u003e\n\u003cp\u003eAscent\u0027s source is hosted on GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/Alpine-DAV/ascent\"\u003ehttps://github.com/Alpine-DAV/ascent\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h1\u003e\n\u003cp\u003eAscent is released under a BSD-style license - for detailed license info, refer to:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://ascent.readthedocs.io/en/latest/Licenses.html\" rel=\"nofollow\"\u003ehttp://ascent.readthedocs.io/en/latest/Licenses.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eor the following files in the Ascent source tree:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/LICENSE\"\u003eLICENSE\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eChangelog\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/CHANGELOG.md\"\u003eChangelog\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 79,
    "subscribers_count": 12,
    "topics": [
      "hpc",
      "parallel-computing",
      "cuda",
      "mpi",
      "rendering",
      "analysis",
      "scientific-computing",
      "data-viz",
      "radiuss"
    ],
    "updated_at": 1621576283.0
  },
  {
    "data_format": 2,
    "description": "Simplified Data Exchange for HPC Simulations",
    "filenames": [
      "scripts/uberenv_configs/spack_envs/llnl/quartz/spack.yaml"
    ],
    "full_name": "LLNL/conduit",
    "latest_release": "v0.7.2",
    "readme": "\u003ch1\u003e\n\u003ca id=\"user-content-conduit\" class=\"anchor\" href=\"#conduit\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConduit\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eConduit: Simplified Data Exchange for HPC Simulations\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eConduit is an open source project from Lawrence Livermore National Laboratory that provides an intuitive model for describing hierarchical scientific data in C++, C, Fortran, and Python. It is used for data coupling between packages in-core, serialization, and I/O tasks.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://travis-ci.org/LLNL/conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/478365930966f70f879ae04d59ea3f5c5888bee7d2a50e7e281dc1da3cf9aff1/68747470733a2f2f7472617669732d63692e6f72672f4c4c4e4c2f636f6e647569742e706e67\" alt=\"Travis CI Build Status\" data-canonical-src=\"https://travis-ci.org/LLNL/conduit.png\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://ci.appveyor.com/project/cyrush/conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a0839e4a484ebb633a1c2ebcd90e345a176f5edc60e42f32636eefa9c3c79fad/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f6769746875622f6c6c6e6c2f636f6e647569743f6272616e63683d646576656c6f70267376673d74727565\" alt=\"Appveyor Build Status\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/github/llnl/conduit?branch=develop\u0026amp;svg=true\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/LLNL/conduit?branch=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/50b12c605f0f4bcc64b6db415dddf2de99c5e19a526d7bc53e45db45c95b2931/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f4c4c4e4c2f636f6e647569742f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/LLNL/conduit/badge.svg?branch=develop\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://scan.coverity.com/projects/llnl-conduit\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d4b204e42fe1ef30b166cdfd7cba043d5d74600b343aedd5e094a810b4c5c727/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f383432362f62616467652e7376673f666c61743d31\" alt=\"Static Analysis Status\" data-canonical-src=\"https://scan.coverity.com/projects/8426/badge.svg?flat=1\" style=\"max-width:100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-documentation\" class=\"anchor\" href=\"#documentation\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentation\u003c/h1\u003e\n\u003cp\u003eTo get started building and using Conduit, check out the full documentation:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://llnl-conduit.readthedocs.io/\" rel=\"nofollow\"\u003ehttp://llnl-conduit.readthedocs.io/\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-source-repo\" class=\"anchor\" href=\"#source-repo\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSource Repo\u003c/h1\u003e\n\u003cp\u003eConduit\u0027s source is hosted on GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/llnl/conduit\"\u003ehttps://github.com/llnl/conduit\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-license\" class=\"anchor\" href=\"#license\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h1\u003e\n\u003cp\u003eConduit is released under a BSD-style license - for detailed license info, refer to:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://llnl-conduit.readthedocs.io/en/latest/licenses.html\" rel=\"nofollow\"\u003ehttps://llnl-conduit.readthedocs.io/en/latest/licenses.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eor the following files in the Conduit source tree:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/LICENSE\"\u003eLICENSE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/thirdparty_licenses.md\"\u003ethirdparty_licenses.md\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\n\u003ca id=\"user-content-changelog\" class=\"anchor\" href=\"#changelog\" aria-hidden=\"true\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eChangelog\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/CHANGELOG.md\"\u003eChangelog\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 88,
    "subscribers_count": 16,
    "topics": [
      "hpc",
      "scientific-computing",
      "cpp",
      "fortran",
      "python",
      "llnl",
      "json",
      "yaml",
      "hdf5",
      "radiuss",
      "data-management"
    ],
    "updated_at": 1621476188.0
  }
]
