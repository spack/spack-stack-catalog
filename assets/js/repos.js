var data =
[
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "mpas_spack.yaml"
    ],
    "full_name": "tpeterka/mpas-o-standalone",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-instructions-for-building-mpas-ocean-as-a-standalone-code-no-workflow\" class=\"anchor\" aria-hidden=\"true\" href=\"#instructions-for-building-mpas-ocean-as-a-standalone-code-no-workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstructions for Building MPAS-Ocean as a Standalone Code (no workflow)\u003c/h1\u003e\n\u003cp\u003eInstallation is done through Spack. If you don\u0027t have Spack installed or if Spack is new to you, go \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehere\u003c/a\u003e first.\u003c/p\u003e\n\u003cp\u003eClone this repository and cd into it. These instructions assume there is a top-level directory called climate.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir ~/climate\ncd ~/climate\ngit clone https://github.com/tpeterka/mpas-o-standalone\ncd mpas-o-standalone\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-spack-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-spack-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up Spack environment\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-and-load-the-spack-environment-for-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create and load the Spack environment for MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate/mpas-o-standalone\nsource ./create-mpas.sh     # requires being in the same directory to work properly\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#subsequent-times-load-the-spack-environment-for-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubsequent times: load the Spack environment for MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/climate/mpas-o-standalone/load-mpas.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding MPAS-Ocean\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-clone-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-clone-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: clone MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate\ngit clone https://github.com/E3SM-Project/E3SM\ncd E3SM\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-build-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#build-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate/E3SM/components/mpas-ocean\nmake clean              # if dirty\nmake -j gfortran\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will take ~ 5 minutes to compile.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-a-test-case-to-execute\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-test-case-to-execute\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a test case to execute\u003c/h2\u003e\n\u003cp\u003eCompass is an E3SM system for generating and running test cases for MPAS-Ocean, and relies on conda environments. The instructions below assume you have conda or miniconda already installed. If not, go \u003ca href=\"https://docs.conda.io/en/latest/miniconda.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e first.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-install-compass-and-create-compass-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-install-compass-and-create-compass-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: install Compass and create Compass environment\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~\ngit clone https://github.com/MPAS-Dev/compass.git compass-env-only\ncd ~/compass-env-only\ngit submodule update --init --recursive\n./conda/configure_compass_env.py --conda ~/miniconda3 --env_only\nsource load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh is the script created by the previous command\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-a-compass-configuration-file-for-a-new-machine\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-a-compass-configuration-file-for-a-new-machine\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create a compass configuration file for a new machine\u003c/h3\u003e\n\u003cp\u003eAssumes the config file is named ~/compass-env-only/compass.cfg and has these contents, or similar (yours may vary)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# This file contains some common config options you might want to set\n\n# The paths section describes paths to databases and shared compass environments\n[paths]\n\n# A root directory where MPAS standalone data can be found\ndatabase_root = /home/tpeterka/compass/mpas_standalonedata\n\n# The parallel section describes options related to running tests in parallel\n[parallel]\n\n# parallel system of execution: slurm or single_node\nsystem = single_node\n\n# whether to use mpirun or srun to run the model\nparallel_executable = mpiexec\n\n# cores per node on the machine, detected automatically by default\n# cores_per_node = 4\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-test-case-for-the-executable\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-test-case-for-the-executable\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create test case for the executable\u003c/h3\u003e\n\u003cp\u003eAssumes that \u003ccode\u003eload_dev_compass_1.2.0-alpha.4.sh\u003c/code\u003e is the name of the conda environment load script created initially\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\ncompass setup -t ocean/baroclinic_channel/10km/default -w ~/spack-baroclinic-test -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-run-the-test-case\" class=\"anchor\" aria-hidden=\"true\" href=\"#run-the-test-case\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun the test case\u003c/h3\u003e\n\u003cp\u003eAssumes that \u003ccode\u003eload_dev_compass_1.2.0-alpha.4.sh\u003c/code\u003e is the name of the conda environment load script created initially\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\nsource ~/climate/mpas-o-standalone/load-mpas.sh\ncd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default\ncompass run\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1680793507.0
  },
  {
    "data_format": 2,
    "description": "Experiments with C++ for HPC and collection of C++ benchmarks. ",
    "filenames": [
      "cpp/libint-hf/spack.yaml"
    ],
    "full_name": "RMeli/HPCpp",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-hpc-experiments-and-notes-for-high-performance-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#hpc-experiments-and-notes-for-high-performance-c\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHPC++: Experiments and Notes for High-Performance C++\u003c/h1\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1664828168.0
  },
  {
    "data_format": 2,
    "description": "A microservice (i.e., Mochi provider) for high performance bulk storage of raw data regions",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-bake",
    "latest_release": "v0.6.4",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-bake\" class=\"anchor\" aria-hidden=\"true\" href=\"#bake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBake\u003c/h1\u003e\n\u003cp\u003eBake is a microservice (i.e., Mochi provider) for high performance bulk\nstorage of raw data regions.  Bake uses modular backends to store data\non persistent memory, conventional file systems, or other storage media.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"https://www.mcs.anl.gov/research/projects/mochi/\" rel=\"nofollow\"\u003ehttps://www.mcs.anl.gov/research/projects/mochi/\u003c/a\u003e and\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/\u003c/a\u003e for more information about Mochi.\u003c/p\u003e\n\u003cp\u003eBake\u0027s scope is limited exclusively to data storage.  Capabilities such as\nindexing, name spaces, and sharding must be provided by other microservice\ncomponents.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eThe easiest way to install Bake is through spack:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003espack install bake\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis will install BAKE and its dependencies.  Please refer to the end of the\ndocument for manual compilation instructions.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-architecture\" class=\"anchor\" aria-hidden=\"true\" href=\"#architecture\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eArchitecture\u003c/h2\u003e\n\u003cp\u003eLike most Mochi services, BAKE relies on a client/provider architecture.\nA provider, identified by its \u003cem\u003eaddress\u003c/em\u003e and \u003cem\u003emultiplex id\u003c/em\u003e, manages one or more\n\u003cem\u003eBAKE targets\u003c/em\u003e, referenced externally by their \u003cem\u003etarget id\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eA target can be thought of as a storage device.  This may be (for example) a\nPMDK volume or a local file system.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-a-bake-target\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-bake-target\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a BAKE target\u003c/h2\u003e\n\u003cp\u003eBAKE requires the backend storage file to be created beforehand using\n\u003ccode\u003ebake-mkpool\u003c/code\u003e. For instance:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-mkpool -s 500M /dev/shm/foo.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003ecreates a 500 MB file at \u003cem\u003e/dev/shm/foo.dat\u003c/em\u003e to be used by BAKE as a target.\nBake will use the \u003ccode\u003epmem\u003c/code\u003e (persistent memory) backend by default, which means\nthat the underlying file will memory mapped for access usign the PMDK\nlibrary.  You can also providie an explicit prefix (such as \u003ccode\u003efile:\u003c/code\u003e for the\nconventional file backend or \u003ccode\u003epmem:\u003c/code\u003e for the persistent memory backend) to\ndictate a specific target type.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-starting-a-daemon\" class=\"anchor\" aria-hidden=\"true\" href=\"#starting-a-daemon\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStarting a daemon\u003c/h2\u003e\n\u003cp\u003eBAKE ships with a default daemon program that can setup providers and attach\nto storage targets. This daemon can be started as follows:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon [options] \u0026lt;listen_address\u0026gt; \u0026lt;bake_pool_1\u0026gt; \u0026lt;bake_pool_2\u0026gt; ...\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe program takes a set of options followed by an address at which to listen for\nincoming RPCs, and a list of\nBAKE targets already created using \u003ccode\u003ebake-mkpool\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eFor example:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ebake-server-daemon -f bake.addr -m providers bmi+tcp://localhost:1234 /dev/shm/foo.dat /dev/shm/bar.dat\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe following options are accepted:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003e-f\u003c/code\u003e provides the name of the file in which to write the address of the daemon.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003e-m\u003c/code\u003e provides the mode (\u003cem\u003eproviders\u003c/em\u003e or \u003cem\u003etargets\u003c/em\u003e).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \u003cem\u003eproviders\u003c/em\u003e mode indicates that, if multiple BAKE targets are used (as above),\nthese targets should be managed by multiple providers, accessible through\ndifferent multiplex ids 1, 2, ... \u003cem\u003eN\u003c/em\u003e where \u003cem\u003eN\u003c/em\u003e is the number of storage targets\nto manage. The \u003cem\u003etargets\u003c/em\u003e mode indicates that a single provider should be used to\nmanage all the storage targets.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-integrating-bake-into-a-larger-service\" class=\"anchor\" aria-hidden=\"true\" href=\"#integrating-bake-into-a-larger-service\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntegrating Bake into a larger service\u003c/h2\u003e\n\u003cp\u003eBake is not intended to be a standalone user-facing service.  See\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/bedrock.html\" rel=\"nofollow\"\u003ehttps://mochi.readthedocs.io/en/latest/bedrock.html\u003c/a\u003e for guidance on how to\nintegrate it with other providers using Mochi\u0027s Bedrock capability.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-client-api-example\" class=\"anchor\" aria-hidden=\"true\" href=\"#client-api-example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eClient API example\u003c/h2\u003e\n\u003cp\u003eData is stored in \u003ccode\u003eregions\u003c/code\u003e within a \u003ccode\u003etarget\u003c/code\u003e using explicit create,\nwrite, and persist operations.  The caller cannot dictate the region id\nthat will be used to reference a region; this identifier is generated\nby Bake at creation time.  The region size must be specified at creation\ntime as well; there is no mechanism for extending the size of an existing\nregion.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003ebake-client.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e **argv)\n{\n    \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e *svr_addr_str; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e string address of the BAKE server\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ehg_addr_t\u003c/span\u003e svr_addr; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Mercury address of the BAKE server\u003c/span\u003e\n    margo_instance_id mid; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Margo instance id\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_client_t\u003c/span\u003e bcl; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE client\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_provider_handle_t\u003c/span\u003e bph; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE handle to provider\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003euint8_t\u003c/span\u003e mplex_id; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e multiplex id of the provider\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003euint32_t\u003c/span\u003e target_number; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e target to use\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003ebake_region_id_t\u003c/span\u003e rid; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e BAKE region id handle\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_target_id_t\u003c/span\u003e* bti; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e array of target ids\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e ... setup variables ... \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Initialize Margo \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\tmid = \u003cspan class=\"pl-c1\"\u003emargo_init\u003c/span\u003e(..., MARGO_CLIENT_MODE, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, -\u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Lookup the server \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003emargo_addr_lookup\u003c/span\u003e(mid, svr_addr_str, \u0026amp;svr_addr);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Creates the BAKE client \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_client_init\u003c/span\u003e(mid, \u0026amp;bcl);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Creates the provider handle \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_provider_handle_create\u003c/span\u003e(bcl, svr_addr, mplex_id, \u0026amp;bph);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Asks the provider for up to target_number target ids \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003euint32_t\u003c/span\u003e num_targets = \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n\tbti = \u003cspan class=\"pl-c1\"\u003ecalloc\u003c/span\u003e(num_targets, \u003cspan class=\"pl-k\"\u003esizeof\u003c/span\u003e(*bti));\n\t\u003cspan class=\"pl-c1\"\u003ebake_probe\u003c/span\u003e(bph, target_number, bti, \u0026amp;num_targets);\n\t\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(num_targets \u0026lt; target_number) {\n\t\t\u003cspan class=\"pl-c1\"\u003efprintf\u003c/span\u003e(stderr, \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eError: provider has only \u003cspan class=\"pl-c1\"\u003e%d\u003c/span\u003e storage targets\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, num_targets);\n\t}\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Create a region \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003esize_t\u003c/span\u003e size = ...; \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e size of the region to create\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_create\u003c/span\u003e(bph, bti[target_number-\u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e], size, \u0026amp;rid);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Write data into the region at offset 0 \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e* buf = ...;\n\t\u003cspan class=\"pl-c1\"\u003ebake_write\u003c/span\u003e(bph, rid, \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e, buf, size);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Make all modifications persistent \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_persist\u003c/span\u003e(bph, rid);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Release provider handle \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_provider_handle_release\u003c/span\u003e(bph);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Release BAKE client \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003ebake_client_finalize\u003c/span\u003e(bcl);\n\t\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e/*\u003c/span\u003e Cleanup Margo resources \u003cspan class=\"pl-c\"\u003e*/\u003c/span\u003e\u003c/span\u003e\n\t\u003cspan class=\"pl-c1\"\u003emargo_addr_free\u003c/span\u003e(mid, svr_addr);\n\t\u003cspan class=\"pl-c1\"\u003emargo_finalize\u003c/span\u003e(mid);\n\t\u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that a \u003ccode\u003ebake_region_id_t\u003c/code\u003e object is persistent.  It can be written\n(into a file or a socket) and stored or sent to another program. These\nregion ids are what uniquely reference a region within a given target.\u003c/p\u003e\n\u003cp\u003eThe rest of the client-side API can be found in \u003ccode\u003ebake-client.h\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-provider-api\" class=\"anchor\" aria-hidden=\"true\" href=\"#provider-api\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProvider API\u003c/h2\u003e\n\u003cp\u003eThe bake-server-daemon source is a good example of how to create providers and\nattach storage targets to them. The provider-side API is located in\n\u003cem\u003ebake-server.h\u003c/em\u003e, and consists of mainly two functions:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_register\u003c/span\u003e(margo_instance_id                     mid,\n                           \u003cspan class=\"pl-c1\"\u003euint16_t\u003c/span\u003e                              provider_id,\n                           \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-k\"\u003estruct\u003c/span\u003e bake_provider_init_info* args,\n                           \u003cspan class=\"pl-c1\"\u003ebake_provider_t\u003c/span\u003e*                      provider);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis creates a provider at the given provider id using the specified margo\ninstance.  The \u003ccode\u003eargs\u003c/code\u003e parameter can be used to modify default settings,\nincluding passing in a fully specified json configuration block.  See\n\u003ccode\u003ebake-server.h\u003c/code\u003e for details.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003ebake_provider_attach_target\u003c/span\u003e(\u003cspan class=\"pl-c1\"\u003ebake_provider_t\u003c/span\u003e   provider,\n                                \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e*       target_name,\n                                \u003cspan class=\"pl-c1\"\u003ebake_target_id_t\u003c/span\u003e* target_id);\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis makes the provider manage the given storage target.\u003c/p\u003e\n\u003cp\u003eOther functions are available to create and detach targets from a provider.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-generic-bake-benchmark\" class=\"anchor\" aria-hidden=\"true\" href=\"#generic-bake-benchmark\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGeneric Bake benchmark\u003c/h2\u003e\n\u003cp\u003eBy using \u003ccode\u003e--enable-benchmark\u003c/code\u003e when compiling Bake (or \u003ccode\u003e+benchmark\u003c/code\u003e when using Spack),\nyou will build a \u003ccode\u003ebake-benchmark\u003c/code\u003e program that can be used as a configurable benchmark.\nThis benchmark requires an MPI compiler, hence you may need to configure Bake with\n\u003ccode\u003eCC=mpicc\u003c/code\u003e and \u003ccode\u003eCXX=mpicxx\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eThe benchmark is an MPI program that can be run on 2 or more ranks. Rank 0 will act\nas a server, while non-zero ranks act as clients. The server will not create\na Bake target. The Bake target needs to be created (with \u003ccode\u003ebake-makepool\u003c/code\u003e) beforehand.\u003c/p\u003e\n\u003cp\u003eThe program takes as parameter the path to a JSON file containing the sequence\nof benchmarks to execute. An example of such a file is located in \u003ccode\u003esrc/benchmark.json\u003c/code\u003e.\nEach entry in the \u003ccode\u003ebenchmarks\u003c/code\u003e array corresponds to a benchmark. The \u003ccode\u003etype\u003c/code\u003e field indicates\nthe type of benchmark to execute. The \u003ccode\u003erepetitions\u003c/code\u003e field indicates how many times the\nbenchmark should be repeated.\u003c/p\u003e\n\u003cp\u003eThe following table describes each type of benchmark and their parameters.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003etype\u003c/th\u003e\n\u003cth\u003eparameter\u003c/th\u003e\n\u003cth\u003edefault\u003c/th\u003e\n\u003cth\u003edescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ewrite\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the input buffer for each write\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to write to the same region\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the input buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epersist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to erase the created regions after the benchmark executed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eread\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of region to read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-region\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to access the same region for each read\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecreate-write-persist\u003c/td\u003e\n\u003ctd\u003enum-entries\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003ctd\u003eNumber of regions to create/write/persist\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eregion-sizes\u003c/td\u003e\n\u003ctd\u003e-\u003c/td\u003e\n\u003ctd\u003eSize of the regions, or range (e.g. [12, 24])\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003ereuse-buffer\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to reuse the same buffer on clients for each operation\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003epreregister-bulk\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003ctd\u003eWhether to preregister the client\u0027s buffer for RDMA\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003eerase-on-teardown\u003c/td\u003e\n\u003ctd\u003etrue\u003c/td\u003e\n\u003ctd\u003eWhether to remove the regions after the benchmark\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual installation\u003c/h2\u003e\n\u003cp\u003eBAKE depends on the following libraries:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003euuid (install uuid-dev package on ubuntu)\u003c/li\u003e\n\u003cli\u003ePMDK (see instructions below)\u003c/li\u003e\n\u003cli\u003ejson-c\u003c/li\u003e\n\u003cli\u003emochi-abt-io\u003c/li\u003e\n\u003cli\u003emochi-margo\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBake will automatically identify these dependencies at configure time using\npkg-config. To compile BAKE:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e./prepare.sh\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emkdir build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecd build\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e../configure --prefix=/home/carns/working/install\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emake\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf any dependencies are installed in a nonstandard location, then\nmodify the configure step listed above to include the following argument:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ePKG_CONFIG_PATH=/home/carns/working/install/lib/pkgconfig\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1633975151.0
  },
  {
    "data_format": 2,
    "description": "Mobject is a prototype Mochi object storage system based on RADOS",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mobject",
    "latest_release": "v0.6.1",
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"mobject_logo.png\"\u003e\u003cimg src=\"mobject_logo.png\" alt=\"logo\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"#mobject\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMobject\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spell.yml/badge.svg\" alt=\"check spelling\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack.yml/badge.svg\" alt=\"spack mobject\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mobject/actions/workflows/spack_bedrock.yml/badge.svg\" alt=\"spack mobject+bedrock\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMobject is a distributed object storage system\nbuilt using a composition of \u003ca href=\"https://mochi.readthedocs.io\" rel=\"nofollow\"\u003eMochi\u003c/a\u003e components:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mochi-bake\"\u003emochi-bake\u003c/a\u003e (for bulk storage)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mochi-bedrock\"\u003emochi-bedrock\u003c/a\u003e\n(for configuration and bootstrapping)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mochi-yokan\"\u003emochi-yokan\u003c/a\u003e\n(for metadata and log indexing)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mochi-hpc/mochi-ssg\"\u003emochi-ssg\u003c/a\u003e (for group membership)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://mochi.readthedocs.io/en/latest/installing.html#installing-spack-and-the-mochi-repository\" rel=\"nofollow\"\u003eInstall Spack and Mochi Spack Repository\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThen, run the following command to install mobject.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e   spack install mobject\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-hdf5-and-mobject\" class=\"anchor\" aria-hidden=\"true\" href=\"#hdf5-and-mobject\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHDF5 and Mobject\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"/include/librados-mobject-store.h\"\u003eMobject API\u003c/a\u003e is a subset of the\n\u003ca href=\"https://github.com/ceph/ceph/blob/main/src/include/rados/librados.h\"\u003eRADOS API\u003c/a\u003e\nfrom Ceph\u2019s object storage layer.\nTherefore, \u003ca href=\"https://github.com/HDFGroup/vol-rados\"\u003eHDF5 RADOS VOL plugin-in\u003c/a\u003e\ncan use Mobject.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-faq\" class=\"anchor\" aria-hidden=\"true\" href=\"#faq\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFAQ\u003c/h2\u003e\n\u003cp\u003eSee \u003ca href=\"doc/FAQ.md\"\u003edoc/FAQ.md\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1640785210.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "mpas_spack.yaml"
    ],
    "full_name": "tpeterka/mpas-o-workflow",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow\" class=\"anchor\" aria-hidden=\"true\" href=\"#instructions-for-building-mpas-ocean-to-run-in-a-wilkins-workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstructions for Building MPAS-Ocean to Run in a Wilkins Workflow\u003c/h1\u003e\n\u003cp\u003eInstallation is done through Spack. If you don\u0027t have Spack installed or if Spack is new to you, go \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehere\u003c/a\u003e first.\u003c/p\u003e\n\u003cp\u003eClone this repository and cd into it. These instructions assume there is a top-level directory called climate.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir ~/climate\ncd ~/climate\ngit clone https://github.com/tpeterka/mpas-o-workflow\ncd mpas-o-workflow\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-spack-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-spack-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up Spack environment\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-and-load-the-spack-environment-for-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-and-load-the-spack-environment-for-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create and load the Spack environment for MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate/mpas-o-workflow\nsource ./create-mpas.sh     # requires being in the same directory to work properly\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-subsequent-times-load-the-spack-environment-for-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#subsequent-times-load-the-spack-environment-for-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubsequent times: load the Spack environment for MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/climate/mpas-o-workflow/load-mpas.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding MPAS-Ocean\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-clone-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-clone-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: clone MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate\ngit clone https://github.com/E3SM-Project/E3SM\ncd E3SM\ngit submodule update --init --recursive\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-first-time-modify-mpas-ocean-makefiles-to-link-to-henson\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-modify-mpas-ocean-makefiles-to-link-to-henson\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: modify MPAS-Ocean makefiles to link to Henson\u003c/h2\u003e\n\u003cp\u003eEdit ~climate/E3SM/components/mpas-ocean/Makefile:\u003c/p\u003e\n\u003cp\u003eInsert at line 596:\n\u003ccode\u003eLIBS += -L $(HENSON)/lib -lhenson\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eInsert at line 732:\n\u003ccode\u003eLDFLAGS += -shared\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eEdit line 1002 to add .so to executable name: \u003ccode\u003e$(EXE_NAME).so\u003c/code\u003e\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-build-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#build-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild MPAS-Ocean\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~/climate/E3SM/components/mpas-ocean\nmake clean              # if dirty\nmake -j gfortran\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will take ~ 5 minutes to compile.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-create-a-run-script-for-mpas-ocean\" class=\"anchor\" aria-hidden=\"true\" href=\"#create-a-run-script-for-mpas-ocean\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCreate a run script for MPAS-Ocean\u003c/h3\u003e\n\u003cp\u003eEdit (create) \u003ccode\u003e~/climate/E3SM/components/mpas-ocean/ocean_model\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epython3 ~/climate/mpas-o-workflow/mpas-henson.py\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eSet permissions of \u003ccode\u003eocean_model\u003c/code\u003e to executable:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003echmod 755 ~/climate/E3SM/components/mpas-ocean/ocean_model\u003c/code\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-a-test-case-to-execute\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-test-case-to-execute\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a test case to execute\u003c/h2\u003e\n\u003cp\u003eCompass is an E3SM system for generating and running test cases for MPAS-Ocean, and relies on conda environments. The instructions below assume you have cond or miniconda already installed. If not, go \u003ca href=\"https://docs.conda.io/en/latest/miniconda.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e first.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-install-compass-and-create-compass-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-install-compass-and-create-compass-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: install Compass and create Compass environment\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003ecd ~\ngit clone https://github.com/MPAS-Dev/compass.git compass-env-only\ncd ~/compass-env-only\ngit submodule update --init --recursive\n./conda/configure_compass_env.py --conda ~/miniconda3 --env_only\nsource load_dev_compass_1.2.0-alpha.4.sh        # load_dev_compass-1.2.0-alpha.4.sh is the script created by the previous command\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-a-compass-configuration-file-for-a-new-machine\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-a-compass-configuration-file-for-a-new-machine\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create a compass configuration file for a new machine\u003c/h3\u003e\n\u003cp\u003eAssumes the config file is named ~/compass-env-only/compass.cfg and has these contents, or similar (yours may vary)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# This file contains some common config options you might want to set\n\n# The paths section describes paths to databases and shared compass environments\n[paths]\n\n# A root directory where MPAS standalone data can be found\ndatabase_root = /home/tpeterka/compass/mpas_standalonedata\n\n# The parallel section describes options related to running tests in parallel\n[parallel]\n\n# parallel system of execution: slurm or single_node\nsystem = single_node\n\n# whether to use mpirun or srun to run the model\nparallel_executable = mpiexec\n\n# cores per node on the machine, detected automatically by default\n# cores_per_node = 4\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-first-time-create-test-case-for-the-executable\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-create-test-case-for-the-executable\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time: create test case for the executable\u003c/h3\u003e\n\u003cp\u003eAssumes that \u003ccode\u003eload_dev_compass_1.2.0-alpha.4.sh\u003c/code\u003e is the name of the conda environment load script created initially\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\ncompass setup -t ocean/baroclinic_channel/10km/default -w ~/spack-baroclinic-test -p ~/climate/E3SM/components/mpas-ocean -f ~/compass-env-only/compass.cfg\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-run-the-test-case\" class=\"anchor\" aria-hidden=\"true\" href=\"#run-the-test-case\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun the test case\u003c/h3\u003e\n\u003cp\u003eAssumes that \u003ccode\u003eload_dev_compass_1.2.0-alpha.4.sh\u003c/code\u003e is the name of the conda environment load script created initially\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/compass-env-only/load_dev_compass_1.2.0-alpha.4.sh\nsource ~/climate/mpas-o-workflow/load-mpas.sh\ncd ~/spack-baroclinic-test/ocean/baroclinic_channel/10km/default\ncompass run\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1679076329.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "utils/Docker/cpu/make-image/spack.yaml",
      "utils/Docker/gpu/make-image-gpu/spack.yaml"
    ],
    "full_name": "acwen11/cactusamrex_copy",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-cactusamrex\" class=\"anchor\" aria-hidden=\"true\" href=\"#cactusamrex\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://bitbucket.org/eschnett/cactusamrex\" rel=\"nofollow\"\u003eCactusAMReX\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"figures/carpetx.png\"\u003e\u003cimg src=\"figures/carpetx.png\" alt=\"CarpetX logo\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCarpetX\u003c/strong\u003e is a \u003ca href=\"https://cactuscode.org/\" rel=\"nofollow\"\u003eCactus\u003c/a\u003e driver based on \u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX\u003c/a\u003e, a software framework for block-structured AMR (adaptive mesh refinement). CarpetX is intended for the \u003ca href=\"https://einsteintoolkit.org/\" rel=\"nofollow\"\u003eEinstein Toolkit\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://bitbucket.org/eschnett/cactusamrex\" rel=\"nofollow\"\u003eBitbucket\u003c/a\u003e: Source code repository\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://dev.azure.com/schnetter/CactusAMReX/_build\" rel=\"nofollow\"\u003eAzure   Pipelines\u003c/a\u003e: Build Status \u003ca href=\"https://dev.azure.com/schnetter/CactusAMReX/_build/latest?definitionId=6\u0026amp;branchName=master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c376f6da8aa212a12313b10b09f29b30a096a8f4bc59b67c7baf9a5aaa2ad8a1/68747470733a2f2f6465762e617a7572652e636f6d2f7363686e65747465722f436163747573414d5265582f5f617069732f6275696c642f7374617475732f436163747573414d5265582d43493f6272616e63684e616d653d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://dev.azure.com/schnetter/CactusAMReX/_apis/build/status/CactusAMReX-CI?branchName=master\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h2\u003e\n\u003cp\u003eCarpetX is almost ready for production. (The only missing feature is\ncheckpointing/recovery.) You are welcome to give it a try, to look at\nwhat changes your code might need to benefit from CarpetX\u0027s new\nfeatures, and to give us feedback.\u003c/p\u003e\n\u003cp\u003eThe recorded talk \u003ca href=\"http://einsteintoolkit.org/seminars/2021_03_18/index.html\" rel=\"nofollow\"\u003e\"Using CarpetX: A Guide for Early\nAdopters\"\u003c/a\u003e.\nThis presentation provides an overview of the current capabilities of\nCarpetX and showcases how to write Cactus code using it.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting started\u003c/h2\u003e\n\u003cp\u003eHere are instructions for downloading the Einstein Toolkit including\nCarpetX, building, and running an example.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-download-and-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#download-and-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDownload and Setup\u003c/h3\u003e\n\u003cp\u003eDownload the Einstein Toolkit, including CarpetX. This will create a\nnew directory \u003ccode\u003eCactus\u003c/code\u003e that will contain the code:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecurl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/master/GetComponents\nperl GetComponents --parallel https://bitbucket.org/eschnett/cactusamrex/raw/master/manifest/einsteintoolkit-carpetx.th\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e Cactus\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe\u0027re using a Docker image to provide dependencies (including AMReX)\nto simplify installation. However, the Einstein Toolkit source code\ndoes not reside in that image; it resides in the \u003ccode\u003eCactus\u003c/code\u003e directory\nwhich you just created. This leads to the following workflow:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTo download, look at, edit, git add/commit/pull/push etc. the code,\nyou use the regular tools you already have installed on your system.\nDocker is not involved in this in any way.\u003c/li\u003e\n\u003cli\u003eTo build and run, you create an emphemeral (stateless) Docker\ncontainer running Bash, with our Docker image mounted. For\nconvenience, there is a shell script for this:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./repos/cactusamrex/utils/Docker/cpu/run-container\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe first time you run this script, Docker will download the Docker\nimage with the dependencies, which might take a few minutes.\u003c/p\u003e\n\u003cp\u003eInside this container, the hostname is \u003ccode\u003ecarpetx-docker-cpu\u003c/code\u003e, so that\nyou know you\u0027re inside the container. (You exit the container by\nexiting the shell, e.g. with the \u003ccode\u003eexit\u003c/code\u003e command.)\u003c/p\u003e\n\u003cp\u003eNote: While the container (running the Bash shell) is thrown away\nafter each use, the changes to the file system you make persist, since\nyour home directory is mounted and thus available in the container.\u003c/p\u003e\n\u003cp\u003eAs usual, the first time you use the Einstein Toolkit, you have to\nconfigure Simfactory for your local machine:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim setup\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild\u003c/h3\u003e\n\u003cp\u003eLet\u0027s build the toolkit with CarpetX.\u003c/p\u003e\n\u003cp\u003eThe default option list doesn\u0027t point to AMReX nor some other\ndependencies. We thus specify our own. (I assume this could be fixed\nin the thorns handling these external dependencies.)\u003c/p\u003e\n\u003cp\u003eThe default thorn list would build the regular Einstein Toolkit\nwithout CarpetX; we need to specify a particular thorn list which\nincludes all CarpetX thorns. This thorn list also disables those\nthorns that do not yet work with CarpetX.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim build --optionlist=repos/cactusamrex/utils/Docker/cpu/carpetx.cfg --thornlist=repos/cactusamrex/utils/Docker/cpu/carpetx.th\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOf course, once you created your configuration with the command above,\nto re-build after changing some code, the command is simply\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim build\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eas usual.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-run\" class=\"anchor\" aria-hidden=\"true\" href=\"#run\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun\u003c/h3\u003e\n\u003cp\u003eLet\u0027s run some examples!\u003c/p\u003e\n\u003cp\u003eStarting slowly, here is a scalar wave:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim submit planewave --parfile=arrangements/CarpetX/WaveToyCPU/par/planewave.par --procs=8 --num-threads=8\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou want to adapt the number of cores (\u003ccode\u003e--procs\u003c/code\u003e) and threads\n(\u003ccode\u003e--num-threads\u003c/code\u003e) to your system.\u003c/p\u003e\n\u003cp\u003eIt seems that the default Simfactory setup that was created above\nbuffers the output, so that there might be long periords of time where\nthe simulation appears to hang. Use \u003ccode\u003etop\u003c/code\u003e to see whether it is still\nrunning, and check the output directory to see whether it is still\nproducing output.\u003c/p\u003e\n\u003cp\u003eWe can also run a binary black hole merger:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim submit planewave --parfile=arrangements/CarpetX/Z4c/par/qc0.rpar --procs=40 --num-threads=10\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis setup requires more memory and time. I\u0027m running it with about\n200 GByte of memory on 40 cores for 24 hours.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1680546511.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "utils/Docker/cpu/make-image/spack.yaml",
      "utils/Docker/gpu/make-image-gpu/spack.yaml"
    ],
    "full_name": "yosef-zlochower/cactusamrex_copy",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-cactusamrex\" class=\"anchor\" aria-hidden=\"true\" href=\"#cactusamrex\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://bitbucket.org/eschnett/cactusamrex\" rel=\"nofollow\"\u003eCactusAMReX\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"figures/carpetx.png\"\u003e\u003cimg src=\"figures/carpetx.png\" alt=\"CarpetX logo\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCarpetX\u003c/strong\u003e is a \u003ca href=\"https://cactuscode.org/\" rel=\"nofollow\"\u003eCactus\u003c/a\u003e driver based on \u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX\u003c/a\u003e, a software framework for block-structured AMR (adaptive mesh refinement). CarpetX is intended for the \u003ca href=\"https://einsteintoolkit.org/\" rel=\"nofollow\"\u003eEinstein Toolkit\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://bitbucket.org/eschnett/cactusamrex\" rel=\"nofollow\"\u003eBitbucket\u003c/a\u003e: Source code repository\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://dev.azure.com/schnetter/CactusAMReX/_build\" rel=\"nofollow\"\u003eAzure   Pipelines\u003c/a\u003e: Build Status \u003ca href=\"https://dev.azure.com/schnetter/CactusAMReX/_build/latest?definitionId=6\u0026amp;branchName=master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c376f6da8aa212a12313b10b09f29b30a096a8f4bc59b67c7baf9a5aaa2ad8a1/68747470733a2f2f6465762e617a7572652e636f6d2f7363686e65747465722f436163747573414d5265582f5f617069732f6275696c642f7374617475732f436163747573414d5265582d43493f6272616e63684e616d653d6d6173746572\" alt=\"Build Status\" data-canonical-src=\"https://dev.azure.com/schnetter/CactusAMReX/_apis/build/status/CactusAMReX-CI?branchName=master\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h2\u003e\n\u003cp\u003eCarpetX is almost ready for production. (The only missing feature is\ncheckpointing/recovery.) You are welcome to give it a try, to look at\nwhat changes your code might need to benefit from CarpetX\u0027s new\nfeatures, and to give us feedback.\u003c/p\u003e\n\u003cp\u003eThe recorded talk \u003ca href=\"http://einsteintoolkit.org/seminars/2021_03_18/index.html\" rel=\"nofollow\"\u003e\"Using CarpetX: A Guide for Early\nAdopters\"\u003c/a\u003e.\nThis presentation provides an overview of the current capabilities of\nCarpetX and showcases how to write Cactus code using it.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting started\u003c/h2\u003e\n\u003cp\u003eHere are instructions for downloading the Einstein Toolkit including\nCarpetX, building, and running an example.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-download-and-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#download-and-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDownload and Setup\u003c/h3\u003e\n\u003cp\u003eDownload the Einstein Toolkit, including CarpetX. This will create a\nnew directory \u003ccode\u003eCactus\u003c/code\u003e that will contain the code:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecurl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/master/GetComponents\nperl GetComponents --parallel https://bitbucket.org/eschnett/cactusamrex/raw/master/manifest/einsteintoolkit-carpetx.th\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e Cactus\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eWe\u0027re using a Docker image to provide dependencies (including AMReX)\nto simplify installation. However, the Einstein Toolkit source code\ndoes not reside in that image; it resides in the \u003ccode\u003eCactus\u003c/code\u003e directory\nwhich you just created. This leads to the following workflow:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTo download, look at, edit, git add/commit/pull/push etc. the code,\nyou use the regular tools you already have installed on your system.\nDocker is not involved in this in any way.\u003c/li\u003e\n\u003cli\u003eTo build and run, you create an emphemeral (stateless) Docker\ncontainer running Bash, with our Docker image mounted. For\nconvenience, there is a shell script for this:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./repos/cactusamrex/utils/Docker/cpu/run-container\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe first time you run this script, Docker will download the Docker\nimage with the dependencies, which might take a few minutes.\u003c/p\u003e\n\u003cp\u003eInside this container, the hostname is \u003ccode\u003ecarpetx-docker-cpu\u003c/code\u003e, so that\nyou know you\u0027re inside the container. (You exit the container by\nexiting the shell, e.g. with the \u003ccode\u003eexit\u003c/code\u003e command.)\u003c/p\u003e\n\u003cp\u003eNote: While the container (running the Bash shell) is thrown away\nafter each use, the changes to the file system you make persist, since\nyour home directory is mounted and thus available in the container.\u003c/p\u003e\n\u003cp\u003eAs usual, the first time you use the Einstein Toolkit, you have to\nconfigure Simfactory for your local machine:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim setup\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-build\" class=\"anchor\" aria-hidden=\"true\" href=\"#build\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild\u003c/h3\u003e\n\u003cp\u003eLet\u0027s build the toolkit with CarpetX.\u003c/p\u003e\n\u003cp\u003eThe default option list doesn\u0027t point to AMReX nor some other\ndependencies. We thus specify our own. (I assume this could be fixed\nin the thorns handling these external dependencies.)\u003c/p\u003e\n\u003cp\u003eThe default thorn list would build the regular Einstein Toolkit\nwithout CarpetX; we need to specify a particular thorn list which\nincludes all CarpetX thorns. This thorn list also disables those\nthorns that do not yet work with CarpetX.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim build --optionlist=repos/cactusamrex/utils/Docker/cpu/carpetx.cfg --thornlist=repos/cactusamrex/utils/Docker/cpu/carpetx.th\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOf course, once you created your configuration with the command above,\nto re-build after changing some code, the command is simply\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim build\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eas usual.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-run\" class=\"anchor\" aria-hidden=\"true\" href=\"#run\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRun\u003c/h3\u003e\n\u003cp\u003eLet\u0027s run some examples!\u003c/p\u003e\n\u003cp\u003eStarting slowly, here is a scalar wave:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim submit planewave --parfile=arrangements/CarpetX/WaveToyCPU/par/planewave.par --procs=8 --num-threads=8\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou want to adapt the number of cores (\u003ccode\u003e--procs\u003c/code\u003e) and threads\n(\u003ccode\u003e--num-threads\u003c/code\u003e) to your system.\u003c/p\u003e\n\u003cp\u003eIt seems that the default Simfactory setup that was created above\nbuffers the output, so that there might be long periords of time where\nthe simulation appears to hang. Use \u003ccode\u003etop\u003c/code\u003e to see whether it is still\nrunning, and check the output directory to see whether it is still\nproducing output.\u003c/p\u003e\n\u003cp\u003eWe can also run a binary black hole merger:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e./simfactory/bin/sim submit planewave --parfile=arrangements/CarpetX/Z4c/par/qc0.rpar --procs=40 --num-threads=10\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis setup requires more memory and time. I\u0027m running it with about\n200 GByte of memory on 40 cores for 24 hours.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1680543777.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "config/docker/spack.yaml"
    ],
    "full_name": "camierjs/mfem-asan",
    "latest_release": null,
    "readme": "\u003cpre\u003e\u003ccode\u003e                Finite Element Discretization Library\n                               __\n                   _ __ ___   / _|  ___  _ __ ___\n                  | \u0027_ ` _ \\ | |_  / _ \\| \u0027_ ` _ \\\n                  | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_| |_| |_|\n\n                           https://mfem.org\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://mfem.org\" rel=\"nofollow\"\u003eMFEM\u003c/a\u003e is a modular parallel C++ library for finite element\nmethods. Its goal is to enable high-performance scalable finite element\ndiscretization research and application development on a wide variety of\nplatforms, ranging from laptops to supercomputers.\u003c/p\u003e\n\u003cp\u003eWe welcome contributions and feedback from the community. Please see the file\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e for additional details about our development\nprocess.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFor building instructions, see the file \u003ca href=\"INSTALL\"\u003eINSTALL\u003c/a\u003e, or type \"make help\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopyright and licensing information can be found in files \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe best starting point for new users interested in MFEM\u0027s features is to\nreview the examples and miniapps at \u003ca href=\"https://mfem.org/examples\" rel=\"nofollow\"\u003ehttps://mfem.org/examples\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstructions for learning with Docker are in \u003ca href=\"config/docker\"\u003econfig/docker\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConceptually, MFEM can be viewed as a finite element toolbox that provides the\nbuilding blocks for developing finite element algorithms in a manner similar to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\nH(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\nbilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping of various finite element discretizations, including Galerkin\nmethods, mixed finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization and Discontinuous Petrov-Galerkin (DPG) approaches.\u003c/p\u003e\n\u003cp\u003eMFEM includes classes for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral and hexahedral, as well as surface and topologically\nperiodical meshes. It has general support for mesh refinement, including local\nconforming and non-conforming (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for high-order mesh elements with curved boundaries,\nare also supported.\u003c/p\u003e\n\u003cp\u003eWhen used as a \"finite element to linear algebra translator\", MFEM can take a\nproblem described in terms of finite element-type objects, and produce the\ncorresponding linear algebra vectors and fully or partially assembled operators,\ne.g. in the form of global sparse matrices or matrix-free operators. The library\nincludes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\nwell as support for sequential sparse direct solvers from the SuiteSparse\nlibrary. Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit and implicit Runge-Kutta time integrators are also available.\u003c/p\u003e\n\u003cp\u003eMFEM supports MPI-based parallelism throughout the library, and can readily be\nused as a scalable unstructured finite element problem generator. Starting with\nversion 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal changes to switch from a serial to a highly-performant MPI-parallel\nversion of the code, where they can take advantage of the integrated linear\nsolvers from the hypre library. Comprehensive support for other external\npackages, e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional linear and nonlinear solvers, preconditioners, time integrators, etc.\u003c/p\u003e\n\u003cp\u003eFor examples of using MFEM, see the \u003ca href=\"examples\"\u003eexamples/\u003c/a\u003e and \u003ca href=\"miniapps\"\u003eminiapps/\u003c/a\u003e\ndirectories, as well as the OpenGL visualization tool GLVis which is available\nat \u003ca href=\"https://glvis.org\" rel=\"nofollow\"\u003ehttps://glvis.org\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eMFEM is distributed under the terms of the BSD-3 license. All new contributions\nmust be made under this license. See \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e for\ndetails.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: BSD-3-Clause \u003cbr\u003e\nLLNL Release Number: LLNL-CODE-806117 \u003cbr\u003e\nDOI: 10.11578/dc.20171025.1248\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1680543921.0
  },
  {
    "data_format": 2,
    "description": "Spack environments",
    "filenames": [
      "envs/local/cp2k-dlaf-mkl-mpich/spack.yaml",
      "envs/alps/dlaf-mkl-cuda/spack.yaml",
      "envs/local/cp2k/spack.yaml",
      "envs/local/dlaf-mkl-mpich/spack.yaml",
      "envs/alps/cp2k-dlaf-cpu/spack.yaml"
    ],
    "full_name": "RMeli/my-spack",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-my-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#my-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMy Spack\u003c/h1\u003e\n\u003cp\u003eSpack-related stuff for @RMeli.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-package-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#package-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePackage Repository\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/repositories.html\" rel=\"nofollow\"\u003eSpack Package Repositories\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1679671251.0
  },
  {
    "data_format": 2,
    "description": "ChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "scs-lab/ChronoLog",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-chronolog\" class=\"anchor\" aria-hidden=\"true\" href=\"#chronolog\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eChronoLog\u003c/h1\u003e\n\u003cp\u003eChronoLog: A High-Performance Storage Infrastructure for Activity and Log Workloads (NSF CSSI 2104013)\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-chronolog-project-synopsis\" class=\"anchor\" aria-hidden=\"true\" href=\"#chronolog-project-synopsis\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eChronoLog Project Synopsis\u003c/h2\u003e\n\u003cp\u003eThis project will design and implement ChronoLog, a distributed and tiered shared log storage ecosystem. ChronoLog uses physical time to distribute log entries while providing total log ordering. It also utilizes multiple storage tiers to elastically scale the log capacity (i.e., auto-tiering). ChronoLog will serve as a foundation for developing scalable new plugins, including a SQL-like query engine for log data, a streaming processor leveraging the time-based data distribution, a log-based key-value store, and a log-based TensorFlow module.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-workloads-and-applications\" class=\"anchor\" aria-hidden=\"true\" href=\"#workloads-and-applications\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorkloads and Applications\u003c/h2\u003e\n\u003cp\u003eModern applications spanning from Edge to High Performance Computing (HPC) systems, produce and process log data and create a plethora of workload characteristics that rely on a common storage model: \u003cstrong\u003ethe distributed shared log\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/doc/images/log_centric_paradigm.svg\"\u003e\u003cimg src=\"/doc/images/log_centric_paradigm.svg\" alt=\"Log centric paradigm\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-hidden=\"true\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFeatures\u003c/h2\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"/doc/images/feature-matrix.png\"\u003e\u003cimg src=\"/doc/images/feature-matrix.png\" alt=\"Feature matrix\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-checkout-chronolog\" class=\"anchor\" aria-hidden=\"true\" href=\"#checkout-chronolog\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCheckout ChronoLog\u003c/h2\u003e\n\u003cp\u003eChronoLog uses HCL internally. It is added to this repository as a submodule. Thus, you need to clone the submodules as well. You can do it using \u003ccode\u003egit clone --recursive git@github.com:scs-lab/ChronoLog.git\u003c/code\u003e to clone ChronoLog. Or you can run \u003ccode\u003egit submodule update --init --recursive\u003c/code\u003e once in \u003ccode\u003eChronoLog\u003c/code\u003e directory after you clone the repository without \u003ccode\u003e--recursive\u003c/code\u003e. For following pulls, you can update the submodule using command \u003ccode\u003egit pull --recurse-submodules\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h2\u003e\n\u003cp\u003eChronoLog has a list of dependencies which can be solved by Spack packages. Thus, Spack needs to be installed and configured as the first step to build ChronoLog.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-install-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#install-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall Spack\u003c/h3\u003e\n\u003cp\u003eSpack can be checked out with \u003ccode\u003egit clone https://github.com/spack/spack.git\u003c/code\u003e. It is assumed that Spack is stored at \u003ccode\u003e~/Spack\u003c/code\u003e for the following step. Spack needs to activated by running \u003ccode\u003esource ~/Spack/spack/share/spack/setup-env.sh\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-install-chronolog-dependencies\" class=\"anchor\" aria-hidden=\"true\" href=\"#install-chronolog-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall ChronoLog dependencies\u003c/h3\u003e\n\u003cp\u003eCurrently, most of the dependencies are listed in \u003ccode\u003espack.yaml\u003c/code\u003e and can be installed via Spack.\u003c/p\u003e\n\u003cp\u003eA Spack environment needs to be created and activated using the following commands. When the environment is activated, a shell prompt \u003ccode\u003e[ChronoLog]\u003c/code\u003e will pop up.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd ChronoLog\ngit switch develop\nspack env create -d .\nspack env activate -p .\nspack install -v\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe installation may take some time (\u0026gt; 30 minutes) to finish.\u003c/p\u003e\n\u003cp\u003eAdditionally, \u003ccode\u003erapidjson\u003c/code\u003e is needed to parse the JSON configuration file. You can install it using command \u003ccode\u003esudo apt install rapidjson-dev\u003c/code\u003e in Ubuntu.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-build-chronolog\" class=\"anchor\" aria-hidden=\"true\" href=\"#build-chronolog\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild ChronoLog\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003ePlease make sure all the building is carried out in the activated Spack environment.\u003c/strong\u003e Otherwise, CMake will not able to find the dependencies.\u003c/p\u003e\n\u003cp\u003eThree tests can be built for not to have a mini testbed. \u003ccode\u003echronovisor_server_test\u003c/code\u003e is for the ChronoVisor. \u003ccode\u003echronolog_client_lib_connect_rpc_test\u003c/code\u003e and \u003ccode\u003echronolog_client_lib_metadata_rpc_test\u003c/code\u003e are two client apps to test the connection/disconnection and metadata operations (e.g., Chronicle and Story management) functionalities, respectively.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd ChronoLog\ngit switch develop\nmkdir build\ncd build\ncmake ..\nmake chronovisor_server_test chronolog_client_lib_connect_rpc_test chronolog_client_lib_metadata_rpc_test\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-configuration-files\" class=\"anchor\" aria-hidden=\"true\" href=\"#configuration-files\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfiguration files\u003c/h3\u003e\n\u003cp\u003eAll ChronoLog executables share one unified configuration file. The template file can be found in \u003ccode\u003etest/default_conf.json.in\u003c/code\u003e. You can modify it for your own preferences. By default, all existing mini tests expect a configuration file \u003ccode\u003edefault_conf.json\u003c/code\u003e in the same directory it launches. The default building process will copy and rename \u003ccode\u003etest/default_conf.json.in\u003c/code\u003e to achieve that. If you want to change the default configurations, you can edit the template file and rebuild the targets, or directly edit the file in the target directory.\u003c/p\u003e\n\u003cp\u003eChronoLog will support sockets/TCP/verbs protocols using ofi transport. You can run command \u003ccode\u003emargo-info\u003c/code\u003e to check which transports and protocols are supported on your system.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1\u003e\u003ca id=\"user-content-coming-soon-\" class=\"anchor\" aria-hidden=\"true\" href=\"#coming-soon-\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eComing soon ...\u003c/h1\u003e\n\u003cp\u003eFor more details about the ChronoLog project, please visit our website \u003ca href=\"http://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html\" rel=\"nofollow\"\u003ehttp://www.cs.iit.edu/~scs/assets/projects/ChronoLog/ChronoLog.html\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1675193782.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Casper system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-casper",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-hidden=\"true\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNCAR Spack Deployment\u003c/h1\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ecasper\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eWed Mar 22 21:50:19 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003efc3df9ab78502b74368eb656923301f672d491f6\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack version\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/casper/23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/work/csgteam/spack-deployments/casper/23.03/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1679548145.0
  },
  {
    "data_format": 2,
    "description": "Muon Collider software repository for Spack",
    "filenames": [
      "environments/mucoll-common/spack.yaml",
      "environments/mucoll-release/spack.yaml"
    ],
    "full_name": "MuonColliderSoft/mucoll-spack",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-package-repository-for-muon-collider-software-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-package-repository-for-muon-collider-software-stack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package repository for Muon Collider software stack\u003c/h1\u003e\n\u003cp\u003eThis repository holds a set of Spack recipes for Muon Collider software (under namespace \u003ccode\u003emucoll\u003c/code\u003e) based on \u003ca href=\"https://key4hep.github.io/key4hep-doc/\" rel=\"nofollow\"\u003eKey4hep\u003c/a\u003e stack. It extends the corresponding \u003ca href=\"https://github.com/key4hep/key4hep-spack\"\u003ekey4hep-stack\u003c/a\u003e repository, which is required for installation, overriding several packages by the ones customised for Muon Collider simulation studies.\u003c/p\u003e\n\u003cp\u003eAfter installing \u003ca href=\"https://github.com/key4hep/spack\"\u003eSpack\u003c/a\u003e and downloading the \u003ca href=\"https://github.com/key4hep/key4hep-spack\"\u003ekey4hep-spack\u003c/a\u003e and \u003ca href=\"https://github.com/MuonColliderSoft/mucoll-spack\"\u003emucoll-spack\u003c/a\u003e repositories, the whole software stack can be installed using the following commands:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Add repositories\u003c/span\u003e\nspack repo add ./key4hep-spack\nspack repo add ./mucoll-spack\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Create a Spack environment\u003c/span\u003e\nspack env create sim\nspack env activate sim\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Copy package configurations\u003c/span\u003e\ncp ./mucoll-spack/environments/mucoll-release/\u003cspan class=\"pl-k\"\u003e*\u003c/span\u003e.yaml \u003cspan class=\"pl-smi\"\u003e$SPACK_ENV\u003c/span\u003e/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Install the software stack\u003c/span\u003e\nspack add mucoll-stack\nspack concretize --reuse\nspack install --fail-fast\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Load the Muon Collider environment\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$MUCOLL_STACK\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setting-up-the-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-the-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up the environment\u003c/h2\u003e\n\u003cp\u003eWhen signing in to a machine with the installed sofware stack (VM or Docker container), it has to be loaded into the environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate sim\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$MUCOLL_STACK\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-package-versioning\" class=\"anchor\" aria-hidden=\"true\" href=\"#package-versioning\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePackage versioning\u003c/h2\u003e\n\u003cp\u003ePreferred convention for version names in Spack is numbers separated by dots, without leading zeros, e.g. \u003ccode\u003e1.2.13\u003c/code\u003e.\nConversion to tag names in \u003ccode\u003emucoll\u003c/code\u003e packages is provided by \u003ccode\u003eMCIlcsoftpackage\u003c/code\u003e class defined in \u003ccode\u003epackages/mucoll-stack/mucoll_utils.py\u003c/code\u003e, e.g. for \u003ca href=\"https://github.com/MuonColliderSoft/lcgeo/releases/tag/v00-17-MC\"\u003e\u003ccode\u003elcgeo\u003c/code\u003e\u003c/a\u003e package version \u003ccode\u003e0.17\u003c/code\u003e corresponds to tag name \u003ccode\u003ev00-17-MC\u003c/code\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-adding-new-versions-for-individual-packages\" class=\"anchor\" aria-hidden=\"true\" href=\"#adding-new-versions-for-individual-packages\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAdding new versions for individual packages\u003c/h2\u003e\n\u003cp\u003eAfter a new tag for the package is created, e.g. \u003ccode\u003ev00-17-MC\u003c/code\u003e in \u003ccode\u003elcgeo\u003c/code\u003e repository, it can be added to this Spack repository in two steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eGet the archive checksum for the new tag\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack checksum lcgeo 0.17\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Validates archive URL and returns the checksum\u003c/span\u003e\n    version(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e0.17\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e, sha256=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e5ab33aaf5bc37deba82c2dde78cdce6c0041257222ed7ea052ecdd388a41cf9b\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eAdd the returned version definition to the corresponding package file: \u003ca href=\"packages/lcgeo/package.py\"\u003e\u003ccode\u003epackages/lcgeo/package.py\u003c/code\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNOTE: This repository only contains packages maintained by the Muon Collider collaboration.\nIf the version of interest is missing from Spack for some other package, the line with a new version definition should be added to the package file in the corresponding repository.\u003cbr\u003e\nTo see locations of other repositories: \u003ccode\u003espack repo list\u003c/code\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2\u003e\u003ca id=\"user-content-creating-a-new-stack-release\" class=\"anchor\" aria-hidden=\"true\" href=\"#creating-a-new-stack-release\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCreating a new stack release\u003c/h2\u003e\n\u003cp\u003eTo introduce a new release version for the whole software stack, update the version number in \u003ca href=\"packages/mucoll-stack/package.py\"\u003e\u003ccode\u003epackages/mucoll-stack/package.py\u003c/code\u003e\u003c/a\u003e and then update versions of all the relevant packages in [environments/mucoll-release/packages.yaml].\u003cbr\u003e\nTest this new configuration in a fresh environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Create a development environment\u003c/span\u003e\nspack env create dev\nspack env activate dev\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Copy the package configuration\u003c/span\u003e\ncp ./mucoll-spack/environments/mucoll-release/\u003cspan class=\"pl-k\"\u003e*\u003c/span\u003e.yaml \u003cspan class=\"pl-smi\"\u003e$SPACK_ENV\u003c/span\u003e/\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Add stack with updated version to the environment\u003c/span\u003e\nspack add mucoll-stack\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Check which packages would be installed\u003c/span\u003e\nspack spec --reuse -NIt\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ePackages that are already installed in the \u003ccode\u003esim\u003c/code\u003e environment are known to Spack and will be reused, providing a clear indication of which part of the dependency tree will be modified by the new release.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1679435634.0
  },
  {
    "data_format": 2,
    "description": "A low-level profiler for capture I/O calls from deep learning applications.",
    "filenames": [
      "dependency/spack.yaml"
    ],
    "full_name": "hariharan-devarajan/dlio-profiler",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-dlio-profiler\" class=\"anchor\" aria-hidden=\"true\" href=\"#dlio-profiler\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003edlio-profiler\u003c/h1\u003e\n\u003cp\u003eA low-level profiler for capture I/O calls from deep learning applications.\u003c/p\u003e\n\u003cp\u003eRequirements\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePython \u0026gt; 3.8\u003c/li\u003e\n\u003cli\u003espack\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eInstall dependencies\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@github.com:hariharan-devarajan/dlio-profiler.git\ncd dlio-profiler\nspack env activater -p ./dependency\nspack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ecreate a virtual env for your python package where u will use dlio_profiler.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 -m venv ./venv\nsource venv/bin/activate\npip install --upgrade pip\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBuild dlio profiler through cmake\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd dlio-profiler\nmkdir build\ncd build\ncmake -DCMAKE_INSTALL_PREFIX=../venv ../\nmake install -j\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eUsage\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport dlio_profiler_py as logger\nfrom time import sleep\nimport os\ncwd = os.getcwd()\ndef custom_events():\n    logger.start(\"test\", \"cat2\")\n    sleep(2)\n    logger.stop()\n\ndef posix_calls1():\n    f = open(f\"{cwd}/data/demofile2.txt\", \"w+\")\n    f.write(\"Now the file has more content!\")\n    f.close()\n\ndef posix_calls2():\n    f = open(f\"{cwd}/data/demofile2.txt\", \"r\")\n    data = f.read()\n    f.close()\n\nposix_calls1()\ncustom_events()\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1680080472.0
  },
  {
    "data_format": 2,
    "description": "New build system for building scientific software.",
    "filenames": [
      "examples/build-image/spack_example_hy-alma8/spack.yaml",
      "examples/without-image/spack_example_ubuntu22.04/spack.yaml"
    ],
    "full_name": "scifihpc/scibuilder",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-scibuilder\" class=\"anchor\" aria-hidden=\"true\" href=\"#scibuilder\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eScibuilder\u003c/h1\u003e\n\u003cp\u003eScibuilder is a tool for helping with automated builds\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eScibuilder is a Python module and it needs an environment with various packages.\u003c/p\u003e\n\u003cp\u003eWe recommend using \u003ccode\u003emamba\u003c/code\u003e for faster installation.\n\u003ca href=\"https://github.com/conda-forge/miniforge#install\"\u003eMambaforge\u003c/a\u003e is an excellent way\nof getting \u003ccode\u003emamba\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eCreating environment:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003emamba env create --file environment.yml\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e activate scibuilder\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-running-scibuilder-example\" class=\"anchor\" aria-hidden=\"true\" href=\"#running-scibuilder-example\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning scibuilder example\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h3\u003e\n\u003cp\u003eThis example build works on Ubuntu 22.04. It installs cmake as an example.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/spack/spack.git\n\u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e spack/share/spack/setup-env.sh\npython -m scibuilder spack build examples/without-image/spackbuilder_example.yml\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-mamba\" class=\"anchor\" aria-hidden=\"true\" href=\"#mamba\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMamba\u003c/h3\u003e\n\u003cp\u003eThis example build will work on any linux system. It creates two conda environments:\none with gpu-enabled packgages and one without.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epython -m scibuilder mamba build examples/without-image/mambabuilder_example.yml\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-scibuilder-build-image\" class=\"anchor\" aria-hidden=\"true\" href=\"#scibuilder-build-image\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003escibuilder-build-image\u003c/h2\u003e\n\u003cp\u003eScibuilder can be run in a docker/podman images.\u003c/p\u003e\n\u003cp\u003eSee image \u003ca href=\"dockerfiles/scibuilder-build-image/README.md\"\u003eREADME.md\u003c/a\u003e for more information.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-configuring-builds\" class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-builds\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfiguring builds\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-spack-1\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-1\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h3\u003e\n\u003cp\u003eSpack builds are configured by creating a YAML-file that describes what environments we\nwant to build and the compilers we want to use for building them.\u003c/p\u003e\n\u003cp\u003eLet\u0027s look at \u003ca href=\"examples/without-image/spackbuilder_example.yml\"\u003eexamples/without-image/spackbuilder_example.yml\u003c/a\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e\u003cspan class=\"pl-ent\"\u003eenvironments\u003c/span\u003e:\n  - \u003cspan class=\"pl-ent\"\u003ename\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003espack_example\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003etags\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003espack\u003c/span\u003e\n      - \u003cspan class=\"pl-s\"\u003emain\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003eenvironment_file\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003eexamples/without-image/spack_example_ubuntu22.04/spack.yaml\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003esystem_compiler\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003egcc@11.3.0\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003ecompilers\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003egcc@11.3.0\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe list \u003ccode\u003eenvironments\u003c/code\u003e consist of multiple independent build with the following\nattributes:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003ename\u003c/code\u003e - Name of the environment\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003etags\u003c/code\u003e - List of arbitrary tags that can be used to limit the builder to only these\nbuilds via the \u003ccode\u003e--tags=TAGS\u003c/code\u003e-parameter.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eenvironmnet_file\u003c/code\u003e - A spack \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003eenvironement file\u003c/a\u003e\nthat contains information on what packages we want to install and where we want to install them.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003esystem_compiler\u003c/code\u003e - A compiler present in the system that the builder will try to locate for\nspack to use as an initial compiler.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ecompilers\u003c/code\u003e: List of compilers that spack will try to locate and build with the system compiler\nbefore building the environment in full.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1678697646.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Derecho system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-derecho",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-hidden=\"true\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNCAR Spack Deployment\u003c/h1\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003ederecho\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eMon Mar 27 17:05:43 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003efaceed4d8058f0f9d5ef385ab0eebb77a9a77c67\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack version\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/derecho/23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/derecho/scratch/csgteam/spack-deployments/derecho/23.03/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1679963542.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "share/spack/gitlab/cloud_pipelines/stacks/data-vis-sdk/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/e4s/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/radiuss/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/e4s-on-power/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml",
      "share/spack/gitlab/cloud_pipelines/stacks/tutorial/spack.yaml"
    ],
    "full_name": "jerrypgreenberg/sdsc-tscc",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-sdsc-hpc-software-deployment-guide\" class=\"anchor\" aria-hidden=\"true\" href=\"#sdsc-hpc-software-deployment-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSDSC HPC Software Deployment Guide\u003c/h1\u003e\n\u003cp\u003eThis document outlines the Spack-based software deployment process in\nuse by the San Diego Supercomputer Center\u0027s (SDSC) High-Performance\nComputing (HPC) User Services Group. All definitions, procedures,\nconventions, and policies defined within this guide are used by the\ngroup to build and maintain the custom Spack instances they deploy on\nSDSC\u0027s HPC systems for end users.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"true\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThis is a new and evolving software deployment process in development\nand use by the SDSC HPC User Services Group to centrally manage HPC\nsoftware on HPC systems with Spack. Please consider the status of the\nproject as a pre-alpha release at this time. Use at your own risk.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-definitions-and-terminology\" class=\"anchor\" aria-hidden=\"true\" href=\"#definitions-and-terminology\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDefinitions and Terminology\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003einstance\u003c/strong\u003e\u003c/em\u003e is a unique, stand-alone installation of a\nspecific version of \u003ccode\u003espack\u003c/code\u003e that includes custom Spack configuration\nfiles, Spack packages, and a collection of Spack-installed software\napplications, libraries, and utilities.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003epackage\u003c/strong\u003e\u003c/em\u003e is a set of instructions that defines how a\nspecific piece of software is compiled and/or installed by Spack. For\nexample, a Spack package specifies where to find and how to retrieve\nthe software\u0027s source code, its required (and/or optional) software\ndependencies, its compile-time options, any patches to apply, etc. A\nSpack package is primarily defined by it \u003cem\u003epackage.py\u003c/em\u003e file.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003espec\u003c/strong\u003e\u003c/em\u003e is a string descriptor that specifies a particular\nbuild configuration of a Spack package. The full syntax of a spec\nmay include the package name, its version, the compiler it should be\nbuilt with, the compiler version, the system architecture it should be\ncompiled for, any compile-time options for the package, and any\nrequirements that should be enforced on its dependencies at build time.\u003c/li\u003e\n\u003cli\u003eThe \u003cem\u003e\u003cstrong\u003ecore\u003c/strong\u003e\u003c/em\u003e packages of a Spack instance are those software\napplications, libraries, and/or utilities compiled with Spack using\nthe default system compiler. These packages form the foundation of the\nsoftware environment upon which additional Spack packages are built.\nIn general, the core packages of a Spack instance are a set of (core)\ncompilers and other general software utilities. e.g., version control\nsystems, data transfer tools, etc.\u003c/li\u003e\n\u003cli\u003eA Spack package \u003cem\u003e\u003cstrong\u003edependency chain\u003c/strong\u003e\u003c/em\u003e is an explicitly-defined\u003cbr\u003e\nordered set of Spack specs that share a common (core) compiler and/or\nMPI library, may depend on one another (or share other software\ndependencies), and should be installed one after another, one at a\ntime, as prescribed by their dependencies.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003edeployment branch\u003c/strong\u003e\u003c/em\u003e is a \u003cem\u003etrunk\u003c/em\u003e-like branch for a specific\nversion of \u003ccode\u003espack\u003c/code\u003e that tracks all of the Spack configuration files,\nSpack packages, and Spack specs used to deploy a Spack instance (or a\nset of instances).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-github-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#github-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGitHub Repository\u003c/h2\u003e\n\u003cp\u003eThe \u003ca href=\"https://github.com/sdsc/spack\"\u003esdsc/spack\u003c/a\u003e project is a custom fork\nof the Spack project\u0027s main GitHub repository, which is referred to in\nthis guide as the \u003ca href=\"https://github.com/spack/spack\"\u003espack/spack\u003c/a\u003e repo.\nThe primary aim of the sdsc/spack repo is to manage and track all\nchanges made to the custom Spack instances deployed by SDSC on its HPC\nsystems.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-deployment-branches\" class=\"anchor\" aria-hidden=\"true\" href=\"#deployment-branches\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeployment Branches\u003c/h3\u003e\n\u003cp\u003eThe sdsc/spack repo and its use in practice are fundamentally structured\naround the concept of \u003cem\u003edeployment branches\u003c/em\u003e. A deployment branch is a\n\u003cem\u003etrunk\u003c/em\u003e-like branch created from an unmodifed, official release version\nof \u003ccode\u003espack\u003c/code\u003e and is named accordingly, unless special circumstances\nrequire that an intermediate commit be used. For example, the\n\u003ccode\u003esdsc-0.17.3\u003c/code\u003e deployment branch was created by checking out the\n\u003ca href=\"https://github.com/spack/spack/releases/tag/v0.17.3\"\u003ev0.17.3\u003c/a\u003e release\u003c/p\u003e\n\u003cp\u003eOnce a version of Spack is selected and checked out, only a few minor\nchanges and/or additions are made to the Spack release in order to\ninitialize a deployment branch within the sdsc/spack repo. These\nmodifications are as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe official version of the Spack \u003ccode\u003eREADME.md\u003c/code\u003e file is removed and\nreplaced with the latest version of this document --- the \u003cem\u003eSDSC HPC\nSoftware Deployment Guide\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eThe latest version of the sdsc/spack \u003ccode\u003eCONTRIBUTING.md\u003c/code\u003e file is also\nincluded to provide information on how one may contribute to the\nsdsc/spack project and its deployment branches.\u003c/li\u003e\n\u003cli\u003eA Spack package repository --- \u003ccode\u003evar/spack/repos/sdsc\u003c/code\u003e --- created to\nstore all custom Spack packages created and/or maintained by SDSC,\nincluding all of SDSC\u0027s custom modifications to Spack\u0027s existing\n\u003ccode\u003ebuiltin\u003c/code\u003e packages.\u003c/li\u003e\n\u003cli\u003eA Spack instance repository --- \u003ccode\u003eetc/spack/sdsc\u003c/code\u003e --- is created\nto  ...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll other types of branches (see\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e) should start from a deployment\nbranch.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-package-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#package-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePackage Repository\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-instance-repositories\" class=\"anchor\" aria-hidden=\"true\" href=\"#instance-repositories\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstance Repositories\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-access-control-and-permissions\" class=\"anchor\" aria-hidden=\"true\" href=\"#access-control-and-permissions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAccess Control and Permissions\u003c/h3\u003e\n\u003cp\u003eetc/spack/repos.yaml\nvar/spack/repos/sdsc/repo.yaml\nvar/spack/repos/sdsc/packages\u003c/p\u003e\n\u003cp\u003eetc/spack/sdsc/expanse/0.17.3/cpu/specs\netc/spack/sdsc/expanse/0.17.3/cpu/yamls\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-deploying-hpc-software-via-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#deploying-hpc-software-via-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeploying HPC Software via Spack\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-deploying-a-spack-instance\" class=\"anchor\" aria-hidden=\"true\" href=\"#deploying-a-spack-instance\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeploying a Spack Instance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003estart from existing deployment branch\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003ca id=\"user-content-managing-changes-to-a-spack-instance\" class=\"anchor\" aria-hidden=\"true\" href=\"#managing-changes-to-a-spack-instance\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManaging Changes to a Spack Instance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003edeploy change to configuration file\u003c/li\u003e\n\u003cli\u003eadd new package to sdsc package repository\u003c/li\u003e\n\u003cli\u003espack install a new spec\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003ca id=\"user-content-setting-up-a-shared-instance-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-shared-instance-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a Shared Instance Configuration\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-using-a-spack-mirror-and-build-caches-for-instance-backups\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-a-spack-mirror-and-build-caches-for-instance-backups\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing a Spack Mirror and Build Caches for Instance Backup(s)\u003c/h3\u003e\n\u003ch2\u003e\u003ca id=\"user-content-additional-notes\" class=\"anchor\" aria-hidden=\"true\" href=\"#additional-notes\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAdditional Notes\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-protecting-the-sdscspack-develop-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#protecting-the-sdscspack-develop-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProtecting the sdsc/spack \u003ccode\u003edevelop\u003c/code\u003e branch\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-fetching-changes-and-re-syncing-the-develop-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#fetching-changes-and-re-syncing-the-develop-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFetching changes and re-syncing the \u003ccode\u003edevelop\u003c/code\u003e branch\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-creating-a-new-deployment-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#creating-a-new-deployment-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCreating a new deployment branch\u003c/h3\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1679762434.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack/envs/triage/spack.yaml"
    ],
    "full_name": "ashermancinelli/vimconfig",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-vimconfig\" class=\"anchor\" aria-hidden=\"true\" href=\"#vimconfig\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003evimconfig\u003c/h1\u003e\n\u003cp\u003eLots and lots of different configurations for various programs all wrapped up into one repo. Under heavy development so tread with some caution :)\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-how-to-use\" class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-use\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to use\u003c/h2\u003e\n\u003cp\u003eThe top directory has a script to deal with installation - you should pretty much only interact with the repo through that script.\nThe help message is quite descriptive:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ ./configure --h\n\n  Usage:\n\n  -p \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epath\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e           Sets install prefix. Default: /people/manc568/.local\n  -r \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epath\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e           Path to RC file \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e given shell. Default: /qfs/people/manc568/.bashrc\n  -d                  Default installation. Installs ctags, vim, and bash\n  -s \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epkg\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e            Show installation script \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e pacakge\n  -i                  One or more of the following list, separated by commas with no spaces:\n\n       zsh\n       bash\n       ctags\n       vim\n       tmux\n       emacs\n       profiles\n       modules\n       rice\n       rice.sh\n       fresh\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-examples\" class=\"anchor\" aria-hidden=\"true\" href=\"#examples\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExamples\u003c/h2\u003e\n\u003cp\u003eFor example, to just install my vim configuration, you\u0027d do:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ ./configure -i vim\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOr to install configs for multiple programs:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ ./configure -i vim,ctags,tmux,emacs,bash\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1670527897.0
  },
  {
    "data_format": 2,
    "description": "Mirror of MFEM - a lightweight, general, scalable C++ library for finite element methods. Please use the official repository, https://github.com/mfem/mfem, to create issues and pull requests. See also the MFEM website: ",
    "filenames": [
      "config/docker/spack.yaml"
    ],
    "full_name": "waynemitchell/mfem",
    "latest_release": null,
    "readme": "\u003cpre\u003e\u003ccode\u003e                Finite Element Discretization Library\n                               __\n                   _ __ ___   / _|  ___  _ __ ___\n                  | \u0027_ ` _ \\ | |_  / _ \\| \u0027_ ` _ \\\n                  | | | | | ||  _||  __/| | | | | |\n                  |_| |_| |_||_|   \\___||_| |_| |_|\n\n                           https://mfem.org\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ca href=\"https://mfem.org\" rel=\"nofollow\"\u003eMFEM\u003c/a\u003e is a modular parallel C++ library for finite element\nmethods. Its goal is to enable high-performance scalable finite element\ndiscretization research and application development on a wide variety of\nplatforms, ranging from laptops to supercomputers.\u003c/p\u003e\n\u003cp\u003eWe welcome contributions and feedback from the community. Please see the file\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e for additional details about our development\nprocess.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eFor building instructions, see the file \u003ca href=\"INSTALL\"\u003eINSTALL\u003c/a\u003e, or type \"make help\".\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopyright and licensing information can be found in files \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eThe best starting point for new users interested in MFEM\u0027s features is to\nreview the examples and miniapps at \u003ca href=\"https://mfem.org/examples\" rel=\"nofollow\"\u003ehttps://mfem.org/examples\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eInstructions for learning with Docker are in \u003ca href=\"config/docker\"\u003econfig/docker\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConceptually, MFEM can be viewed as a finite element toolbox that provides the\nbuilding blocks for developing finite element algorithms in a manner similar to\nthat of MATLAB for linear algebra methods. In particular, MFEM provides support\nfor arbitrary high-order H1-conforming, discontinuous (L2), H(div)-conforming,\nH(curl)-conforming and NURBS finite element spaces in 2D and 3D, as well as many\nbilinear, linear and nonlinear forms defined on them. It enables the quick\nprototyping of various finite element discretizations, including Galerkin\nmethods, mixed finite elements, Discontinuous Galerkin (DG), isogeometric\nanalysis, hybridization and Discontinuous Petrov-Galerkin (DPG) approaches.\u003c/p\u003e\n\u003cp\u003eMFEM includes classes for dealing with a wide range of mesh types: triangular,\nquadrilateral, tetrahedral and hexahedral, as well as surface and topologically\nperiodical meshes. It has general support for mesh refinement, including local\nconforming and non-conforming (AMR) adaptive refinement. Arbitrary element\ntransformations, allowing for high-order mesh elements with curved boundaries,\nare also supported.\u003c/p\u003e\n\u003cp\u003eWhen used as a \"finite element to linear algebra translator\", MFEM can take a\nproblem described in terms of finite element-type objects, and produce the\ncorresponding linear algebra vectors and fully or partially assembled operators,\ne.g. in the form of global sparse matrices or matrix-free operators. The library\nincludes simple smoothers and Krylov solvers, such as PCG, MINRES and GMRES, as\nwell as support for sequential sparse direct solvers from the SuiteSparse\nlibrary. Nonlinear solvers (the Newton method), eigensolvers (LOBPCG), and\nseveral explicit and implicit Runge-Kutta time integrators are also available.\u003c/p\u003e\n\u003cp\u003eMFEM supports MPI-based parallelism throughout the library, and can readily be\nused as a scalable unstructured finite element problem generator. Starting with\nversion 4.0, MFEM offers support for GPU acceleration, and programming models,\nsuch as CUDA, HIP, OCCA, RAJA and OpenMP. MFEM-based applications require\nminimal changes to switch from a serial to a highly-performant MPI-parallel\nversion of the code, where they can take advantage of the integrated linear\nsolvers from the hypre library. Comprehensive support for other external\npackages, e.g. PETSc, SUNDIALS and libCEED is also included, giving access to\nadditional linear and nonlinear solvers, preconditioners, time integrators, etc.\u003c/p\u003e\n\u003cp\u003eFor examples of using MFEM, see the \u003ca href=\"examples\"\u003eexamples/\u003c/a\u003e and \u003ca href=\"miniapps\"\u003eminiapps/\u003c/a\u003e\ndirectories, as well as the OpenGL visualization tool GLVis which is available\nat \u003ca href=\"https://glvis.org\" rel=\"nofollow\"\u003ehttps://glvis.org\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eMFEM is distributed under the terms of the BSD-3 license. All new contributions\nmust be made under this license. See \u003ca href=\"LICENSE\"\u003eLICENSE\u003c/a\u003e and \u003ca href=\"NOTICE\"\u003eNOTICE\u003c/a\u003e for\ndetails.\u003c/p\u003e\n\u003cp\u003eSPDX-License-Identifier: BSD-3-Clause \u003cbr\u003e\nLLNL Release Number: LLNL-CODE-806117 \u003cbr\u003e\nDOI: 10.11578/dc.20171025.1248\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1679324110.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "haampie/spack-prune-specs",
    "latest_release": null,
    "readme": "\u003cp\u003eUtilities:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003emake buildcache-minus-pipelines.filelist\u003c/code\u003e: specs in buildcache no longer referenced by develop pipelines in the last x days.\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003emake buildcache-intersect-pipelines.filelist\u003c/code\u003e: specs both in buildcache referenced by develop pipelines in the last x days.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSet \u003ccode\u003eSINCE=yyy-mm-dd\u003c/code\u003e to control the window (note that artifacts are removed after 30 days, so it can be max one month back).\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003emake\u003c/code\u003e installs \u003ccode\u003eaws\u003c/code\u003e, \u003ccode\u003ejq\u003c/code\u003e and other utilities for you.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1678906710.0
  },
  {
    "data_format": 2,
    "description": "My Spack environments",
    "filenames": [
      "local/spack.yaml"
    ],
    "full_name": "thomas-bouvier/spack-envs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-envs\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-envs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-envs\u003c/h1\u003e\n\u003cpre\u003e\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git ~/spack\ngit clone https://github.com/mochi-hpc/mochi-spack-packages.git ~/mochi-spack-packages\ngit clone https://github.com/thomas-bouvier/spack-envs.git ~/spack-envs\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-locally\" class=\"anchor\" aria-hidden=\"true\" href=\"#locally\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLocally\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack config --scope defaults edit config\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003einstall_tree: $spack/opt/spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ebuild_stage: $user_cache_path/stage\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003espack env activate ~/Dev/spack-envs/local\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003espack install\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-g5k\" class=\"anchor\" aria-hidden=\"true\" href=\"#g5k\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eG5k\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003espack config --scope defaults edit config\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003einstall_tree: /mnt/spack\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ebuild_stage: /tmp/spack-stage\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-anl\" class=\"anchor\" aria-hidden=\"true\" href=\"#anl\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eANL\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-cooley\" class=\"anchor\" aria-hidden=\"true\" href=\"#cooley\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCooley\u003c/h3\u003e\n\u003cp\u003eBefore using Spack to compile stuff on Cooley, we recommend to run \u003ccode\u003euse_build_cooley\u003c/code\u003e to get access to newer gcc, cmake, and mvapich versions.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-thetagpu\" class=\"anchor\" aria-hidden=\"true\" href=\"#thetagpu\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThetaGPU\u003c/h3\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1678891926.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "share/spack/gitlab/cloud_pipelines/stacks/build_systems/spack.yaml"
    ],
    "full_name": "jerrygreenberg2/sdsc",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-sdsc-hpc-software-deployment-guide\" class=\"anchor\" aria-hidden=\"true\" href=\"#sdsc-hpc-software-deployment-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSDSC HPC Software Deployment Guide\u003c/h1\u003e\n\u003cp\u003eThis document outlines the Spack-based software deployment process in\nuse by the San Diego Supercomputer Center\u0027s (SDSC) High-Performance\nComputing (HPC) User Services Group. All definitions, procedures,\nconventions, and policies defined within this guide are used by the\ngroup to build and maintain the custom Spack instances they deploy on\nSDSC\u0027s HPC systems for end users.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"true\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThis is a new and evolving software deployment process in development\nand use by the SDSC HPC User Services Group to centrally manage HPC\nsoftware on HPC systems with Spack. Please consider the status of the\nproject as a pre-alpha release at this time. Use at your own risk.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-definitions-and-terminology\" class=\"anchor\" aria-hidden=\"true\" href=\"#definitions-and-terminology\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDefinitions and Terminology\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003einstance\u003c/strong\u003e\u003c/em\u003e is a unique, stand-alone installation of a\nspecific version of \u003ccode\u003espack\u003c/code\u003e that includes custom Spack configuration\nfiles, Spack packages, and a collection of Spack-installed software\napplications, libraries, and utilities.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003epackage\u003c/strong\u003e\u003c/em\u003e is a set of instructions that defines how a\nspecific piece of software is compiled and/or installed by Spack. For\nexample, a Spack package specifies where to find and how to retrieve\nthe software\u0027s source code, its required (and/or optional) software\ndependencies, its compile-time options, any patches to apply, etc. A\nSpack package is primarily defined by it \u003cem\u003epackage.py\u003c/em\u003e file.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003espec\u003c/strong\u003e\u003c/em\u003e is a string descriptor that specifies a particular\nbuild configuration of a Spack package. The full syntax of a spec\nmay include the package name, its version, the compiler it should be\nbuilt with, the compiler version, the system architecture it should be\ncompiled for, any compile-time options for the package, and any\nrequirements that should be enforced on its dependencies at build time.\u003c/li\u003e\n\u003cli\u003eThe \u003cem\u003e\u003cstrong\u003ecore\u003c/strong\u003e\u003c/em\u003e packages of a Spack instance are those software\napplications, libraries, and/or utilities compiled with Spack using\nthe default system compiler. These packages form the foundation of the\nsoftware environment upon which additional Spack packages are built.\nIn general, the core packages of a Spack instance are a set of (core)\ncompilers and other general software utilities. e.g., version control\nsystems, data transfer tools, etc.\u003c/li\u003e\n\u003cli\u003eA Spack package \u003cem\u003e\u003cstrong\u003edependency chain\u003c/strong\u003e\u003c/em\u003e is an explicitly-defined\u003cbr\u003e\nordered set of Spack specs that share a common (core) compiler and/or\nMPI library, may depend on one another (or share other software\ndependencies), and should be installed one after another, one at a\ntime, as prescribed by their dependencies.\u003c/li\u003e\n\u003cli\u003eA Spack \u003cem\u003e\u003cstrong\u003edeployment branch\u003c/strong\u003e\u003c/em\u003e is a \u003cem\u003etrunk\u003c/em\u003e-like branch for a specific\nversion of \u003ccode\u003espack\u003c/code\u003e that tracks all of the Spack configuration files,\nSpack packages, and Spack specs used to deploy a Spack instance (or a\nset of instances).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-github-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#github-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGitHub Repository\u003c/h2\u003e\n\u003cp\u003eThe \u003ca href=\"https://github.com/sdsc/spack\"\u003esdsc/spack\u003c/a\u003e project is a custom fork\nof the Spack project\u0027s main GitHub repository, which is referred to in\nthis guide as the \u003ca href=\"https://github.com/spack/spack\"\u003espack/spack\u003c/a\u003e repo.\nThe primary aim of the sdsc/spack repo is to manage and track all\nchanges made to the custom Spack instances deployed by SDSC on its HPC\nsystems.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-deployment-branches\" class=\"anchor\" aria-hidden=\"true\" href=\"#deployment-branches\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeployment Branches\u003c/h3\u003e\n\u003cp\u003eThe sdsc/spack repo and its use in practice are fundamentally structured\naround the concept of \u003cem\u003edeployment branches\u003c/em\u003e. A deployment branch is a\n\u003cem\u003etrunk\u003c/em\u003e-like branch created from an unmodifed, official release version\nof \u003ccode\u003espack\u003c/code\u003e and is named accordingly, unless special circumstances\nrequire that an intermediate commit be used. For example, the\n\u003ccode\u003esdsc-0.17.3\u003c/code\u003e deployment branch was created by checking out the\n\u003ca href=\"https://github.com/spack/spack/releases/tag/v0.17.3\"\u003ev0.17.3\u003c/a\u003e release\u003c/p\u003e\n\u003cp\u003eOnce a version of Spack is selected and checked out, only a few minor\nchanges and/or additions are made to the Spack release in order to\ninitialize a deployment branch within the sdsc/spack repo. These\nmodifications are as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe official version of the Spack \u003ccode\u003eREADME.md\u003c/code\u003e file is removed and\nreplaced with the latest version of this document --- the \u003cem\u003eSDSC HPC\nSoftware Deployment Guide\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eThe latest version of the sdsc/spack \u003ccode\u003eCONTRIBUTING.md\u003c/code\u003e file is also\nincluded to provide information on how one may contribute to the\nsdsc/spack project and its deployment branches.\u003c/li\u003e\n\u003cli\u003eA Spack package repository --- \u003ccode\u003evar/spack/repos/sdsc\u003c/code\u003e --- created to\nstore all custom Spack packages created and/or maintained by SDSC,\nincluding all of SDSC\u0027s custom modifications to Spack\u0027s existing\n\u003ccode\u003ebuiltin\u003c/code\u003e packages.\u003c/li\u003e\n\u003cli\u003eA Spack instance repository --- \u003ccode\u003eetc/spack/sdsc\u003c/code\u003e --- is created\nto  ...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAll other types of branches (see\n\u003ca href=\"CONTRIBUTING.md\"\u003eCONTRIBUTING.md\u003c/a\u003e) should start from a deployment\nbranch.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-package-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#package-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePackage Repository\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-instance-repositories\" class=\"anchor\" aria-hidden=\"true\" href=\"#instance-repositories\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstance Repositories\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-access-control-and-permissions\" class=\"anchor\" aria-hidden=\"true\" href=\"#access-control-and-permissions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAccess Control and Permissions\u003c/h3\u003e\n\u003cp\u003eetc/spack/repos.yaml\nvar/spack/repos/sdsc/repo.yaml\nvar/spack/repos/sdsc/packages\u003c/p\u003e\n\u003cp\u003eetc/spack/sdsc/expanse/0.17.3/cpu/specs\netc/spack/sdsc/expanse/0.17.3/cpu/yamls\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-deploying-hpc-software-via-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#deploying-hpc-software-via-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeploying HPC Software via Spack\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-deploying-a-spack-instance\" class=\"anchor\" aria-hidden=\"true\" href=\"#deploying-a-spack-instance\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeploying a Spack Instance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003estart from existing deployment branch\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003ca id=\"user-content-managing-changes-to-a-spack-instance\" class=\"anchor\" aria-hidden=\"true\" href=\"#managing-changes-to-a-spack-instance\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManaging Changes to a Spack Instance\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003edeploy change to configuration file\u003c/li\u003e\n\u003cli\u003eadd new package to sdsc package repository\u003c/li\u003e\n\u003cli\u003espack install a new spec\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003ca id=\"user-content-setting-up-a-shared-instance-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-up-a-shared-instance-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting up a Shared Instance Configuration\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-using-a-spack-mirror-and-build-caches-for-instance-backups\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-a-spack-mirror-and-build-caches-for-instance-backups\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing a Spack Mirror and Build Caches for Instance Backup(s)\u003c/h3\u003e\n\u003ch2\u003e\u003ca id=\"user-content-additional-notes\" class=\"anchor\" aria-hidden=\"true\" href=\"#additional-notes\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAdditional Notes\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-protecting-the-sdscspack-develop-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#protecting-the-sdscspack-develop-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eProtecting the sdsc/spack \u003ccode\u003edevelop\u003c/code\u003e branch\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-fetching-changes-and-re-syncing-the-develop-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#fetching-changes-and-re-syncing-the-develop-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFetching changes and re-syncing the \u003ccode\u003edevelop\u003c/code\u003e branch\u003c/h3\u003e\n\u003ch3\u003e\u003ca id=\"user-content-creating-a-new-deployment-branch\" class=\"anchor\" aria-hidden=\"true\" href=\"#creating-a-new-deployment-branch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCreating a new deployment branch\u003c/h3\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1678670738.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "dependency/spack.yaml"
    ],
    "full_name": "hariharan-devarajan/unifyfs-bug",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-unifyfs-bug\" class=\"anchor\" aria-hidden=\"true\" href=\"#unifyfs-bug\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eunifyfs-bug\u003c/h1\u003e\n\u003ch2\u003e\u003ca id=\"user-content-the-bug-comes-in-multi-node-case-only\" class=\"anchor\" aria-hidden=\"true\" href=\"#the-bug-comes-in-multi-node-case-only\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe bug comes in multi-node case only.\u003c/h2\u003e\n\u003ch2\u003e\u003ca id=\"user-content-instructions\" class=\"anchor\" aria-hidden=\"true\" href=\"#instructions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstructions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eupdate path of unifyfs on dependency/spack.yaml packages\u003c/li\u003e\n\u003cli\u003eactivate dependency spack folder\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack activate -p dependency\nspack install\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003eupdate path of unifyfs install on line 3 of CMakeLists\u003c/li\u003e\n\u003cli\u003ebuild code.\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ecmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_C_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/gcc -DCMAKE_CXX_COMPILER=/usr/tce/packages/gcc/gcc-8.3.1/bin/g++ -G \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eCodeBlocks - Unix Makefiles\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e /g/g92/haridev/temp/unifyfs-bug\ncmake --build /g/g92/haridev/temp/unifyfs-bug/cmake-build-debug --target all -- -j 128\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003eRun Unifyfs server\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e unifyfs-bug\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e UNIFYFS_LOG_VERBOSITY=3\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e SET ME\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e UNIFYFS_ROOT_DIR=/usr/workspace/iopp/software/tailorfs/dependency/.spack-env/view  \n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e UNIFYFS_LOG_DIR=\u003cspan class=\"pl-smi\"\u003e${HOME}\u003c/span\u003e/unifyfs/logs\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e pfs=/p/gpfs1/iopp\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e LD_LIBRARY_PATH=\u003cspan class=\"pl-smi\"\u003e${PWD}\u003c/span\u003e/dependency/.spack-env/view/lib:\u003cspan class=\"pl-smi\"\u003e${UNIFYFS_ROOT_DIR}\u003c/span\u003e/lib\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e ACTUAL RUN\u003c/span\u003e\nUNIFYFS_LOG_DIR=\u003cspan class=\"pl-smi\"\u003e$UNIFYFS_LOG_DIR\u003c/span\u003e UNIFYFS_SERVER_CORES=8 \u003cspan class=\"pl-smi\"\u003e${UNIFYFS_ROOT_DIR}\u003c/span\u003e/bin/unifyfs start --share-dir=\u003cspan class=\"pl-smi\"\u003e${pfs}\u003c/span\u003e/unifyfs/share-dir -d\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003cli\u003eRun code\n\u003ch2\u003e\u003ca id=\"user-content-bug-1\" class=\"anchor\" aria-hidden=\"true\" href=\"#bug-1\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBug 1\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ejsrun -r 1 -a 1 -c 1  -d packed \u003cspan class=\"pl-smi\"\u003e$PWD\u003c/span\u003e/cmake-build-debug/unifyfs-bug 1\u003c/pre\u003e\u003c/div\u003e\nOutput\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eRunning transfer\n2023-03-27T09:36:22 tid=30501 @ \u003cspan class=\"pl-en\"\u003eforward_to_server\u003c/span\u003e() [margo_client.c:233] \u003cspan class=\"pl-en\"\u003emargo_forward_timed\u003c/span\u003e() failed - HG_TIMEOUT\n2023-03-27T09:36:22 tid=30501 @ \u003cspan class=\"pl-en\"\u003einvoke_client_transfer_rpc\u003c/span\u003e() [margo_client.c:614] forward of transfer rpc to server failed\nunifyfs-bug: /g/g92/haridev/project/unifyfs-bug/bug.cpp:137: int main(int, char\u003cspan class=\"pl-k\"\u003e**\u003c/span\u003e): Assertion \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e`\u003c/span\u003erc == UNIFYFS_SUCCESS\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e failed.\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-s\"\u003e[lassen1:30501] *** Process received signal ***\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-s\"\u003e[lassen1:30501] Signal: Aborted (6)\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-s\"\u003e[lassen1:30501] Signal code:  (-6)\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode\u003e  ## Bug 2\n\n  ```bash\n  jsrun -r 1 -a 1 -c 1  -d packed $PWD/cmake-build-debug/unifyfs-bug 2\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1675706965.0
  },
  {
    "data_format": 2,
    "description": "Build optimized docker images for Spack",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "haampie/spack-docker-bootstrap",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-in-docker-with-buildcache\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-in-docker-with-buildcache\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack in Docker with buildcache\u003c/h1\u003e\n\u003cp\u003eThis bootstraps Spack\u0027s own, optimized dependencies, as well as the\ncompiler toolchain of the distro, so that in the end we just depend\non system libc.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"spack.yaml\"\u003espack.yaml\u003c/a\u003e for things that are built by Spack, and\n\u003ca href=\"Makefile\"\u003eMakefile\u003c/a\u003e and \u003ca href=\"Dockerfile\"\u003eDockerfile\u003c/a\u003e for how it\u0027s built.\u003c/p\u003e\n\u003cp\u003eDocker buildkit is required.\u003c/p\u003e\n\u003cp\u003eBuild with:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eDOCKER_BUILDKIT=1 docker build -f linux-ubuntu22.04-x86_64_v2/Dockerfile -t spack-optimized --progress=plain .\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSince this uses Python 3.11 and clingo with some optimizations, it should\ngenerally be faster:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eBenchmark 1: docker run --rm spack-optimized spack spec hdf5\n  Time (mean \u00b1 \u03c3):      8.494 s \u00b1  0.401 s    [User: 0.015 s, System: 0.008 s]\n  Range (min \u2026 max):    8.034 s \u2026  8.763 s    3 runs\n\nBenchmark 2: docker run --rm spack/ubuntu-focal spec hdf5\n  Time (mean \u00b1 \u03c3):     10.795 s \u00b1  0.382 s    [User: 0.013 s, System: 0.009 s]\n  Range (min \u2026 max):   10.355 s \u2026 11.030 s    3 runs\n\nSummary\n  \u0027docker run --rm spack-optimized spack spec hdf5\u0027 ran\n    1.27 \u00b1 0.07 times faster than \u0027docker run --rm spack/ubuntu-focal spec hdf5\u0027\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1674134786.0
  },
  {
    "data_format": 2,
    "description": "AsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes",
    "filenames": [
      "compile-notes/frontera-bitbucket/CPU/spack.yaml",
      "compile-notes/frontera-bitbucket/GPU/spack.yaml",
      "compile-notes/frontera-github/GPU/spack.yaml",
      "compile-notes/frontera-github/CPU/spack.yaml"
    ],
    "full_name": "jaykalinani/AsterX-Docs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-asterx\" class=\"anchor\" aria-hidden=\"true\" href=\"#asterx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAsterX\u003c/h1\u003e\n\u003cp\u003eAsterX: a new open-source GPU-accelerated GRMHD code for dynamical spacetimes\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1677876939.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "docker-images/spack.yaml",
      "spack.yaml"
    ],
    "full_name": "eugeneswalker/qmcpack-ci-container",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1678143972.0
  },
  {
    "data_format": 2,
    "description": "Template for a thallium-based Mochi microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/thallium-microservice-template",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-thallium-microservice-template\" class=\"anchor\" aria-hidden=\"true\" href=\"#thallium-microservice-template\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThallium Microservice Template\u003c/h1\u003e\n\u003cp\u003eThis project is a template to start developing a Mochi microservice based on Thallium.\nThe complete documentation to get started using this template is available\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/templates/02_thallium.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo use this template:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eClick on the green \"Use this template\" button at the top.\u003c/li\u003e\n\u003cli\u003eGive a name to your project.\u003c/li\u003e\n\u003cli\u003eOnce your project repository is created, go to Settings \u0026gt; Actions \u0026gt; General and give \"Read and write permissions\" under \u003cem\u003eWorkflow permissions\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eFinally, edit the initial-setup.json file and push the changes to your repo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEditing the initial-setup.json file with trigger a github action that will\ncleanup your repository and rename files, namespaces, functions, etc. according\nto the name of your service and the resources it manages.\u003c/p\u003e\n\u003cp\u003eEnjoy working with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1649080284.0
  },
  {
    "data_format": 2,
    "description": "Template for a margo-based Mochi microservice.",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/margo-microservice-template",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-margo-microservice-template\" class=\"anchor\" aria-hidden=\"true\" href=\"#margo-microservice-template\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMargo Microservice Template\u003c/h1\u003e\n\u003cp\u003eThis project is a template to start developing a Mochi microservice based on Margo.\nThe complete documentation to get started using this template is available\n\u003ca href=\"https://mochi.readthedocs.io/en/latest/templates/01_margo.html\" rel=\"nofollow\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTo use this template:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eClick on the green \"Use this template\" button at the top.\u003c/li\u003e\n\u003cli\u003eGive a name to your project.\u003c/li\u003e\n\u003cli\u003eOnce your project repository is created, go to Settings \u0026gt; Actions \u0026gt; General and give \"Read and write permissions\" under \u003cem\u003eWorkflow permissions\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eFinally, edit the initial-setup.json file and push the changes to your repo.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEditing the initial-setup.json file with trigger a github action that will\ncleanup your repository and rename files, namespaces, functions, etc. according\nto the name of your service and the resources it manages.\u003c/p\u003e\n\u003cp\u003eEnjoy working with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1649078785.0
  },
  {
    "data_format": 2,
    "description": "This repository provides a set of configuration files and example scripts for running DeepHyper experiments on various platforms.",
    "filenames": [
      "ANL/Swing/spack.yaml",
      "ANL/Polaris/spack.yaml"
    ],
    "full_name": "deephyper/deephyper-platform-configurations",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-deephyper-platform-configurations\" class=\"anchor\" aria-hidden=\"true\" href=\"#deephyper-platform-configurations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeepHyper Platform Configurations\u003c/h1\u003e\n\u003cp\u003eThis repository provides a set of configuration files and example scripts for running DeepHyper experiments on various platforms.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003egeneric\u003c/code\u003e subdirectory contains a minimal DeepHyper environment example that can be used as a starting point for systems for which there is no existing recipe.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-using-spackyaml-files\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-spackyaml-files\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing spack.yaml files\u003c/h2\u003e\n\u003cp\u003eEach platform subdirectory in this repository provides a \u003ccode\u003espack.yaml\u003c/code\u003e file.\nA \u003ccode\u003espack.yaml\u003c/code\u003e file fully describes a Spack environment, including\nsystem-provided packages and compilers. It does so independently of any\n\u003ccode\u003ecompilers.yaml\u003c/code\u003e or \u003ccode\u003epackages.yaml\u003c/code\u003e files installed in \u003ccode\u003e~/.spack\u003c/code\u003e, thereby\npreventing interference with user-specific spack configurations as much as\npossible.\u003c/p\u003e\n\u003cp\u003eYou may use \u003ccode\u003espack.yaml\u003c/code\u003e files to create a\n\u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003eSpack environment\u003c/a\u003e\nin which DeepHyper packages will be installed.\u003c/p\u003e\n\u003cp\u003eIf you don\u0027t have Spack installed on your platform, clone it and set it up\nas follows.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git\n\u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e spack/share/spack/setup-env.sh\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eRemember that the second line needs to be executed every time you open a new\nterminal; it may be helpful to create an alias in your bashrc file as a\nshortcut.\u003c/p\u003e\n\u003cp\u003eYou will then need to clone \u003ccode\u003edeephyper-spack-packages\u003c/code\u003e, which contains the DeepHyper packages.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/deephyper/deephyper-spack-packages.git\nspack repo add deephyper-spack-packages\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNow clone the present repository and \u003ccode\u003ecd\u003c/code\u003e into the subdirectory relevant\nto your platform. For example:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/deephyper/deephyper-platform-configurations.git\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e deephyper-platform-configurations/ANL/Polaris\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eEdit the path to \u003ccode\u003edeephyper-spack-packages\u003c/code\u003e in the \u003ccode\u003erepos\u003c/code\u003e field of the \u003ccode\u003espack.yaml\u003c/code\u003e file to\nmatch your installation.\u003c/p\u003e\n\u003cp\u003eThen, execute the following command\n(changing \u003cem\u003emyenv\u003c/em\u003e into an appropriate name for your environment).\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env create myenv spack.yaml\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eChange to a directory outside of the \u003ccode\u003edeephyper-platform-configurations\u003c/code\u003e folders\nand activate the environment as follows.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate myenv\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOnce you have added the specs you need in your environment, install\neverything by executing the following command.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eYou may add more specs later on. For more information on how to manage\nSpack environments, please refer to the Spack documentation.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-acknowledgment\" class=\"anchor\" aria-hidden=\"true\" href=\"#acknowledgment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAcknowledgment\u003c/h2\u003e\n\u003cp\u003eThis repository was created by following the example of the \u003ca href=\"https://github.com/mochi-hpc-experiments/platform-configurations\"\u003eMochi Project\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1675421226.0
  },
  {
    "data_format": 2,
    "description": "SKA Spack environments related files",
    "filenames": [
      "env-bipp-izar/spack.yaml",
      "bipp-izar-gcc/spack.yaml",
      "bipp-jed-gcc/spack.yaml"
    ],
    "full_name": "epfl-radio-astro/ska-spack-env",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-ska-spack-env\" class=\"anchor\" aria-hidden=\"true\" href=\"#ska-spack-env\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eska-spack-env\u003c/h1\u003e\n\u003cp\u003eSKA Spack environments related files\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1674857920.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "falcon/environments/applications/ncview/_spack.yaml",
      "falcon/environments/base/_spack.yaml",
      "falcon/environments/libraries/hdf5/_spack.yaml",
      "falcon/environments/applications/wps/_spack.yaml",
      "borah/environments/b4s/_spack.yaml",
      "falcon/environments/compilers/_spack.yaml",
      "falcon/environments/libraries/netcdf/_spack.yaml",
      "falcon/environments/applications/vasp/_spack.yaml",
      "falcon/environments/applications/quantum-espresso/_spack.yaml",
      "falcon/environments/applications/vacuumms/_spack.yaml",
      "falcon/environments/applications/ncl/_spack.yaml"
    ],
    "full_name": "bsurc/BSU-software-configs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-configurations-used-to-stand-up-stacks-at-boise-state-university\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-configurations-used-to-stand-up-stacks-at-boise-state-university\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack configurations used to stand up stacks at Boise State University\u003c/h1\u003e\n\u003cp\u003e(C) 2022 Frank Willmore, et. al. Boise State Univesity Reseach Computing\n\u003ca href=\"mailto:frankwillmore@boisestate.edu\"\u003efrankwillmore@boisestate.edu\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eNote that the environment (spack.yaml) files as checked in are named _spack.yaml, since spack rewrites and reorders spack.yaml as it digests the environment. _spack.yaml can be regarded as the master, and copied to spack.yaml when processing an environment. There is a .gitignore under BOISESTATE set to ignore spack.yaml\u0027s under this tree.\u003c/p\u003e\n\u003cp\u003eBase configurations provided gcc and oneapi compilers, cuda built with these compilers, mpich, openmpi, and intel-oneapi-mpi MPI stacks built with these compilers, and modules that will load the correct cuda build and compiler when loading the MPI.\u003c/p\u003e\n\u003cp\u003eCopies of modules are checked in as well, as these needed to be modified considerably from the original generated modules.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1676657373.0
  },
  {
    "data_format": 2,
    "description": "Support for building CHIP-SPV via Spack",
    "filenames": [
      "Environments/LevelZero/spack.yaml",
      "Environments/Rothdt-POCL/spack.yaml"
    ],
    "full_name": "CHIP-SPV/CHIP-SPV-Spack",
    "latest_release": null,
    "readme": "\n\u003ch1\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/CHIP-SPV/chip-spv\"\u003eCHIP-SPV\u003c/a\u003e is software that\nallows software written to use the \u003ca href=\"https://https://github.com/ROCm-Developer-Tools/HIP\" rel=\"nofollow\"\u003eHeterogeneous-compute Interface for\nPortability (HIP)\u003c/a\u003e\ninterface and kernel language to target GPUs via the\n\u003ca href=\"https://registry.khronos.org/spir\" rel=\"nofollow\"\u003eSPIR-V\u003c/a\u003e intermediate language.\nCHIP-SPV can use either the Intel Level Zero runtime or an OpenCL\nruntime as a backend.\u003c/p\u003e\n\u003cp\u003eThis repository contains support for building CHIP-SPV and its\ndependencies via the \u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package\nmanager.\u003c/p\u003e\n\u003cp\u003eNote: most development to date has been done with the Level Zero\nenvironment, and it is expected that substantial work is needed for\nthe environment targeting the OpenCL backend to work.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-hidden=\"true\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eAn x86_64 system running a common Linux distribution.  OpenSLES 15 is\nthe best tested to date.\u003c/li\u003e\n\u003cli\u003eA working Spack installation.\u003c/li\u003e\n\u003cli\u003eClang 15.x installed and registered as a Spack compiler.  Installing\nthis compiler via Spack (i.e., by installing a package like \u003ccode\u003ellvm@15.0.7\u003c/code\u003e,\nand then using \u003ccode\u003espack compiler add\u003c/code\u003e) is the approach that is currently\nbest tested.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h1\u003e\n\u003col start=\"0\"\u003e\n\u003cli\u003eClone this repository to the target system.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ git clone https://github.com/CHIP-SPV/CHIP-SPV-Spack\u003c/pre\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eVerify that the compiler version is correctly represented in the\ndesired environment\u0027s \u003ccode\u003espack.yaml\u003c/code\u003e file.  For instance, if the Clang\ncompiler to be used is version 15.0.7, ensure that the version\nnumbers for the \u003ccode\u003ecompilers\u003c/code\u003e definition, the \u003ccode\u003ellvm\u003c/code\u003e spec, and\nthe \u003ccode\u003espirv-llvm-translator\u003c/code\u003e spec are consistent.  In this instance,\nthese should be \u003ccode\u003eclang@15.0.7\u003c/code\u003e, \u003ccode\u003ellvm@15.0.7\u003c/code\u003e and\n\u003ccode\u003espirv-llvm-translator@15\u003c/code\u003e, respectively.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eActivate and concretize the environment.  E.g.,\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e CHIP-SPV-Spack/Environments/LevelZero\n$ spack activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n$ spack concretize -f\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eBuild the environment.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e$ spack install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf all goes well with the build, a \u003ccode\u003espack find\u003c/code\u003e with the environment\nactive should show \u003ccode\u003echip-spv\u003c/code\u003e available.\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eUse the installed software.  The easiest way to use the installed\nsoftware when compiling and running HIP code is to activate the\nenvironment and then build the software.  Because other packages like\n\u003ccode\u003ecmake\u003c/code\u003e and \u003ccode\u003eboost\u003c/code\u003e are not roots in the Spack environments, they\nare not automatically added to one\u0027s environment when one activates\nthe Spack environment.  To use these, one must load them before\nactivating the Spack environment, or ensure that they are available\nusing the \u003ccode\u003emodule\u003c/code\u003e command.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1\u003e\u003ca id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"true\" href=\"#todo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTODO\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eEnsure the OpenCL-based environment can use any OpenCL implementation.\u003c/li\u003e\n\u003cli\u003eClean up and verify the OpenCL-based environment using POCL.\u003c/li\u003e\n\u003cli\u003eIncorporate HIP libraries like HipBLAS into the environments.\u003c/li\u003e\n\u003cli\u003eSupport using the software installed by the environment via \u003ccode\u003emodule\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1676574454.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "L-LYR/playground",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1676371970.0
  },
  {
    "data_format": 2,
    "description": "Fortran Interface to ECMWF\u0027s FDB",
    "filenames": [
      "docker/spack.yaml"
    ],
    "full_name": "MeteoSwiss/fdb-fortran",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [
      "numericalweatherpredictions"
    ],
    "updated_at": 1678447894.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "dyokelson/soma_cpp",
    "latest_release": null,
    "readme": "\u003cp\u003eYour project \"soma\" has been setup!\nEnjoy programming with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1675794086.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "environments/spack/spack.yaml"
    ],
    "full_name": "hancheng2000/calcHW",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1676957739.0
  },
  {
    "data_format": 2,
    "description": "Spack configuration files for LUMI",
    "filenames": [
      "22.08/0.19.0/spack.yaml"
    ],
    "full_name": "Lumi-supercomputer/lumi-spack-settings",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-configuration-files-for-lumi\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-configuration-files-for-lumi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack configuration files for LUMI\u003c/h1\u003e\n\u003cp\u003eRepository containing configuration files for the Spack instances installed in \u003ccode\u003e/appl/lumi/spack\u003c/code\u003e on LUMI for public use. The files in this repository can be found in \u003ccode\u003e/appl/lumi/spack/etc/\u003c/code\u003e on LUMI. The folder hierarchy is determined by the Cray Programming Environment (CPE) version and Spack release version. For example, the directory\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e22.08/0.18.1/\n22.08/0.18.1-user/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003econtains the configuration files for Spack version 0.18.1 configured to use CPE 22.08. The first instance \u003ccode\u003e0.18.1\u003c/code\u003e is the upstream instance, which is maintained by the LUMI Support Team. The second instance \u003ccode\u003e0.18.1-user\u003c/code\u003e is a separate instance configured to install packages in a user-defined directory in e.g. \u003ccode\u003e/project/\u003c/code\u003e. It is chained to the upstream instance, so that already installed packages can be reused.\u003c/p\u003e\n\u003cp\u003eIf you are user of LUMI, and want to set up your own instance, you can copy the \u003ccode\u003ecompilers.yaml\u003c/code\u003eand  \u003ccode\u003epackages.yaml\u003c/code\u003e files to your instance. The \u003ccode\u003econfig.yaml\u003c/code\u003e needs to be modified if you want to use that one.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 12,
    "topics": [],
    "updated_at": 1675956191.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "dyokelson/soma_c",
    "latest_release": null,
    "readme": "\u003cp\u003eYour project \"soma\" has been setup!\nEnjoy programming with Mochi!\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1675627136.0
  },
  {
    "data_format": 2,
    "description": "Mochi\u0027s REsource Migration Interface",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-remi",
    "latest_release": "v0.3.2",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-resource-migration-interface\" class=\"anchor\" aria-hidden=\"true\" href=\"#resource-migration-interface\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eREsource Migration Interface\u003c/h1\u003e\n\u003cp\u003eREMI is a Mochi microservice designed to handle the migration of sets of files\nfrom a node to another. It uses RDMA and memory mapping to efficiently transfer\npotentially large groups of files at once.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-installing\" class=\"anchor\" aria-hidden=\"true\" href=\"#installing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling\u003c/h3\u003e\n\u003cp\u003eJust like all Mochi services, REMI can be installed using Spack. Once you have\nclone the \u003ca href=\"https://xgitlab.cels.anl.gov/sds/sds-repo\" rel=\"nofollow\"\u003esds-repo\u003c/a\u003e package repository\nand added it to your spack installation, you can install REMI using the following\ncommand:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install mochi-remi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eREMI depends on \u003ca href=\"https://xgitlab.cels.anl.gov/sds/thallium/\" rel=\"nofollow\"\u003eThallium\u003c/a\u003e, which\nSpack will install (if needed) along with Thallium\u0027s own dependencies. It also\ndepends on Bedrock, unless the \u003ccode\u003ebedrock\u003c/code\u003e variant is disable when installing\nwith Spack (i.e. passing \u003ccode\u003e~bedrock\u003c/code\u003e to the above command).\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h3\u003e\n\u003cp\u003eREMI works with \u003cem\u003efilesets\u003c/em\u003e. A fileset consists of a root directory and\na set of file paths relative to this root directory. A fileset is also characterized\nby the name of its \u003cem\u003emigration class\u003c/em\u003e.\u003c/p\u003e\n\u003cp\u003eREMI clients create filesets to group files corresponding to a particular resource\n(e.g. a database\u0027s files). They can then request the migration of fileset to\na target provider.\u003c/p\u003e\n\u003cp\u003eUppon receiving a request for migration, a provider will recreate the tree of\ndirectories required to receive the files of the fileset, create the files,\nmmap them into memory, and issue an RDMA pull operation from the client\u0027s files\n(themselves mmap-ed into the client\u0027s memory).\u003c/p\u003e\n\u003cp\u003eFollowing successful migration, the provider will call a user-supplied callback\ncorresponding to the particular fileset\u0027s migration class.\u003c/p\u003e\n\u003cp\u003eFor an example of code, please see the \u003ca href=\"examples\"\u003eexamples\u003c/a\u003e\nfolder in the source tree.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1633975455.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "intel_master_x86_64/spack.yaml",
      "gnu_release_x86_64/spack.yaml",
      "gnu_master_x86_64/spack.yaml",
      "intel_release_x86_64/spack.yaml"
    ],
    "full_name": "hppritcha/spack_ompix",
    "latest_release": null,
    "readme": "\u003cp\u003eProject for using Gitlab CI to test spack builds of Open MPI master and release tarballs.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1640037910.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "robertu94/roibin-sz3-experiments",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-roibin-sz-experiments\" class=\"anchor\" aria-hidden=\"true\" href=\"#roibin-sz-experiments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eROIBIN-SZ Experiments\u003c/h1\u003e\n\u003ch2\u003e\u003ca id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"true\" href=\"#system-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSystem Information\u003c/h2\u003e\n\u003cp\u003eThe hardware and software versions used for the performance evaluations can be found in Table I in the paper. These nodes come from Clemson University\u0027s Palmetto Cluster.\u003c/p\u003e\n\u003cp\u003eThe quality assessment was done on the PSANA system at SLAC national accelerator laboratory using PSOCAKE, PHENIX, and CCP4.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-where-is-the-implementation-of-roibin-sz3\" class=\"anchor\" aria-hidden=\"true\" href=\"#where-is-the-implementation-of-roibin-sz3\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhere is the implementation of ROIBIN-SZ3?\u003c/h2\u003e\n\u003cp\u003eThis repository contains only our experimental codes and configuration files.\u003c/p\u003e\n\u003cp\u003eWe contributed the composed building blocks for ROIBIN-SZ3 into the \u003ca href=\"https://github.com/robertu94/libpressio\"\u003elibpressio\u003c/a\u003e repository specifically \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/binning.cc\"\u003e\u003ccode\u003ebinning.cc\u003c/code\u003e\u003c/a\u003e,  \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin.cc\"\u003e\u003ccode\u003eroibin.cc\u003c/code\u003e\u003c/a\u003e and \u003ca href=\"https://github.com/robertu94/libpressio/blob/d1fee62c84f82b71753d64a509d45244b9b9a88e/src/plugins/compressors/roibin_impl.h\"\u003e\u003ccode\u003eroibin_impl.h\u003c/code\u003e\u003c/a\u003e in the \u003ccode\u003esrc/plugins/compressors\u003c/code\u003e subdirectory.  The automated tuning implementation was used directly from \u003ca href=\"https://github.com/robertu94/libpressio_opt\"\u003eOptZConfig/LibPressioOpt\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSee \u003ca href=\"#obtaining-data\"\u003eObtaining Data\u003c/a\u003e to request the dataset used.\u003c/p\u003e\n\u003cp\u003eThe quality assessment software was not designed in this paper.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting started\u003c/h2\u003e\n\u003cp\u003eFor ease of evaluation, we provide a docker container to evaluate our performance results.\u003c/p\u003e\n\u003cp\u003eThere are several key steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eObtaining Data\u003c/li\u003e\n\u003cli\u003eInstalling the software (either in a container or on the host system)\u003c/li\u003e\n\u003cli\u003eRunning the experiments\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003e\u003ca id=\"user-content-obtaining-data\" class=\"anchor\" aria-hidden=\"true\" href=\"#obtaining-data\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eObtaining Data\u003c/h3\u003e\n\u003cp\u003eThe data for these experiments are extremely large (6+TB for one complete dataset used in the quality assessment). The full Se-SAD dataset is publicly available here \u003ca href=\"https://cxidb.org/id-54.html\" rel=\"nofollow\"\u003ehttps://cxidb.org/id-54.html\u003c/a\u003e, but require some domain knowledge to process the entire dataset. We include a subset of the data for testing roibin-sz3. For more information about CXI files used for this paper, contact the authors.\u003c/p\u003e\n\u003cp\u003eTo run in the container, you may need to set the files to world readable \u003ccode\u003echmod a+r\u003c/code\u003e to be read inside the container depending on your container manager.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-quality-assessment\" class=\"anchor\" aria-hidden=\"true\" href=\"#quality-assessment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQuality Assessment\u003c/h3\u003e\n\u003cp\u003eThe quality analysis results (Figures 1,4-8 and Table 3)  were produced using \u003ca href=\"https://confluence.slac.stanford.edu/display/PSDM/Psocake+SFX+tutorial\" rel=\"nofollow\"\u003ePSOCAKE\u003c/a\u003e, \u003ca href=\"https://phenix-online.org\" rel=\"nofollow\"\u003ePHENIX\u003c/a\u003e, and \u003ca href=\"https://www.ccp4.ac.uk\" rel=\"nofollow\"\u003eCCP4\u003c/a\u003e.\nCorrect use of this tool requires experience and expertise in serial\ncrystallography and is outside the scope of this document.\u003c/p\u003e\n\u003cp\u003eWhere decompressed outputs were needed for inputs for these tools, they were outputted from the Performance Assessment codes.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-container-install-for-ease-of-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#container-install-for-ease-of-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainer Install (for ease of setup)\u003c/h3\u003e\n\u003cp\u003eWe provide a container for \u003ccode\u003ex86_64\u003c/code\u003e image for ease of installation.\u003c/p\u003e\n\u003cp\u003eThis container differs from our experimental setup in 2 ways:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThe production build used \u003ccode\u003e-march=native -mtune=native\u003c/code\u003e for architecture optimized builds where as the container does not use these flags to maximize compatablity across \u003ccode\u003ex86_64\u003c/code\u003e hardware.\u003c/li\u003e\n\u003cli\u003eWe use MPICH in the container rather than the OpenMPI because we found MPICH more reliably ran in the container during testing while OpenMPI was the system MPI.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eNOTE this file is \u0026gt;= 6 GB (without datasets; see above), download with caution.\u003c/p\u003e\n\u003ch4\u003e\u003ca id=\"user-content-singularity\" class=\"anchor\" aria-hidden=\"true\" href=\"#singularity\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSingularity\u003c/h4\u003e\n\u003cp\u003eYou can install and start the container on many super computers using singularity.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e this first commmand may issue a ton of warnings regarding xattrs depending on your filesystem on your container host; these were benign in our testing.\u003c/span\u003e\nsingularity pull roibin.sif docker://ghcr.io/robertu94/roibin:latest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -c enables additional confinement than singularity uses by default to prevent polution from /home\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -B bind mounts in the data directory containing your CXI files.\u003c/span\u003e\nsingularity run -c -B path/to/datadir:/data:ro roibin.sif bash\u003c/pre\u003e\u003c/div\u003e\n\u003ch4\u003e\u003ca id=\"user-content-docker\" class=\"anchor\" aria-hidden=\"true\" href=\"#docker\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocker\u003c/h4\u003e\n\u003cp\u003eYou can run an example code on a small dataset by running with the following container and requesting a dataset.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003edocker pull ghcr.io/robertu94/roibin:latest\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003emost systems\u003c/span\u003e\ndocker run -it --rm -v path/to/datadir:/data:ro ghcr.io/robertu94/roibin:latest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e if running on a SeLinux enforcing system\u003c/span\u003e\ndocker run -it --rm --security-opt label=disable -v path/to/datadir:/data:ro roibin\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-building-the-container\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-the-container\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the container\u003c/h3\u003e\n\u003cp\u003eYou can build the container yourself as follows:\nNOTE this process takes 3+ hours on a modern laptop, and most clusters do not\nprovide sufficient permissions to run container builds on the cluster.\u003c/p\u003e\n\u003cp\u003eAdditional some of the dependencies (i.e. MGARD) require 4GB/RAM per core to build.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install/module load git-lfs, needed to download example_data for building the container\u003c/span\u003e\nsudo dnf install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eFedora/CentOS Stream 8\u003c/span\u003e\nsudo apt-get install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\nspack install git-lfs\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e spack load git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e using spack\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e clone this repository\u003c/span\u003e\ngit clone --recursive https://github.com/robertu94/roibin-sz3-experiments\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e roibin-sz3-experiments\ndocker build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e -t roibin\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you forgot to install \u003ccode\u003egit-lfs\u003c/code\u003e before and have an empty \u003ccode\u003eexample_data\u003c/code\u003e folder, you should install \u003ccode\u003egit-lfs\u003c/code\u003e\nand then run the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit lfs fetch\ngit lfs checkout\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-manual-install-for-scale\" class=\"anchor\" aria-hidden=\"true\" href=\"#manual-install-for-scale\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual Install (for scale)\u003c/h3\u003e\n\u003cp\u003eThe easiest way to install this manually is with \u003ccode\u003espack\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --recursive https://github.com/robertu94/roibin-sz3-experiments\ngit clone https://github.com/spack/spack\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh\nspack compiler find\n\nspack env activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003esee note about MPI below\u003c/span\u003e\nspack install\n\nmkdir build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e build\ncmake ..\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThis software is not compatible with Windows, and hasn\u0027t been tested on MacOS.\u003c/p\u003e\n\u003cp\u003ePlease note all functionality will not work on Debian/Ubuntu (due to known bug in LibPressio we hope to resolve soon).\nPlease use on a RedHat based distribution for testing (i.e. Fedora, CentOS, RHEL, ...).\nAdditionally some of this code requires a newer compiler and may not compile on older versions of CentOS.\u003c/p\u003e\n\u003cp\u003eYou may wish to configure the build to use your local version of MPI.\nPlease see \u003ca href=\"https://spack.readthedocs.io/en/latest/build_settings.html#external-packages\" rel=\"nofollow\"\u003ethe spack guide\u003c/a\u003e for how to do this.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-running-the-experiments\" class=\"anchor\" aria-hidden=\"true\" href=\"#running-the-experiments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning the Experiments\u003c/h2\u003e\n\u003cp\u003eOnce the container is installed, you can run our testing commmands.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003empiexec -np \u003cspan class=\"pl-smi\"\u003e$procs\u003c/span\u003e /app/build/roibin_test -c 1 -f /app/example_data/cxic0415_0020.cxi -p /app/share/roibin_sz.json\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ewhere \u003ccode\u003e-f\u003c/code\u003e is the input data file, and \u003ccode\u003e-p\u003c/code\u003e is the configuration to use \u003ccode\u003e-c\u003c/code\u003e is the chunk size.\u003c/p\u003e\n\u003cp\u003ePlease see \u003ccode\u003erun_all.sh\u003c/code\u003e for our production configurations.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-example-output\" class=\"anchor\" aria-hidden=\"true\" href=\"#example-output\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExample Output\u003c/h3\u003e\n\u003cp\u003eNOTE results below from a laptop, not the server grade hardware from the paper\nand in the container with the differences noted above so bandwidth will differ.\nAdditionally, this files results were only reported in aggregate in the paper\nand may not represent the entire 6TB dataset.  It was selected as one of the smaller\nfiles from the data-set to ease reproduce-ability.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-e\"\u003e[demo@620bb069495a app]\u003c/span\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e /app\u003c/span\u003e\n\u003cspan class=\"pl-e\"\u003e[demo@620bb069495a app]\u003c/span\u003e$ \u003cspan class=\"pl-s1\"\u003empiexec -np 8 ./build/roibin_test -f ./example_data/cxic0415_0020.cxi -p ./share/roibin_sz.json -c 32\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:abs \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:lossless \u0026lt;int32\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:pw_rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:pressio:rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:abs_err_bound \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:accelerate_pw_rel_compression \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:app \u0026lt;char*\u0026gt; = \"SZ\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:config_file \u0026lt;char*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:config_struct \u0026lt;void*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:data_type \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:error_bound_mode \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:error_bound_mode_str \u0026lt;char*\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:bin_size \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:calib_panel \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:num_peaks \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peak_size \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_cols \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_rows \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:peaks_segs \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:sz_dim \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:exafel:tolerance \u0026lt;double\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:gzip_mode \u0026lt;int32\u0026gt; = 3\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:lossless_compressor \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:max_quant_intervals \u0026lt;uint32\u0026gt; = 65536\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:pred_threshold \u0026lt;float\u0026gt; = 0.99\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:prediction_mode \u0026lt;int32\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:protect_value_range \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:psnr_err_bound \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:pw_rel_err_bound \u0026lt;double\u0026gt; = 0.001\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:quantization_intervals \u0026lt;uint32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:rel_err_bound \u0026lt;double\u0026gt; = 0.0001\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sample_distance \u0026lt;int32\u0026gt; = 100\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:segment_size \u0026lt;int32\u0026gt; = 36\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:snapshot_cmpr_step \u0026lt;int32\u0026gt; = 5\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sol_id \u0026lt;int32\u0026gt; = 101\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:sz_mode \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio/sz:sz:user_params \u0026lt;void*\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:abs \u0026lt;double\u0026gt; = 90\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:compressor \u0026lt;char*\u0026gt; = \"sz\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:rel \u0026lt;double\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background/pressio:pressio:reset_mode \u0026lt;bool\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:compressor \u0026lt;char*\u0026gt; = \"pressio\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:nthreads \u0026lt;uint32\u0026gt; = 4\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:binning:shape \u0026lt;data\u0026gt; = data{ type=double dims={3, } has_data=[2, 2, 1, ]}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/background:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite/time:time:metric \u0026lt;char*\u0026gt; = \"noop\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:names \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:plugins \u0026lt;char*[]\u0026gt; = {size, time, }\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi/composite:composite:scripts \u0026lt;char*[]\u0026gt; = {}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:has_header \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:fpzip:prec \u0026lt;int32\u0026gt; = 0\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin/roi:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:background \u0026lt;char*\u0026gt; = \"binning\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:centers \u0026lt;data\u0026gt; = data{ type=byte dims={} has_data=false}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:nthreads \u0026lt;uint32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:roi \u0026lt;char*\u0026gt; = \"fpzip\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio/roibin:roibin:roi_size \u0026lt;data\u0026gt; = data{ type=double dims={3, } has_data=[8, 8, 0, ]}\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:metrics:copy_compressor_results \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:metrics:errors_fatal \u0026lt;int32\u0026gt; = 1\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:compressor \u0026lt;char*\u0026gt; = \"roibin\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:metric \u0026lt;char*\u0026gt; = \"composite\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e/pressio:pressio:reset_mode \u0026lt;bool\u0026gt; = \u0026lt;empty\u0026gt;\u003c/span\u003e\n\n\u003cspan class=\"pl-c1\"\u003eprocessing 0 256\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eglobal_cr=51.805\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ewallclock_ms=2811\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecompress_ms=1098\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ecompress_bandwidth_GBps=1.08781\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003ewallclock_bandwidth_GBps=0.424909\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIn this output, the lines beginning with \u003ccode\u003e/pressio\u003c/code\u003e are the represent the configuration used for the experiment.\nAll of the configurations we used can be found in the \u003ccode\u003e/app/share\u003c/code\u003e directory.\nMore details on the meanings of these options by calling \u003ccode\u003epressio -a help \u0026lt;compressor_id\u0026gt;\u003c/code\u003e where the compressor id is one of \u003ccode\u003ebinning\u003c/code\u003e, \u003ccode\u003eroi\u003c/code\u003e, \u003ccode\u003eopt\u003c/code\u003e, \u003ccode\u003efpzip\u003c/code\u003e, \u003ccode\u003esz\u003c/code\u003e, \u003ccode\u003esz3\u003c/code\u003e, \u003ccode\u003ezfp\u003c/code\u003e, \u003ccode\u003emgard\u003c/code\u003e, \u003ccode\u003eblosc\u003c/code\u003e, etc...\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003e-o\u003c/code\u003e flag provided in some of our run codes outputs the decompressed dataset.\nThere is also a \u003ccode\u003e-d\u003c/code\u003e and \u003ccode\u003e-D\u003c/code\u003e which together output fine grained metrics on individual events.\u003c/p\u003e\n\u003cp\u003ethe lines \u003ccode\u003eprocessing \u0026lt;start\u0026gt; \u0026lt;end\u0026gt;\u003c/code\u003e show the progress of each stage of the compression.\nFor example \u003ccode\u003eprocessing 0 256\u003c/code\u003e means that the first 256 events are being processed.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eglobal_cr\u003c/code\u003e is the compression ratio across all events.\n\u003ccode\u003ewallclock_ms\u003c/code\u003e is the wall clock time including IO from the CXI file.  In the real system, there would not be the IO from the CXI files.\n\u003ccode\u003ecompress_ms\u003c/code\u003e is the compression clock time.\n\u003ccode\u003ecompress_bandwidth_GBps\u003c/code\u003e is the compression bandwidth in GB/s.\n\u003ccode\u003ewallclock_bandwidth_GBps\u003c/code\u003e is the wallclock bandwidth in GB/s\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-results-for-figures\" class=\"anchor\" aria-hidden=\"true\" href=\"#results-for-figures\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eResults for Figures\u003c/h2\u003e\n\u003cp\u003eThe script \u003ccode\u003erun_all.sh\u003c/code\u003e contains configurations for all runs for all results in the paper.  Each specific configuration corresponds to a configuration file in the \u003ccode\u003eshare\u003c/code\u003e directory.  We would comment and uncomment specific sections to run various sub experiments. All results output metrics files (not the decompressed data) are also included from all past runs.\u003c/p\u003e\n\u003cp\u003eThe results for table 2 are in from the lines in the sectoin labeled \"full_table2\".\nThe results for table 3 come from the section labeled \"full scale\" with cxi_file set to the appropriate dataset.\nThe results for table 4 come from the section labeled \"tune\"\nThe results for table 5 come from the section labeled \"scalability\"\nThe results for table 6 come from the section labeled \"overview\"\u003c/p\u003e\n\u003cp\u003eMany of the visualizations come from the section labeled \"full scale\"\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1648861627.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "FTHPC/Correlation_Compressibility",
    "latest_release": "v0.1",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-compressibility-analysis-correlation_compressibility\" class=\"anchor\" aria-hidden=\"true\" href=\"#compressibility-analysis-correlation_compressibility\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompressibility Analysis (Correlation_Compressibility)\u003c/h1\u003e\n\u003ch2\u003e\u003ca id=\"user-content-statement-of-purpose\" class=\"anchor\" aria-hidden=\"true\" href=\"#statement-of-purpose\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStatement of Purpose\u003c/h2\u003e\n\u003cp\u003eThis repo contains scripts to perform compressibility analysis on several leading lossy compressors.\nThe compressibility analysis relies on deriving statistics on scientific data and explore their relationships to their compression ratios from various lossy compressors (based on various compression scheme).\nThe extracted relationships between compression ratios and statistical predictors are modeled via regression models, which provide a statistical framework to predict compression ratios for the different studied lossy compressors.\u003c/p\u003e\n\u003cp\u003eThis repo contains an automatic framework of scripts that perform the compression of scientific datasets from 8 compressors (SZ2, ZFP, MGARD, FPZIP, Digit Rounding and Bit Grooming), the derivation of the statistical predictors of compression ratios (SVD, standard deviation, quantized entropy), and scripts to perform the training of the regression models (linear and spline regressions) as well as the validation of the regression predictions.\nA runtime analysis is also performed and associated codes are provided.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-main-code-structures\" class=\"anchor\" aria-hidden=\"true\" href=\"#main-code-structures\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMain code structures\u003c/h3\u003e\n\u003cp\u003eCompression metrics, including compression ratios, and derivation of statistical predictors (SVD, standard deviation, quantized entropy) codes are found in \u003ccode\u003ecompress_package\u003c/code\u003e and are run via \u003ccode\u003escripts/run.sh\u003c/code\u003e as described in the section \"How to compute statistical predictors and compression analysis on datasets\".\nLinear and spline regressions training and validation (functions \u003ccode\u003ecr_regression_linreg\u003c/code\u003e and \u003ccode\u003ecr_regression_gam\u003c/code\u003e from the script \u003ccode\u003ereplicate_figures/functions_paper.R\u003c/code\u003e).\nCodes for the different runtime analysis are found in the folder \u003ccode\u003eruntime_analysis\u003c/code\u003e and are automated with the script \u003ccode\u003eruntime.sh\u003c/code\u003e, the study includes compression time for SZ2, ZFP, MAGRD, FPZIP, data quantization, SVD, local (tiled) variogram and local (tiled) variogram, and runtime for training and prediction of the regressions.\u003cbr\u003e\nFinally, the script \u003ccode\u003ereplicate_figures/graphs_paper_container.R\u003c/code\u003e replicates and saves all the figures from the paper ad as well as numbers from the tables.\u003c/p\u003e\n\u003cp\u003eFor each dataset in the \u003ccode\u003edataset\u003c/code\u003e folder, slicing is performed for each variable field (e.g. density in Miranda), each slice is stored in a class. The class is updated as compressions with the 8 compressors is performed and updated as the statistical predictors are derived. Results of each class are stored in a .csv file (example of csv files can be found at \u003ccode\u003ereplicate_figures/generated_data/\u003c/code\u003e).\nAll the datasets stored in the \u003ccode\u003edataset\u003c/code\u003e folder can be analyzed with the given set of codes, one needs to source \u003ccode\u003escripts/config.json\u003c/code\u003e with the appropriate dataset name as described in the below section \"How to compute statistical predictors and compression analysis on datasets\".\nThe regression analysis and its prediction is then performed on R dataframes based on the aforementioned .csv files.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-system-information\" class=\"anchor\" aria-hidden=\"true\" href=\"#system-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSystem Information\u003c/h2\u003e\n\u003cp\u003eThe hardware and software versions used for the performance evaluations can be found in the table below. These nodes come from Clemson University\u0027s Palmetto Cluster.\u003c/p\u003e\n\u003cp\u003eThese nodes have:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003ecomponent\u003c/th\u003e\n\u003cth\u003eversion\u003c/th\u003e\n\u003cth\u003ecomponent\u003c/th\u003e\n\u003cth\u003eversion\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCPU\u003c/td\u003e\n\u003ctd\u003eIntel Xeon 6148G (40 cores)\u003c/td\u003e\n\u003ctd\u003esz2\u003c/td\u003e\n\u003ctd\u003e2.1.12.2\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eGPU\u003c/td\u003e\n\u003ctd\u003e2 Nvidia v100\u003c/td\u003e\n\u003ctd\u003esz3\u003c/td\u003e\n\u003ctd\u003e3.1.3.1\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMemory\u003c/td\u003e\n\u003ctd\u003e372GB\u003c/td\u003e\n\u003ctd\u003ezfp\u003c/td\u003e\n\u003ctd\u003e0.5.5\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eNetwork\u003c/td\u003e\n\u003ctd\u003e2 Mellanox MT27710 (HDR)\u003c/td\u003e\n\u003ctd\u003emgard\u003c/td\u003e\n\u003ctd\u003e1.0.0\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eFileSystem\u003c/td\u003e\n\u003ctd\u003eBeeGFS 7.2.3 (24 targets)\u003c/td\u003e\n\u003ctd\u003ebit grooming\u003c/td\u003e\n\u003ctd\u003e2.1.9\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCompiler\u003c/td\u003e\n\u003ctd\u003eGCC 8.4.1\u003c/td\u003e\n\u003ctd\u003edigit rounding\u003c/td\u003e\n\u003ctd\u003e2.1.9\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eOS\u003c/td\u003e\n\u003ctd\u003eCentOS 8.2.2004\u003c/td\u003e\n\u003ctd\u003eR\u003c/td\u003e\n\u003ctd\u003e4.1.3\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMPI\u003c/td\u003e\n\u003ctd\u003eOpenMPI 4.0.5\u003c/td\u003e\n\u003ctd\u003ePython\u003c/td\u003e\n\u003ctd\u003e3.9.12\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLibPressio\u003c/td\u003e\n\u003ctd\u003e0.83.4\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003e\u003ca id=\"user-content-first-time-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#first-time-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFirst time setup\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-container-installation-for-ease-of-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#container-installation-for-ease-of-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContainer Installation (for ease of setup)\u003c/h3\u003e\n\u003cp\u003eWe provide a container for \u003ccode\u003ex86_64\u003c/code\u003e image for ease of installation.\u003c/p\u003e\n\u003cp\u003eThis container differs from our experimental setup slightly. The production build used \u003ccode\u003e-march=native -mtune=native\u003c/code\u003e for architecture optimized builds where as the container does not use these flags to maximize compatibility across \u003ccode\u003ex86_64\u003c/code\u003e hardware.\u003c/p\u003e\n\u003cp\u003eNOTE this file is \u0026gt;= 11 GB , download with caution.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual Installation\u003c/h3\u003e\n\u003cp\u003eBy default, it is recommended to follow the install locations that are indicated on the top of \u003ccode\u003escripts/run.sh\u003c/code\u003e\nand the top of \u003ccode\u003econfig.json\u003c/code\u003e. These two files provide the configuration options to get the program running.\u003c/p\u003e\n\u003cp\u003eSpack should be installed in the following location: \u003ccode\u003e$HOME/spack/\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThis Github repo should be cloned in the following location: \u003ccode\u003e$HOME/Correlation_Compressibility/\u003c/code\u003e\nThis location is also referenced as the \u003ccode\u003eCOMPRESS_HOME\u003c/code\u003e environment variable.\u003c/p\u003e\n\u003cp\u003eA dataset folder called \u0027datasets\u0027 should be in the following location: \u003ccode\u003e$HOME/Correlation_Compressibility/datasets/\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eClone the repo but make sure to install or load \u003ccode\u003egit-lfs\u003c/code\u003e first.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e install/module load git-lfs, needed to download example_data for building the container\u003c/span\u003e\nsudo dnf install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003eFedora/CentOS Stream 8\u003c/span\u003e\nsudo apt-get install git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e Ubuntu\u003c/span\u003e\nspack install git-lfs\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e spack load git-lfs \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e using spack\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e clone this repository\u003c/span\u003e\ngit clone https://github.com/FTHPC/Correlation_Compressibility \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you forgot to install \u003ccode\u003egit-lfs\u003c/code\u003e before and have an empty file in the  \u003ccode\u003edatasets\u003c/code\u003e folder, you should install \u003ccode\u003egit-lfs\u003c/code\u003e\nand then run the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit lfs fetch\ngit lfs checkout\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce Spack is installed, there is a \u003ccode\u003espack.yaml\u003c/code\u003e configuration file containing the Spack environment necessary to run the program.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e\ngit clone --depth=1 https://github.com/spack/spack\ngit clone --depth=1 https://github.com/robertu94/spack_packages \n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh \nspack compiler find\nspack external find \nspack repo add --scope=site ./spack_packages \n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility \nspack env activate \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\nspack install\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e COMPRESS_HOME=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/Correlation_Compressibility \u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThese commands will install the environment. The environment only needs to be installed once.\nIf you are using an older \u0026lt; gcc11, then you will need to add the following to the \u003ccode\u003espack.yaml\u003c/code\u003e file:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e^libstdcompat+boost\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eafter \u003ccode\u003e^mgard@robertu94+cuda\u003c/code\u003e but before the \u003ccode\u003e,\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-to-run-the-training-and-prediction-timing-analysis-demonstration\" class=\"anchor\" aria-hidden=\"true\" href=\"#to-run-the-training-and-prediction-timing-analysis-demonstration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTo run the training and prediction timing analysis demonstration\u003c/h3\u003e\n\u003cp\u003eIn order to run the timing analysis, a dataset must be specified.\nThere are two datasets setup within this demonstration.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003esh runtime_analysis/runtime.sh -d [DATASET]\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e[DATASET] can be either [NYX] or [SCALE]\u003c/p\u003e\n\u003cp\u003eAfter running the above script, an *.RData file(s) will be produced giving the approprirate timing information of\nthe training and prediction for the regression models.\u003c/p\u003e\n\u003cp\u003eNote: A quicker and more efficient quantized entropy method is demonstrated in \u003ccode\u003eqentropy.cc\u003c/code\u003e\u003c/p\u003e\n\u003ch4\u003e\u003ca id=\"user-content-the-following-below-runs-qentropycc\" class=\"anchor\" aria-hidden=\"true\" href=\"#the-following-below-runs-qentropycc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe following below runs \u003ccode\u003eqentropy.cc\u003c/code\u003e\n\u003c/h4\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003eg++ -std=c++2a -O3 qentropy.cc -o qentropy -march=native -mtune=native\n./qentropy\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote: Please run the runtime analysis for both datasets before running the following section.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\" class=\"anchor\" aria-hidden=\"true\" href=\"#replication-of-figures-how-to-run-statistical-prediction-of-compression-ratios-and-the-prediction-validation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReplication of figures: how to run statistical prediction of compression ratios and the prediction validation\u003c/h3\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e  saves the graphs presented in the paper and provides associated validation metrics (correlation and median absolute error percentage).\u003c/p\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e will source the scripts  \u003ccode\u003eload_dataset_paper.R\u003c/code\u003e and \u003ccode\u003efunctions_paper.R\u003c/code\u003e that respectively load the dataset of interest and perform the regression analysis (training and prediction in cross-validation).\nAs a consequence the scripts  \u003ccode\u003eload_dataset_paper.R\u003c/code\u003e and \u003ccode\u003efunctions_paper.R\u003c/code\u003e do not need to be run by the user.\u003c/p\u003e\n\u003cp\u003eThe script \u003ccode\u003egraphs_paper_container.R\u003c/code\u003e  is run via the command:\n\u003ccode\u003ebash sh replicate.sh\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFrom running the script once, it will save all Figures 1, 3, 4 and 5 into .png files from the paper as well as corresponding validation metrics.\nFigure 2 is not saved as it provides a simple vizualization of slices of the datasets.\nSlices of the datasets are generated in the Section \"How to compute statistical predictors and compression metrics\" and can be stored, however we do not save them here to save space in the container.\nNumbers for Tables 2, 3 and 5 are printed in the R console.\nAll printed validation metrics are save into a file named \u003ccode\u003efigure_replication.log\u003c/code\u003e.\nFigures and the log-file are saved in the same folder as the one where R script is run and the filename structure is \u003ccode\u003efigY_*.png\u003c/code\u003e with Y is the figure number reference in the paper and \u003ccode\u003e*\u003c/code\u003e provides additional informnation about the data and the compressor.\u003cbr\u003e\nNumbers for Table 4 are saved in the last section in .txt files \u003ccode\u003estatistic_benchmark_runtime_X.txt\u003c/code\u003e with X the studied dataset (NYX or SCALE).\u003c/p\u003e\n\u003cp\u003eIn order to limit the container size to aid reproducibility, we only added a restricted number of scientific datasets in the container and we rely on csv files from our production runs (saved as described above in the Section \"How to compute statistical predictors on datasets\").\nMore datasets are available on \u003ca href=\"https://sdrbench.github.io\" rel=\"nofollow\"\u003eSDRBench\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1675473427.0
  },
  {
    "data_format": 2,
    "description": "Set up a simplified test case based on spack/HDF5 build fail due to /usr/local contents",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "AlexanderRichert-NOAA/CItest",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1671482597.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "nvhpc/spack.yaml",
      "nvhpc/failures/spack.yaml"
    ],
    "full_name": "eugeneswalker/noaa",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1675202595.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ompi1-dev/spack.yaml"
    ],
    "full_name": "youwuyou/slimfly_collectives",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-slim-fly-mpi-collective-optimization\" class=\"anchor\" aria-hidden=\"true\" href=\"#slim-fly-mpi-collective-optimization\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSlim Fly MPI collective optimization\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTODO: this repo is reset and needs to be put under source control with the new structure! Remember to add the \u003ccode\u003e.github/workflows/ci.yml\u003c/code\u003e as in the current git repo\u003c/p\u003e\n\u003c/blockquote\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1671447123.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "oneapi/spack.yaml",
      "nvhpc/spack.yaml",
      "gnu/spack.yaml"
    ],
    "full_name": "eugeneswalker/noaa-prototyping",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1666800656.0
  },
  {
    "data_format": 2,
    "description": "CEES spack configurations (take 3). Focus on environments only (or mostly), and modular configs.",
    "filenames": [
      "spack_env_files/py-bottleneck_spack.yaml",
      "spack_env_files/paraview_spack.yaml",
      "spack_env_files/cees-x86-intel_spack.yaml",
      "spack_env_files/pflotran_spack.yaml",
      "spack_env_files/pflotran_ompi_sif_spack.yaml",
      "spack_env_files/pflotran_sif_spack.yaml",
      "spack_env_files/cees-x86-oneapi_spack.yaml"
    ],
    "full_name": "jeffersonscientific/cees_spack_configs",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-cees_spack_configs\" class=\"anchor\" aria-hidden=\"true\" href=\"#cees_spack_configs\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ecees_spack_configs\u003c/h1\u003e\n\u003cp\u003eCEES spack configurations (take 3). Focus on environments only (or mostly), and modular configs.\u003c/p\u003e\n\u003cp\u003eThis constitutes a continued effort to find a way to Git-Support and modularize Spack setups. While knowledge is much improved, success\nis arguably limited -- alas. The idea is to be able to easily maintain a list of SW that is then compiled over a suite of compiler, mpi,\narchitecture types.\u003c/p\u003e\n\u003cp\u003eA few points:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eUsing environments is key.\u003c/li\u003e\n\u003cli\u003eUsing an \u003ccode\u003einclude:\u003c/code\u003e section can help. For example,\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode\u003e  include:\n  - $spack/../configs/packages_petsc.yaml\n  - $spack/../configs/compilers_sherlock_O2.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003emight be useful to build \u003ccode\u003epetsc\u003c/code\u003e environments for multiple architectures or compilers. Unfortunatly -- at least at this time, not all sections\ncan be satisfied as \u003ccode\u003einclude\u003c/code\u003e files.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCompilers remain a challenge...\u003c/li\u003e\n\u003cli\u003eIf \u003ccode\u003eproviders\u003c/code\u003e are specified, optimal (and functional) choices will likely vary for different compilers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCONVENTIONS:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConfiguration components indicated with \u003ccode\u003e_inc\u003c/code\u003e in name, eg \u003ccode\u003epackages_inc.yaml\u003c/code\u003e. These files should stand alone for non-environment builds\n(not recommended...) or can be included in an \u003ccode\u003einclude:\u003c/code\u003e clause of an environment.\u003c/li\u003e\n\u003cli\u003eEnvironment files may be tagged with \u003ccode\u003e_mod\u003c/code\u003e in the name, to indicate a \"modular\" envorinment, that uses an \u003ccode\u003einclude:\u003c/code\u003e section.\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1641864561.0
  },
  {
    "data_format": 2,
    "description": "Toolset to deploy software stacks",
    "filenames": [
      "samples/spack.yaml"
    ],
    "full_name": "epfl-scitas/spack-sdploy",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-sdploy\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-sdploy\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-sdploy\u003c/h1\u003e\n\u003cp\u003eSpack extension for automatic package configuration and deployment.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-how-to-install\" class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-install\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to install\u003c/h2\u003e\n\u003cp\u003eYou can try out this Spack extension be executing 4 easy steps:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSet up and activate a local python environment\u003c/li\u003e\n\u003cli\u003eSet up and activate \u003ccode\u003espack\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eInstall \u003ccode\u003espack-sdploy\u003c/code\u003e dependencies\u003c/li\u003e\n\u003cli\u003eClone and configure spack-sdploy\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis 4 steps are now detailed in the next section.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-step-by-step-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#step-by-step-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eStep-by-step installation\u003c/h3\u003e\n\u003cp\u003eJust for a matter of completeness, all the steps needed get up and running with\nspack-sdploy extension will be covered, which can be a bit pedantic.\u003c/p\u003e\n\u003ch4\u003e\u003ca id=\"user-content-set-up-and-activate-a-local-python-environment\" class=\"anchor\" aria-hidden=\"true\" href=\"#set-up-and-activate-a-local-python-environment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSet up and activate a local python environment\u003c/h4\u003e\n\u003cp\u003eIt is recommended that a Python environment be used to support sdploy. This same\nPython can also be used to run Spack.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epython3 -m venv \u0026lt;path-to-environment-directory\u0026gt;\n. \u0026lt;path-to-environment-directory\u0026gt;/bin/activate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor more information on how to create a virtual environment in Python refer to\nthe PEP 405 \u2013 Python Virtual Environments documentation.\u003c/p\u003e\n\u003ch4\u003e\u003ca id=\"user-content-set-up-and-activate-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#set-up-and-activate-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSet up and activate Spack\u003c/h4\u003e\n\u003cp\u003eSee the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/getting_started.html#installation\" rel=\"nofollow\"\u003eSpack documentation\u003c/a\u003e\non how to install Spack. For sake of completeness, we copy paste the commands here:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git\n. spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e\u003ca id=\"user-content-install-spack-sdploy-dependencies\" class=\"anchor\" aria-hidden=\"true\" href=\"#install-spack-sdploy-dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstall \u003ccode\u003espack-sdploy\u003c/code\u003e dependencies\u003c/h4\u003e\n\u003cp\u003eUp to now the only dependency of spack-sdploy if jinja2. Once you have activated\nPython environment, you can simply use pip to install the packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install jinja2\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003e\u003ca id=\"user-content-clone-and-configure-spack-sdploy\" class=\"anchor\" aria-hidden=\"true\" href=\"#clone-and-configure-spack-sdploy\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eClone and configure spack-sdploy\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@github.com:epfl-scitas/spack-sdploy\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo activate the spack-sdploy extension you must add it to the config.yaml. If\nyou already have another Spack installation and just want to try out\nspack-sdploy may very well create a temporary directory to store the\nconfiguration and then use the SPACK_USER_CONFIG_PATH variable to point this new\ndirectory.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emkdir temporary_config\nexport SPACK_USER_CONFIG_PATH=/path/to/temporary_config\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eand then, inside the temporary_config directory, write a config.yaml file with\nthe following contents:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003econfig:\n  extensions:\n  - /path/to/spack-sdploy\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBe sure you do not change the spack-dploy directory. Spack forces the extensions\nto follow strict rules. Please see the\n\u003ca href=\"https://spack.readthedocs.io/en/latest/extensions.html\" rel=\"nofollow\"\u003eSpack Extensions\u003c/a\u003e\ndocumentation for more details about this subject. At this point you should now\nbe able to call \u003ccode\u003espack -h\u003c/code\u003e and see the new Spack commands deployed by the\nspack-sdploy extension.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-how-to-use\" class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-use\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to use\u003c/h2\u003e\n\u003cp\u003eAt the present time, spack-sdploy will add 2 commands to your already existing\nSpack commands. These commandes are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack write-spack-yaml\nspack write-packages-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn the future we may change the names of these commands, but for now lets just\nimagine these are short and easy to type commands.\u003c/p\u003e\n\u003cp\u003eAs you may have guessed it (if you haven\u0027t that\u0027s ok), write-spack-yaml will\nwrite the spack.yaml file and write-packages-yaml will write the packages.yaml\nfile. Of course, Spack does not (yet!) guess what you may want to install and\nfor that purpose, both these commands will read all the specs you want in your\nspack.yaml file by reading another file you have previously written and which\nwe call by stack.yaml.\u003c/p\u003e\n\u003cp\u003eFor the time being, spack-sdploy already comes with a dummy stack.yaml so we can\nget started using the new commands.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-write-spack-yaml\" class=\"anchor\" aria-hidden=\"true\" href=\"#write-spack-yaml\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ewrite-spack-yaml\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003espack write-spack-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-write-packages-yaml\" class=\"anchor\" aria-hidden=\"true\" href=\"#write-packages-yaml\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ewrite-packages-yaml\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003espack write-packages-yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-write-activate-list\" class=\"anchor\" aria-hidden=\"true\" href=\"#write-activate-list\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ewrite-activate-list\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003espack write-activate-list -p \u0026lt;platform\u0026gt; -s \u0026lt;stack\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWrite to file named \u003ccode\u003epackages_to_activate\u003c/code\u003e list of packages to activate, using \u003ccode\u003espack activate \u0026lt;package\u0026gt;\u003c/code\u003e. Packages are writen one per line.\u003c/p\u003e\n\u003cp\u003ePackages to activate can be marked in the stack file in two possible ways: by adding the keyword \u003ccode\u003eactivate: true\u003c/code\u003e in the metadata section of a list of packages or by adding the keyword \u003ccode\u003eactivate: true\u003c/code\u003e to an individual package. Duplicates are removed.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1669125412.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack/spack.yaml"
    ],
    "full_name": "j-woz/SV-CP-2022-11-23",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1669233200.0
  },
  {
    "data_format": 2,
    "description": "Software environments",
    "filenames": [
      "catalog-config/libxc-5.2.3/spack.yaml",
      "catalog-config/core/spack.yaml",
      "catalog-config/compilers/nvhpc-22.9/spack.yaml",
      "catalog-config/compilers/gcc-11.3.0/spack.yaml"
    ],
    "full_name": "toxa81/se",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-software-environments\" class=\"anchor\" aria-hidden=\"true\" href=\"#software-environments\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSoftware environments\u003c/h1\u003e\n\u003cp\u003eDeployment steps\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eclone spack \u003ccode\u003egit clone https://github.com/spack/spack.git\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003eenable spack \u003ccode\u003esource enable-spack\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003esrun -N2 -n8 --partition=nvgpu spack -e ./env-spec/core install -j16\u003c/li\u003e\n\u003cli\u003einstall gcc-11.3.0 view \u003ccode\u003espack -e  ./env-spec/gcc-11.3.0/ install\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003einstall nvhpc-22.9 \u003ccode\u003esrun -N1 --partition=nvgpu spack -e . install -j64\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003espack compiler find $(spack find --format {prefix.bin} gcc@11)\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1669195550.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "compilers_env/spack.yaml",
      "complete_env/spack.yaml"
    ],
    "full_name": "antoine-morvan/spack-offline-env",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1644310043.0
  },
  {
    "data_format": 2,
    "description": "Set up fenics spack on csd3",
    "filenames": [
      "spack-skylake.yaml",
      "spack-icelake.yaml"
    ],
    "full_name": "ma595/fenics-csd3-spack",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-fenics-csd3-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#fenics-csd3-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003efenics-csd3-spack\u003c/h1\u003e\n\u003cp\u003eFollow instructions in icelake-spack-env.sh\u003c/p\u003e\n\u003cp\u003eOr, copy existing \u003ccode\u003espack.yaml\u003c/code\u003e files into cloned Spack repo. It is necessary to \u003ccode\u003emodule purge\u003c/code\u003e environment first, otherwise the prepend path inside \u003ccode\u003espack.yaml\u003c/code\u003e will lead to duplications.\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1667830944.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack-envs/rocm/spack.yaml",
      "spack-envs/cuda/spack.yaml"
    ],
    "full_name": "simonpintarelli/acclapack-tests",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1667393188.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack-settings/22.06/0.18.1/prod/spack.yaml"
    ],
    "full_name": "PDC-support/PDC-SoftwareStack",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-pdc-software-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"#pdc-software-stack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePDC Software Stack\u003c/h1\u003e\n\u003cp\u003eRepository to store documentation, installation procedure, installation procedures and data for validation of installed software\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-modules\" class=\"anchor\" aria-hidden=\"true\" href=\"#modules\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eModules\u003c/h2\u003e\n\u003cp\u003eModules for easybuild and CrayPE are within the module folder.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-easybuild\" class=\"anchor\" aria-hidden=\"true\" href=\"#easybuild\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eEasyBuild\u003c/h2\u003e\n\u003cp\u003eEasyBuild easyconfigs should be stored in \u003cem\u003eeasybuild/easyconfigs\u003c/em\u003e folder\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h2\u003e\n\u003cp\u003eSpack installation procedures for software should be store in the \u003cem\u003espack\u003c/em\u003e folder\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-manual-installations\" class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual installations\u003c/h2\u003e\n\u003cp\u003eProcedures should be store in the \u003cem\u003eother\u003c/em\u003e folder\u003c/p\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1666354279.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "environments/CMSSW_12_6_X/spack.yaml"
    ],
    "full_name": "iarspider/cms-spack-repo",
    "latest_release": null,
    "stargazers_count": 0,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1638894331.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "build-lassen-spectrum/spack.yaml",
      "build-mvapich/spack-mvapich.yaml",
      "configs/unm-hopper/spack-mpich+yaksa+ucx.yaml",
      "configs/unm-hopper/spack-mpich+yaksa.yaml",
      "configs/unm-hopper/spack-openmpi+ucx.yaml",
      "build-xlc/spack-xlc-spectrum.yaml",
      "build-xlc/spack-xlc-mvapich.yaml",
      "configs/llnl-lassen/spack-spectrum.yaml",
      "configs/llnl-lassen/spack-mvapich.yaml",
      "build-hpctoolkit/spack-spectrum.yaml"
    ],
    "full_name": "CUP-ECS/ping-pong-gpu",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-gpu-ping-pong-benchmark\" class=\"anchor\" aria-hidden=\"true\" href=\"#gpu-ping-pong-benchmark\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGPU Ping Pong Benchmark\u003c/h1\u003e\n\u003cp\u003eBasic regular mesh ping pong benchmark for GPUs written in Kokkos. Baseline for\ncomparison is a Kokkos parallel loop that packs the data prior to sending. Mesh\ndata structure extracted from UNM Fiesta CFD application.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-running\" class=\"anchor\" aria-hidden=\"true\" href=\"#running\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning\u003c/h2\u003e\n\u003cp\u003eArguments:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e-n: Length of one face of the mesh being communicated (resulting communciation is n * n * 5 * 3 doubles\u003c/li\u003e\n\u003cli\u003e-i: Number of iterations to perform\u003c/li\u003e\n\u003cli\u003e-d: Face of mesh to communicate (0 = y/z, 1 = x/z, 2 = x/y)\u003c/li\u003e\n\u003cli\u003e-m: Mode to use for sending and receiving (0 = MPI datatypes, 1 = Hand gpu pack, gpu-aware MPI, 2 = Hand gpu pack, host memory send)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExample command line:\n\u003ccode\u003esrun --mpi=pmi2 --ntasks 2 --gpus-per-task=1 --tasks-per-node=1 -p cup-ecs ping_pong -n 200 -i 100 -d 1 -m 0\u003c/code\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h2\u003e\n\u003cp\u003eSpack configuration files for different MPIs are in the configs/ directory. Generally\nwe create spack environments for building, use a setup script to load any necessary\nmodules (generally the compiler, which the spack environment doesn\u0027t necessarily\nprovide), and activate the spack environment for the buiuld\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-future-features\" class=\"anchor\" aria-hidden=\"true\" href=\"#future-features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFuture features\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eOption to pack into pinned host memory instead of GPU memory\u003c/li\u003e\n\u003cli\u003eRestructure to support other ping pong of data structures extracted from\nother applications.\u003c/li\u003e\n\u003cli\u003eOption to change number of ghost cell layers sent\u003c/li\u003e\n\u003c/ol\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1667693779.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack/envs/dev/spack.yaml"
    ],
    "full_name": "range3/kvs-evaluation",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-kvs-evaluation\" class=\"anchor\" aria-hidden=\"true\" href=\"#kvs-evaluation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ekvs-evaluation\u003c/h1\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e external/YCSB-C\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e sudo\u3092\u4f7f\u3063\u3066libhiredis.so\u304c/usr/local/lib\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b\u003c/span\u003e\nmake\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e LD_LIBRARY_PATH=/usr/local/lib\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e \u52d5\u4f5c\u78ba\u8a8d\u003c/span\u003e\n./ycsbc -db basic -threads 1 -P workloads/workloada.spec\u003c/pre\u003e\u003c/div\u003e\n\u003ch1\u003e\u003ca id=\"user-content-ycsb-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#ycsb-c\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eYCSB-C\u003c/h1\u003e\n\u003ch2\u003e\u003ca id=\"user-content-workload\" class=\"anchor\" aria-hidden=\"true\" href=\"#workload\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eworkload\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003eworkload\u003c/th\u003e\n\u003cth align=\"left\"\u003edescription\u003c/th\u003e\n\u003cth align=\"right\"\u003eread\u003c/th\u003e\n\u003cth align=\"right\"\u003einsert\u003c/th\u003e\n\u003cth align=\"right\"\u003eupdate\u003c/th\u003e\n\u003cth align=\"right\"\u003escan\u003c/th\u003e\n\u003cth align=\"right\"\u003eR-M-W\u003c/th\u003e\n\u003cth align=\"center\"\u003edistribution\u003c/th\u003e\n\u003cth align=\"center\"\u003eremarks\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eA\u003c/td\u003e\n\u003ctd align=\"left\"\u003eUpdate heavy\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.5\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.5\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003ezipfian\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eB\u003c/td\u003e\n\u003ctd align=\"left\"\u003eRead mostly\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.95\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.05\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003ezipfian\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eC\u003c/td\u003e\n\u003ctd align=\"left\"\u003eRead only\u003c/td\u003e\n\u003ctd align=\"right\"\u003e1\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003ezipfian\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eD\u003c/td\u003e\n\u003ctd align=\"left\"\u003eRead latest\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.95\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.05\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003elatest\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eE\u003c/td\u003e\n\u003ctd align=\"left\"\u003eShort ranges\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.05\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.95\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"center\"\u003ezipfian\u003c/td\u003e\n\u003ctd align=\"center\"\u003emaxscanlength=100 random(uniform)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003eF\u003c/td\u003e\n\u003ctd align=\"left\"\u003eRead-modify-write\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.5\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e\u003c/td\u003e\n\u003ctd align=\"right\"\u003e0.5\u003c/td\u003e\n\u003ctd align=\"center\"\u003ezipfian\u003c/td\u003e\n\u003ctd align=\"center\"\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003e\u003ca id=\"user-content-class-diagram-subset\" class=\"anchor\" aria-hidden=\"true\" href=\"#class-diagram-subset\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eclass diagram (subset)\u003c/h2\u003e\n\u003cdiv class=\"highlight highlight-source-mermaid\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eclassDiagram\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eDBFactory\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eDB\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003einterface\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eDB\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eabstruct\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlDB\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStringHashtable\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eV\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003einterface\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStringHashtable\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eKeyHashtable\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003einterface\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eKeyHashtable\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eFieldHashtable\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003einterface\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e\u0026gt;\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eFieldHashtable\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTable\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eV\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableKey\u003c/span\u003e \u003cspan class=\"pl-sg\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"pl-k\"\u003estd::unorderd_map\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eString,FieldHashtable*\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e}\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableField\u003c/span\u003e \u003cspan class=\"pl-sg\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"pl-k\"\u003estd::unorderd_map\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eString,const char*\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e}\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtable\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\u003cspan class=\"pl-ent\"\u003eT\u003c/span\u003e\u003cspan class=\"pl-sg\"\u003e~\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableKey\u003c/span\u003e \u003cspan class=\"pl-sg\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"pl-k\"\u003estd::mutex\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e}\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eclass\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableField\u003c/span\u003e \u003cspan class=\"pl-sg\"\u003e{\u003c/span\u003e\n  \u003cspan class=\"pl-k\"\u003estd::mutex\u003c/span\u003e\n\u003cspan class=\"pl-sg\"\u003e}\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eDBFactory\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003ecreate\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eLockStlDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e*--\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableKey\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eLockStlHashtableKey\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eo--\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableField\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eLockStlDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableField\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003ecreate\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlDB\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStringHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTable\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStlHashTable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|--\u003c/span\u003e\u003cspan class=\"pl-en\"\u003eLockStlHashtable\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eStringHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eFieldHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStringHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eKeyHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStlHashTable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableKey\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStlHashTable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableField\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eLockStlHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableKey\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eLockStlHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableField\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003einstantiation\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eStlHashTableKey\u003c/span\u003e  \u003cspan class=\"pl-k\"\u003e\u0026lt;|--\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableKey\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eStlHashTableField\u003c/span\u003e  \u003cspan class=\"pl-k\"\u003e\u0026lt;|--\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eLockStlHashtableField\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eKeyHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableKey\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eFieldHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e\u0026lt;|..\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eStlHashTableField\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eKeyHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003euse\u003c/span\u003e\n\u003cspan class=\"pl-en\"\u003eHashtableDB\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e..\u0026gt;\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eFieldHashtable\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e:\u003c/span\u003e \u003cspan class=\"pl-s\"\u003euse\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 0,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1667533964.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack/spack.yaml"
    ],
    "full_name": "charmoniumQ/wf-reg-test",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-wf-reg-test\" class=\"anchor\" aria-hidden=\"true\" href=\"#wf-reg-test\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ewf-reg-test\u003c/h1\u003e\n\u003cp\u003eSoftware tends to break or \"collapse\" over time, even if it is unchanged, due to non-obvious changes in the computational environment.\nCollapse in computational experiments undermines long-term credibility and hinders day-to-day operations.\nWe propose to create the first public dataset of automatically executable scientific experiments.\nThis data could be used to identify best practices, make continuous testing feasible, and repair broken programs.\nThese techniques increase the replicability of computational experiments.\u003c/p\u003e\n\u003cp\u003eConceptually, we intend to collect the following:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eregistry\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eregistries\u003c/span\u003e:\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eexperiment\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eregistry\u003c/span\u003e:\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eversion\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eexperiment\u003c/span\u003e:\n            \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-en\"\u003erange\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003enum_repetitions\u003c/span\u003e):\n                \u003cspan class=\"pl-s1\"\u003eexecution\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-en\"\u003eexecute\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003eversion\u003c/span\u003e)\n                \u003cspan class=\"pl-s1\"\u003edata\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eappend\u003c/span\u003e((\n                    \u003cspan class=\"pl-s1\"\u003eexecution\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003edate\u003c/span\u003e,   \u003cspan class=\"pl-s1\"\u003eexecution\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eoutput\u003c/span\u003e,\n                    \u003cspan class=\"pl-s1\"\u003eexecution\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003elogs\u003c/span\u003e,   \u003cspan class=\"pl-s1\"\u003eexecuiton\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eres_usage\u003c/span\u003e,\n                    \u003cspan class=\"pl-s1\"\u003eversion\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003edate\u003c/span\u003e,     \u003cspan class=\"pl-s1\"\u003eversion\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003ecode\u003c/span\u003e,\n                    \u003cspan class=\"pl-s1\"\u003eexperiment\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003ename\u003c/span\u003e,  \u003cspan class=\"pl-s1\"\u003eregistry\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003ename\u003c/span\u003e,\n                ))\u003c/pre\u003e\u003c/div\u003e\n\u003ch1\u003e\u003ca id=\"user-content-reproducing\" class=\"anchor\" aria-hidden=\"true\" href=\"#reproducing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReproducing\u003c/h1\u003e\n\u003cp\u003eSee \u003ca href=\"REPRODUCING.md\"\u003e\u003ccode\u003eREPRODUCING.md\u003c/code\u003e\u003c/a\u003e for instructions on reproducing these results.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-todo\" class=\"anchor\" aria-hidden=\"true\" href=\"#todo\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTODO\u003c/h1\u003e\n\u003cp\u003eSee \u003ca href=\"TODO.md\"\u003e\u003ccode\u003eTODO.md\u003c/code\u003e\u003c/a\u003e for instructions on reproducing these results.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing\u003c/h1\u003e\n\u003cp\u003eSee \u003ca href=\"CONTRIBUTING.md\"\u003e\u003ccode\u003eCONTRIBUTING.md\u003c/code\u003e\u003c/a\u003e for instructions on setting up a development environment.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1676689037.0
  },
  {
    "data_format": 2,
    "description": "Testing environment for PDI",
    "filenames": [
      "spack/1b-spack/spack.yaml"
    ],
    "full_name": "pdidev/test_env",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-docker-images\" class=\"anchor\" aria-hidden=\"true\" href=\"#docker-images\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocker images:\u003c/h1\u003e\n\u003cp\u003eA set of related Docker images to build and test PDI.\u003c/p\u003e\n\u003cp\u003eWe provide images based on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpack recipes,\u003c/li\u003e\n\u003cli\u003eBinary packages.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-spack-based-images\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-based-images\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack-based images\u003c/h2\u003e\n\u003cp\u003eThese images are based on a minimal Ubuntu 18.08, with spack and all dependencies installed through\nspack.\u003c/p\u003e\n\u003cp\u003eThe images are named as: \u003ccode\u003eghcr.io/pdidev/spack/${deps_version}/${compiler}/${mpi}/${level}\u003c/code\u003e\nWith the following parameters:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003edeps_version\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eoldest\u003c/code\u003e: dependencies use the oldest versions supported by PDI,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003elatest\u003c/code\u003e: dependencies use the latest versions available in spack at the time of generation,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ecompiler\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003egcc\u003c/code\u003e:   using GCC compiler,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eclang\u003c/code\u003e: using clang for C/C++ and gfortran for Fortran,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003empi\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eopenmpi\u003c/code\u003e: using openmpi implementation of MPI,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003elevel\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003emini\u003c/code\u003e: dependencies \"vendored\" in PDI are not included in the image,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eall\u003c/code\u003e: dependencies \"vendored\" in PDI are included in the image.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-binary-package-based-images\" class=\"anchor\" aria-hidden=\"true\" href=\"#binary-package-based-images\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBinary package based images\u003c/h2\u003e\n\u003cp\u003eThese images are based on Ubuntu 18.08, with all dependencies installed through packages.\u003c/p\u003e\n\u003cp\u003eThe images are named as: \u003ccode\u003eghcr.io/pdidev/ubuntu/bionic/${mpi}/${level}\u003c/code\u003e\nWith the following parameters:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003empi\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003empich\u003c/code\u003e: using mpich implementation of MPI,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eopenmpi\u003c/code\u003e: using openmpi implementation of MPI,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003elevel\u003c/code\u003e:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003emini\u003c/code\u003e: dependencies \"vendored\" in PDI are not included in the image,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eall\u003c/code\u003e: dependencies \"vendored\" in PDI are included in the image,\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003epdi\u003c/code\u003e: PDI is included in the image.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1641653805.0
  },
  {
    "data_format": 2,
    "description": "Toy pipeline for simple Nextflow tests",
    "filenames": [
      "scripts/containerize-spack/spack.yaml",
      "scripts/spack/spack.yaml"
    ],
    "full_name": "marcodelapierre/toy-cowsay-nf",
    "latest_release": null,
    "readme": "\u003ch2\u003e\u003ca id=\"user-content-toy-pipeline-for-simple-nextflow-tests\" class=\"anchor\" aria-hidden=\"true\" href=\"#toy-pipeline-for-simple-nextflow-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eToy pipeline for simple Nextflow tests\u003c/h2\u003e\n\u003cp\u003eThe purpose of this repo is to have a pipeline with features including:\u003c/p\u003e\n\u003cp\u003eGeneral:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSimple\u003c/li\u003e\n\u003cli\u003eSmall (including required software)\u003c/li\u003e\n\u003cli\u003eQuick to setup and run\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePipeline:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRequires a small package, that can be installed with Conda or Spack\n\u003cul\u003e\n\u003cli\u003eConda: \u003ccode\u003ecowpy\u003c/code\u003e (from \u003ccode\u003econda-forge\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eSpack: \u003ccode\u003ecowsay\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eReads/writes files\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSoftware options:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHost\u003c/li\u003e\n\u003cli\u003eContainers\u003c/li\u003e\n\u003cli\u003eConda\u003c/li\u003e\n\u003cli\u003eConda with Wave\u003c/li\u003e\n\u003cli\u003eSpack\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1676008940.0
  },
  {
    "data_format": 2,
    "description": "Dockerfile and Spack spec files for hardware optimized benchmark containers",
    "filenames": [
      "openfoam-amd/spack.yaml",
      "gromacs-amd/spack.yaml",
      "lammps-amd/spack.yaml",
      "nwchem-amd/spack.yaml",
      "namd-amd/spack.yaml",
      "hpcg-amd/spack.yaml",
      "wrf-amd/spack.yaml",
      "hmmer-amd/spack.yaml",
      "hpl-amd/spack.yaml",
      "quantum-espresso-amd/spack.yaml"
    ],
    "full_name": "dbkinghorn/Benchmark-Containers",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-benchmark-containers\" class=\"anchor\" aria-hidden=\"true\" href=\"#benchmark-containers\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBenchmark Containers\u003c/h1\u003e\n\u003cp\u003eThis is a collection of container spec files used to build the images available on \u003ca href=\"https://hub.docker.com/orgs/pugetsystems/repositories\" rel=\"nofollow\"\u003ehttps://hub.docker.com/orgs/pugetsystems/repositories\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eMost of these images are based on performance optimized application builds for specific hardware targets i.e. AMD Zen3, Zen4, Intel OneAPI, NVIDIA CUDA etc.\u003c/p\u003e\n\u003cp\u003eThese container images are the basis for some of our Scientific and Machine Learning benchmarks at \u003ca href=\"pugetsystems.com\"\u003ePuget Systems\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFiles for each application include,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSpack spec.yaml (build specifications with targeted optimizations)\u003c/li\u003e\n\u003cli\u003eDockerfiles (Multi-stage build/install)\u003c/li\u003e\n\u003cli\u003e*Enroot container-bundle (self running) build scripts\u003c/li\u003e\n\u003cli\u003eBenchmarks\u003c/li\u003e\n\u003cli\u003eUsage notes\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e* Enroot container bundles are self-running containers. No container runtime (docker) install is needed. These \".run\" files are generally too large to be hosted on GitHub. Download locations will be provided at a later time.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 2,
    "topics": [],
    "updated_at": 1676846633.0
  },
  {
    "data_format": 2,
    "description": "Container recipes used or maintained by EPSCI group",
    "filenames": [
      "geant4/spack.yaml"
    ],
    "full_name": "JeffersonLab/epsci-containers",
    "latest_release": null,
    "readme": "",
    "stargazers_count": 1,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1679432879.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack/agaspar/spack.yaml"
    ],
    "full_name": "lanl/cellar-gtest-mpi",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-google-test-for-mpi-gtest-mpi\" class=\"anchor\" aria-hidden=\"true\" href=\"#google-test-for-mpi-gtest-mpi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGoogle Test for MPI (gtest-mpi)\u003c/h1\u003e\n\u003cp\u003eThis is a support library that helps users write Google Test unit tests that\nrely on MPI.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-features\" class=\"anchor\" aria-hidden=\"true\" href=\"#features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFeatures\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSerialized and rank-tagged Google Test output.\u003c/li\u003e\n\u003cli\u003eRank-tagged failure reports.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e is the easiest way to install gtest-mpi. The gtest-mpi\npackage is available in\n\u003ca href=\"https://gitlab.lanl.gov/agaspar/spack-repo\" rel=\"nofollow\"\u003eagaspar/spack-repo\u003c/a\u003e. Follow the\nREADME there to use that spack repo. Once the agaspar-spack-repo repo is\ninstalled, installing gtest-mpi is as simple as running:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003espack install gtest-mpi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen you want to use gtest-mpi, run \u003ccode\u003espack load gtest-mpi\u003c/code\u003e to load it into your\ncurrent environment.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCMake\u003c/h3\u003e\n\u003cp\u003eIf you don\u0027t want to use spack, you can install gtest-mpi directly using CMake.\ngtest-mpi uses CMake, so all of your knowledge of CMake applies. gtest-mpi\nhas a dependency on Google Test, and uses\n\u003ca href=\"https://cmake.org/cmake/help/latest/module/FindGTest.html\" rel=\"nofollow\"\u003eFindGTest.cmake\u003c/a\u003e to\nfind it. Therefore, in order to install gtest-mpi, you must first have a\nworking installation of \u003ca href=\"https://github.com/google/googletest/\"\u003eGoogle Test\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOnce you\u0027ve installed Google Test, building and installing gtest-mpi is just\nlike any other modern CMake package.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone git@gitlab.lanl.gov:agaspar/gtest-mpi.git\ncd gtest-mpi\nmkdir build \u0026amp;\u0026amp; cd build\ncmake ..\nmake install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-using-gtest-mpi\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-gtest-mpi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing gtest-mpi\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-with-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#with-cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWith CMake\u003c/h3\u003e\n\u003cp\u003eIf you don\u0027t need any custom startup logic, using gtest-mpi in your own CMake\nproject is simple:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003efind_package\u003c/span\u003e(gtest-mpi 0.1 \u003cspan class=\"pl-k\"\u003eREQUIRED\u003c/span\u003e)\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e gtest-mpi-main provides a main function for you\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eadd_executable\u003c/span\u003e(my-test mytest.cpp)\n\u003cspan class=\"pl-c1\"\u003etarget_link_libraries\u003c/span\u003e(my-test gtest-mpi-main)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThen you can write a Google Test just like you normally would:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e mytest.cpp\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003egtest/gtest.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003empi.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-en\"\u003eTEST\u003c/span\u003e(GTestMPI, Basic) {\n    \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e rank;\n    \u003cspan class=\"pl-c1\"\u003eMPI_Comm_rank\u003c/span\u003e(MPI_COMM_WORLD, \u0026amp;rank);\n\n    \u003cspan class=\"pl-k\"\u003ebool\u003c/span\u003e is_root = rank == \u003cspan class=\"pl-c1\"\u003e0\u003c/span\u003e;\n\n    \u003cspan class=\"pl-k\"\u003ebool\u003c/span\u003e is_anyone_root = \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e;\n    \u003cspan class=\"pl-c1\"\u003eMPI_Allreduce\u003c/span\u003e(\n        \u0026amp;is_root, \u0026amp;is_anyone_root, \u003cspan class=\"pl-c1\"\u003e1\u003c/span\u003e, MPI_CXX_BOOL, MPI_LOR, MPI_COMM_WORLD);\n\n    \u003cspan class=\"pl-c1\"\u003eASSERT_TRUE\u003c/span\u003e(is_anyone_root);\n}\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you need to write your own main function, that\u0027s also fairly straighforward.\nIn your CMake project, you link against \u003ccode\u003egtest-mpi-lib\u003c/code\u003e instead of\n\u003ccode\u003egtest-mpi-main\u003c/code\u003e. Then you must provide your own main function:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e main.cpp\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003egtest-mpi/init.hpp\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003egtest/gtest.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003empi.h\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e \u003cspan class=\"pl-en\"\u003emain\u003c/span\u003e(\u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e argc, \u003cspan class=\"pl-k\"\u003echar\u003c/span\u003e **argv) {\n    \u003cspan class=\"pl-c1\"\u003etesting::InitGoogleTest\u003c/span\u003e(\u0026amp;argc, argv);\n    \u003cspan class=\"pl-c1\"\u003eMPI_Init\u003c/span\u003e(\u0026amp;argc, \u0026amp;argv);\n    \u003cspan class=\"pl-c1\"\u003egtest_mpi::init\u003c/span\u003e(\u0026amp;argc, \u0026amp;argv);\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Your custom init logic goes here\u003c/span\u003e\n\n    \u003cspan class=\"pl-k\"\u003eint\u003c/span\u003e exit_code = \u003cspan class=\"pl-c1\"\u003eRUN_ALL_TESTS\u003c/span\u003e();\n\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e Your custom finalize logic goes here\u003c/span\u003e\n\n    \u003cspan class=\"pl-c1\"\u003egtest_mpi::finalize\u003c/span\u003e();\n    \u003cspan class=\"pl-c1\"\u003eMPI_Finalize\u003c/span\u003e();\n\n    \u003cspan class=\"pl-k\"\u003ereturn\u003c/span\u003e exit_code;\n}\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-without-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#without-cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWithout CMake\u003c/h3\u003e\n\u003cp\u003eCMake is not required to use gtest-mpi, but it is recommended. If you wish to\nuse a different build system, then adding \u003ccode\u003e-lgtest-mpi-lib\u003c/code\u003e and (optionally)\n\u003ccode\u003e-lgtest-mpi-main\u003c/code\u003e to your link line will work.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-ctest\" class=\"anchor\" aria-hidden=\"true\" href=\"#ctest\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCTest\u003c/h2\u003e\n\u003cp\u003eHere\u0027s an example of adding a CTest using gtest-mpi to your CMake file:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eenable_testing\u003c/span\u003e()\n\n\u003cspan class=\"pl-c1\"\u003eadd_test\u003c/span\u003e(\n    \u003cspan class=\"pl-k\"\u003eNAME\u003c/span\u003e my-test\n    \u003cspan class=\"pl-k\"\u003eCOMMAND\u003c/span\u003e\n        \u003cspan class=\"pl-smi\"\u003e${MPIEXEC}\u003c/span\u003e \u003cspan class=\"pl-smi\"\u003e${MPIEXEC_NUMPROC_FLAG}\u003c/span\u003e 4 \u003cspan class=\"pl-smi\"\u003e${MPIEXEC_PREFLAGS}\u003c/span\u003e\n            $\u0026lt;\u003cspan class=\"pl-k\"\u003eTARGET_FILE\u003c/span\u003e:my-test\u0026gt; \u003cspan class=\"pl-smi\"\u003e${MPIEXEC_POSTFLAGS}\u003c/span\u003e)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThese tests can be run using \u003ccode\u003ectest\u003c/code\u003e.\u003c/p\u003e\n",
    "stargazers_count": 1,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1668046366.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "robertu94/poorjit",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-poorjit\" class=\"anchor\" aria-hidden=\"true\" href=\"#poorjit\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003epoorjit\u003c/h1\u003e\n\u003cp\u003eA poor man\u0027s jit for C++ for when you want to instantiate and call templates at\nruntime. Is there a more efficient way to do this? sure, but this is ~100 lines\nof code I wrote in less than an afternoon. Almost certainly only works on Linux\nand with either clang or g++.\u003c/p\u003e\n\u003cp\u003eSee \u003ccode\u003etest\u003c/code\u003e for a usage example.\u003c/p\u003e\n",
    "stargazers_count": 2,
    "subscribers_count": 1,
    "topics": [],
    "updated_at": 1668715291.0
  },
  {
    "data_format": 2,
    "description": "Spack production user software stack on the Gust test system",
    "filenames": [
      "spack.yaml"
    ],
    "full_name": "NCAR/spack-gust",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-ncar-spack-deployment\" class=\"anchor\" aria-hidden=\"true\" href=\"#ncar-spack-deployment\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eNCAR Spack Deployment\u003c/h1\u003e\n\u003cp\u003eThis branch tracks the \u003cstrong\u003eproduction\u003c/strong\u003e deployment of Spack for the following configuration:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003egust\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCreation date\u003c/td\u003e\n\u003ctd\u003eWed Mar 22 08:26:39 MDT 2023\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003encar-spack commit\u003c/td\u003e\n\u003ctd\u003efc3df9ab78502b74368eb656923301f672d491f6\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eHost version\u003c/td\u003e\n\u003ctd\u003e23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpack version\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eDeployment path\u003c/td\u003e\n\u003ctd\u003e/glade/u/apps/gust/23.03\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eEnvironments path\u003c/td\u003e\n\u003ctd\u003e/glade/work/csgteam/spack-deployments/gust/23.03/envs\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThis repository should \u003cem\u003eonly\u003c/em\u003e be updated via the \u003ccode\u003epublish\u003c/code\u003e script contained in the build environment. Any manual changes to this branch will cause headaches when you or another consultant attempt to publish new packages!\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 13,
    "topics": [],
    "updated_at": 1680620000.0
  },
  {
    "data_format": 2,
    "description": "memoized spack configs for some DOE systems",
    "filenames": [
      "anl/polaris/polaris.spack.yaml"
    ],
    "full_name": "jmellorcrummey/spack-configs",
    "latest_release": null,
    "readme": "\u003cp\u003eThis directory contains the various files, scripts, and instructions for installing hpctoolkit\nat various sites, using Spack to do the install.\u003c/p\u003e\n\u003cp\u003eThe top-level directory has an \u003ca href=\"install.txt\"\u003einstall.txt\u003c/a\u003e script with detailed,\nand hopefully, idiot-proof instructions for using Spack to install hpctoolkit.\u003c/p\u003e\n\u003cp\u003eIt has a \u003ccode\u003ebin\u003c/code\u003e directory, containing a script named \u003ccode\u003espacklink\u003c/code\u003e that will set up a spack\nrepository to do the installation at a specific \u003ccode\u003e\u0026lt;site\u0026gt;\u003c/code\u003e on a specific \u003ccode\u003e\u0026lt;machine\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eIt has a number of sub-directories, named by \u003ccode\u003e\u0026lt;site\u0026gt;\u003c/code\u003e.\nEach of those subdirectories contains one or more subdirectories, named by \u003ccode\u003e\u0026lt;machine\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eEach of those \u003ccode\u003e\u0026lt;site\u0026gt;/\u0026lt;machine\u0026gt;\u003c/code\u003e subdirectories contains several files:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.config.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003especifies the directories in which to put the module files and packages for a particular install.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.modules.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003especifies information about the modules to be built\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.packages.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003ethis includes configuration for the software environment, including MPI, CUDA, python, perl, etc.;\nspecifies the build-dependency version for installing hpctoolkit\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e\u0026lt;machine\u0026gt;.spack.yaml\u003c/code\u003e:\u003c/p\u003e\n\u003cp\u003ethis specifies a Spack environment file, which allows building several HPCToolkit configurations\nwith Spack in one go. If present, the \u003ccode\u003espacklink\u003c/code\u003e script will create a new directory parallel to\nthe Spack repository called \u003ccode\u003espack-env\u003c/code\u003e. The installation steps then become:\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e  $ spack/bin/spack -e spack-env concretize \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e add \"-f\" to re-concretize as needed\u003c/span\u003e\n  $ spack/bin/spack -e spack-env install\u003c/pre\u003e\u003c/div\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1658934301.0
  },
  {
    "data_format": 2,
    "description": "Repository for c2sm spack config and repo files",
    "filenames": [
      "upstreams/daint/spack.yaml"
    ],
    "full_name": "C2SM/spack-c2sm",
    "latest_release": "v0.18.1.3",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-the-spack-extension-of-c2sm-and-mch\" class=\"anchor\" aria-hidden=\"true\" href=\"#the-spack-extension-of-c2sm-and-mch\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe spack extension of C2SM and MCH\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/67d98f3f50b1ad629290b2fc5a38331fc19df5a656363fb14bdd892b371dcf0e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f616e7369636f6c6f72746167732f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/ansicolortags/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSpack is the package manager used by C2SM and MeteoSwiss to install and deploy software on supercomputers, local machines and the cloud.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-documentations\" class=\"anchor\" aria-hidden=\"true\" href=\"#documentations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentations\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eInfos about c2sm-supported software and machines\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/latest\" rel=\"nofollow\"\u003espack-c2sm latest\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.3\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.3\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.2\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://C2SM.github.io/spack-c2sm/v0.18.1.1\" rel=\"nofollow\"\u003espack-c2sm v0.18.1.1\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eGeneral infos about spack\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/\" rel=\"nofollow\"\u003eOfficial spack v0.18.1\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-workflow\" class=\"anchor\" aria-hidden=\"true\" href=\"#workflow\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWorkflow\u003c/h2\u003e\n\u003cp\u003eWith spack v0.18 we suggest local/individual spack instances and the use of spack environments.\u003c/p\u003e\n\u003cp\u003eA user clones the spack repo\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone --depth 1 --recurse-submodules --shallow-submodules -b v0.18.1.3 https://github.com/C2SM/spack-c2sm.git\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003egets spack in the command line\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e spack-c2sm/setup-env.sh\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eactivates an environment\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack env activate -p \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epath_to_env\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand starts exploring\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack info \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003epackage\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\nspack spec \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand building\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack install \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\nspack dev-build \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003espec\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ea package.\u003c/p\u003e\n\u003cp\u003eUpdating spack-c2sm is in the hands of the user.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit pull\ngit submodule update --recursive\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAfter an update we advice to clean\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003espack uninstall -a\nspack clean -a\nrm -rf \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/.spack\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand rebuild.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-command-cheat-sheet\" class=\"anchor\" aria-hidden=\"true\" href=\"#command-cheat-sheet\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCommand cheat sheet\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eCommand\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eClone\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003egit clone --depth 1 --recurse-submodules --shallow-submodules -b \u0026lt;branch/tag\u0026gt; https://github.com/C2SM/spack-c2sm.git\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLoad\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003e. spack-c2sm/setup-env.sh\u003c/code\u003e autodetects machine \u003cbr\u003eor\u003cbr\u003e\u003ccode\u003e. spack-c2sm/setup-env.sh \u0026lt;machine\u0026gt;\u003c/code\u003e forces machine\u003cbr\u003eor\u003cbr\u003e\u003ccode\u003e. spack-c2sm/setup-env.sh unknown\u003c/code\u003e uses blank config\u003cbr\u003e\u003ccode\u003espack compiler find\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-compiler-find\" rel=\"nofollow\"\u003eautodetects compilers\u003c/a\u003e\u003cbr\u003e\u003ccode\u003espack external find --all\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-external-find\" rel=\"nofollow\"\u003eautodetects externally installed packages\u003c/a\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eUpdate\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003egit pull\u003c/code\u003e\u003cbr\u003e\u003ccode\u003egit submodule update --recursive\u003c/code\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eClean\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack uninstall -a\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-uninstall\" rel=\"nofollow\"\u003euninstalls all packages\u003c/a\u003e\u003cbr\u003e\u003ccode\u003espack clean -a\u003c/code\u003e \u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-clean\" rel=\"nofollow\"\u003ecleans all misc caches\u003c/a\u003e\u003cbr\u003e\u003ccode\u003erm -rf ~/.spack\u003c/code\u003e removes user scope data\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies\" rel=\"nofollow\"\u003e\u003cstrong\u003eSpec syntax\u003c/strong\u003e\u003c/a\u003e: \u003ccode\u003e\u0026lt;package\u0026gt;\u003c/code\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#version-specifier\" rel=\"nofollow\"\u003e\u003ccode\u003e@\u0026lt;version\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-specifier\" rel=\"nofollow\"\u003e\u003ccode\u003e%\u0026lt;compiler\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#variants\" rel=\"nofollow\"\u003e\u003ccode\u003e+\u0026lt;variant\u0026gt; ~\u0026lt;variant\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#specs-dependencies\" rel=\"nofollow\"\u003e\u003ccode\u003e^\u0026lt;sub-package\u0026gt; +\u0026lt;sub-package-variant\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/basic_usage.html#compiler-flags\" rel=\"nofollow\"\u003e\u003ccode\u003e\u0026lt;compiler flags\u0026gt;\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e\u003c/th\u003e\n\u003cth\u003eCommand\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eFind\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack find\u003c/code\u003e lists all installed packages. \u003cbr\u003e\u003ccode\u003espack find \u0026lt;spec\u0026gt;\u003c/code\u003e lists all installed packages that match the spec.\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eInfo\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack info \u0026lt;package\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eSpec\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack spec \u0026lt;spec\u0026gt;\u003c/code\u003e concretizes abstract spec (unspecfied variant = \u003cstrong\u003eany\u003c/strong\u003e)\u003cbr\u003e\u003cem\u003eSpack is not required to use the default of an unspecified variant. The default value is only a tiebreaker for the concretizer.\u003c/em\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eInstall\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack install \u0026lt;spec\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eLocate\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack location --install-dir \u0026lt;spec\u0026gt;\u003c/code\u003e prints location of \u003cstrong\u003eall\u003c/strong\u003e installs that satisfy the spec\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/command_index.html?highlight=spack%20load#spack-load\" rel=\"nofollow\"\u003eLoad env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003ccode\u003espack load \u0026lt;spec\u0026gt;\u003c/code\u003e loads run environment\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/environments.html\" rel=\"nofollow\"\u003eActivate env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack env activate -p \u0026lt;env_name\u0026gt;\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ca href=\"https://spack.readthedocs.io/en/v0.18.1/environments.html\" rel=\"nofollow\"\u003eDeactivate env\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003espack deactivate\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 19,
    "topics": [],
    "updated_at": 1676997668.0
  },
  {
    "data_format": 2,
    "description": "This repository provides a set of configuration files and example scripts for running Mochi experiments on various platforms.",
    "filenames": [
      "ANL/Cooley/spack.yaml",
      "ORNL/Crusher/spack.yaml",
      "ANL/Theta/spack.yaml",
      "ANL/JLSE/spack.yaml",
      "ORNL/Summit/spack.yaml"
    ],
    "full_name": "mochi-hpc-experiments/platform-configurations",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-platform-configurations-for-mochi\" class=\"anchor\" aria-hidden=\"true\" href=\"#platform-configurations-for-mochi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePlatform configurations for Mochi\u003c/h1\u003e\n\u003cp\u003eThis repository provides Spack configuration files, example job scripts, and\nnotes about building and running Mochi-based codes on various platforms.\nPlease refer to the subdirectory for your platform of interest for more\ninformation.\u003c/p\u003e\n\u003cp\u003eThe \u003ccode\u003egeneric\u003c/code\u003e subdirectory contains a minimal Spack environment example that\ncan be used as a starting point for systems for which there is no existing\nrecipe.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-using-spackyaml-files\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-spackyaml-files\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing spack.yaml files\u003c/h2\u003e\n\u003cp\u003eEach platform subdirectory in this repository provides a \u003ccode\u003espack.yaml\u003c/code\u003e file.\nA \u003ccode\u003espack.yaml\u003c/code\u003e file fully describes a Spack environment, including\nsystem-provided packages and compilers. It does so independently of any\n\u003ccode\u003ecompilers.yaml\u003c/code\u003e or \u003ccode\u003epackages.yaml\u003c/code\u003e files installed in \u003ccode\u003e~/.spack\u003c/code\u003e, thereby\npreventing interference with user-specific spack configurations as much as\npossible.\u003c/p\u003e\n\u003cp\u003eYou may use \u003ccode\u003espack.yaml\u003c/code\u003e files to create a\n\u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003eSpack environment\u003c/a\u003e\nin which Mochi packages will be installed.\u003c/p\u003e\n\u003cp\u003eIf you don\u0027t have Spack installed on your platform, clone it and set it up\nas follows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/spack/spack.git\n$ . spack/share/spack/setup-env.sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eRemember that the second line needs to be executed every time you open a new\nterminal; it may be helpful to create an alias in your bashrc file as a\nshortcut.\u003c/p\u003e\n\u003cp\u003eYou will then need to clone \u003ccode\u003emochi-spack-packages\u003c/code\u003e, which contains the Mochi packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/mochi-hpc/mochi-spack-packages.git\n$ spack repo add mochi-spack-packages\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow clone the present repository and \u003ccode\u003ecd\u003c/code\u003e into the subdirectory relevant\nto your platform. For example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ git clone https://github.com/mochi-hpc-experiments/platform-configurations.git\n$ cd platform-configurations/ANL/Bebop\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEdit the path to \u003ccode\u003emochi-spack-packages\u003c/code\u003e in the \u003ccode\u003erepos\u003c/code\u003e field of the \u003ccode\u003espack.yaml\u003c/code\u003e file to\nmatch your installation.\u003c/p\u003e\n\u003cp\u003eThen, execute the following command\n(changing \u003cem\u003emyenv\u003c/em\u003e into an appropriate name for your environment).\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack env create myenv spack.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eChange to a directory outside of the \u003ccode\u003eplatform-configurations\u003c/code\u003e folders\nand activate the environment as follows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack env activate myenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou may now add specs to your environment. For instance if you want\nto install Margo, execute the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack add mochi-margo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIf the \u003ccode\u003espack.yaml\u003c/code\u003e file provides multiple compilers and you want\nto use another than the default one, specify the compiler explicitely,\nfor example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack add mochi-margo %gcc@8.2.0\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote that the \u003ccode\u003espack.yaml\u003c/code\u003e file you used may already have a spec\nadded as an example (usually \u003ccode\u003emochi-margo\u003c/code\u003e). You can remove it as\nfollows.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack rm mochi-margo\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you have added the specs you need in your environment, install\neverything by executing the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ spack install\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou may add more specs later on. For more information on how to manage\nSpack environments, please refer to the Spack documentation.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contributing-to-this-repository\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-to-this-repository\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing to this repository\u003c/h2\u003e\n\u003cp\u003eShould you want to contribute a \u003ccode\u003espack.yaml\u003c/code\u003e for a particular machine,\nplease submit a merge request with it, and ensure the following.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should contain the compiler(s) that have been tested\nand confirmed to work with Mochi packages.\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should try to list system-provided packages,\nin particular packages used for building (\u003ccode\u003ecmake\u003c/code\u003e, \u003ccode\u003eautoconf\u003c/code\u003e, etc.),\nand relevant system-provided MPI implementations.\n\u003cul\u003e\n\u003cli\u003eNote that this must be done manually.  Spack provides a \u003ccode\u003espack external find\u003c/code\u003e command that can be used to locate a subset of system packages,\nbut it does not populate the \u003ccode\u003espack.yaml\u003c/code\u003e file.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThe \u003ccode\u003espack.yaml\u003c/code\u003e file should contain the relevant variants for packages,\nin particular the transport methods to use with \u003ccode\u003elibfabric\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eThe path to the \u003ccode\u003espack.yaml\u003c/code\u003e file should be of the form\n\u003ccode\u003e\u0026lt;institution\u0026gt;/\u0026lt;platform\u0026gt;/spack.yaml\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003ePlease make sure that your \u003ccode\u003espack.yaml\u003c/code\u003e is a reliable way to work with\nMochi on the target platform, other people will rely on it!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can also contribute changes to existing \u003ccode\u003espack.yaml\u003c/code\u003e files, in particular\nto add working compilers, system packages, etc. As always, please test that\nnew setups work before creating a merge request.\u003c/p\u003e\n",
    "stargazers_count": 3,
    "subscribers_count": 3,
    "topics": [],
    "updated_at": 1677790084.0
  },
  {
    "data_format": 2,
    "description": "Documentations and tutorials for Margo, Thallium, Argobots, Mercury, and other Mochi libraries.",
    "filenames": [
      "code/spack.yaml"
    ],
    "full_name": "mochi-hpc/mochi-doc",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg\"\u003e\u003cimg src=\"https://github.com/mochi-hpc/mochi-doc/actions/workflows/build.yml/badge.svg\" alt=\"build\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-mochi-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#mochi-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMochi documentation\u003c/h1\u003e\n\u003cp\u003eThis repository contains a Sphinx-based documentation\nfor the Mochi libraries: Margo, Thallium, Argobots, Mercury,\nABT-IO, and SSG, as well as corresponding code examples.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building-the-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-the-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the documentation\u003c/h2\u003e\n\u003cp\u003eTo build and/or contribute to this documentation, you must have a Sphinx and\na few related extensions installed.  These can be installed as follows using\nPython\u0027s \u003ccode\u003epip\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003epip install sphinx\npip install sphinx_rtd_theme\npip install sphinx_copybutton\npip install recommonmark\npip install breathe\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou must also install the \u003ccode\u003edoxygen\u003c/code\u003e documentation system.  This is likely\navailable in your platform\u0027s primary package manager.  For example on Ubuntu:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt install doxygen\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce you have these dependencies installed, clone this\nrepository and cd into it. You can change the documentation\nby editing the files in the source subdirectory (these files\nuse the .rst format). You can build the documentation\nusing the following command.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd docs\nmake html\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd check the result by opening the \u003ccode\u003ebuild/html/index.html\u003c/code\u003e page\nthat has been created in the docs directory.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building-the-code-examples\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-the-code-examples\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding the code examples\u003c/h2\u003e\n\u003cp\u003eTo build the code, you will need spack and the\n\u003ca href=\"https://github.com/mochi-hpc/mochi-spack-packages\"\u003emochi repo\u003c/a\u003e setup.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd code\nspack env create mochi-doc-env spack.yaml\nspack env activate mochi-doc-env\nspack install\nmkdir build\ncd build\ncmake .. -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_C_COMPILER=mpicc\nmake\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 4,
    "subscribers_count": 4,
    "topics": [],
    "updated_at": 1668505847.0
  },
  {
    "data_format": 2,
    "description": "Bash shell script for installing xSDK and other IDEAS packages",
    "filenames": [
      "platformFiles/crusher/PrgEnv-cray/spack.yaml",
      "platformFiles/lassen/spack.yaml",
      "platformFiles/summit/spack.yaml",
      "platformFiles/crusher/PrgEnv-gnu/spack.yaml",
      "platformFiles/polaris/gcc-11.2.0/spack.yaml"
    ],
    "full_name": "xsdk-project/installxSDK",
    "latest_release": "v0.1.1",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-useful-supplementary-materials-for-installing-the-xsdk\" class=\"anchor\" aria-hidden=\"true\" href=\"#useful-supplementary-materials-for-installing-the-xsdk\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUseful supplementary materials for installing the xSDK\u003c/h1\u003e\n\u003cp\u003eSee \u003ca href=\"https://xsdk.info/download/\" rel=\"nofollow\"\u003ehttps://xsdk.info/download/\u003c/a\u003e for full directions on obtaining the xSDK.\u003c/p\u003e\n\u003cp\u003eThe primary content of this repository includes packages.yaml and\ncompilers.yaml files, as well as other files useful for configuring builds of\nthe xSDK through Spack for various platforms.\u003c/p\u003e\n\u003cp\u003eThe files are arranged generally as follows:\u003c/p\u003e\n\u003cp\u003einstallxSDK/platformFiles/\u0026lt;platform description\u0026gt;/\u0026lt;files for platfom\u0026gt;\u003c/p\u003e\n\u003cp\u003eThis repository is to be tagged for each major and minor release of the xSDK.\u003c/p\u003e\n",
    "stargazers_count": 5,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1669065329.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "buildspecs/apps/e4s/22.05/spack.yaml",
      "buildspecs/apps/e4s/22.02/spack.yaml"
    ],
    "full_name": "buildtesters/buildtest-nersc",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-buildtest-nersc\" class=\"anchor\" aria-hidden=\"true\" href=\"#buildtest-nersc\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ebuildtest-nersc\u003c/h1\u003e\n\u003cp\u003eThis repository contains tests for Cori and Perlmutter using the \u003ca href=\"https://buildtest.readthedocs.io/en/devel/\" rel=\"nofollow\"\u003ebuildtest\u003c/a\u003e framework.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-useful-links\" class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUseful Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCDASH: \u003ca href=\"https://my.cdash.org/index.php?project=buildtest-nersc\" rel=\"nofollow\"\u003ehttps://my.cdash.org/index.php?project=buildtest-nersc\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eUpstream Repo: \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc\" rel=\"nofollow\"\u003ehttps://software.nersc.gov/NERSC/buildtest-nersc\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eGithub Mirror Repo: \u003ca href=\"https://github.com/buildtesters/buildtest-nersc\"\u003ehttps://github.com/buildtesters/buildtest-nersc\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-buildtest-references\" class=\"anchor\" aria-hidden=\"true\" href=\"#buildtest-references\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuildtest References\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDocumentation: \u003ca href=\"https://buildtest.readthedocs.io/en/devel/\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSchema Docs: \u003ca href=\"https://buildtesters.github.io/buildtest/\" rel=\"nofollow\"\u003ehttps://buildtesters.github.io/buildtest/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSlack Channel: \u003ca href=\"https://hpcbuildtest.slack.com\" rel=\"nofollow\"\u003ehttps://hpcbuildtest.slack.com\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eGetting Started: \u003ca href=\"https://buildtest.readthedocs.io/en/devel/getting_started.html\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/getting_started.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eWriting Buildspecs: \u003ca href=\"https://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/buildspec_tutorial.html\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eContributing Guide: \u003ca href=\"https://buildtest.readthedocs.io/en/devel/contributing.html\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/contributing.html\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetup\u003c/h2\u003e\n\u003cp\u003eTo get started, please \u003ca href=\"https://docs.nersc.gov/connect/\" rel=\"nofollow\"\u003econnect to NERSC system\u003c/a\u003e and clone this repo and buildtest:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/buildtesters/buildtest\ngit clone https://software.nersc.gov/NERSC/buildtest-nersc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNote if you don\u0027t have access to Gitlab server you may clone the mirror on Github:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003egit clone https://github.com/buildtesters/buildtest-nersc\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou will need python 3.7 or higher to \u003ca href=\"https://buildtest.readthedocs.io/en/devel/installing_buildtest.html\" rel=\"nofollow\"\u003einstall buildtest\u003c/a\u003e, on Cori/Perlmutter this can be done by loading \u003cstrong\u003epython\u003c/strong\u003e\nmodule and create a conda environment as shown below.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emodule load python\nconda create -n buildtest\nconda activate buildtest\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow let\u0027s install buildtest, assuming you have cloned buildtest in $HOME directory source the setup script. For csh users you need to source \u003cstrong\u003esetup.csh\u003c/strong\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esource ~/buildtest/setup.sh\n\n# csh users\nsource ~/buildtest/setup.csh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNext, navigate to \u003ccode\u003ebuildtest-nersc\u003c/code\u003e directory and set environment \u003ccode\u003eBUILDTEST_CONFIGFILE\u003c/code\u003e to point to \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/config.yml\" rel=\"nofollow\"\u003econfig.yml\u003c/a\u003e which is the configuration file for NERSC system.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd buildtest-nersc\nexport BUILDTEST_CONFIGFILE=$(pwd)/config.yml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMake sure the configuration is valid, this can be done by running the following. buildtest will validate the configuration file with the JSON schema :\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest config validate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ePlease make sure you are using tip of \u003ca href=\"https://github.com/buildtesters/buildtest/tree/devel\"\u003edevel\u003c/a\u003e branch of buildtest when writing tests. You should sync your local devel branch with upstream\nfork, for more details see \u003ca href=\"https://buildtest.readthedocs.io/en/devel/contributing/code_contribution_guide.html\" rel=\"nofollow\"\u003econtributing guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFirst time around you should discover all buildspecs this can be done via \u003ccode\u003ebuildtest buildspec find\u003c/code\u003e.  The command below will find\nand validate all buildspecs in the \u003cstrong\u003ebuildtest-nersc\u003c/strong\u003e repo and load them in buildspec cache. Note that one needs to specify \u003ccode\u003e--root\u003c/code\u003e to specify location where\nall buildspecs are located, we have not configured \u003ca href=\"https://buildtest.readthedocs.io/en/devel/configuring_buildtest/overview.html#buildspec-roots\" rel=\"nofollow\"\u003ebuildspec_root\u003c/a\u003e in the configuration file since we don\u0027t have a central location where this repo will reside.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecd buildtest-nersc\nbuildtest buildspec find --root buildspecs --rebuild -q\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe buildspecs are loaded in buildspec cache file (JSON) that is used by \u003ccode\u003ebuildtest buildspec find\u003c/code\u003e for querying cache. Subsequent runs will\nread from cache.  For more details see \u003ca href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/buildspecs_interface.html\" rel=\"nofollow\"\u003ebuildspec interface\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building-tests\" class=\"anchor\" aria-hidden=\"true\" href=\"#building-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding Tests\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eNote: All tests are written in YAML using .yml extension\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eTo build tests use \u003ccode\u003ebuildtest build\u003c/code\u003e command for example we build all tests in \u003ccode\u003esystem\u003c/code\u003e directory as follows\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest build -b system/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can specify multiple buildspecs either files or directory via \u003ccode\u003e-b\u003c/code\u003e option\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest build -b slurm/partition.yml -b slurmutils/\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can exclude a buildspec via \u003ccode\u003e-x\u003c/code\u003e option this behaves same way as \u003ccode\u003e-b\u003c/code\u003e option so you can specify\na directory or filepath which could be absolute path, or relative path. This is useful when\nyou want to run multiple tests grouped in directory but exclude a few.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest build -b slurm -x slurm/sinfo.yml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ebuildtest can run tests via tags which can be useful when grouping tests, to see a list of available tags you\ncan run: \u003ccode\u003ebuildtest buildspec find --tags\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eFor instance if you want to run all \u003ccode\u003elustre\u003c/code\u003e tests you can run the following:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest build --tags lustre\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFor more details on buildtest test please see the \u003ca href=\"https://buildtest.readthedocs.io/en/devel/getting_started.html\" rel=\"nofollow\"\u003ebuildtest tutorial\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-tags-breakdown\" class=\"anchor\" aria-hidden=\"true\" href=\"#tags-breakdown\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTags Breakdown\u003c/h2\u003e\n\u003cp\u003eWhen you write buildspecs, please make sure you attach one or more \u003ccode\u003etags\u003c/code\u003e to the test that way your test will get picked up during one of the CI checks. Shown\nbelow is a summary of tag description\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003edaily\u003c/strong\u003e - this tag is used for running daily system checks using gitlab CI. Tests should run relatively quick\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003esystem\u003c/strong\u003e - this tag is used for classifying all system tests that may include: system configuration, servers, network, cray tests. This tag should be used\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eslurm\u003c/strong\u003e - this tag is used for slurm test that includes slurm utility check, slurm controller, etc... This tag \u003cstrong\u003eshouldn\u0027t\u003c/strong\u003e be used for job submission that is managed by \u003cstrong\u003ejobs\u003c/strong\u003e tag. The \u003ccode\u003eslurm\u003c/code\u003e tag tests should be short running test that use a Local Executor.\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003ejobs\u003c/strong\u003e - this tag is used for testing slurm policies by submitting jobs to scheduler.\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003ecompile\u003c/strong\u003e - this tag is used for compilation of application (OpenMP, MPI, OpenACC, CUDA, upc, bupc, etc...)\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003ee4s\u003c/strong\u003e - this tag is used for running tests for E4S stack via \u003ccode\u003espack test\u003c/code\u003e or \u003ca href=\"https://github.com/E4S-Project/testsuite\"\u003eE4S Testsuite\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003emodule\u003c/strong\u003e - this tag is used for testing module system\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003ebenchmark\u003c/strong\u003e - this tag is used for benchmark tests. This can be application benchmarks, mini-benchmarks, kernels, etc...\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can see breakdown of tags and buildspec summary with the following commands\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ebuildtest buildspec summary\nbuildtest buildspec find --group-by-tags\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e\u003ca id=\"user-content-querying-tests\" class=\"anchor\" aria-hidden=\"true\" href=\"#querying-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eQuerying Tests\u003c/h2\u003e\n\u003cp\u003eYou can use \u003ccode\u003ebuildtest report\u003c/code\u003e and \u003ccode\u003ebuildtest inspect\u003c/code\u003e to query tests. The commands differ slightly and data is\nrepresented differently. The \u003ccode\u003ebuildtest report\u003c/code\u003e command will show output in tabular form and only show some of the metadata,\nif you want to access the entire test record use \u003ccode\u003ebuildtest inspect\u003c/code\u003e command which displays the content in JSON format.\nFor more details on querying tests see \u003ca href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-ci-setup\" class=\"anchor\" aria-hidden=\"true\" href=\"#ci-setup\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCI Setup\u003c/h2\u003e\n\u003cp\u003eTests are run on schedule basis with one schedule corresponding to one gitlab job in \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/.gitlab-ci.yml\" rel=\"nofollow\"\u003e.gitlab-ci.yml\u003c/a\u003e. The scheduled pipelines are configured in\n\u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules\" rel=\"nofollow\"\u003ehttps://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules\u003c/a\u003e. Each schedule has a variable \u003ccode\u003eTESTNAME\u003c/code\u003e defined to control which pipeline\nis run since we have multiple gitlab jobs. In the \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e we make use of conditional rules using \u003ca href=\"https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic\" rel=\"nofollow\"\u003eonly\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe scheduled jobs are run at different intervals (1x/day, 1x/week, etc...) at different times of day to avoid overloading the system. The gitlab jobs\nwill run jobs based on tags, alternately some tests may be defined by running all tests in a directory (\u003ccode\u003ebuildtest build -b apps\u003c/code\u003e). If you want to add a new\nscheduled job, please define a \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/pipeline_schedules/new\" rel=\"nofollow\"\u003enew schedule\u003c/a\u003e with an appropriate time. The\n\u003ccode\u003etarget branch\u003c/code\u003e should be \u003ccode\u003edevel\u003c/code\u003e and define a unique variable used to distinguish scheduled jobs. Next, create a job in \u003ccode\u003e.gitlab-ci.yml\u003c/code\u003e that references the scheduled job and define variable \u003ccode\u003eTESTNAME\u003c/code\u003e in the scheduled pipeline.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-integrations\" class=\"anchor\" aria-hidden=\"true\" href=\"#integrations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIntegrations\u003c/h2\u003e\n\u003cp\u003eThis project has integration with Slack to notify CI builds to \u003ca href=\"https://hpcbuildtest.slack.com\" rel=\"nofollow\"\u003ebuildtest Slack\u003c/a\u003e at \u003cstrong\u003e#buildtest-nersc\u003c/strong\u003e workspace. The integrations can be\nfound at \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations\" rel=\"nofollow\"\u003ehttps://software.nersc.gov/NERSC/buildtest-nersc/-/settings/integrations\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThis project has setup a push mirror to \u003ca href=\"https://github.com/buildtesters/buildtest-nersc\"\u003ehttps://github.com/buildtesters/buildtest-nersc\u003c/a\u003e which can be seen at \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository\" rel=\"nofollow\"\u003ehttps://software.nersc.gov/NERSC/buildtest-nersc/-/settings/repository\u003c/a\u003e\nunder \u003cstrong\u003eMirroring Repositories\u003c/strong\u003e. If the push mirror is not setup, please add the mirror.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-cdash\" class=\"anchor\" aria-hidden=\"true\" href=\"#cdash\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCDASH\u003c/h2\u003e\n\u003cp\u003ebuildtest will push test results to \u003ca href=\"https://www.cdash.org/\" rel=\"nofollow\"\u003eCDASH\u003c/a\u003e server\nat \u003ca href=\"https://my.cdash.org/index.php?project=buildtest-nersc\" rel=\"nofollow\"\u003ehttps://my.cdash.org/index.php?project=buildtest-nersc\u003c/a\u003e using \u003ccode\u003ebuildtest cdash upload\u003c/code\u003e command.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contributing-guide\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-guide\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing Guide\u003c/h2\u003e\n\u003cp\u003eTo contribute back you will want to make sure your buildspec is validated before you contribute back, this could be\ndone by running test manually \u003ccode\u003ebuildtest build\u003c/code\u003e or see if buildspec is valid via \u003ccode\u003ebuildtest buildspec find\u003c/code\u003e. It\nwould be good to run your test and make sure it is working as expected, you can view test detail using \u003ccode\u003ebuildtest inspect name \u0026lt;testname\u0026gt;\u003c/code\u003e or \u003ccode\u003ebuildtest inspect query \u0026lt;testname\u0026gt;\u003c/code\u003e. For more\ndetails on querying test please see \u003ca href=\"https://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\" rel=\"nofollow\"\u003ehttps://buildtest.readthedocs.io/en/devel/gettingstarted/query_test_report.html\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eIf you want to contribute your tests, please see \u003ca href=\"https://software.nersc.gov/NERSC/buildtest-nersc/-/blob/devel/CONTRIBUTING.md\" rel=\"nofollow\"\u003eCONTRIBUTING.md\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-submitting-an-issue\" class=\"anchor\" aria-hidden=\"true\" href=\"#submitting-an-issue\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSubmitting an Issue\u003c/h2\u003e\n\u003cp\u003ePlease submit all issues to \u003ca href=\"https://github.com/buildtesters/buildtest-nersc/issues\"\u003ehttps://github.com/buildtesters/buildtest-nersc/issues\u003c/a\u003e. When creating an issue, please see the \u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels\"\u003elabels\u003c/a\u003e\nand try to select one or more labels to categorize issue. Please use the following labels depending on the type of issue you are reporting\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/bug\"\u003eBug\u003c/a\u003e: When creating an issue related to a test bug\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/new-test\"\u003enew-test\u003c/a\u003e: An issue for adding a new test\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/E4S-Testsuite\"\u003eE4S-Testsuite\u003c/a\u003e: Issues related to \u003ca href=\"https://github.com/E4S-Project/testsuite\"\u003eE4S testsuite project\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/spack\"\u003espack\u003c/a\u003e: Issues related to \u003ccode\u003espack test\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/documentation\"\u003edocumentation\u003c/a\u003e: Issues with documentation such as README.md, CONTRIBUTING.md\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/buildtesters/buildtest-nersc/labels/gitlab-ci\"\u003egitlab-ci\u003c/a\u003e: Issues with Gitlab CI/CD\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 6,
    "subscribers_count": 4,
    "topics": [
      "buildtest"
    ],
    "updated_at": 1671402594.0
  },
  {
    "data_format": 2,
    "description": "AsterX is a GPU-accelerated GRMHD code for dynamical spacetimes",
    "filenames": [
      "Docs/compile-notes/frontera-bitbucket/CPU/spack.yaml",
      "Docs/compile-notes/frontera-github/CPU/spack.yaml",
      "Docs/compile-notes/frontera-bitbucket/GPU/spack.yaml",
      "Docs/compile-notes/frontera-github/GPU/spack.yaml"
    ],
    "full_name": "jaykalinani/AsterX",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"Docs/figures/asterx.png\"\u003e\u003cimg align=\"top\" src=\"Docs/figures/asterx.png\" width=\"140\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAsterX\u003c/strong\u003e is a GPU-accelerated GRMHD code for dynamical spacetimes, written in C++. It is built upon the \u003ca href=\"https://github.com/eschnett/CarpetX\"\u003eCarpetX\u003c/a\u003e driver, which is intended for the \u003ca href=\"https://einsteintoolkit.org/\" rel=\"nofollow\"\u003eEinstein Toolkit\u003c/a\u003e. \u003cstrong\u003eCarpetX\u003c/strong\u003e is based on \u003ca href=\"https://amrex-codes.github.io\" rel=\"nofollow\"\u003eAMReX\u003c/a\u003e, a software framework for block-structured AMR (adaptive mesh refinement).\u003c/p\u003e\n\u003cp\u003eFull documentation will soon be available at \u003ca href=\"https://asterx.readthedocs.io/en/latest/#\" rel=\"nofollow\"\u003easterx.readthedocs.io\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jaykalinani/AsterX/actions\"\u003e\u003cimg src=\"https://github.com/jaykalinani/AsterX/workflows/CI/badge.svg\" alt=\"GitHub CI\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e  \u003ca href=\"https://asterx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8257fa34c1c5b6c660b31bf16a6196859c354c9c503b7742e1cdee871fbb96c8/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6173746572782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/asterx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca href=\"https://github.com/jaykalinani/AsterX/blob/main/LICENSE.md\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b768fc44ae95216e4b53ff734978771466ba222596e760da27e9e60a0d47d6f7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4c47504c5f76332d626c75652e737667\" alt=\"License: LGPL v3\" data-canonical-src=\"https://img.shields.io/badge/License-LGPL_v3-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eHeavily derived from the GRMHD code \u003ca href=\"https://zenodo.org/record/4350072\" rel=\"nofollow\"\u003eSpritz\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eSolves the GRMHD equations in 3D Cartesian coordinates and on dynamical spacetimes using high-resolution shock capturing (HRSC) schemes.\u003c/li\u003e\n\u003cli\u003eBased on the flux-conservative Valencia formulation.\u003c/li\u003e\n\u003cli\u003eDirectly evolves the staggered vector potential.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-available-modules\" class=\"anchor\" aria-hidden=\"true\" href=\"#available-modules\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAvailable modules\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eAsterX\u003c/code\u003e - the core GRMHD module\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eAsterSeeds\u003c/code\u003e - initial data module\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eCon2PrimFactory\u003c/code\u003e - module providing different conservative-to-primitive variable recovery routines\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eEOSX\u003c/code\u003e - equation of state driver\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eTOVSolver\u003c/code\u003e - a modified version of the publicly available TOVSolver thorn used within the Einstein Toolkit\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting started\u003c/h2\u003e\n\u003cp\u003eInstructions for downloading and building the Einstein Toolkit including\nCarpetX can be found \u003ca href=\"https://github.com/eschnett/CarpetX\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eDetails for building and running AsterX along with CarpetX will be added to \u003ca href=\"https://asterx.readthedocs.io/en/latest/#\" rel=\"nofollow\"\u003easterx.readthedocs.io\u003c/a\u003e soon..\u003c/p\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1679282900.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "spack-configs/perlmutter-e4s-22.05/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/cce/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/prod/nvhpc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/prod/cce/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/prod/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/prod/nvhpc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/nvhpc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/cuda/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/gcc/spack.yaml",
      "spack-configs/perlmutter-e4s-22.11/prod/cuda/spack.yaml",
      "spack-configs/perlmutter-e4s-21.11/ci/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/cuda/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/prod/cce/spack.yaml",
      "spack-configs/perlmutter-user-spack/spack.yaml",
      "spack-configs/perlmutter-e4s-22.05/cce/spack.yaml"
    ],
    "full_name": "NERSC/spack-infrastructure",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-infrastructure\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-infrastructure\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack Infrastructure\u003c/h1\u003e\n\u003cp\u003eThe spack infrastructure repository contains spack configuration in the form of \u003ccode\u003espack.yaml\u003c/code\u003e required to build spack stacks on Cori and Perlmutter system. We leverage gitlab to automate software stack deployment which is configured using the \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\" rel=\"nofollow\"\u003e.gitlab-ci.yml\u003c/a\u003e file. The documentation is available at \u003ca href=\"https://nersc-spack-infrastructure.rtfd.io\" rel=\"nofollow\"\u003ehttps://nersc-spack-infrastructure.rtfd.io\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-spack-configuration\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-configuration\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack Configuration\u003c/h2\u003e\n\u003cp\u003eThe spack configuration can be found in \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/tree/main/spack-configs\" rel=\"nofollow\"\u003espack-configs\u003c/a\u003e directory with subdirectory for each deployment.\nEach pipeline can be run if one sets the variable \u003ccode\u003ePIPELINE_NAME\u003c/code\u003e to a unique value in order to run a pipeline. You can check the \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/blob/main/.gitlab-ci.yml\" rel=\"nofollow\"\u003e.gitlab-ci.yml\u003c/a\u003e for the gitlab configuration. The pipeline can be run via \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"nofollow\"\u003eweb interface\u003c/a\u003e, if you chose this route, you must set \u003ccode\u003ePIPELINE_NAME\u003c/code\u003e to the appropriate value.\u003c/p\u003e\n\u003cp\u003eIf you want to trigger pipeline via \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipelines/new\" rel=\"nofollow\"\u003eweb-interface\u003c/a\u003e you will need to define PIPELINE_NAME variable to trigger the appropriate pipeline.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-running-ci-pipelines\" class=\"anchor\" aria-hidden=\"true\" href=\"#running-ci-pipelines\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRunning CI Pipelines\u003c/h2\u003e\n\u003cp\u003eThis project is configured with several \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/pipeline_schedules\" rel=\"nofollow\"\u003escheduled pipelines\u003c/a\u003e that will run at different times.\u003c/p\u003e\n\u003cp\u003eCurrently, we have a shell runner installed on Perlmutter using \u003ccode\u003ee4s\u003c/code\u003e account which is configured with following settings. You can find list of runners and their runner status under \u003ca href=\"https://software.nersc.gov/NERSC/spack-infrastructure/-/settings/ci_cd\" rel=\"nofollow\"\u003eSettings \u0026gt; CI/CD \u0026gt; Runners\u003c/a\u003e. Please make sure you login to the appropriate hostname when starting the gitlab runner.\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eSystem\u003c/th\u003e\n\u003cth\u003eRunner Name\u003c/th\u003e\n\u003cth\u003eHostname\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eperlmutter\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003eperlmutter-e4s\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003elogin27\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecori\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ecori-e4s\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003ecori02\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emuller\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003emuller-e4s\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003elogin02\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egerty\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003egerty-e4s\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ccode\u003egert01\u003c/code\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eThe runner configuration files are located in \u003ccode\u003e~/.gitlab-runner\u003c/code\u003e for user \u003cstrong\u003ee4s\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eThe production pipelines are triggered via web-interface which requires approval from a project maintainer. Production pipelines should be run when we need to do full redeployment of stack.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-current-challenges\" class=\"anchor\" aria-hidden=\"true\" href=\"#current-challenges\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCurrent Challenges\u003c/h2\u003e\n\u003cp\u003eThere are several challenges with building spack stack at NERSC which can be summarized as follows\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSystem OS + Cray Programming Environment (CPE) changes\u003c/strong\u003e: A system upgrade such as change to \u003ccode\u003eglibc\u003c/code\u003e or upgrades in CPE can lead to full software stack rebuild, especially if you have external packages set for packages like \u003ccode\u003ecray-mpich\u003c/code\u003e, \u003ccode\u003ecray-libsci\u003c/code\u003e which generally change between versions\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eIncompatibile compilers\u003c/strong\u003e: Some packages can\u0027t be built with certain compilers (\u003ccode\u003envhpc\u003c/code\u003e, \u003ccode\u003eaocc\u003c/code\u003e) which could be due to several factors.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAn application doesn\u0027t have support though it was be added in newer version but you don\u0027t have it in your spack release used for deployment\u003c/li\u003e\n\u003cli\u003eLack of support in spack package recipe or spack-core base including spack-cray detection. This may require getting fix and cherry-pick commit or waiting for new version\u003c/li\u003e\n\u003cli\u003eSpack Cray detection is an important part in build errors including how one specifies externals via \u003ccode\u003emodules\u003c/code\u003e vs \u003ccode\u003eprefix\u003c/code\u003e both could be provided and it requires experimentation. An example of this is trying to get \u003ccode\u003ecray-mpich\u003c/code\u003e external one could set something like this with modules or prefix\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"highlight highlight-source-yaml\"\u003e\u003cpre\u003e  \u003cspan class=\"pl-ent\"\u003ecray-mpich\u003c/span\u003e:\n    \u003cspan class=\"pl-ent\"\u003ebuildable\u003c/span\u003e: \u003cspan class=\"pl-c1\"\u003efalse\u003c/span\u003e\n    \u003cspan class=\"pl-ent\"\u003eexternals\u003c/span\u003e:\n    - \u003cspan class=\"pl-ent\"\u003espec\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003ecray-mpich@8.1.11 %gcc@9.3.0\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003eprefix\u003c/span\u003e: \u003cspan class=\"pl-s\"\u003e/opt/cray/pe/mpich/8.1.11/ofi/gnu/9.1\u003c/span\u003e\n      \u003cspan class=\"pl-ent\"\u003emodules\u003c/span\u003e:\n      - \u003cspan class=\"pl-s\"\u003ecray-mpich/8.1.11\u003c/span\u003e\n      - \u003cspan class=\"pl-s\"\u003ecudatoolkit/21.9_11.4\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eSpack concretizer\u003c/strong\u003e prevent one from chosing a build configration for a spec. This requires a few troubleshooting step but usually boils down to:\n\u003cul\u003e\n\u003cli\u003eRead the spack package file \u003ccode\u003espack edit \u0026lt;package\u0026gt;\u003c/code\u003e for conflicts and try \u003ccode\u003espack spec\u003c/code\u003e to see concretized spec.\u003c/li\u003e\n\u003cli\u003eTry different version, different compiler, different dependency. Some packages have conflicting variant for instance one can\u0027t enable \u003ccode\u003e+openmp\u003c/code\u003e and \u003ccode\u003e+pthread\u003c/code\u003e it is mutually exclusive.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThere is a document \u003ca href=\"https://docs.google.com/document/d/1jWrCcK8LgpNDMytXhLdBYpIusidkoowrZAH1zos7zIw/edit?usp=sharing\" rel=\"nofollow\"\u003eSpack E4S Issues on Permlutter\u003c/a\u003e outlining current issues with spack. If you need access to document please contact \u003cstrong\u003eShahzeb Siddiqui\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"#contact\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContact\u003c/h2\u003e\n\u003cp\u003eIf you need elevated privledge or assistance with this project please contact one of the maintainers:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eShahzeb Siddiqui (\u003ca href=\"mailto:shahzebsiddiqui@lbl.gov\"\u003eshahzebsiddiqui@lbl.gov\u003c/a\u003e)\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eErik Palmer (\u003ca href=\"mailto:epalmer@lbl.gov\"\u003eepalmer@lbl.gov\u003c/a\u003e)\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eJustin Cook (\u003ca href=\"mailto:JSCook@lbl.gov\"\u003eJSCook@lbl.gov\u003c/a\u003e)\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eE4S Team: \u003cstrong\u003eSameer Shende (\u003ca href=\"mailto:sameer@cs.uoregon.edu\"\u003esameer@cs.uoregon.edu\u003c/a\u003e)\u003c/strong\u003e, \u003cstrong\u003eChristopher Peyralans (\u003ca href=\"mailto:lpeyrala@uoregon.edu\"\u003elpeyrala@uoregon.edu\u003c/a\u003e)\u003c/strong\u003e, \u003cstrong\u003eWyatt Spear (\u003ca href=\"mailto:wspear@cs.uoregon.edu\"\u003ewspear@cs.uoregon.edu\u003c/a\u003e)\u003c/strong\u003e, \u003cstrong\u003eNicholas Chaimov (\u003ca href=\"mailto:nchaimov@paratools.com\"\u003enchaimov@paratools.com\u003c/a\u003e)\u003c/strong\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 14,
    "topics": [],
    "updated_at": 1673545287.0
  },
  {
    "data_format": 2,
    "description": "A Spack recipe repository of Key4hep software.",
    "filenames": [
      "environments/key4hep-release-user/spack.yaml"
    ],
    "full_name": "key4hep/key4hep-spack",
    "latest_release": "2021-10-29",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-package-repo-for-key4hep-software-packaging\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-package-repo-for-key4hep-software-packaging\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/spack/spack\"\u003eSpack\u003c/a\u003e package repo for Key4HEP software packaging\u003c/h1\u003e\n\u003cp\u003eThis repository holds a set of Spack recipes for key4hep software. It grew out of \u003ca href=\"https://github.com/HSF/hep-spack\"\u003ehttps://github.com/HSF/hep-spack\u003c/a\u003e, and many recipes habe been included in the upstream spack repostiory.\u003c/p\u003e\n\u003cp\u003eConsult the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack documentation\u003c/a\u003e and the \u003ca href=\"https://cern.ch/key4hep\" rel=\"nofollow\"\u003ekey4hep documentation website\u003c/a\u003e for more details.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-repository-contents\" class=\"anchor\" aria-hidden=\"true\" href=\"#repository-contents\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRepository Contents\u003c/h3\u003e\n\u003cp\u003eApart from the recipes for key4hep packages in the folder \u003ccode\u003epackages\u003c/code\u003e, the repository contains some \u003ccode\u003escripts\u003c/code\u003e used for publishing on cvmfs, and \u003ccode\u003econfig\u003c/code\u003e files for spack.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-central-installations\" class=\"anchor\" aria-hidden=\"true\" href=\"#central-installations\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCentral Installations\u003c/h3\u003e\n\u003cp\u003eInstallations of the software stack can be found under \u003ccode\u003e/cvmfs/sw.hsf.org/\u003c/code\u003e, see:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\" rel=\"nofollow\"\u003ehttps://key4hep.github.io/key4hep-doc/setup-and-getting-started/README.html\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 8,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1680637567.0
  },
  {
    "data_format": 2,
    "description": "Performance benchmarks and regression tests for the ExCALIBUR project",
    "filenames": [
      "benchmarks/spack/myriad/compute-node/spack.yaml"
    ],
    "full_name": "ukri-excalibur/excalibur-tests",
    "latest_release": null,
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-excalibur-tests\" class=\"anchor\" aria-hidden=\"true\" href=\"#excalibur-tests\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eExCALIBUR tests\u003c/h1\u003e\n\u003cp\u003ePerformance benchmarks and regression tests for the ExCALIBUR project.\u003c/p\u003e\n\u003cp\u003eThese benchmarks are based on a similar project by\n\u003ca href=\"https://github.com/stackhpc/hpc-tests\"\u003eStackHPC\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote\u003c/strong\u003e: at the moment the ExCALIBUR benchmarks are a work-in-progress.\u003c/em\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eIt is recommended to install the \u003cstrong\u003eexcalibur-tests\u003c/strong\u003e package with \u003ccode\u003epip\u003c/code\u003e by\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epip install \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eOn most systems, it is recommended to install the package in a virtual environment.\nFor example, using the python3 \u003ca href=\"https://docs.python.org/3/library/venv.html\" rel=\"nofollow\"\u003ebuilt-in virtual environment tool \u003ccode\u003evenv\u003c/code\u003e\u003c/a\u003e,\ncreate an environment called \u003ccode\u003emy_environment\u003c/code\u003e with\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epython3 -m venv ./my_environment\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eand activate it with\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./my_environment/bin/activate\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor \u003ca href=\"https://setuptools.pypa.io/en/latest/userguide/development_mode.html\" rel=\"nofollow\"\u003edevelopment\u003c/a\u003e,\npass the \u003ccode\u003e-e/--editable\u003c/code\u003e flag to \u003ccode\u003epip\u003c/code\u003e to link the installed package to the files in the local\ndirectory, instead of copying, to be able to make changes to the installed package.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"#requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRequirements\u003c/h2\u003e\n\u003cp\u003eThe pip install will install a compatible version of \u003cstrong\u003eReFrame\u003c/strong\u003e from\n\u003ca href=\"https://pypi.org/project/ReFrame-HPC/\" rel=\"nofollow\"\u003ePyPi\u003c/a\u003e. However, you will have to\nmanually provide an installation of \u003cstrong\u003eSpack\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSpack\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://spack.io/\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e is a package manager specifically designed for HPC\nfacilities. In some HPC facilities there may be already a central Spack installation available.\nHowever, the version installed is most likely too old to support all the features\nused by this package. Therefore we recommend you install the latest version locally,\nfollowing the instructions below.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003eNote\u003c/strong\u003e: if you have already installed spack locally and you want to upgrade to\na newer version, you might first have to clear the cache to avoid conflicts:\n\u003ccode\u003espack clean -m\u003c/code\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eFollow the \u003ca href=\"https://spack.readthedocs.io/en/latest/getting_started.html\" rel=\"nofollow\"\u003eofficial instructions\u003c/a\u003e\nto install the latest version of Spack (summarised here for convenience, but not guaranteed to be\nup-to-date):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003egit clone spack:\n\u003ccode\u003egit clone -c feature.manyFiles=true https://github.com/spack/spack.git\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003erun spack setup script: \u003ccode\u003esource ./spack/share/spack/setup-env.sh\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003echeck spack is in \u003ccode\u003e$PATH\u003c/code\u003e, for example \u003ccode\u003espack --version\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIn order to use Spack in ReFrame, the framework we use to run the benchmarks\n(see below), the directory where the \u003ccode\u003espack\u003c/code\u003e program is installed needs to be in\nthe \u003ccode\u003ePATH\u003c/code\u003e environment variable. This is taken care of by the \u003ccode\u003esetup-env.sh\u003c/code\u003e\nscript as above, and you can have your shell init script (e.g. \u003ccode\u003e.bashrc\u003c/code\u003e)\ndo that automatically in every session, by adding the following lines to it:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e SPACK_ROOT=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e/path/to/spack\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e [ \u003cspan class=\"pl-k\"\u003e-f\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${SPACK_ROOT}\u003c/span\u003e/share/spack/setup-env.sh\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e ]\u003cspan class=\"pl-k\"\u003e;\u003c/span\u003e \u003cspan class=\"pl-k\"\u003ethen\u003c/span\u003e\n    \u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${SPACK_ROOT}\u003c/span\u003e/share/spack/setup-env.sh\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003efi\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ereplacing \u003ccode\u003e/path/to/spack\u003c/code\u003e with the actual path to your Spack installation.\u003c/p\u003e\n\u003cp\u003eReFrame also requires a \u003ca href=\"https://spack.readthedocs.io/en/latest/environments.html\" rel=\"nofollow\"\u003eSpack\nEnvironment\u003c/a\u003e.  We\nprovide Spack environments for some of the systems that are part of the\nExCALIBUR and DiRAC projects in\n\u003ca href=\"https://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack\"\u003ehttps://github.com/ukri-excalibur/excalibur-tests/tree/main/benchmarks/spack/\u003c/a\u003e.\nIf you want to use a different Spack environment,\nset the environment variable \u003ccode\u003eEXCALIBUR_SPACK_ENV\u003c/code\u003e to the path of the directory\nwhere the environment is.  If this is not set, ReFrame will try to use the\nenvironment for the current system if known, otherwise it will automatically\ncreate a very basic environment (see \"Usage on unsupported systems\" section below).\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-reframe\" class=\"anchor\" aria-hidden=\"true\" href=\"#reframe\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eReFrame\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/\" rel=\"nofollow\"\u003eReFrame\u003c/a\u003e is a high-level\nframework for writing regression tests for HPC systems.  For our tests we\nrequire ReFrame v4.1.0.\u003c/p\u003e\n\u003cp\u003eIf you need to manually install ReFrame, follow the \u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/started.html\" rel=\"nofollow\"\u003eofficial\ninstructions\u003c/a\u003e to\ninstall this package.  Note that ReFrame requires Python 3.6: in your HPC system\nyou may need to load a specific module to have this version of Python available.\u003c/p\u003e\n\u003cp\u003eWe provide a ReFrame configuration file with the settings of some systems that\nare part of the ExCALIBUR or DiRAC projects.  You can point ReFrame to this file by\nsetting the\n\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_CONFIG_FILE\" rel=\"nofollow\"\u003e\u003ccode\u003eRFM_CONFIG_FILE\u003c/code\u003e\u003c/a\u003e\nenvironment variable:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e RFM_CONFIG_FILE=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-smi\"\u003e${PWD}\u003c/span\u003e/benchmarks/reframe_config.py\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf you want to use a different ReFrame configuration file, for example because\nyou use a different system, you can set this environment variable to the path of\nthat file.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: in order to use the Spack build system in ReFrame, the \u003ccode\u003espack\u003c/code\u003e\nexecutable must be in the \u003ccode\u003ePATH\u003c/code\u003e also on the compute nodes of a cluster, if\nyou want to run your benchmarks on them. This is taken care of by adding it\nto your init file (see spack section above).\u003c/p\u003e\n\u003cp\u003eHowever, you will also need to set the\n\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#envvar-RFM_USE_LOGIN_SHELL\" rel=\"nofollow\"\u003e\u003ccode\u003eRFM_USE_LOGIN_SHELL\u003c/code\u003e\u003c/a\u003e\nenvironment variable (\u003ccode\u003eexport RFM_USE_LOGIN_SHELL=\"Yes\"\u003c/code\u003e) in order to make ReFrame use\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e!\u003c/span\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e/bin/bash -l\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eas \u003ca href=\"https://en.wikipedia.org/wiki/Shebang_(Unix)\" rel=\"nofollow\"\u003eshebang\u003c/a\u003e line, which would load\nthe user\u0027s init script.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003cp\u003eOnce you have set up Spack and ReFrame, you can execute a benchmark with\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ereframe -c benchmarks/apps/BENCH_NAME -r --performance-report\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003ewhere \u003ccode\u003ebenchmarks/apps/BENCH_NAME\u003c/code\u003e is the directory where the benchmark is.  The command\nabove assumes you have the program \u003ccode\u003ereframe\u003c/code\u003e in your PATH.  If you have followed the instructions\nto install using \u003ccode\u003epip\u003c/code\u003e into the default directory, it should have been automatically added.\nIf it is not the case, call \u003ccode\u003ereframe\u003c/code\u003e with its relative or absolute path.\u003c/p\u003e\n\u003cp\u003eFor example, to run the Sombrero benchmark in the \u003ccode\u003ebenchmarks/apps/sombrero\u003c/code\u003e directory you can\nuse\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ereframe -c benchmarks/apps/sombrero -r --performance-report\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor benchmarks that use the Spack build system, the tests define a default Spack specification\nto be installed in the environment, but users can change it when invoking ReFrame on the\ncommand line with the\n\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-S\" rel=\"nofollow\"\u003e\u003ccode\u003e-S\u003c/code\u003e\u003c/a\u003e option to set\nthe \u003ccode\u003espack_spec\u003c/code\u003e variable:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ereframe -c benchmarks/apps/sombrero -r --performance-report -S spack_spec=\u0027sombrero@2021-08-16%intel\u0027\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e\u003ca id=\"user-content-setting-environment-variables\" class=\"anchor\" aria-hidden=\"true\" href=\"#setting-environment-variables\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSetting environment variables\u003c/h3\u003e\n\u003cp\u003eAll the built-in fields of ReFrame regression classes can be set on a per-job basis using the\n\u003ccode\u003e-S\u003c/code\u003e command-line option. One useful such field is\n\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/regression_test_api.html#reframe.core.pipeline.RegressionTest.env_vars\" rel=\"nofollow\"\u003e\u003ccode\u003eenv_vars\u003c/code\u003e\u003c/a\u003e,\nwhich controls the environment variables used in a job.\nThe syntax to set dictionary items, like for \u003ccode\u003eenv_vars\u003c/code\u003e, is a comma-separated list of \u003ccode\u003ekey:value\u003c/code\u003e pairs: \u003ccode\u003e-S dict=key_1:value_1,key_2:value_2\u003c/code\u003e.\nFor example\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ereframe -c benchmarks/apps/sombrero -r --performance-report -S env_vars=OMP_PLACES:threads\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eruns the \u003ccode\u003ebenchmarks/apps/sombrero\u003c/code\u003e benchmark setting the environment variable \u003ccode\u003eOMP_PLACES\u003c/code\u003e\nto \u003ccode\u003ethreads\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-selecting-system-and-queue-access-options\" class=\"anchor\" aria-hidden=\"true\" href=\"#selecting-system-and-queue-access-options\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSelecting system and queue access options\u003c/h3\u003e\n\u003cp\u003eThe provided ReFrame configuration file contains the settings for multiple systems.  If you\nuse it, the automatic detection of the system may fail, as some systems may use clashing\nhostnames.  To avoid this, you can use the flag \u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-system\" rel=\"nofollow\"\u003e\u003ccode\u003e--system NAME:PARTITION\u003c/code\u003e\u003c/a\u003e\nto specify the system (and optionally the partition) to use.\u003c/p\u003e\n\u003cp\u003eAdditionally, if submitting jobs to the compute nodes requires additional options, like for\nexample the resource group you belong to (for example \u003ccode\u003e--account=...\u003c/code\u003e for Slurm), you have\nto pass the command line flag\n\u003ca href=\"https://reframe-hpc.readthedocs.io/en/stable/manpage.html#cmdoption-J\" rel=\"nofollow\"\u003e\u003ccode\u003e--job-option=...\u003c/code\u003e\u003c/a\u003e\nto \u003ccode\u003ereframe\u003c/code\u003e (e.g., \u003ccode\u003e--job-option=\u0027--account=...\u0027\u003c/code\u003e).\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-usage-on-unsupported-systems\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage-on-unsupported-systems\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage on unsupported systems\u003c/h3\u003e\n\u003cp\u003eThe configuration provided in \u003ca href=\"./reframe_config.py\"\u003e\u003ccode\u003ereframe_config.py\u003c/code\u003e\u003c/a\u003e lets you run the\nbenchmarks on pre-configured HPC systems.  However you\ncan use this framework on any system by choosing the \"generic\" system with \u003ccode\u003e--system generic\u003c/code\u003e, or by using your own ReFrame configuration.  You can use the \"generic\" system to run\nbenchmarks in ReFrame without using a queue manager or an MPI launcher (e.g. on a personal workstation).\u003c/p\u003e\n\u003cp\u003eIf you choose the \"generic\" system and a benchmark using the Spack build system,\na new empty Spack environment will be automatically created in\n\u003ccode\u003espack-environments/generic\u003c/code\u003e when ReFrame is launched for the first time.\nYou should populate the environment with the packages already installed on your system\nbefore running Spack to avoid excessively rebuilding system packages. See the\n\u003cem\u003eSpack configuration\u003c/em\u003e section of \u003ca href=\"./CONTRIBUTING.md\"\u003e\u003ccode\u003eCONTRIBUTING.md\u003c/code\u003e\u003c/a\u003e for instructions on how\nto set up a Spack environment.\nIn particular, make sure that at least a compiler and an MPI library are added into the environment.\nAfter the Spack environment is set up, tell ReFrame to use it by setting the environment\nvariable \u003ccode\u003eEXCALIBUR_SPACK_ENV\u003c/code\u003e, as described above.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-system-specific-flags\" class=\"anchor\" aria-hidden=\"true\" href=\"#system-specific-flags\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSystem-specific flags\u003c/h3\u003e\n\u003cp\u003eWhile the aim is to automate as much system-specific configuration as possible, there are some options that have to be provided by the user, such as accounting details, and unfortunately the syntax can vary.\nThe file \u003ca href=\"./SYSTEMS.md\"\u003e\u003ccode\u003eSYSTEMS.md\u003c/code\u003e\u003c/a\u003e contains information about the use of this framework on specific systems.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contributing-new-systems-or-benchmarks\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing-new-systems-or-benchmarks\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing new systems or benchmarks\u003c/h2\u003e\n\u003cp\u003eFeel free to add new benchmark apps or support new systems that are part of the\nExCALIBUR benchmarking collaboration.  Read \u003ca href=\"./CONTRIBUTING.md\"\u003e\u003ccode\u003eCONTRIBUTING.md\u003c/code\u003e\u003c/a\u003e for more details.\u003c/p\u003e\n",
    "stargazers_count": 9,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1679052649.0
  },
  {
    "data_format": 2,
    "description": "explore the FV3 data for parameterization",
    "filenames": [
      "docker/ufs_utils/spack.yaml"
    ],
    "full_name": "ai2cm/fv3net",
    "latest_release": "n2f-3km-initial-submission",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-fv3net\" class=\"anchor\" aria-hidden=\"true\" href=\"#fv3net\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003efv3net\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://circleci.com/gh/ai2cm/fv3net/tree/master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a552f20b68ca052bd00beeb5ce611dd080f121e453b44f371d63405aeec20c78/68747470733a2f2f636972636c6563692e636f6d2f67682f616932636d2f6676336e65742f747265652f6d61737465722e7376673f7374796c653d737667\" alt=\"CircleCI\" data-canonical-src=\"https://circleci.com/gh/ai2cm/fv3net/tree/master.svg?style=svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eImproving the GFDL FV3 model physics with machine learning. See the \u003ca href=\"https://vulcanclimatemodeling.com/docs/fv3net/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e for more information on using this suite of tools.\u003c/p\u003e\n\u003cp\u003eDisclaimer: This is a work in progress.\u003c/p\u003e\n",
    "stargazers_count": 14,
    "subscribers_count": 8,
    "topics": [],
    "updated_at": 1675296401.0
  },
  {
    "data_format": 2,
    "description": "Accelerated demonstrator of electromagnetic Particle Transport",
    "filenames": [
      "scripts/spack.yaml"
    ],
    "full_name": "apt-sim/AdePT",
    "latest_release": null,
    "readme": "\n\u003ch1\u003e\u003ca id=\"user-content-adept\" class=\"anchor\" aria-hidden=\"true\" href=\"#adept\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAdePT\u003c/h1\u003e\n\u003cp\u003eAccelerated demonstrator of electromagnetic Particle Transport\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-build-requirements\" class=\"anchor\" aria-hidden=\"true\" href=\"#build-requirements\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuild Requirements\u003c/h2\u003e\n\u003cp\u003eThe following packages are a required to build and run:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCMake \u0026gt;= 3.18\u003c/li\u003e\n\u003cli\u003eC/C++ Compiler with C++14 support\u003c/li\u003e\n\u003cli\u003eCUDA Toolkit (tested 10.1, min version TBD)\u003c/li\u003e\n\u003cli\u003eVecCore \u003ca href=\"https://github.com/root-project/veccore\"\u003elibrary\u003c/a\u003e 0.7.0 (recommended, but older versions \u0026gt;= 0.5.0 also work)\u003c/li\u003e\n\u003cli\u003eVecGeom \u003ca href=\"https://gitlab.cern.ch/VecGeom/VecGeom\" rel=\"nofollow\"\u003elibrary\u003c/a\u003e \u0026gt;= 1.1.20\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eA suitable environment may be set up either from CVMFS (requires the sft.cern.ch and projects.cern.ch repos\nto be available on the local system):\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e /cvmfs/sft.cern.ch/lcg/views/devAdePT/latest/x86_64-centos7-gcc11-opt/setup.sh\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eor from the supplied \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003espack\u003c/a\u003e environment file:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003espack env create adept-spack ./scripts/spack.yaml\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack -e adept-spack concretize -f\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack -e adept-spack install\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e...\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003espack env activate -p adept-spack\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eNote that the above assumes your spack configuration defaults to use a suitable C++ compiler and has\n\u003ccode\u003ecuda_arch\u003c/code\u003e set appropriately for the hardware you will be running on.\u003c/p\u003e\n\u003cp\u003eYou can also build the packages manually as follows. To configure and build VecCore, simply run:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ecmake -S. -B./veccore-build -DCMAKE_INSTALL_PREFIX=\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0026lt;path_to_veccore_installation\u0026gt;\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003ecmake --build ./veccore-build --target install\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdd your CUDA installation to the PATH and LD_LIBRARY_PATH environment variables, as in:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PATH=\u003cspan class=\"pl-smi\"\u003e${PATH}\u003c/span\u003e:/usr/local/cuda/bin\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e LD_LIBRARY_PATH=\u003cspan class=\"pl-smi\"\u003e${LD_LIBRARY_PATH}\u003c/span\u003e:/usr/local/cuda/lib64\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFind the CUDA architecture for the target GPU. If you installed the CUDA demo suite, the fastest way is to use the deviceQuery executable from \u003ccode\u003eextras/demo_suite\u003c/code\u003e. This lists the CUDA capability for all installed GPUs, remember the value for your target:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e/usr/local/cuda/extras/demo_suite/deviceQuery\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eDevice 0: \"GeForce RTX 2080 SUPER\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  CUDA Capability Major/Minor version number:    7.5 (cuda_architecture=75)\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e...\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eDevice 1: \"Quadro K4200\"\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  CUDA Capability Major/Minor version number:    3.0 (cuda_architecture=30)\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo configure and build VecGeom, use the configuration options below, using as \u0026lt;cuda_architecture\u0026gt; the value from the step above:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ecmake -S. -B./vecgeom-build \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DCMAKE_INSTALL_PREFIX=\"\u0026lt;path_to_vecgeom_installation\u0026gt;\" \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DCMAKE_PREFIX_PATH=\"\u0026lt;path_to_veccore_installation\u0026gt;\" \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DVECGEOM_ENABLE_CUDA=ON \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DVECGEOM_GDML=ON \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DBACKEND=Scalar \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DCMAKE_CUDA_ARCHITECTURES=\u0026lt;cuda_architecture\u0026gt; \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DVECGEOM_USE_NAVINDEX=ON \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e  -DCMAKE_BUILD_TYPE=Release\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003ecmake --build ./vecgeom-build --target install -- -j6 \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e## build using 6 threads and install\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo configure AdePT, simply run:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ecmake -S. -B./adept-build \u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eotherargs\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAs  one needs to provide the paths to the dependence libraries VecCore and VecGeom, and optionally the path to the Alpaka installation (in case you want to build FisherPrice_Alpaka)\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003e   -DCMAKE_PREFIX_PATH=\"\u0026lt;path_to_veccore_installation\u0026gt;;\u0026lt;path_to_vecgeom_installation\u0026gt;;[\u0026lt;alpakaInstallDir\u0026gt;]\" \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e   -DCMAKE_CUDA_ARCHITECTURES=\u0026lt;cuda_architecture\u0026gt; \\\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003e   -DCMAKE_BUILD_TYPE=Release\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eTo build, run:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003ecmake --build ./adept-build -- -j6 \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e## build using 6 threads\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe provided examples and tests can be run from the build directory:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-text-shell-session\"\u003e\u003cpre\u003e$ \u003cspan class=\"pl-s1\"\u003e\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e adept-build\u003c/span\u003e\n$ \u003cspan class=\"pl-s1\"\u003eCUDA_VISIBLE_DEVICES=0 BuildProducts/bin/\u003cspan class=\"pl-k\"\u003e\u0026lt;\u003c/span\u003eexecutable\u003cspan class=\"pl-k\"\u003e\u0026gt;\u003c/span\u003e   \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e## use the device number matching the selected \u0026lt;cuda_architecture\u0026gt;\u003c/span\u003e\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-copyright\" class=\"anchor\" aria-hidden=\"true\" href=\"#copyright\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCopyright\u003c/h2\u003e\n\u003cp\u003eAdePT code is Copyright (C) CERN, 2020, for the benefit of the AdePT project.\nAny other code in the project has (C) and license terms clearly indicated.\u003c/p\u003e\n\u003cp\u003eContributions of all authors to AdePT and their institutes are acknowledged in\nthe \u003ccode\u003eAUTHORS.md\u003c/code\u003e file.\u003c/p\u003e\n",
    "stargazers_count": 14,
    "subscribers_count": 9,
    "topics": [],
    "updated_at": 1678241719.0
  },
  {
    "data_format": 2,
    "description": "E4S for Spack",
    "filenames": [
      "environments/23.02/cuda-x86_64/spack.yaml",
      "environments/23.02/cuda-aarch64/spack.yaml",
      "environments/23.02/cuda-ppc64le/spack.yaml",
      "environments/23.02/oneapi-x86_64/spack.yaml",
      "environments/23.02/rocm-x86_64/spack.yaml",
      "environments/22.11/rocm-x86_64/spack.yaml",
      "environments/22.11/cuda-ppc64le/spack.yaml",
      "environments/22.11/cuda-x86_64/spack.yaml",
      "environments/22.11/oneapi-x86_64/spack.yaml",
      "environments/22.11/cuda-aarch64/spack.yaml"
    ],
    "full_name": "E4S-Project/e4s",
    "latest_release": null,
    "readme": "\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://github.com/E4S-Project/e4s/blob/master/logos/E4S-dark-green.png\"\u003e\u003cimg src=\"https://github.com/E4S-Project/e4s/raw/master/logos/E4S-dark-green.png\" width=\"200\" alt=\"E4S\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e \n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/58e7ffdceb32cd7a8facd6b6cd3920a56c15e0e2ef1d3398158ef4ec0d6ec886/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f4534532d50726f6a6563742f653473\" alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/E4S-Project/e4s\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/94cdab1cd9efc5521be1590b3d0b5dc5f707838e0d20015c14f23921ef2b7326/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6534732f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation\" data-canonical-src=\"https://readthedocs.org/projects/e4s/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c2e45205070ba0928aece78cf95f8658ef1cf69f7c113dc56f7d05e29e68755e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f4534532d50726f6a6563742f6534732e737667\" alt=\"GitHub Issues\" data-canonical-src=\"https://img.shields.io/github/issues/E4S-Project/e4s.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/011fb27187d5b878949948752f73e86dea6828febca879ee69a5a5d52ce651ca/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d70722f4534532d50726f6a6563742f653473\" alt=\"GitHub pull requests\" data-canonical-src=\"https://img.shields.io/github/issues-pr/E4S-Project/e4s\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-e4s\" class=\"anchor\" aria-hidden=\"true\" href=\"#e4s\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eE4S\u003c/h1\u003e\n\u003cp\u003eThe \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003eExtreme-scale Scientific Software Stack (E4S)\u003c/a\u003e is a community effort to provide open source\nsoftware packages for developing, deploying and running scientific applications on high-performance\ncomputing (HPC) platforms. E4S provides from-source builds and containers of a\n\u003ca href=\"https://e4s-project.github.io/Resources/ProductInfo.html\" rel=\"nofollow\"\u003ebroad collection of HPC software packages\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eE4S is available to download in the following formats:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eContainers: Docker, Singularity, CharlieCloud, OVA\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSpack manifest (\u003ccode\u003espack.yaml\u003c/code\u003e) to install from source. These can be found in \u003ca href=\"https://github.com/E4S-Project/e4s/tree/master/environments\"\u003eenvironments\u003c/a\u003e directory.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"http://aws.amazon.com/\" rel=\"nofollow\"\u003eAWS EC2 image\u003c/a\u003e with image name \u003ccode\u003eami-0db9d49091db1c25f\u003c/code\u003e in \u003cstrong\u003eUS-West-2 (Oregon)\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://oaciss.uoregon.edu/e4s/inventory.html\" rel=\"nofollow\"\u003eE4S Build Cache\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePlease see \u003ca href=\"https://github.com/E4S-Project/e4s/blob/master/E4S_Products.md\"\u003eE4S Product Dictionary\u003c/a\u003e for complete list of E4S products.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-useful-links\" class=\"anchor\" aria-hidden=\"true\" href=\"#useful-links\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUseful Links\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eUser Documentation: \u003ca href=\"https://e4s.readthedocs.io\" rel=\"nofollow\"\u003ehttps://e4s.readthedocs.io\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eMain Page: \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003ehttps://e4s-project.github.io/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S GitHub: \u003ca href=\"https://github.com/E4S-Project/\"\u003ehttps://github.com/E4S-Project/\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S Slack Channel: \u003ca href=\"https://e4s-project.slack.com\" rel=\"nofollow\"\u003ehttps://e4s-project.slack.com\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eSlack Channel Invitation: \u003ca href=\"https://communityinviter.com/apps/e4s-project/e4s\" rel=\"nofollow\"\u003ehttps://communityinviter.com/apps/e4s-project/e4s\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eE4S Dashboard: \u003ca href=\"https://dashboard.e4s.io/\" rel=\"nofollow\"\u003ehttps://dashboard.e4s.io/\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-related-projects\" class=\"anchor\" aria-hidden=\"true\" href=\"#related-projects\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eRelated Projects\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/E4S-Project.github.io\"\u003eE4S-Project/E4S-Project.github.io\u003c/a\u003e - E4S Documentation repo that is hosted on \u003ca href=\"https://e4s-project.github.io/\" rel=\"nofollow\"\u003ehttps://e4s-project.github.io/\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/testsuite\"\u003eE4S-Project/testsuite\u003c/a\u003e - E4S Testsuite with collection of validation tests that can be run post-install.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/e4s-cl\"\u003eE4S-Project/e4s-cl\u003c/a\u003e - E4S Container Launcher is a tool to easily run MPI applications in E4S containers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/E4S-Project/e4s-ci-badges\"\u003eE4S-Project/e4s-ci-badges\u003c/a\u003e - Display CI badges for E4S products that are available from \u003ca href=\"https://shields.io/\" rel=\"nofollow\"\u003eshields.io\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eE4S is released as MIT license for more details see \u003ca href=\"https://github.com/E4S-Project/e4s/blob/master/LICENSE\"\u003eLICENSE\u003c/a\u003e file\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contact\" class=\"anchor\" aria-hidden=\"true\" href=\"#contact\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContact\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eMike Heroux (\u003ca href=\"mailto:maherou@sandia.gov\"\u003emaherou@sandia.gov\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eSameer Shende (\u003ca href=\"mailto:sameer@cs.uoregon.edu\"\u003esameer@cs.uoregon.edu\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 16,
    "subscribers_count": 10,
    "topics": [],
    "updated_at": 1680351263.0
  },
  {
    "data_format": 2,
    "description": "A library to abstract between different lossless and lossy compressors",
    "filenames": [
      "docker/spack.yaml"
    ],
    "full_name": "robertu94/libpressio",
    "latest_release": "0.70.0",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-libpressio\" class=\"anchor\" aria-hidden=\"true\" href=\"#libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLibPressio\u003c/h1\u003e\n\u003cp\u003e\u003cem\u003ethe stable version of this code is found at \u003ca href=\"https://github.com/CODARcode/libpressio\"\u003eat the CODARCode organization\u003c/a\u003e it is updated about anually\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003ePressio is latin for compression.  LibPressio is a C++ library with C compatible bindings to abstract between different lossless and lossy compressors and their configurations.  It solves the problem of having to having to write separate application level code for each lossy compressor that is developed.  Instead, users write application level code using LibPressio, and the library will make the correct underlying calls to the compressors.  It provides interfaces to represent data, compressors settings, and compressors.\u003c/p\u003e\n\u003cp\u003eDocumentation for the \u003ccode\u003emaster\u003c/code\u003e branch can be \u003ca href=\"https://robertu94.github.io/libpressio/\" rel=\"nofollow\"\u003efound here\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-using-libpressio\" class=\"anchor\" aria-hidden=\"true\" href=\"#using-libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsing LibPressio\u003c/h1\u003e\n\u003cp\u003eExample using the CLI from \u003ca href=\"https://github.com/robertu94/pressio-tools\"\u003e\u003ccode\u003epressio-tools\u003c/code\u003e\u003c/a\u003e\nWe also have C, C++, Rust, Julia, and Python bindings.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003epressio -i \u003cspan class=\"pl-k\"\u003e~\u003c/span\u003e/git/datasets/hurricane/100x500x500/CLOUDf48.bin.f32 \\\n    -b compressor=sz3 -o abs=1e-4 -O all \\\n    -m \u003cspan class=\"pl-k\"\u003etime\u003c/span\u003e -m size -m error_stat -M all \\\n    -w /path/to/output.dec\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe reccomended way to learn LibPressio is with self-pased \u003ca href=\"https://github.com/robertu94/libpressio_tutorial\"\u003eLibPressio Tutorial\u003c/a\u003e.\nHere you will find examples of how to use LibPressio in a series of lessons for several common languages.\u003c/p\u003e\n\u003cp\u003eYou can also find a \u003ca href=\"https://youtu.be/hZ_dFCMxmGw\" rel=\"nofollow\"\u003erecording of the tutorial on YouTube\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-getting-started\" class=\"anchor\" aria-hidden=\"true\" href=\"#getting-started\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGetting Started\u003c/h2\u003e\n\u003cp\u003eAfter skimming the example, LibPressio has 6 major headers that you will need to use:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eType\u003c/th\u003e\n\u003cth\u003eUse\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eError reporting and aquiring handles to compressors\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_compressor.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eUsed to compress and decompress data, provided by plugins\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_data.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eRepresents data and associated metadata (size, type, dimentionality, memory ownership)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_options.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eMaps between names and values, used for options for compressors and metrics results\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_metrics.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eA set of metrics to run while compressors run\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003epressio_io.h\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAn extension header that provides methods to load or store data from/to persistent storage\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eAll of these are included by the convience header \u003ccode\u003elibpressio.h\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eYou can pick up the more advanced features as you need them.\u003c/p\u003e\n\u003cp\u003eYou can also find more examples in \u003ccode\u003etest/\u003c/code\u003e or in the \u003ca href=\"https://github.com/robertu94/libpressio-interesting-scripts\"\u003eLibPressio intresting scripts collection\u003c/a\u003e which catalogs intresting higher-level use cases.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-supported-compressors-and-metrics\" class=\"anchor\" aria-hidden=\"true\" href=\"#supported-compressors-and-metrics\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eSupported Compressors and Metrics\u003c/h2\u003e\n\u003cp\u003eLibpressio provides a number of builtin compressor and metrics modules.\nAll of these are \u003cstrong\u003edisabled by default\u003c/strong\u003e.\nThey can be enabled by passing the corresponding \u003ccode\u003eLIBPRESSIO_HAS_*\u003c/code\u003e variable to CMake.\u003c/p\u003e\n\u003cp\u003eAdditionally, Libpressio is extensible.\nFor information on writing a compressor plugin see [Writing a Compressor Plugin](@ref writingacompressor)\nFor information on writing a metrics plugin see [Writing a Metrics Plugin](@ref writingametric)\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-compressor-plugins\" class=\"anchor\" aria-hidden=\"true\" href=\"#compressor-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCompressor Plugins\u003c/h3\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/compressors\"\u003esrc/plugins/compressors\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the [compressor settings page](@ref compressors) for information on how to configure them.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-metrics-plugins\" class=\"anchor\" aria-hidden=\"true\" href=\"#metrics-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMetrics Plugins\u003c/h3\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/metrics\"\u003esrc/plugins/metrics\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the [metrics results page](@ref metrics) for information on what they produce\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-io-plugins\" class=\"anchor\" aria-hidden=\"true\" href=\"#io-plugins\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eIO Plugins\u003c/h3\u003e\n\u003cp\u003e1st party compressors plugins can be found in \u003ca href=\"https://github.com/robertu94/libpressio/tree/master/src/plugins/io\"\u003esrc/plugins/io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSee the [io settings page](@ref io) for information on how to configure them\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h1\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installing-libpressio-using-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#installing-libpressio-using-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstalling LibPressio using Spack\u003c/h2\u003e\n\u003cp\u003eLibPressio can be built using \u003ca href=\"https://github.com/spack/spack/\"\u003espack\u003c/a\u003e.  This example will install libpressio with only the SZ3 plugin.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/spack/spack\n\u003cspan class=\"pl-c1\"\u003esource\u003c/span\u003e ./spack/share/spack/setup-env.sh\nspack install libpressio+sz3\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eMore information on spack can be found in the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack documentation\u003c/a\u003e or \u003ca href=\"https://robertu94.github.io/guides\" rel=\"nofollow\"\u003emy quick start guides for systems that I use\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can see the other available versions and compilation options by calling \u003ccode\u003espack info libpressio\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eThe following language bindings are in this repository.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eC\u003c/code\u003e -- (default) if you need a stable interface\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eC++\u003c/code\u003e -- (default) if you want a more productive interface, or want to extend LibPressio\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003ePython\u003c/code\u003e -- (\u003ccode\u003e+python\u003c/code\u003e; BUILD_PYTHON_WRAPPER) if you know or want to intergate Python\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eHDF5\u003c/code\u003e -- (\u003ccode\u003e+hdf5+json\u003c/code\u003e; LIBPRESSIO_HAS_HDF AND LIBPRESSIO_HAS_JSON) you already use HDF5\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following bindings must be installed seperately:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eR\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/libpressio-r\"\u003er-libpressio\u003c/a\u003e if you know or want to integrate with R\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eBash/CLI\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/pressio-tools\"\u003elibpressio-tools\u003c/a\u003e  if you want to quickly prototype from the CLI\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe following bindings are experimental and can be installed manually:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003eJulia\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/LibPressio.jl\"\u003elibpressio-jl\u003c/a\u003e if you know or want to integrate with Julia\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eRust\u003c/code\u003e -- \u003ca href=\"https://github.com/robertu94/libpressio-rs\"\u003elibpressio-rs\u003c/a\u003e if you know or want to integrate with Rust\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-doing-a-development-build-with-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#doing-a-development-build-with-spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDoing a development build with spack\u003c/h2\u003e\n\u003cp\u003eThe easiest way to do a development build of libpressio is to use Spack envionments.\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e one time setup: create an envionment\u003c/span\u003e\nspack env create -d mydevenviroment\nspack env activate mydevenvionment\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e one time setup: install libpressio-tools and checkout \u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e libpressio for development\u003c/span\u003e\nspack add libpressio-tools\nspack develop libpressio@git.master\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e compile and install (repeat as needed)\u003c/span\u003e\nspack install \u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-manual-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#manual-installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManual Installation\u003c/h2\u003e\n\u003cp\u003eLibpressio unconditionally requires:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecmake\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003epkg-config\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/robertu94/std_compat\"\u003e\u003ccode\u003estd_compat\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eeither:\n\u003cul\u003e\n\u003cli\u003e\n\u003ccode\u003egcc-4.8.5\u003c/code\u003e or later\u003c/li\u003e\n\u003cli\u003e\n\u003ccode\u003eclang-7.0.0\u003c/code\u003e or later using either \u003ccode\u003elibc++\u003c/code\u003e or \u003ccode\u003elibstdc++\u003c/code\u003e.  Beware that system libraries may need to be recompiled with \u003ccode\u003elibc++\u003c/code\u003e if using \u003ccode\u003elibc++\u003c/code\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDependency versions and optional dependencies are documented \u003ca href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\u003ein the spack package\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-configuring-libpressio-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"#configuring-libpressio-manually\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eConfiguring LibPressio Manually\u003c/h2\u003e\n\u003cp\u003eLibPressio uses a fairly standard CMake buildsystem.\nFor more information on \u003ca href=\"https://robertu94.github.io/learning/cmake\" rel=\"nofollow\"\u003eCMake refer to these docs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe set of configuration options for LibPressio can be found using \u003ccode\u003ecmake -L $BUILD_DIR\u003c/code\u003e.\nFor information on what these settings do, see the \u003ca href=\"https://github.com/spack/spack/blob/develop/var/spack/repos/builtin/packages/libpressio/package.py\"\u003espack package\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-api-stability\" class=\"anchor\" aria-hidden=\"true\" href=\"#api-stability\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAPI Stability\u003c/h1\u003e\n\u003cp\u003ePlease refer to \u003ca href=\"docs/stability.md\"\u003edocs/stability.md\u003c/a\u003e.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-how-to-contribute\" class=\"anchor\" aria-hidden=\"true\" href=\"#how-to-contribute\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHow to Contribute\u003c/h1\u003e\n\u003cp\u003ePlease refer to \u003ca href=\"CONTRIBUTORS.md\"\u003eCONTRIBUTORS.md\u003c/a\u003e for a list of contributors, sponsors, and contribution guidelines.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-bug-reports\" class=\"anchor\" aria-hidden=\"true\" href=\"#bug-reports\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBug Reports\u003c/h1\u003e\n\u003cp\u003ePlease files bugs to the Github Issues page on the CODARCode libpressio repository.\u003c/p\u003e\n\u003cp\u003ePlease read this post on \u003ca href=\"https://codingnest.com/how-to-file-a-good-bug-report/\" rel=\"nofollow\"\u003ehow to file a good bug report\u003c/a\u003e.\u00a0 After reading this post, please provide the following information specific to libpressio:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYour OS version and distribution information, usually this can be found in \u003ccode\u003e/etc/os-release\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe output of \u003ccode\u003ecmake -L $BUILD_DIR\u003c/code\u003e\n\u003c/li\u003e\n\u003cli\u003ethe version of each of libpressio\u0027s dependencies listed in the README that you have installed. Where possible, please provide the commit hashes.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\u003ca id=\"user-content-citing-libpressio\" class=\"anchor\" aria-hidden=\"true\" href=\"#citing-libpressio\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCiting LibPressio\u003c/h1\u003e\n\u003cp\u003eIf you find LibPressio useful, please cite this paper:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e@inproceedings{underwood2021productive,\n  title={Productive and Performant Generic Lossy Data Compression with LibPressio},\n  author={Underwood, Robert and Malvoso, Victoriana and Calhoun, Jon C and Di, Sheng and Cappello, Franck},\n  booktitle={2021 7th International Workshop on Data Analysis and Reduction for Big Scientific Data (DRBSD-7)},\n  pages={1--10},\n  year={2021},\n  organization={IEEE}\n}\n\u003c/code\u003e\u003c/pre\u003e\n",
    "stargazers_count": 16,
    "subscribers_count": 5,
    "topics": [],
    "updated_at": 1673367032.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "configs/templates/gfs-v16.2/spack.yaml"
    ],
    "full_name": "NOAA-EMC/spack-stack",
    "latest_release": "spack-stack-1.2.0",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-spack-stack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack-stack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003espack-stack\u003c/h1\u003e\n\u003cp\u003eSpack-stack enables the installation of software required\nfor HPC system deployments of NOAA\u0027s Unified Forecast System (UFS) and\nother weather and climate models, including components of the Joint\nEffort for Data assimilation Integration (JEDI).\u003c/p\u003e\n\u003cp\u003eSpack-stack is a collaborative effort between:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.emc.ncep.noaa.gov/emc_new.php\" rel=\"nofollow\"\u003eNOAA Environmental Modeling Center (EMC)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.jcsda.org/\" rel=\"nofollow\"\u003eUCAR Joint Center for Satellite Data Assimilation (JCSDA)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://epic.noaa.gov/\" rel=\"nofollow\"\u003eEarth Prediction Innovation Center (EPIC)\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSpack-stack is a thin layer around a fork of the\n\u003ca href=\"https://github.com/spack/spack\"\u003espack\u003c/a\u003e repository. Spack is a\ncommunity-supported, multi-platform, Python-based package manager\noriginally developed by the Lawrence Livermore National Laboratory\n(LLNL). Spack is provided as a submodule to spack-stack so that a\nstable version can be referenced. For more information about spack see\nthe \u003ca href=\"https://computing.llnl.gov/projects/spack-hpc-package-manager\" rel=\"nofollow\"\u003eLLNL project page for\nspack\u003c/a\u003e\nand the \u003ca href=\"https://spack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003espack\ndocumentation\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe stack can be installed on a range of platforms, from Linux and\nmacOS laptops to HPC systems, and comes pre-configured for many\nsystems. Users can install the necessary packages for a particular\napplication and later add the missing packages for another application\nwithout having to rebuild the entire stack.\u003c/p\u003e\n\u003cp\u003espack-stack is mainly a collection of Spack configuration files, but\nprovides a Spack extension to simplify the installation process:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003espack stack create\u003c/code\u003e is provided to copy common, site-specific, and\napplication-specific configuration files into a coherent Spack\nenvironment and to create container recipes\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003espack stack setup-meta-modules\u003c/code\u003e creates compiler, MPI and Python\nmeta-modules for a convenient setup of a user environment using\nmodules (lua and tcl)\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDocumentation for installing and using spack-stack can be found here:\n\u003ca href=\"https://spack-stack.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://spack-stack.readthedocs.io/en/latest/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003espack-stack is maintained by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.github.com/AlexanderRichert-NOAA\"\u003eAlex Richert\u003c/a\u003e, \u003ca href=\"https://www.github.com/Hang-Lei-NOAA\"\u003eHang\nLei\u003c/a\u003e, \u003ca href=\"https://www.github.com/edwardhartnett\"\u003eEd\nHartnett\u003c/a\u003e NOAA-EMC\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ca href=\"https://www.github.com/climbfuji\"\u003eDom Heinzeller\u003c/a\u003e, JCSDA\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFor more information about the organization of the spack-stack\nproject, see the \u003ca href=\"project_charter.md\"\u003eProject Charter\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"true\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is\nprovided on an \"as is\" basis and the user assumes responsibility for\nits use. DOC has relinquished control of the information and no longer\nhas responsibility to protect the integrity, confidentiality, or\navailability of the information. Any claims against the Department of\nCommerce stemming from the use of its GitHub project will be governed\nby all applicable Federal law. Any reference to specific commercial\nproducts, processes, or services by service mark, trademark,\nmanufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of\nCommerce. The Department of Commerce seal and logo, or the seal and\nlogo of a DOC bureau, shall not be used in any manner to imply\nendorsement of any commercial product or activity by DOC or the United\nStates Government.\u003c/p\u003e\n",
    "stargazers_count": 16,
    "subscribers_count": 7,
    "topics": [],
    "updated_at": 1680703509.0
  },
  {
    "data_format": 2,
    "description": "Automates using spack to build and deploy software",
    "filenames": [
      ".ci/test-project/spack_configs/linux_ubuntu_22/spack.yaml",
      ".ci/test-project/spack_configs/toss_3_x86_64_ib/spack.yaml",
      ".ci/test-project/spack_configs/darwin/spack.yaml"
    ],
    "full_name": "LLNL/uberenv",
    "latest_release": "v1.0.0",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-uberenv\" class=\"anchor\" aria-hidden=\"true\" href=\"#uberenv\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003euberenv\u003c/h1\u003e\n\u003cp\u003eAutomates using a package manager to build and deploy software.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://uberenv.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/02247bd3961daeb4d17d6d1d8f821df0c991efeb0c5f0411fed0a94bd9fa3ebe/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f75626572656e762f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Read the Docs\" data-canonical-src=\"https://readthedocs.org/projects/uberenv/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eUberenv is a python script that helps automate building\nthird-party dependencies for development and deployment.\u003c/p\u003e\n\u003cp\u003eUberenv uses Spack (\u003ca href=\"https://www.spack.io/\" rel=\"nofollow\"\u003ehttps://www.spack.io/\u003c/a\u003e) on Unix-based systems (e.g. Linux and macOS)\nand Vcpkg (\u003ca href=\"https://github.com/microsoft/vcpkg\"\u003ehttps://github.com/microsoft/vcpkg\u003c/a\u003e) on Windows systems.\u003c/p\u003e\n\u003cp\u003eUberenv was released as part of the Conduit project (\u003ca href=\"https://github.com/LLNL/conduit/\"\u003ehttps://github.com/LLNL/conduit/\u003c/a\u003e).\nIt is included in-source in several projects, this repo is used to hold the latest reference version.\u003c/p\u003e\n\u003cp\u003eFor more details, see Uberenv\u0027s documention:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://uberenv.readthedocs.io\" rel=\"nofollow\"\u003ehttps://uberenv.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can also find details about how it is used in Conduit\u0027s documentation:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies\" rel=\"nofollow\"\u003ehttps://llnl-conduit.readthedocs.io/en/latest/building.html#building-conduit-and-third-party-dependencies\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eConduit\u0027s source repo also serves as an example for uberenv and spack configuration files, etc:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/LLNL/conduit/tree/master/scripts/uberenv\"\u003ehttps://github.com/LLNL/conduit/tree/master/scripts/uberenv\u003c/a\u003e\u003c/p\u003e\n",
    "stargazers_count": 20,
    "subscribers_count": 9,
    "topics": [
      "shell",
      "build-tools"
    ],
    "updated_at": 1676463765.0
  },
  {
    "data_format": 2,
    "description": "E4S Spack environments and container recipes",
    "filenames": [
      "docker-recipes/archived/minimal/ubuntu22.04-aarch64/spack.yaml",
      "docker-recipes/archived/minimal/rhel8-x86_64/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu18.04-ppc64le/spack.yaml",
      "docker-recipes/runner/_archived/ubuntu18.04-x86_64/spack.yaml",
      "docker-recipes/archived/minimal/rhel8-aarch64/spack.yaml",
      "docker-recipes/archived/minimal/rhel8-ppc64le/spack.yaml"
    ],
    "full_name": "UO-OACISS/e4s",
    "latest_release": null,
    "readme": "\u003cp\u003eThis is a collection of configurations for building ECP SDK\ncontainers with combinations of packages, including the full\nE4S set.\u003c/p\u003e\n\u003cp\u003eThese are the set of stacks that are targeted for the first release:\u003c/p\u003e\n\u003cp\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer\" href=\"figures/SDKdefinition1.png\"\u003e\u003cimg src=\"figures/SDKdefinition1.png\" alt=\"SDK definitions\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe configuration files for each container platform will be specified under each directory.  For example, the Docker configurations are under the \"docker\" subdirectory.  Each subdirectory will have a README.md file to explain how to build the container image for each stack.\u003c/p\u003e\n",
    "stargazers_count": 20,
    "subscribers_count": 6,
    "topics": [],
    "updated_at": 1673374590.0
  },
  {
    "data_format": 2,
    "description": null,
    "filenames": [
      "ci/spack.yaml"
    ],
    "full_name": "NOAA-EMC/UPP",
    "latest_release": "upp-srw-v2.1.0",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-unified-post-processing-upp\" class=\"anchor\" aria-hidden=\"true\" href=\"#unified-post-processing-upp\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUnified Post-Processing (UPP)\u003c/h1\u003e\n\u003cp\u003eThe Unified Post Processor (UPP) software package is a software\npackage designed to generate useful products from raw model\noutput.\u003c/p\u003e\n\u003cp\u003eThe UPP is currently used in operations with the Global Forecast\nSystem (GFS), GFS Ensemble Forecast System (GEFS), North American\nMesoscale (NAM), Rapid Refresh (RAP), High Resolution Rapid Refresh\n(HRRR), Short Range Ensemble Forecast (SREF), and Hurricane WRF (HWRF)\napplications. It is also used in the Unified Forecasting System (UFS),\nincluding the Rapid Refresh Forecast System (RRFS), Hurricane Application\nForecasting System (HAFS), and the Medium Range Weather (MRW) and Short\nRange Weather (SRW) Applications.\u003c/p\u003e\n\u003cp\u003eThe UPP provides the capability to compute a variety of diagnostic\nfields and interpolate to pressure levels or other vertical\ncoordinates.\u003c/p\u003e\n\u003cp\u003eUPP also incorporates the Joint Center for Satellite Data Assimilation\n(JCSDA) Community Radiative Transfer Model (CRTM) to compute model\nderived brightness temperature (TB) for various instruments and\nchannels. This additional feature enables the generation of a number\nof simulated satellite products including GOES products.\u003c/p\u003e\n\u003cp\u003eOutput from the UPP is in National Weather Service (NWS) and World\nMeteorological Organization (WMO) GRIB2 format and can be used\ndirectly by visualization, plotting, or verification packages, or for\nfurther downstream post-processing, e.g. statistical post-processing\ntechniques.\u003c/p\u003e\n\u003cp\u003eExamples of UPP products include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eT, Z, humidity, wind, cloud water, cloud ice, rain, and snow on pressure levels\u003c/li\u003e\n\u003cli\u003eSLP, shelter level T, humidity, and wind fields\u003c/li\u003e\n\u003cli\u003ePrecipitation-related fields\u003c/li\u003e\n\u003cli\u003ePBL-related fields\u003c/li\u003e\n\u003cli\u003eSevere weather products (e.g. CAPE, Vorticity, Wind shear)\u003c/li\u003e\n\u003cli\u003eRadiative/Surface fluxes\u003c/li\u003e\n\u003cli\u003eCloud related fields\u003c/li\u003e\n\u003cli\u003eAviation products\u003c/li\u003e\n\u003cli\u003eRadar reflectivity products\u003c/li\u003e\n\u003cli\u003eSatellite look-alike products\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-user-support\" class=\"anchor\" aria-hidden=\"true\" href=\"#user-support\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUser Support\u003c/h2\u003e\n\u003cp\u003eSupport for the UFS UPP is provided through \u003ca href=\"https://github.com/NOAA-EMC/UPP/discussions\"\u003eGitHub Discussions\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentation\u003c/h2\u003e\n\u003cp\u003eUser Guide for latest public release: \u003ca href=\"https://upp.readthedocs.io/en/latest/\" rel=\"nofollow\"\u003ehttps://upp.readthedocs.io/en/latest/\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eTechnical code-level documentation: \u003ca href=\"https://noaa-emc.github.io/UPP/\" rel=\"nofollow\"\u003ehttps://noaa-emc.github.io/UPP/\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-developer-information\" class=\"anchor\" aria-hidden=\"true\" href=\"#developer-information\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDeveloper Information\u003c/h2\u003e\n\u003cp\u003ePlease see review the \u003ca href=\"https://github.com/NOAA-EMC/UPP/wiki\"\u003ewiki\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-authors\" class=\"anchor\" aria-hidden=\"true\" href=\"#authors\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAuthors\u003c/h2\u003e\n\u003cp\u003eNCEP/EMC Developers\u003c/p\u003e\n\u003cp\u003eCode Managers: Wen Meng, Huiya Chuang, Kate Fossell\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-hidden=\"true\" href=\"#prerequisites\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePrerequisites\u003c/h2\u003e\n\u003cp\u003eThe UPP requires certain NCEPLIB packages to be installed via\nthe HPC-Stack project.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-g2\"\u003eNCEPLIBS-g2\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-g2tmpl\"\u003eNCEPLIBS-g2tmpl\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-sp\"\u003eNCEPLIBS-sp\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-ip\"\u003eNCEPLIBS-ip\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-bacio\"\u003eNCEPLIBS-bacio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-w3emc\"\u003eNCEPLIBS-w3emc\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-w3nco\"\u003eNCEPLIBS-w3nco\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/noaa-emc/emc_crtm\"\u003eCRTM\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlso required to build NCEPpost executable (cmake option\nBUILD_POSTEXEC):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-sigio\"\u003eNCEPLIBS-sigio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-sfcio\"\u003eNCEPLIBS-sfcio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-nemsio\"\u003eNCEPLIBS-nemsio\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-gfsio\"\u003eNCEPLIBS-gfsio\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe \u003ca href=\"https://github.com/NOAA-EMC/NCEPLIBS-wrf_io\"\u003eNCEPLIBS-wrf_io\u003c/a\u003e\nlibrary is required to build with NCEPpost with WRF-IO library (cmake\noption BUILD_WITH_WRFIO).\u003c/p\u003e\n\u003cp\u003eThe following third-party libraries are required:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Unidata/netcdf-c\"\u003enetcdf-c\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Unidata/netcdf-fortran\"\u003enetcdf-fortran\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/jasper-software/jasper\"\u003eJasper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.libpng.org/pub/png/libpng.html\" rel=\"nofollow\"\u003elibpng\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://zlib.net/\" rel=\"nofollow\"\u003elibz\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-building\" class=\"anchor\" aria-hidden=\"true\" href=\"#building\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eBuilding\u003c/h2\u003e\n\u003cp\u003eBuilds include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eInline post (UPP library): Currently only supported for the GFS, RRFS,\nHAFS, and the UFS-MRW Application.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eOffline post (UPP executable): Supported for Regional applications\nincluding SRW, RRFS, HAFS, and standalone applications of UPP.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eCMake is used to manage all builds of the UPP.\nThe script \u003ccode\u003eUPP/tests/compile_upp.sh\u003c/code\u003e can be used to automatically\nbuild UPP on fully supported platforms where HPC-stack is supported.\nDetails in this script can be used to build on new platforms.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"true\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is\nprovided on an \"as is\" basis and the user assumes responsibility for\nits use. DOC has relinquished control of the information and no longer\nhas responsibility to protect the integrity, confidentiality, or\navailability of the information. Any claims against the Department of\nCommerce stemming from the use of its GitHub project will be governed\nby all applicable Federal law. Any reference to specific commercial\nproducts, processes, or services by service mark, trademark,\nmanufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of\nCommerce. The Department of Commerce seal and logo, or the seal and\nlogo of a DOC bureau, shall not be used in any manner to imply\nendorsement of any commercial product or activity by DOC or the United\nStates Government.\u003c/p\u003e\n",
    "stargazers_count": 25,
    "subscribers_count": 15,
    "topics": [],
    "updated_at": 1680455964.0
  },
  {
    "data_format": 2,
    "description": ":floppy_disk: C++ \u0026 Python API for Scientific I/O",
    "filenames": [
      ".github/ci/spack-envs/clang7_nopy_ompi_h5_ad1_ad2_bp3_libcpp/spack.yaml",
      ".github/ci/spack-envs/gcc7_py36_ompi_h5_ad1_ad2/spack.yaml",
      ".github/ci/spack-envs/clang7_nopy_nompi_h5_libcpp/spack.yaml"
    ],
    "full_name": "openPMD/openPMD-api",
    "latest_release": "0.15.1",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-c--python-api-for-scientific-io-with-openpmd\" class=\"anchor\" aria-hidden=\"true\" href=\"#c--python-api-for-scientific-io-with-openpmd\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eC++ \u0026amp; Python API for Scientific I/O with openPMD\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/openPMD/openPMD-standard/releases\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5957dc11cb68f6705ef9ef6683152c6c4fcc057a24dff340e1e8bada1bee0d01/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e504d442d312e302e302d2d312e312e302d626c7565\" alt=\"Supported openPMD Standard\" data-canonical-src=\"https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openpmd.org/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2d54fa5adcf7ca50d2cdb45823be5064379b613d526fa06f6e193ba2ce616318/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4150492d446f787967656e2d626c7565\" alt=\"Doxygen\" data-canonical-src=\"https://img.shields.io/badge/API-Doxygen-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://gitter.im/openPMD/API\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f551141eea2176c34aa163092549d6fdde9a220d605d6efe9128b024c6e5932b/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6f70656e504d442f415049\" alt=\"Gitter chat\" data-canonical-src=\"https://img.shields.io/gitter/room/openPMD/API\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" title=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.gnu.org/licenses/lgpl-3.0.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4fc8091716dbd967fa2a82eef3d29227110e5081f3128aaa38663e547c24f812/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4c47504c76332d626c7565\" alt=\"License\" data-canonical-src=\"https://img.shields.io/badge/license-LGPLv3-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.14278/rodare.27\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/104f6901ae04bff8385acc8273bb276ab84656a927a418108b940d09fd6e5d7c/68747470733a2f2f726f646172652e687a64722e64652f62616467652f444f492f31302e31343237382f726f646172652e32372e737667\" alt=\"DOI\" data-canonical-src=\"https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0d568047fbbd300af56b766d9a4235a20534485f5827194e859d4f5c20e58334/68747470733a2f2f7777772e636f6465666163746f722e696f2f7265706f7369746f72792f6769746875622f6f70656e706d642f6f70656e706d642d6170692f6261646765\" alt=\"CodeFactor\" data-canonical-src=\"https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/openPMD/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f0487a8fc14d269210ae8ce80b556d4afcd93684f02e61386d2d02daa4423cbd/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6f70656e504d442f6f70656e504d442d6170692f6261646765\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/openPMD/openPMD-api/badge\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8f438ca4eaa308f982d0a28c48f05bf63ca1a86e52c3d2817f6d7559d1dee68e/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6f70656e706d642d6170692f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/openpmd-api/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://travis-ci.com/openPMD/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8278d89e3634e25a818a2d673fe997c2aa5a09fd5995f716aeffa743388030ee/68747470733a2f2f7472617669732d63692e636f6d2f6f70656e504d442f6f70656e504d442d6170692e7376673f6272616e63683d646576\" alt=\"Linux/OSX Build Status dev\" data-canonical-src=\"https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/30679331f3c6a5ae54970eda85f36a30347dee8a9111448d7aa48587fd524a1d/68747470733a2f2f63692e6170707665796f722e636f6d2f6170692f70726f6a656374732f7374617475732f78393571346e36323070716b306530742f6272616e63682f6465763f7376673d74727565\" alt=\"Windows Build Status dev\" data-canonical-src=\"https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels\"\u003e\u003cimg src=\"https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels\u0026amp;event=push\" alt=\"PyPI Wheel Release\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1\u0026amp;branchName=azure_install\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/1fc9c860bb1fc8e7e145ea9dd6723b9ac6ac2743c195e5e899f6cfa3d38a5a69/68747470733a2f2f6465762e617a7572652e636f6d2f6178656c687565626c2f6f70656e504d442d6170692f5f617069732f6275696c642f7374617475732f6f70656e504d442e6f70656e504d442d6170693f6272616e63684e616d653d617a7572655f696e7374616c6c266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Packages Status\" data-canonical-src=\"https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install\u0026amp;label=nightly%20packages\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://scan.coverity.com/projects/openpmd-openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0b068d7b5718aafccb46e2ee35f8249938ef189a36ba353c15222ed5e6f65e49/68747470733a2f2f7363616e2e636f7665726974792e636f6d2f70726f6a656374732f31373630322f62616467652e737667\" alt=\"Coverity Scan Build Status\" data-canonical-src=\"https://scan.coverity.com/projects/17602/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eopenPMD is an open meta-data schema that provides meaning and self-description for data sets in science and engineering.\nSee \u003ca href=\"https://github.com/openPMD/openPMD-standard\"\u003ethe openPMD standard\u003c/a\u003e for details of this schema.\u003c/p\u003e\n\u003cp\u003eThis library provides a reference API for openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable, hierarchical file formats, this library implements various backends such as HDF5, ADIOS1, ADIOS2 and JSON.\nWriting \u0026amp; reading through those backends and their associated files are supported for serial and \u003ca href=\"https://www.mpi-forum.org/docs/\" rel=\"nofollow\"\u003eMPI-parallel\u003c/a\u003e workflows.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-usage\" class=\"anchor\" aria-hidden=\"true\" href=\"#usage\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eUsage\u003c/h2\u003e\n\u003ch3\u003e\u003ca id=\"user-content-c\" class=\"anchor\" aria-hidden=\"true\" href=\"#c\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eC++\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/8d47ea5fd5ff323ff5c76593ea37f2340533c73de5e6e37a2b27d7dc28070cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d79656c6c6f77677265656e\" alt=\"C++17\" title=\"C++17 API\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"C++17 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-c++\"\u003e\u003cpre\u003e#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003eopenPMD/openPMD.hpp\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n#\u003cspan class=\"pl-k\"\u003einclude\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0026lt;\u003c/span\u003eiostream\u003cspan class=\"pl-pds\"\u003e\u0026gt;\u003c/span\u003e\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e//\u003c/span\u003e ...\u003c/span\u003e\n\n\u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e s = openPMD::Series(\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003esamples/git-sample/data%T.h5\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e, openPMD::Access::READ_ONLY);\n\n\u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [step, it] : s.iterations ) {\n    std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eIteration: \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; step \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [name, mesh] : it.\u003cspan class=\"pl-smi\"\u003emeshes\u003c/span\u003e ) {\n        std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e  Mesh \u0027\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0027 attributes:\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e\u0026amp; val : mesh.\u003cspan class=\"pl-c1\"\u003eattributes\u003c/span\u003e() )\n            std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e    \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e;\n    }\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e \u0026amp; [name, species] : it.\u003cspan class=\"pl-smi\"\u003eparticles\u003c/span\u003e ) {\n        std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e  Particle species \u0027\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u0027 attributes:\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e;\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e( \u003cspan class=\"pl-k\"\u003eauto\u003c/span\u003e \u003cspan class=\"pl-k\"\u003econst\u003c/span\u003e\u0026amp; val : species.\u003cspan class=\"pl-c1\"\u003eattributes\u003c/span\u003e() )\n            std::cout \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e    \u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003cspan class=\"pl-cce\"\u003e\\n\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\u0027\u003c/span\u003e\u003c/span\u003e;\n    }\n}\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-python\" class=\"anchor\" aria-hidden=\"true\" href=\"#python\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003ePython\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://www.python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/acd285afab5d7ddd4942e5215ade53e84551c9d7d635642ba92c19fde7d4345b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e332d79656c6c6f77677265656e\" alt=\"Python3\" title=\"Python3 API\" data-canonical-src=\"https://img.shields.io/badge/language-Python3-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e \u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7ec85c013128e804b5696f4fdf0c910a9f5456c4295b16217b194e8691f026b5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f70686173652d626574612d79656c6c6f77677265656e\" alt=\"Python3 API: Beta\" title=\"Status: Beta\" data-canonical-src=\"https://img.shields.io/badge/phase-beta-yellowgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-python\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eimport\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eopenpmd_api\u003c/span\u003e \u003cspan class=\"pl-k\"\u003eas\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e# ...\u003c/span\u003e\n\n\u003cspan class=\"pl-s1\"\u003eseries\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003e=\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eSeries\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"samples/git-sample/data%T.h5\"\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003eio\u003c/span\u003e.\u003cspan class=\"pl-v\"\u003eAccess\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eread_only\u003c/span\u003e)\n\n\u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_i\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003eseries\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eiterations\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n    \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"Iteration: {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_i\u003c/span\u003e))\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_m\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003em\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003emeshes\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n        \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"  Mesh \u0027{0}\u0027 attributes:\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_m\u003c/span\u003e))\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003em\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eattributes\u003c/span\u003e:\n            \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"    {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e))\n\n    \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ek_p\u003c/span\u003e, \u003cspan class=\"pl-s1\"\u003ep\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ei\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eparticles\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eitems\u003c/span\u003e():\n        \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"  Particle species \u0027{0}\u0027 attributes:\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ek_p\u003c/span\u003e))\n        \u003cspan class=\"pl-k\"\u003efor\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e \u003cspan class=\"pl-c1\"\u003ein\u003c/span\u003e \u003cspan class=\"pl-s1\"\u003ep\u003c/span\u003e.\u003cspan class=\"pl-s1\"\u003eattributes\u003c/span\u003e:\n            \u003cspan class=\"pl-en\"\u003eprint\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"    {0}\"\u003c/span\u003e.\u003cspan class=\"pl-en\"\u003eformat\u003c/span\u003e(\u003cspan class=\"pl-s1\"\u003ea\u003c/span\u003e))\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-more\" class=\"anchor\" aria-hidden=\"true\" href=\"#more\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMore!\u003c/h3\u003e\n\u003cp\u003eCurious?\nOur manual shows full \u003ca href=\"https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html\" rel=\"nofollow\"\u003eread \u0026amp; write examples\u003c/a\u003e, both serial and MPI-parallel!\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-dependencies\" class=\"anchor\" aria-hidden=\"true\" href=\"#dependencies\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDependencies\u003c/h2\u003e\n\u003cp\u003eRequired:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCMake 3.15.0+\u003c/li\u003e\n\u003cli\u003eC++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eShipped internally in \u003ccode\u003eshare/openPMD/thirdParty/\u003c/code\u003e:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/catchorg/Catch2\"\u003eCatch2\u003c/a\u003e 2.13.10+ (\u003ca href=\"https://github.com/catchorg/Catch2/blob/master/LICENSE.txt\"\u003eBSL-1.0\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11\"\u003epybind11\u003c/a\u003e 2.10.1+ (\u003ca href=\"https://github.com/pybind/pybind11/blob/master/LICENSE\"\u003enew BSD\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/nlohmann/json\"\u003eNLohmann-JSON\u003c/a\u003e 3.9.1+ (\u003ca href=\"https://github.com/nlohmann/json/blob/develop/LICENSE.MIT\"\u003eMIT\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ToruNiina/toml11\"\u003etoml11\u003c/a\u003e 3.7.1+ (\u003ca href=\"https://github.com/ToruNiina/toml11/blob/master/LICENSE\"\u003eMIT\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eI/O backends:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"nofollow\"\u003eJSON\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://support.hdfgroup.org/HDF5\" rel=\"nofollow\"\u003eHDF5\u003c/a\u003e 1.8.13+ (optional)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://www.olcf.ornl.gov/center-projects/adios\" rel=\"nofollow\"\u003eADIOS1\u003c/a\u003e 1.13.1+ (optional, deprecated)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ornladios/ADIOS2\"\u003eADIOS2\u003c/a\u003e 2.7.0+ (optional)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ewhile those can be built either with or without:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOptional language bindings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePython:\n\u003cul\u003e\n\u003cli\u003ePython 3.7 - 3.11\u003c/li\u003e\n\u003cli\u003epybind11 2.10.1+\u003c/li\u003e\n\u003cli\u003enumpy 1.15+\u003c/li\u003e\n\u003cli\u003empi4py 2.1+ (optional, for MPI)\u003c/li\u003e\n\u003cli\u003epandas 1.0+ (optional, for dataframes)\u003c/li\u003e\n\u003cli\u003edask 2021+ (optional, for dask dataframes)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCUDA C++ (optional, currently used only in tests)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/580cdb6331254f66680bd967326d9630f5124291efd5ace18549fbb93cbae6db/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737061636b2e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Spack Package\" data-canonical-src=\"https://img.shields.io/badge/spack.io-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3c3728308a9e416589fa8b3b8168967287c515037bfbd4b40f1b14f266de56fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612e696f2d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Conda Package\" data-canonical-src=\"https://img.shields.io/badge/conda.io-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/openPMD/homebrew-openPMD\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/92b7b7bb69b2b17d1981ae5fdcdb32f971ee57f54a98ea4804e93fd0a2eb58ef/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772e73682d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"Brew Package\" data-canonical-src=\"https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4eeb2c48c0e554ea8dbe8e90f73a6f2d217e775e0bd5e5cb90ddf4619ef3a6a0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707970692e6f72672d6f70656e706d642d2d6170692d627269676874677265656e\" alt=\"PyPI Package\" data-canonical-src=\"https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2babf79954ea524c24f2f9b1cfa05728fdaccbe0a80c2da6a7a7595cc131894c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f66726f6d5f736f757263652d434d616b652d627269676874677265656e\" alt=\"From Source\" data-canonical-src=\"https://img.shields.io/badge/from_source-CMake-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur community loves to help each other.\nPlease \u003ca href=\"https://github.com/openPMD/openPMD-api/issues/new?labels=install\u0026amp;template=install_problem.md\"\u003ereport installation problems\u003c/a\u003e in case you should get stuck.\u003c/p\u003e\n\u003cp\u003eChoose \u003cem\u003eone\u003c/em\u003e of the install methods below to get started:\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-spack\" class=\"anchor\" aria-hidden=\"true\" href=\"#spack\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/becffbecb6a50502286f02ec86c4e62f239f3671148d11341152e0dc695a2fc9/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f6f70656e706d642d617069\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Spack Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b29fc54abf92a2a6d1d2c70159eb276df53b67a1294ae3f82b1b0bf22a3c586b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392c5f646576656c6f706d656e742c5f4850432d627269676874677265656e\" alt=\"Spack Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:               +python +adios1 -adios2 -hdf5 -mpi\u003c/span\u003e\nspack install openpmd-api\nspack load openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-conda\" class=\"anchor\" aria-hidden=\"true\" href=\"#conda\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://conda.io\" rel=\"nofollow\"\u003eConda\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/3ad2b345bb3589aa2d733ca20df72938ed54a48342b69f7cbe9eacab43d84549/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Conda Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"Conda Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/openpmd-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a51d3cd2bfa3c6b01bd0f2e36abc206fb9db5700105fac2acd2c2105fced2ec4/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f646e2f636f6e64612d666f7267652f6f70656e706d642d617069\" alt=\"Conda Downloads\" data-canonical-src=\"https://img.shields.io/conda/dn/conda-forge/openpmd-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                      OpenMPI support  =*=mpi_openmpi*\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                        MPICH support  =*=mpi_mpich*\u003c/span\u003e\nconda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-brew\" class=\"anchor\" aria-hidden=\"true\" href=\"#brew\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://brew.sh\" rel=\"nofollow\"\u003eBrew\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/openPMD/homebrew-openPMD\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d873c8c473fece8abf1c34a8299a50b7ee0da9772eb50cce8649e7ca32468a6c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f627265772d6c61746573745f76657273696f6e2d6f72616e6765\" alt=\"Brew Version\" data-canonical-src=\"https://img.shields.io/badge/brew-latest_version-orange\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://docs.brew.sh/Homebrew-on-Linux\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/ceb548d628bb13bf7eed61d8bb9292368f02fb952a549f53c7f34c8afad3ed11/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f73782532302d626c7565\" alt=\"Brew Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://brew.sh\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7b767b67facc26db7d850ae5c3155fa949048991dde7a0f5471c1e6862f0a586/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f253238432532422532422c5f70792532392d627269676874677265656e\" alt=\"Brew Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003ebrew tap openpmd/openpmd\nbrew install openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-pypi\" class=\"anchor\" aria-hidden=\"true\" href=\"#pypi\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003e\u003ca href=\"https://pypi.org\" rel=\"nofollow\"\u003ePyPI\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fc28bd368523d0b8adab5f4b414aebb304743130eef42bca203f4e9eed428ae7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6f70656e504d442d617069\" alt=\"PyPI Version\" data-canonical-src=\"https://img.shields.io/pypi/v/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api/#files\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"PyPI Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a422d06dfefa14bef9b5ad8fbd0df126763371e6f988172ee60ff850303a4fa4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d6465736b746f705f25323870792532392d627269676874677265656e\" alt=\"PyPI Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7cef25e887c028f65d5d7e20f3e7abe394ab328ecb499e34e47460afd2c78558/68747470733a2f2f696d672e736869656c64732e696f2f707970692f666f726d61742f6f70656e504d442d617069\" alt=\"PyPI Format\" data-canonical-src=\"https://img.shields.io/pypi/format/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://pypi.org/project/openPMD-api\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/82acdd95515851a5ba4a3006871151f76cfe4d6583f6c24e80bd0fd29d391845/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6f70656e504d442d617069\" alt=\"PyPI Downloads\" data-canonical-src=\"https://img.shields.io/pypi/dm/openPMD-api\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOn very old macOS versions (\u0026lt;10.9) or on exotic processor architectures, this install method \u003cem\u003ecompiles from source\u003c/em\u003e against the found installations of HDF5, ADIOS1, ADIOS2, and/or MPI (in system paths, from other package managers, or loaded via a module system, ...).\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e we need pip 19 or newer\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                   --user\u003c/span\u003e\npython3 -m pip install -U pip\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                        --user\u003c/span\u003e\npython3 -m pip install openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eIf MPI-support shall be enabled, we always have to recompile:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                    --user\u003c/span\u003e\npython3 -m pip install -U pip setuptools wheel\npython3 -m pip install -U cmake\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                                                   --user\u003c/span\u003e\nopenPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor some exotic architectures and compilers, you might need to disable a compiler feature called \u003ca href=\"https://en.wikipedia.org/wiki/Interprocedural_optimization\" rel=\"nofollow\"\u003elink-time/interprocedural optimization\u003c/a\u003e if you encounter linking problems:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional:                                                --user\u003c/span\u003e\npython3 -m pip install openpmd-api --no-binary openpmd-api\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdditional CMake options can be passed via individual environment variables, which need to be prefixed with \u003ccode\u003eopenPMD_CMAKE_\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-from-source\" class=\"anchor\" aria-hidden=\"true\" href=\"#from-source\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eFrom Source\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/0a40953107090abff3b564ec3436668756b873cd4d9e021738a046781a5a0e6b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7573655f636173652d646576656c6f706d656e742d627269676874677265656e\" alt=\"Source Use Case\" data-canonical-src=\"https://img.shields.io/badge/use_case-development-brightgreen\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eopenPMD-api can also be built and installed from source using \u003ca href=\"https://cmake.org/\" rel=\"nofollow\"\u003eCMake\u003c/a\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003egit clone https://github.com/openPMD/openPMD-api.git\n\nmkdir openPMD-api-build\n\u003cspan class=\"pl-c1\"\u003ecd\u003c/span\u003e openPMD-api-build\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: for full tests, with unzip\u003c/span\u003e\n../openPMD-api/share/openPMD/download_samples.sh\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e for own install prefix append:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DCMAKE_INSTALL_PREFIX=$HOME/somepath\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e for options append:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DopenPMD_USE_...=...\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e e.g. for python support add:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which python3)\u003c/span\u003e\ncmake ../openPMD-api\n\ncmake --build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional\u003c/span\u003e\nctest\n\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e sudo might be required for system paths\u003c/span\u003e\ncmake --build \u003cspan class=\"pl-c1\"\u003e.\u003c/span\u003e --target install\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eThe following options can be added to the \u003ccode\u003ecmake\u003c/code\u003e call to control features.\nCMake controls options with prefixed \u003ccode\u003e-D\u003c/code\u003e, e.g. \u003ccode\u003e-DopenPMD_USE_MPI=OFF\u003c/code\u003e:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_MPI\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eParallel, Multi-Node I/O for clusters\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_HDF5\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eHDF5 backend (\u003ccode\u003e.h5\u003c/code\u003e files)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_ADIOS1\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eAUTO/ON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eADIOS1 backend (\u003ccode\u003e.bp\u003c/code\u003e files up to version BP3) - deprecated\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_ADIOS2\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eADIOS2 backend (\u003ccode\u003e.bp\u003c/code\u003e files in BP3, BP4 or higher)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_PYTHON\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eAUTO\u003c/strong\u003e/ON/OFF\u003c/td\u003e\n\u003ctd\u003eEnable Python bindings\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INVASIVE_TESTS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eEnable unit tests that modify source code \u003csup\u003e1\u003c/sup\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_VERIFY\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eEnable internal VERIFY (assert) macro independent of build type \u003csup\u003e2\u003c/sup\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_INSTALL\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eAdd installation targets\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_INSTALL_RPATH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eAdd RPATHs to installed binaries\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003ePython_EXECUTABLE\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e(newest found)\u003c/td\u003e\n\u003ctd\u003ePath to Python executable\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003csup\u003e1\u003c/sup\u003e \u003cem\u003ee.g. changes C++ visibility keywords, breaks MSVC\u003c/em\u003e\n\u003csup\u003e2\u003c/sup\u003e \u003cem\u003ethis includes most pre-/post-condition checks, disabling without specific cause is highly discouraged\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eAdditionally, the following libraries are shipped internally.\nThe following options allow to switch to external installs:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eLibrary\u003c/th\u003e\n\u003cth\u003eVersion\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_CATCH\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eCatch2\u003c/td\u003e\n\u003ctd\u003e2.13.10+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_PYBIND11\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003epybind11\u003c/td\u003e\n\u003ctd\u003e2.10.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_JSON\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eNLohmann-JSON\u003c/td\u003e\n\u003ctd\u003e3.9.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_INTERNAL_TOML11\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003etoml11\u003c/td\u003e\n\u003ctd\u003e3.7.1+\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eBy default, this will build as a shared library (\u003ccode\u003elibopenPMD.[so|dylib|dll]\u003c/code\u003e) and installs also its headers.\nIn order to build a static library, append \u003ccode\u003e-DBUILD_SHARED_LIBS=OFF\u003c/code\u003e to the \u003ccode\u003ecmake\u003c/code\u003e command.\nYou can only build a static or a shared library at a time.\u003c/p\u003e\n\u003cp\u003eBy default, the \u003ccode\u003eRelease\u003c/code\u003e version is built.\nIn order to build with debug symbols, pass \u003ccode\u003e-DCMAKE_BUILD_TYPE=Debug\u003c/code\u003e to your \u003ccode\u003ecmake\u003c/code\u003e command.\u003c/p\u003e\n\u003cp\u003eBy default, tests, examples and command line tools are built.\nIn order to skip building those, pass \u003ccode\u003eOFF\u003c/code\u003e to these \u003ccode\u003ecmake\u003c/code\u003e options:\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eCMake Option\u003c/th\u003e\n\u003cth\u003eValues\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_TESTING\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild tests\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_EXAMPLES\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild examples\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_BUILD_CLI_TOOLS\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003e\n\u003cstrong\u003eON\u003c/strong\u003e/OFF\u003c/td\u003e\n\u003ctd\u003eBuild command-line tools\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003ccode\u003eopenPMD_USE_CUDA_EXAMPLES\u003c/code\u003e\u003c/td\u003e\n\u003ctd\u003eON/\u003cstrong\u003eOFF\u003c/strong\u003e\n\u003c/td\u003e\n\u003ctd\u003eUse CUDA in examples\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2\u003e\u003ca id=\"user-content-linking-to-your-project\" class=\"anchor\" aria-hidden=\"true\" href=\"#linking-to-your-project\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLinking to your project\u003c/h2\u003e\n\u003cp\u003eThe install will contain header files and libraries in the path set with \u003ccode\u003e-DCMAKE_INSTALL_PREFIX\u003c/code\u003e.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-cmake\" class=\"anchor\" aria-hidden=\"true\" href=\"#cmake\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCMake\u003c/h3\u003e\n\u003cp\u003eIf your project is using CMake for its build, one can conveniently use our provided \u003ccode\u003eopenPMDConfig.cmake\u003c/code\u003e package which is installed alongside the library.\u003c/p\u003e\n\u003cp\u003eFirst set the following environment hint if openPMD-api was \u003cem\u003enot\u003c/em\u003e installed in a system path:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: only needed if installed outside of system paths\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e CMAKE_PREFIX_PATH=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/somepath:\u003cspan class=\"pl-smi\"\u003e$CMAKE_PREFIX_PATH\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eUse the following lines in your project\u0027s \u003ccode\u003eCMakeLists.txt\u003c/code\u003e:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS1 ADIOS2\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003efind_package\u003c/span\u003e(openPMD 0.9.0 \u003cspan class=\"pl-k\"\u003eCONFIG\u003c/span\u003e)\n\n\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e(openPMD_FOUND)\n    \u003cspan class=\"pl-c1\"\u003etarget_link_libraries\u003c/span\u003e(YourTarget \u003cspan class=\"pl-k\"\u003ePRIVATE\u003c/span\u003e openPMD::openPMD)\n\u003cspan class=\"pl-k\"\u003eendif\u003c/span\u003e()\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003e\u003cem\u003eAlternatively\u003c/em\u003e, add the openPMD-api repository source directly to your project and use it via:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003eadd_subdirectory\u003c/span\u003e(\u003cspan class=\"pl-s\"\u003e\"path/to/source/of/openPMD-api\"\u003c/span\u003e)\n\n\u003cspan class=\"pl-c1\"\u003etarget_link_libraries\u003c/span\u003e(YourTarget \u003cspan class=\"pl-k\"\u003ePRIVATE\u003c/span\u003e openPMD::openPMD)\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eFor development workflows, you can even automatically download and build openPMD-api from within a depending CMake project.\nJust replace the \u003ccode\u003eadd_subdirectory\u003c/code\u003e call with:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-cmake\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c1\"\u003einclude\u003c/span\u003e(FetchContent)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(CMAKE_POLICY_DEFAULT_CMP0077 \u003cspan class=\"pl-k\"\u003eNEW\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_CLI_TOOLS \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_EXAMPLES \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_TESTING \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_BUILD_SHARED_LIBS \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)  \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e precedence over BUILD_SHARED_LIBS if needed\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_INSTALL \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)            \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e or instead use:\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e set(openPMD_INSTALL ${BUILD_SHARED_LIBS})  # only install if used as a shared library\u003c/span\u003e\n\u003cspan class=\"pl-c1\"\u003eset\u003c/span\u003e(openPMD_USE_PYTHON \u003cspan class=\"pl-k\"\u003eOFF\u003c/span\u003e)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY \u003cspan class=\"pl-s\"\u003e\"https://github.com/openPMD/openPMD-api.git\"\u003c/span\u003e\n  GIT_TAG        \u003cspan class=\"pl-s\"\u003e\"dev\"\u003c/span\u003e)\nFetchContent_MakeAvailable(openPMD)\u003c/pre\u003e\u003c/div\u003e\n\u003ch3\u003e\u003ca id=\"user-content-manually\" class=\"anchor\" aria-hidden=\"true\" href=\"#manually\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eManually\u003c/h3\u003e\n\u003cp\u003eIf your (Linux/OSX) project is build by calling the compiler directly or uses a manually written \u003ccode\u003eMakefile\u003c/code\u003e, consider using our \u003ccode\u003eopenPMD.pc\u003c/code\u003e helper file for \u003ccode\u003epkg-config\u003c/code\u003e which are installed alongside the library.\u003c/p\u003e\n\u003cp\u003eFirst set the following environment hint if openPMD-api was \u003cem\u003enot\u003c/em\u003e installed in a system path:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e optional: only needed if installed outside of system paths\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eexport\u003c/span\u003e PKG_CONFIG_PATH=\u003cspan class=\"pl-smi\"\u003e$HOME\u003c/span\u003e/somepath/lib/pkgconfig:\u003cspan class=\"pl-smi\"\u003e$PKG_CONFIG_PATH\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp\u003eAdditional linker and compiler flags for your project are available via:\u003c/p\u003e\n\u003cdiv class=\"highlight highlight-source-shell\"\u003e\u003cpre\u003e\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e switch to check if openPMD-api was build as static library\u003c/span\u003e\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e (via BUILD_SHARED_LIBS=OFF) or as shared library (default)\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eif\u003c/span\u003e [ \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e$(\u003c/span\u003epkg-config --variable=static openPMD\u003cspan class=\"pl-pds\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e \u003cspan class=\"pl-k\"\u003e==\u003c/span\u003e \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003etrue\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e ]\n\u003cspan class=\"pl-k\"\u003ethen\u003c/span\u003e\n    pkg-config --libs --static openPMD\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003eelse\u003c/span\u003e\n    pkg-config --libs openPMD\n    \u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -L${HOME}/somepath/lib -lopenPMD\u003c/span\u003e\n\u003cspan class=\"pl-k\"\u003efi\u003c/span\u003e\n\npkg-config --cflags openPMD\n\u003cspan class=\"pl-c\"\u003e\u003cspan class=\"pl-c\"\u003e#\u003c/span\u003e -I${HOME}/somepath/include\u003c/span\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003ch2\u003e\u003ca id=\"user-content-author-contributions\" class=\"anchor\" aria-hidden=\"true\" href=\"#author-contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eAuthor Contributions\u003c/h2\u003e\n\u003cp\u003eopenPMD-api is developed by many people.\nIt was initially started by the \u003ca href=\"https://hzdr.de/crp\" rel=\"nofollow\"\u003eComputational Radiation Physics Group\u003c/a\u003e at \u003ca href=\"https://www.hzdr.de/\" rel=\"nofollow\"\u003eHZDR\u003c/a\u003e as successor to \u003ca href=\"https://github.com/ComputationalRadiationPhysics/libSplash/\"\u003elibSplash\u003c/a\u003e, generalizing the \u003ca href=\"https://arxiv.org/abs/1706.00522\" rel=\"nofollow\"\u003esuccessful HDF5 \u0026amp; ADIOS1 implementations\u003c/a\u003e in \u003ca href=\"https://github.com/ComputationalRadiationPhysics/picongpu\"\u003ePIConGPU\u003c/a\u003e.\nThe following people and institutions \u003ca href=\"https://github.com/openPMD/openPMD-api/graphs/contributors\"\u003econtributed\u003c/a\u003e to openPMD-api:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ax3l\"\u003eAxel Huebl (HZDR, now LBNL)\u003c/a\u003e:\nproject lead, releases, documentation, automated CI/CD, Python bindings, Dask, installation \u0026amp; packaging, prior reference implementations\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/franzpoeschel\"\u003eFranz Poeschel (CASUS)\u003c/a\u003e:\nJSON \u0026amp; ADIOS2 backend, data staging/streaming, reworked class design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/C0nsultant\"\u003eFabian Koller (HZDR)\u003c/a\u003e:\ninitial library design and implementation with HDF5 \u0026amp; ADIOS1 backend\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/guj\"\u003eJunmin Gu (LBNL)\u003c/a\u003e:\nnon-collective parallel I/O fixes, ADIOS improvements, benchmarks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eFurther thanks go to improvements and contributions from:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/CFGrote\"\u003eCarsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)\u003c/a\u003e:\ndraft of our Python unit tests\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/StanczakDominik\"\u003eDominik Sta\u0144czak (Warsaw University of Technology)\u003c/a\u003e:\ndocumentation improvements\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/mingwandroid\"\u003eRay Donnelly (Anaconda, Inc.)\u003c/a\u003e:\nsupport on conda packaging and libc++ quirks\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/amundson\"\u003eJames Amundson (FNAL)\u003c/a\u003e:\ncompile fix for newer compilers\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/psychocoderHPC\"\u003eRen\u00e9 Widera (HZDR)\u003c/a\u003e:\ndesign improvements for initial API design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/erikzenker\"\u003eErik Zenker (HZDR)\u003c/a\u003e:\ndesign improvements for initial API design\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/sbastrakov\"\u003eSergei Bastrakov (HZDR)\u003c/a\u003e:\ndocumentation improvements (windows)\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/RemiLehe\"\u003eR\u00e9mi Lehe (LBNL)\u003c/a\u003e:\npackage integration testing on macOS and Linux\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/LDAmorim\"\u003eL\u00edgia Diana Amorim (LBNL)\u003c/a\u003e:\npackage integration testing on macOS\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/KseniaBastrakova\"\u003eKseniia Bastrakova (HZDR)\u003c/a\u003e:\ncompatibility testing\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/PrometheusPi\"\u003eRichard Pausch (HZDR)\u003c/a\u003e:\ncompatibility testing, documentation improvements\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pordyna\"\u003ePawe\u0142 Ordyna (HZDR)\u003c/a\u003e:\nreport on NVCC warnings\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/dmitry-ganyushin\"\u003eDmitry Ganyushin (ORNL)\u003c/a\u003e:\nDask prototyping \u0026amp; ADIOS2 benchmarking\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jakirkham\"\u003eJohn Kirkham (NVIDIA)\u003c/a\u003e:\nDask guidance \u0026amp; reviews\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/eschnett\"\u003eErik Schnetter (PITP)\u003c/a\u003e:\nC++ API bug fixes\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/jeanbez\"\u003eJean Luca Bez (LBNL)\u003c/a\u003e:\nHDF5 performance tuning\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/bernhardmgruber\"\u003eBernhard Manfred Gruber (CERN)\u003c/a\u003e:\nCMake fix for parallel HDF5\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/DerNils-git\"\u003eNils Schild (IPP)\u003c/a\u003e:\nCMake improvements for subprojects\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003ca id=\"user-content-grants\" class=\"anchor\" aria-hidden=\"true\" href=\"#grants\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGrants\u003c/h3\u003e\n\u003cp\u003eThe openPMD-api authors acknowledge support via the following programs.\nSupported by the CAMPA collaboration, a project of the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research and Office of High Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\nPreviously supported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration).\nThis project has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 654220.\nThis work was partially funded by the Center of Advanced Systems Understanding (CASUS), which is financed by Germany\u0027s Federal Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism (SMWK) with tax funds on the basis of the budget approved by the Saxon State Parliament.\u003c/p\u003e\n\u003ch3\u003e\u003ca id=\"user-content-transitive-contributions\" class=\"anchor\" aria-hidden=\"true\" href=\"#transitive-contributions\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eTransitive Contributions\u003c/h3\u003e\n\u003cp\u003eopenPMD-api stands on the shoulders of giants and we are grateful for the following projects included as direct dependencies:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ornladios/ADIOS\"\u003eADIOS1\u003c/a\u003e and \u003ca href=\"https://github.com/ornladios/ADIOS2\"\u003eADIOS2\u003c/a\u003e by \u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003eS. Klasky (ORNL), team, collaborators\u003c/a\u003e and \u003ca href=\"https://github.com/ornladios/ADIOS2/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/catchorg/Catch2\"\u003eCatch2\u003c/a\u003e by \u003ca href=\"https://github.com/philsquared\"\u003ePhil Nash\u003c/a\u003e, \u003ca href=\"https://github.com/horenmar\"\u003eMartin Ho\u0159e\u0148ovsk\u00fd\u003c/a\u003e and \u003ca href=\"https://github.com/catchorg/Catch2/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eHDF5 by \u003ca href=\"https://www.hdfgroup.org\" rel=\"nofollow\"\u003ethe HDF group\u003c/a\u003e and community\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/nlohmann/json\"\u003ejson\u003c/a\u003e by \u003ca href=\"https://github.com/nlohmann\"\u003eNiels Lohmann\u003c/a\u003e and \u003ca href=\"https://github.com/nlohmann/json/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/ToruNiina/toml11\"\u003etoml11\u003c/a\u003e by \u003ca href=\"https://github.com/ToruNiina\"\u003eToru Niina\u003c/a\u003e and \u003ca href=\"https://github.com/ToruNiina/toml11#Contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\"https://github.com/pybind/pybind11\"\u003epybind11\u003c/a\u003e by \u003ca href=\"https://github.com/wjakob\"\u003eWenzel Jakob (EPFL)\u003c/a\u003e and \u003ca href=\"https://github.com/pybind/pybind11/graphs/contributors\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eall contributors to the evolution of modern C++ and early library preview developers, e.g. \u003ca href=\"https://github.com/mpark\"\u003eMichael Park (Facebook)\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003ethe \u003ca href=\"https://cmake.org\" rel=\"nofollow\"\u003eCMake build system\u003c/a\u003e and \u003ca href=\"https://github.com/Kitware/CMake/blob/master/Copyright.txt\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003epackaging support by the \u003ca href=\"https://conda-forge.org\" rel=\"nofollow\"\u003econda-forge\u003c/a\u003e, \u003ca href=\"https://pypi.org\" rel=\"nofollow\"\u003ePyPI\u003c/a\u003e and \u003ca href=\"https://spack.io\" rel=\"nofollow\"\u003eSpack\u003c/a\u003e communities, among others\u003c/li\u003e\n\u003cli\u003ethe \u003ca href=\"https://github.com/openPMD/openPMD-standard\"\u003eopenPMD-standard\u003c/a\u003e by \u003ca href=\"https://github.com/ax3l\"\u003eAxel Huebl (HZDR, now LBNL)\u003c/a\u003e and \u003ca href=\"https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md\"\u003econtributors\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n",
    "stargazers_count": 103,
    "subscribers_count": 10,
    "topics": [
      "openpmd",
      "openscience",
      "hdf5",
      "adios",
      "mpi",
      "hpc",
      "research",
      "file-handling",
      "python3",
      "opendata",
      "cpp14",
      "metadata"
    ],
    "updated_at": 1680167205.0
  },
  {
    "data_format": 2,
    "description": "SpECTRE is a code for multi-scale, multi-physics problems in astrophysics and gravitational physics.",
    "filenames": [
      "support/DevEnvironments/spack.yaml"
    ],
    "full_name": "sxs-collaboration/spectre",
    "latest_release": "v2023.03.09",
    "readme": "\u003cp\u003e\u003ca href=\"https://github.com/sxs-collaboration/spectre/blob/develop/LICENSE.txt\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667\" alt=\"license\" data-canonical-src=\"https://img.shields.io/badge/license-MIT-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://en.wikipedia.org/wiki/C%2B%2B#Standardization\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a3dbfd7a9a0364af5f02772460bf69fce89f741e10fb7c8e9aa3f26a0d96cfe7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f632532422532422d31372d626c75652e737667\" alt=\"Standard\" data-canonical-src=\"https://img.shields.io/badge/c%2B%2B-17-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/sxs-collaboration/spectre/actions\"\u003e\u003cimg src=\"https://github.com/sxs-collaboration/spectre/workflows/Tests/badge.svg?branch=develop\" alt=\"Build Status\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/sxs-collaboration/spectre?branch=develop\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/e909837c9640462fc3f2587028319e5f5dc6198453d97af6b12696ddeb34930b/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7378732d636f6c6c61626f726174696f6e2f737065637472652f62616467652e7376673f6272616e63683d646576656c6f70\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/github/sxs-collaboration/spectre/badge.svg?branch=develop\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/gh/sxs-collaboration/spectre\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2b0d1a9c279878e18a98627f608e86ad2f22a730eebd7713b9ba9b173a16cdbb/68747470733a2f2f636f6465636f762e696f2f67682f7378732d636f6c6c61626f726174696f6e2f737065637472652f6272616e63682f646576656c6f702f67726170682f62616467652e737667\" alt=\"codecov\" data-canonical-src=\"https://codecov.io/gh/sxs-collaboration/spectre/branch/develop/graph/badge.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/sxs-collaboration/spectre/releases/tag/v2023.03.09\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/36fb71d6655953b650cc30ab23228d985df7be762686ee9d782c7845d5a7672b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d76323032332e30332e30392d696e666f726d6174696f6e616c\" alt=\"release\" data-canonical-src=\"https://img.shields.io/badge/release-v2023.03.09-informational\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.7713393\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7380a3d98ac67e0155c3f98f70a781375d8ca217100ebaef49c0c1b250be710c/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f646f692f31302e353238312f7a656e6f646f2e373731333339332e737667\" alt=\"DOI\" data-canonical-src=\"https://zenodo.org/badge/doi/10.5281/zenodo.7713393.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-what-is-spectre\" class=\"anchor\" aria-hidden=\"true\" href=\"#what-is-spectre\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWhat is SpECTRE?\u003c/h2\u003e\n\u003cp\u003eSpECTRE is an open-source code for multi-scale, multi-physics problems\nin astrophysics and gravitational physics. In the future, we hope that\nit can be applied to problems across discipline boundaries in fluid\ndynamics, geoscience, plasma physics, nuclear physics, and\nengineering. It runs at petascale and is designed for future exascale\ncomputers.\u003c/p\u003e\n\u003cp\u003eSpECTRE is being developed in support of our collaborative Simulating\neXtreme Spacetimes (SXS) research program into the multi-messenger\nastrophysics of neutron star mergers, core-collapse supernovae, and\ngamma-ray bursts.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-citing-spectre\" class=\"anchor\" aria-hidden=\"true\" href=\"#citing-spectre\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCiting SpECTRE\u003c/h2\u003e\n\u003cp\u003ePlease cite SpECTRE in any publications that make use of its code or data. Cite\nthe latest version that you use in your publication. The DOI for this version\nis:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDOI: \u003ca href=\"https://doi.org/10.5281/zenodo.7713393\" rel=\"nofollow\"\u003e10.5281/zenodo.7713393\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can cite this BibTeX entry in your publication:\u003c/p\u003e\n\n\n\u003cdiv class=\"highlight highlight-text-bibtex\"\u003e\u003cpre\u003e\u003cspan class=\"pl-k\"\u003e@software\u003c/span\u003e{\u003cspan class=\"pl-en\"\u003espectrecode\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eauthor\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eDeppe, Nils and Throwe, William and Kidder, Lawrence E. and Vu,\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eNils L. and H\\\u0027ebert, Fran\\c{c}ois and Moxon, Jordan and Armaza, Crist\\\u0027obal and\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eBonilla, Gabriel S. and Kim, Yoonsoo and Kumar, Prayush and Lovelace, Geoffrey\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eand Macedo, Alexandra and Nelli, Kyle C. and O\u0027Shea, Eamonn and Pfeiffer, Harald\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eP. and Scheel, Mark A. and Teukolsky, Saul A. and Wittek, Nikolas A. and\u003c/span\u003e\n\u003cspan class=\"pl-s\"\u003eothers\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003etitle\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\\texttt{SpECTRE v2023.03.09}\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eversion\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e2023.03.09\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003epublisher\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eZenodo\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003edoi\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e10.5281/zenodo.7713393\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eurl\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003ehttps://spectre-code.org\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003ehowpublished\u003c/span\u003e =\n\u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\\href{https://doi.org/10.5281/zenodo.7713393}{10.5281/zenodo.7713393}\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003elicense\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003eMIT\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003eyear\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e2023\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e,\n    \u003cspan class=\"pl-s\"\u003emonth\u003c/span\u003e = \u003cspan class=\"pl-s\"\u003e\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e3\u003cspan class=\"pl-pds\"\u003e\"\u003c/span\u003e\u003c/span\u003e\n}\u003c/pre\u003e\u003c/div\u003e\n\n\u003cp\u003eTo aid reproducibility of your scientific results with SpECTRE, we recommend you\nkeep track of the version(s) you used and report this information in your\npublication. We also recommend you supply the YAML input files and, if\nappropriate, any additional C++ code you wrote to compile SpECTRE executables as\nsupplemental material to the publication.\u003c/p\u003e\n\u003cp\u003eSee our \u003ca href=\"https://spectre-code.org/publication_policies.html\" rel=\"nofollow\"\u003epublication policy\u003c/a\u003e\nfor more information.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-viewing-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#viewing-documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eViewing Documentation\u003c/h2\u003e\n\u003cp\u003eThe documentation can be viewed at \u003ca href=\"https://spectre-code.org/\" rel=\"nofollow\"\u003ehttps://spectre-code.org/\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 122,
    "subscribers_count": 14,
    "topics": [],
    "updated_at": 1680540221.0
  },
  {
    "data_format": 2,
    "description": "WarpX is an advanced, time-based electromagnetic \u0026 electrostatic Particle-In-Cell code.",
    "filenames": [
      "Tools/machines/desktop/spack-ubuntu-openmp.yaml",
      "Tools/machines/desktop/spack-macos-openmp.yaml"
    ],
    "full_name": "ECP-WarpX/WarpX",
    "latest_release": "23.04",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-warpx\" class=\"anchor\" aria-hidden=\"true\" href=\"#warpx\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eWarpX\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build/latest?definitionId=1\u0026amp;branchName=development\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/992695de99c1381c366d74cf333cc4b4a29d53878b4808d643fb673748a73c5b/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e57617270583f6272616e63684e616d653d646576656c6f706d656e74\" alt=\"Code Status development\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.WarpX?branchName=development\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://dev.azure.com/ECP-WarpX/WarpX/_build?definitionId=2\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/f95e83fed565d15a3d259197389c3fbb68e0e9d529df7da1f73702528739c16f/68747470733a2f2f6465762e617a7572652e636f6d2f4543502d57617270582f57617270582f5f617069732f6275696c642f7374617475732f4543502d57617270582e4e696768746c793f6272616e63684e616d653d6e696768746c79266c6162656c3d6e696768746c792532307061636b61676573\" alt=\"Nightly Installation Tests\" data-canonical-src=\"https://dev.azure.com/ECP-WarpX/WarpX/_apis/build/status/ECP-WarpX.Nightly?branchName=nightly\u0026amp;label=nightly%20packages\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://warpx.readthedocs.io/en/latest/?badge=latest\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2fe6e4a1201d33edf1bdd9968c6c0446da41d44fef1b7a1e532cddc4fbd4c2ae/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f77617270782f62616467652f3f76657273696f6e3d6c6174657374\" alt=\"Documentation Status\" data-canonical-src=\"https://readthedocs.org/projects/warpx/badge/?version=latest\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://spack.readthedocs.io/en/latest/package_list.html#warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/86cd172f84e0a3b89161faaeb17eb247cdb10062ed0e65f9f291db3011697416/68747470733a2f2f696d672e736869656c64732e696f2f737061636b2f762f7761727078\" alt=\"Spack Version\" data-canonical-src=\"https://img.shields.io/spack/v/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://anaconda.org/conda-forge/warpx\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4434c608221acef026a4af7cb491f491413ab135a781e3537087938592334617/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f636f6e64612d666f7267652f7761727078\" alt=\"Conda Version\" data-canonical-src=\"https://img.shields.io/conda/vn/conda-forge/warpx\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://gitter.im/ECP-WarpX/community?utm_source=badge\u0026amp;utm_medium=badge\u0026amp;utm_campaign=pr-badge\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c1799ddb014bc7c83ab051f3668c05f25049c81bbf1ae3c4e4dd6a61c68314aa/68747470733a2f2f6261646765732e6769747465722e696d2f4543502d57617270582f636f6d6d756e6974792e737667\" alt=\"Gitter\" data-canonical-src=\"https://badges.gitter.im/ECP-WarpX/community.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://warpx.readthedocs.io/en/latest/install/users.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/114e64f6c29b3e409c6de5b19ee4074ec3053396d43319fe4876231f1480e0d1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d6c696e75782532302537432532306f737825323025374325323077696e2d626c7565\" alt=\"Supported Platforms\" data-canonical-src=\"https://img.shields.io/badge/platforms-linux%20%7C%20osx%20%7C%20win-blue\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/ECP-WarpX/WarpX/compare/development\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4cb34757a4ca0098f7c5b01c1d559e13991f5cb4e6add106761194c2967a7911/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d6974732d73696e63652f4543502d57617270582f57617270582f6c61746573742f646576656c6f706d656e742e737667\" alt=\"GitHub commits since last release\" data-canonical-src=\"https://img.shields.io/github/commits-since/ECP-WarpX/WarpX/latest/development.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.exascaleproject.org/research/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/fe7a996983f2a22d3a469de3af6e13b7062bca7f02ffad7974bb724b27c2b218/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f737570706f7274656425323062792d4543502d6f72616e6765\" alt=\"Exascale Computing Project\" data-canonical-src=\"https://img.shields.io/badge/supported%20by-ECP-orange\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://isocpp.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/5d59fff46d59a1783cc24942cb4eb374014513db99f991164bd051bcd94aa598/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d4325324225324231372d6f72616e67652e737667\" alt=\"Language: C++17\" data-canonical-src=\"https://img.shields.io/badge/language-C%2B%2B17-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://python.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9cf7ec75b074af6953db1304db75950ab917ecd8a1aecb41f0d1191d10872298/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c616e67756167652d507974686f6e2d6f72616e67652e737667\" alt=\"Language: Python\" data-canonical-src=\"https://img.shields.io/badge/language-Python-orange.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://spdx.org/licenses/BSD-3-Clause-LBNL.html\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c468c77da60663856e2be1cdd66db538d4bca1b2a3bdf34a76a7f3953e58fc26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d2d4c424e4c2d626c75652e737667\" alt=\"License WarpX\" data-canonical-src=\"https://img.shields.io/badge/license-BSD--3--Clause--LBNL-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.5281/zenodo.4571577\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/a80e066c199b28e39d95c8a3cd8a7061bb4c190c717db8b58ff8cea2de0952be/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f4925323028736f75726365292d31302e353238312f7a656e6f646f2e343537313537372d626c75652e737667\" alt=\"DOI (source)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(source)-10.5281/zenodo.4571577-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://doi.org/10.1109/SC41404.2022.00008\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/2be0ab9ceaff22581aac9ee5d5eac9cc73cae7e4bad2c69bcf0ffd6713337293/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f444f49253230287061706572292d31302e313130392f534334313430342e323032322e30303030382d626c75652e737667\" alt=\"DOI (paper)\" data-canonical-src=\"https://img.shields.io/badge/DOI%20(paper)-10.1109/SC41404.2022.00008-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-overview\" class=\"anchor\" aria-hidden=\"true\" href=\"#overview\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eOverview\u003c/h2\u003e\n\u003cp\u003eWarpX is an advanced \u003cstrong\u003eelectromagnetic \u0026amp; electrostatic Particle-In-Cell\u003c/strong\u003e code.\nIt supports many features including Perfectly-Matched Layers (PML), mesh refinement, and the boosted-frame technique.\u003c/p\u003e\n\u003cp\u003eWarpX is a \u003cem\u003ehighly-parallel and highly-optimized code\u003c/em\u003e, which can run on GPUs and multi-core CPUs, and includes load balancing capabilities.\nWarpX scales to the world\u0027s largest supercomputers and was awarded the \u003ca href=\"https://www.exascaleproject.org/ecp-supported-collaborative-teams-win-the-2022-acm-gordon-bell-prize-and-special-prize/\" rel=\"nofollow\"\u003e2022 ACM Gordon Bell Prize\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-documentation\" class=\"anchor\" aria-hidden=\"true\" href=\"#documentation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDocumentation\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://picmi-standard.github.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/343c1eefa7d19641daf3e00da21e54db3a6211fe5f692c3004f2836a185668d8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532325049434d4925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICMI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22PICMI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.openPMD.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/062e5330b80f6eca55b1df50d6d154214f5a2033b7a87344ef2a580fd7a616dc/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d2532326f70656e504d4425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22openPMD%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://yt-project.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/9e6cacd2df0d5a581d8afad30a57807b71f4b67c58e74faa4080dad7d81c6184/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d253232776f726b7325323077697468253232266d6573736167653d253232797425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"yt-project\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22works%20with%22\u0026amp;message=%22yt%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eIn order to learn how to install and run the code, please see the online documentation:\n\u003ca href=\"https://warpx.readthedocs.io\" rel=\"nofollow\"\u003ehttps://warpx.readthedocs.io\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTo contact the developers, feel free to open an issue on this repo, or visit our Gitter room at \u003ca href=\"https://gitter.im/ECP-WarpX/community\" rel=\"nofollow\"\u003ehttps://gitter.im/ECP-WarpX/community\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://amrex-codes.github.io/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/7053679f4412132d376afadf481432a9d435336f8127e7c8650808bc66d019b2/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232414d52655825323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"AMReX\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22AMReX%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://picsar.net\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/793037a9842c5343f4942ce7475c7c7696e69b44621531f666492ac87b5e80b8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323250494353415225323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"PICSAR\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22PICSAR%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://openpmd-api.readthedocs.io\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/b7108e47d5ad6b76b60f07a4e04173ba260c5eef9bb244680f65ff91d8a319f8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532326f70656e504d442d61706925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"openPMD-api\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22openPMD-api%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://csmd.ornl.gov/adios\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/d525e37817dc6dfc5f173eb31f4e9fd52947e668793967565910166b335ced93/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324144494f5325323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"ADIOS\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22ADIOS%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://www.hdfgroup.org/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/005f778c667adb78e4302d47579b9bedc5ec0f59f88c13552f6b4bb399f93438/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d2532324844463525323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"HDF5\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22HDF5%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"http://www.ascent-dav.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/204f53a0d216a0a2fce9a367e3ba3a1957ac2285ed89026cb80321df6a125fc4/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d253232417363656e7425323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"Ascent\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22Ascent%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://sensei-insitu.org\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/6f870e29c1d57a4e4209ec97a00fbe4f73c8fd6fb589bf4c12f3feef9d3aaaeb/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d25323272756e732532306f6e253232266d6573736167653d25323253454e53454925323226636f6c6f723d253232626c756576696f6c6574253232\" alt=\"SENSEI\" data-canonical-src=\"https://img.shields.io/static/v1?label=%22runs%20on%22\u0026amp;message=%22SENSEI%22\u0026amp;color=%22blueviolet%22\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur workflow is described in \u003ca href=\"CONTRIBUTING.rst\"\u003eCONTRIBUTING.rst\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-license\" class=\"anchor\" aria-hidden=\"true\" href=\"#license\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eLicense\u003c/h2\u003e\n\u003cp\u003eWarpX Copyright (c) 2018-2023, The Regents of the University of California,\nthrough Lawrence Berkeley National Laboratory (subject to receipt of any\nrequired approvals from the U.S. Dept. of Energy).  All rights reserved.\u003c/p\u003e\n\u003cp\u003eIf you have questions about your rights to use or distribute this software,\nplease contact Berkeley Lab\u0027s Innovation \u0026amp; Partnerships Office at\n\u003ca href=\"mailto:IPO@lbl.gov\"\u003eIPO@lbl.gov\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNOTICE.  This Software was developed under funding from the U.S. Department\nof Energy and the U.S. Government consequently retains certain rights. As\nsuch, the U.S. Government has been granted for itself and others acting on\nits behalf a paid-up, nonexclusive, irrevocable, worldwide license in the\nSoftware to reproduce, distribute copies to the public, prepare derivative\nworks, and perform publicly and display publicly, and to permit other to do\nso.\u003c/p\u003e\n\u003cp\u003eLicense for WarpX can be found at \u003ca href=\"LICENSE.txt\"\u003eLICENSE.txt\u003c/a\u003e.\u003c/p\u003e\n",
    "stargazers_count": 180,
    "subscribers_count": 15,
    "topics": [
      "laser",
      "plasma",
      "physics",
      "gpu",
      "simulation",
      "particle-in-cell",
      "pic",
      "research"
    ],
    "updated_at": 1680625963.0
  },
  {
    "data_format": 2,
    "description": "WAVEWATCH III",
    "filenames": [
      "model/ci/spack_intel.yaml",
      "model/ci/spack_gnu.yaml"
    ],
    "full_name": "NOAA-EMC/WW3",
    "latest_release": "6.07.1",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-the-wavewatch-iii-framework\" class=\"anchor\" aria-hidden=\"true\" href=\"#the-wavewatch-iii-framework\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eThe WAVEWATCH III Framework\u003c/h1\u003e\n\u003cp\u003eWAVEWATCH III\u003csup\u003e\u00ae\u003c/sup\u003e  is a community wave modeling framework that includes the\nlatest scientific advancements in the field of wind-wave modeling and dynamics.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-general-features\" class=\"anchor\" aria-hidden=\"true\" href=\"#general-features\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eGeneral Features\u003c/h2\u003e\n\u003cp\u003eWAVEWATCH III\u003csup\u003e\u00ae\u003c/sup\u003e solves the random phase spectral action density\nbalance equation for wavenumber-direction spectra. The model includes options\nfor shallow-water (surf zone) applications, as well as wetting and drying of\ngrid points. Propagation of a wave spectrum can be solved using regular\n(rectilinear or curvilinear) and unstructured (triangular) grids. See\n\u003ca href=\"https://github.com/NOAA-EMC/WW3/wiki/About-WW3\"\u003eAbout WW3\u003c/a\u003e for a\ndetailed description of WAVEWATCH III\u003csup\u003e\u00ae\u003c/sup\u003e .\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-installation\" class=\"anchor\" aria-hidden=\"true\" href=\"#installation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eThe WAVEWATCH III\u003csup\u003e\u00ae\u003c/sup\u003e  framework package has two parts that need to be combined so\nall runs smoothly: the GitHub repo itself, and a binary data file bundle that\nneeds to be obtained from our ftp site. Steps to successfully acquire and install\nthe framework are outlined in our \u003ca href=\"https://github.com/NOAA-EMC/WW3/wiki/Quick-Start\"\u003eQuick Start\u003c/a\u003e\nguide.\u003c/p\u003e\n\u003ch2\u003e\u003ca id=\"user-content-disclaimer\" class=\"anchor\" aria-hidden=\"true\" href=\"#disclaimer\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThe United States Department of Commerce (DOC) GitHub project code is provided\non an \u0027as is\u0027 basis and the user assumes responsibility for its use. DOC has\nrelinquished control of the information and no longer has responsibility to\nprotect the integrity, confidentiality, or availability of the information. Any\nclaims against the Department of Commerce stemming from the use of its GitHub\nproject will be governed by all applicable Federal law. Any reference to\nspecific commercial products, processes, or services by service mark,\ntrademark, manufacturer, or otherwise, does not constitute or imply their\nendorsement, recommendation or favoring by the Department of Commerce. The\nDepartment of Commerce seal and logo, or the seal and logo of a DOC bureau,\nshall not be used in any manner to imply endorsement of any commercial product\nor activity by DOC or the United States Government.\u003c/p\u003e\n",
    "stargazers_count": 194,
    "subscribers_count": 46,
    "topics": [],
    "updated_at": 1680776948.0
  },
  {
    "data_format": 2,
    "description": "MPI wrappers for Julia",
    "filenames": [
      ".ci/mvapich/spack.yaml"
    ],
    "full_name": "JuliaParallel/MPI.jl",
    "latest_release": "v0.20.8",
    "readme": "\u003ch1\u003e\u003ca id=\"user-content-mpi-interface-for-the-julia-language\" class=\"anchor\" aria-hidden=\"true\" href=\"#mpi-interface-for-the-julia-language\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eMPI interface for the Julia language\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://juliaparallel.github.io/MPI.jl/latest/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/56f8252ba8e9d3f0b810769543f77823d2fe031ce560d4c2d69fb1fcad800383/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c75652e737667\" alt=\"Docs latest\" data-canonical-src=\"https://img.shields.io/badge/docs-latest-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://juliaparallel.github.io/MPI.jl/stable/\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667\" alt=\"Docs stable\" data-canonical-src=\"https://img.shields.io/badge/docs-stable-blue.svg\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml\"\u003e\u003cimg src=\"https://github.com/JuliaParallel/MPI.jl/actions/workflows/UnitTests.yml/badge.svg\" alt=\"Unit Tests\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://buildkite.com/julialang/mpi-dot-jl\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/87debbd756a8b45df7ac1f25dc034436051f7ccfe155df49f1ec1f6209e51caf/68747470733a2f2f62616467652e6275696c646b6974652e636f6d2f65643831336263346437396635353761646264623832316231633863386465393839393936383665363937646634613337332e7376673f6272616e63683d6d6173746572\" alt=\"GPU tests\" data-canonical-src=\"https://badge.buildkite.com/ed813bc4d79f557adbdb821b1c8c8de98999686e697df4a373.svg?branch=master\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://codecov.io/github/JuliaParallel/MPI.jl?branch=master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/00ad86424fd334dccd9dde2876e4f3e82b84ad4219e5c1661d6a06b63f46f516/68747470733a2f2f636f6465636f762e696f2f6769746875622f4a756c6961506172616c6c656c2f4d50492e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572\" alt=\"codecov.io\" data-canonical-src=\"https://codecov.io/github/JuliaParallel/MPI.jl/coverage.svg?branch=master\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003ca href=\"https://coveralls.io/github/JuliaParallel/MPI.jl?branch=master\" rel=\"nofollow\"\u003e\u003cimg src=\"https://camo.githubusercontent.com/4d989c928ad758732dcf79e5d1a0b592a1765763c2237af784955ed806e37ef1/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f4a756c6961506172616c6c656c2f4d50492e6a6c2f62616467652e7376673f6272616e63683d6d617374657226736572766963653d676974687562\" alt=\"Coverage Status\" data-canonical-src=\"https://coveralls.io/repos/JuliaParallel/MPI.jl/badge.svg?branch=master\u0026amp;service=github\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis provides \u003ca href=\"http://julialang.org/\" rel=\"nofollow\"\u003eJulia\u003c/a\u003e interface to the Message Passing Interface (\u003ca href=\"http://www.mpi-forum.org/\" rel=\"nofollow\"\u003eMPI\u003c/a\u003e), roughly inspired by \u003ca href=\"https://github.com/mpi4py/mpi4py/\"\u003empi4py\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePlease see the \u003ca href=\"https://juliaparallel.github.io/MPI.jl/stable/\" rel=\"nofollow\"\u003edocumentation\u003c/a\u003e for instructions on \u003ca href=\"https://juliaparallel.github.io/MPI.jl/stable/configuration/\" rel=\"nofollow\"\u003econfiguration\u003c/a\u003e and \u003ca href=\"https://juliaparallel.github.io/MPI.jl/stable/usage/\" rel=\"nofollow\"\u003eusage\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBreaking changes with v0.20:\u003c/strong\u003e The way how MPI.jl is configured to use\ndifferent MPI implementations has changed from v0.19 to v0.20 in a\n\u003cem\u003enon-backward-compatible\u003c/em\u003e manner.\nSpecifically, most \u003ccode\u003eJULIA_MPI_XXX\u003c/code\u003e variables do not have an effect anymore.\nPlease refer to the\n\u003ca href=\"https://juliaparallel.org/MPI.jl/stable/configuration/#Migration-from-MPI.jl-v0.19-or-earlier\" rel=\"nofollow\"\u003edocs\u003c/a\u003e\nfor information on how to migrate your existing configuration.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-help-and-discussion\" class=\"anchor\" aria-hidden=\"true\" href=\"#help-and-discussion\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eHelp and discussion\u003c/h1\u003e\n\u003cp\u003eFor help and discussion, we suggest asking on the following venues:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://discourse.julialang.org/c/domain/parallel/34\" rel=\"nofollow\"\u003e\"Julia at Scale\" topic on the Julia Discourse\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e#distributed channel on the \u003ca href=\"https://julialang.slack.com/\" rel=\"nofollow\"\u003eJulia Slack\u003c/a\u003e (visit \u003ca href=\"https://julialang.org/slack/\" rel=\"nofollow\"\u003ehttps://julialang.org/slack/\u003c/a\u003e to join).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e\u003ca id=\"user-content-contributing\" class=\"anchor\" aria-hidden=\"true\" href=\"#contributing\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eContributing\u003c/h1\u003e\n\u003cp\u003eContributions are encouraged. In particular, MPI provides several hundred functions, only a small number of which are currently exposed. If there are additional functions you would like to use, please open an \u003ca href=\"https://github.com/JuliaParallel/MPI.jl/issues\"\u003eissue\u003c/a\u003e or \u003ca href=\"https://github.com/JuliaParallel/MPI.jl/pulls\"\u003epull request\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAdditional examples and documentation improvements are also very welcome.\u003c/p\u003e\n\u003ch1\u003e\u003ca id=\"user-content-citation\" class=\"anchor\" aria-hidden=\"true\" href=\"#citation\"\u003e\u003cspan aria-hidden=\"true\" class=\"octicon octicon-link\"\u003e\u003c/span\u003e\u003c/a\u003eCitation\u003c/h1\u003e\n\u003cp\u003eIf you use MPI.jl in your work, please cite the following paper:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSimon Byrne, Lucas C. Wilcox, and Valentin Churavy (2021) \"MPI.jl: Julia bindings for the Message Passing Interface\". \u003cem\u003eJuliaCon Proceedings\u003c/em\u003e, 1(1), 68, doi: \u003ca href=\"https://doi.org/10.21105/jcon.00068\" rel=\"nofollow\"\u003e10.21105/jcon.00068\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n",
    "stargazers_count": 319,
    "subscribers_count": 21,
    "topics": [
      "mpi",
      "julia",
      "hpc",
      "julia-language",
      "mpich",
      "openmpi",
      "microsoft-mpi"
    ],
    "updated_at": 1680005017.0
  }
]
