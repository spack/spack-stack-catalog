spack:
  view: false

  concretizer:
    reuse: false
    unify: false

  compilers:
  - compiler:
      spec: nvhpc@21.11
      paths:
        cc: cc
        cxx: CC
        f77: ftn
        fc: ftn
      flags: {}
      operating_system: sles15
      target: any
      modules:
      - PrgEnv-nvhpc
      - nvhpc/21.11
      environment: {}
      extra_rpaths: []

  modules:
    default:
      'enable:': [lmod]
      lmod:
        defaults:
        - cray-mpich@8.1.17
        core_compilers: [nvhpc@21.11]
        blacklist_implicits: true
        verbose: true
        hash_length: 0
        whitelist: [cray-mpich, cmake]
        hierarchy: [mpi]
        projections: {}
        core_specs: []
        all:
          autoload: direct
          environment:
            set:
              ${PACKAGE}_ROOT: ${PREFIX}
          suffixes:
            +cuda cuda_arch=70: cuda70
            +cuda cuda_arch=80: cuda80
            +openmp: openmp
        bricks:
          suffixes:
            +cuda: cuda
        cabana:
          suffixes:
            ^kokkos +cuda cuda_arch=70: cuda70
            ^kokkos +cuda cuda_arch=80: cuda80
        flux-core:
          suffixes:
            +cuda: cuda
        hpctoolkit:
          suffixes:
            +cuda: cuda
        legion:
          suffixes:
            +cuda: cuda
        mpich:
          suffixes:
            ^hwloc+cuda: hwloc-cuda
        papi:
          suffixes:
            +cuda: cuda
        py-warpx:
          suffixes:
            ^warpx dims=2: dims2
            ^warpx dims=3: dims3
            ^warpx dims=rz: dimsRZ
        tau:
          suffixes:
            +cuda: cuda
        upcxx:
          suffixes:
            +cuda: cuda

  packages:
    all:
      compiler: [nvhpc@21.11]
      providers:
        blas: [openblas]
        mpi: [cray-mpich]
      target: [zen3]
      variants: +mpi
    binutils:
      variants: +ld +gold +headers +libiberty ~nls
    cuda:
      version: [11.4.2]
    elfutils:
      variants: +bzip2 ~nls +xz
    hdf5:
      variants: +fortran +hl +shared
    libunwind:
      variants: +pic +xz
    mpich:
      variants: ~wrapperrpath
    ncurses:
      variants: +termlib
    openblas:
      variants: threads=openmp
    python:
      version: [3.8.13]
    trilinos:
      variants: +amesos +amesos2 +anasazi +aztec +belos +boost +epetra +epetraext
        +ifpack +ifpack2 +intrepid +intrepid2 +isorropia +kokkos +ml +minitensor +muelu
        +nox +piro +phalanx +rol +rythmos +sacado +stk +shards +shylu +stokhos +stratimikos
        +teko +tempus +tpetra +trilinoscouplings +zoltan +zoltan2 +superlu-dist gotype=long_long
    xz:
      variants: +pic
    mesa:
      version: [21.3.8]

    # EXTERNALS
    libfabric:
      buildable: false
      externals:
      - spec: libfabric@1.11.0
        modules:
        - libfabric/1.11.0.4.124
    slurm:
      buildable: false
      version: [21.08.8]
      externals:
      - spec: slurm@21.08.8
        prefix: /usr
    cray-mpich:
      buildable: false
      externals:
      - spec: cray-mpich@8.1.17 %nvhpc@21.11
        prefix: /opt/cray/pe/mpich/8.1.17/ofi/nvidia/20.7
        modules:
        - cray-mpich/8.1.17
        - libfabric

  # DEALING W NVHPC CONFLICTS
    python:
      buildable: false
      externals:
      - spec: python@3.8.13
        prefix: /global/cfs/cdirs/m3896/shared/ParaTools/E4S/22.05/PrgEnv-nvhpc/spack/opt/spack/cray-sles15-zen3/gcc-11.2.0/python-3.8.13-fkuesdnl4nfpn4dbaop7ks2urs5a4jd4

  specs:
  # CPU
  - adios@1.13.1 # %nvhpc ^python%gcc
  - adios2@2.8.0
  - aml@0.1.0
  - amrex@22.05
  - arborx@1.2
  - archer@2.0.0 # %nvhpc ^python%gcc
  - argobots@1.1
  - axom@0.6.1
  - bolt@2.0
  - butterflypack@2.1.1
  - cabana@0.4.0
  - caliper@2.7.0
  - chai@2.4.0 ~benchmarks ~tests
  - charliecloud@0.26 # %nvhpc ^python%gcc
  - conduit@0.8.3
  - darshan-runtime@3.3.1
  - darshan-util@3.3.1
  - datatransferkit@3.1-rc3
  - dyninst@12.1.0
  - exaworks@0.1.0 # %nvhpc ^python%gcc
  - faodel@1.2108.1
  - flecsi@1.4.2 # %nvhpc ^python%gcc
  - flit@2.1.0 # %nvhpc ^python%gcc
  - flux-core@0.38.0 # %nvhpc ^python%gcc
  - fortrilinos@2.0.0
  - gasnet@2022.3.0
  - ginkgo@1.4.0
  - globalarrays@5.8
  - gmp@6.2.1
  - gotcha@1.0.3
  - gptune@3.0.0 # %nvhpc ^python%gcc
  - hdf5@1.10.7 +fortran +hl +shared
  - heffte@2.2.0 +fftw
  - hpctoolkit@2022.04.15 # %nvhpc ^python%gcc
  - hpx@1.7.1 networking=mpi # %nvhpc ^python%gcc
  - hypre@2.24.0
  - kokkos@3.6.00 +openmp
  - kokkos-kernels@3.6.00 +openmp
  - lammps@20220107
  - legion@21.03.0
  - libquo@1.3.1
  - libunwind@1.6.2
  - mercury@2.1.0
  - metall@0.20
  - mfem@4.4.0
  - mpark-variant@1.4.0
  - mpifileutils@0.11.1 ~xattr
  - nccmp@1.9.0.1
  - nco@5.0.1
  - netlib-scalapack@2.2.0
  - nrm@0.1.0 # %nvhpc ^python%gcc
  - omega-h@9.34.1
  - openmpi@4.1.3
  - openpmd-api@0.14.4
  - papi@6.0.0.1
  - papyrus@1.0.2
  - parallel-netcdf@1.12.2
  - parsec@3.0.2012 ~cuda # %nvhpc ^python%gcc
  - pdt@3.25.1
  - petsc@3.17.1 # %nvhpc ^python%gcc
  - phist@1.9.5
  - plasma@21.8.29
  - precice@2.4.0
  - pumi@2.2.7
  - py-cinemasci@1.7.0 # %nvhpc ^python%gcc
  - py-jupyterhub@1.4.1 # %nvhpc ^python%gcc
  - py-libensemble@0.9.1 # %nvhpc ^python%gcc
  - py-petsc4py@3.17.1 # %nvhpc ^python%gcc
  - py-warpx@22.05 ^warpx dims=2 # %nvhpc ^python%gcc
  - py-warpx@22.05 ^warpx dims=3 # %nvhpc ^python%gcc
  - py-warpx@22.05 ^warpx dims=rz # %nvhpc ^python%gcc
  - qthreads@1.16 scheduler=distrib
  - raja@0.14.0
  - scr@3.0rc2
  - slate@2021.05.02 ~cuda
  - slepc@3.17.1 # %nvhpc ^python%gcc
  - stc@0.9.0
  - strumpack@6.3.1 ~slate
  - sundials@6.2.0
  - superlu@5.3.0
  - superlu-dist@7.2.0
  - sz@2.1.12
  - tasmanian@7.7
  - tau@2.31 +mpi +python # %nvhpc ^python%gcc
  - trilinos@13.0.1 +amesos +amesos2 +anasazi +aztec +belos +boost +epetra +epetraext
    +ifpack +ifpack2 +intrepid +intrepid2 +isorropia +kokkos +ml +minitensor +muelu
    +nox +piro +phalanx +rol +rythmos +sacado +stk +shards +shylu +stokhos +stratimikos
    +teko +tempus +tpetra +trilinoscouplings +zoltan +zoltan2 +superlu-dist gotype=long_long
  - turbine@1.3.0
  - umap@2.1.0
  - umpire@6.0.0
  - unifyfs@0.9.2
  - veloc@1.5
  - zfp@0.5.5
  
  # GPU
  - adios2@2.8.0 +cuda cuda_arch=80
  - arborx@1.2 +cuda cuda_arch=80 ^kokkos@3.6.00 +wrapper
  - cabana@0.4.0 +cuda ^kokkos@3.6.00 +wrapper +cuda_lambda +cuda cuda_arch=80
  - caliper@2.7.0 +cuda cuda_arch=80 # %nvhpc ^python%gcc
  - chai@2.4.0 ~benchmarks ~tests +cuda cuda_arch=80 ^umpire@6.0.0 ~shared
  - flux-core@0.38.0 +cuda # %nvhpc ^python%gcc
  - ginkgo@1.4.0 +cuda cuda_arch=80
  - heffte@2.2.0 +cuda cuda_arch=80
  - hpctoolkit@2022.04.15 +cuda # %nvhpc ^python%gcc
  - hpx@1.7.1 +cuda cuda_arch=80 # %nvhpc ^python%gcc
  - hypre@2.24.0 +cuda cuda_arch=80
  - kokkos-kernels@3.6.00 +cuda cuda_arch=80 ^kokkos@3.6.00 +wrapper +cuda cuda_arch=80
  - kokkos@3.6.00 +wrapper +cuda cuda_arch=80
  - legion@21.03.0 +cuda cuda_arch=80
  - magma@2.6.2 +cuda cuda_arch=80
  - mfem@4.4.0 +cuda cuda_arch=80
  - papi@6.0.0.1 +cuda
  - petsc@3.17.1+cuda cuda_arch=80 # %nvhpc ^python%gcc
  - raja@0.14.0 +cuda cuda_arch=80
  - slate@2021.05.02 +cuda cuda_arch=80
  - slepc@3.17.1 +cuda cuda_arch=80 # %nvhpc ^python%gcc
  - strumpack@6.3.1 ~slate +cuda cuda_arch=80
  - sundials@6.2.0 +cuda cuda_arch=80
  - superlu-dist@7.2.0 +cuda cuda_arch=80
  - tasmanian@7.7 +cuda cuda_arch=80
  - tau@2.31.1 +mpi +cuda
  - umpire@6.0.0 ~shared +cuda cuda_arch=80
  - zfp@0.5.5 +cuda cuda_arch=80

  # NVHPC CONFLICTS
  # - swig@4.0.2
  # - swig@4.0.2-fortran
  # - nvhpc@22.3 # don't install nvhpc w/ %nvhpc...

  # FACILITY BUILD FAILED - CPU
  #- alquimia@1.0.9                           # pflotran
  #- ascent@0.8.0                             # vtk-m
  #- bricks@r0.1                              # bricks
  #- geopm@1.1.0                              # geopm
  #- h5bench@1.2                              # h5bench
  #- loki@0.1.7                               # loki
  #- paraview@5.10.1 +qt                      # font-util
  #- plumed@2.6.3                             # plumed
  #- pruners-ninja@1.0.1                      # pruners-ninja
  #- rempi@1.1.0                              # rempi
  #- upcxx@2022.3.0                           # upcxx
  #- variorum@0.4.1                           # variorum
  #- vtk-m@1.7.1                              # vtk-m
  #- wannier90@3.1.0                          # wannier90
  # -----
  # bricks: fetch error
  # font-util: fonts/X11/cyrillic: failed to write cache
  # geopm: configure: error: Failed to determine MPI Fortran build flags use --with-mpi-bin or --with-mpicxx or --disable-mpi
  # h5bench: commons/h5bench_util.h:196: multiple definition of `has_vol_async';
  # loki: loki/SmallObj.h:462:57: error: ISO C++17 does not allow dynamic exception specifications
  # pflotran: Error: Rank mismatch between actual argument at (1) and actual argument at (2) (scalar and rank-1)
  # plumed: lepton/Operation.h:902:39: error: 'numeric_limits' is not a member of 'std'
  # pruners-ninja: test/ninja_test_util.c:34: multiple definition of `a';
  # rempi: rempi_message_manager.h:53:3: error: 'string' does not name a type; did you mean 'stdin'?
  # upcxx: configure error: Requested PMI version cray could not be found
  # variorum: /usr/bin/ld: Intel/CMakeFiles/variorum_intel.dir/IvyBridge_3E.c.o:(.bss+0x0): multiple definition of `g_platform';
  # vtk-m: vtkmdiy/mpi/datatypes.hpp:42:12: error: 'size_t' has not been declared
  # wannier90: ../comms.F90:1214:22: Type mismatch between actual argument at (1) and actual argument at (2) (COMPLEX(8)/INTEGER(4)).

  # FACILITY BUILD FAILED - GPU
  #- bricks@r0.1 +cuda                        # bricks
  #- parsec@3.0.2012 +cuda cuda_arch=80       # parsec
  #- trilinos@13.2.0 +cuda cuda_arch=80       # trilinos
  #- upcxx@2022.3.0 +cuda                     # upcxx
  #- vtk-m@1.7.1 +cuda cuda_arch=80           # vtk-m
  # -----
  # bricks: fetch error
  # parsec: parsec/mca/device/cuda/transfer.c:168: multiple definition of `parsec_CUDA_d2h_max_flows'
  # trilinos: /opt/cray/pe/mpich/8.1.15/ofi/gnu/9.1/bin/mpicxx unable to compile test program
  # upcxx: configure error: Requested PMI version cray could not be found
  # vtk-m: vtkmdiy/mpi/datatypes.hpp:42:12: error: 'size_t' has not been declared

  # CONCRETIZATION ISSUE
  #- amrex@2.8.0 +cuda cuda_arch=80
  #- flecsi@1.4.2 +cuda cuda_arch=80

  # SKIPPED
  #- gasnet@2022.3.0 +cuda cuda_arch=80 conduits=mpi       # requires driver
  #- libnrm@0.1.0                                          # explicit depends_on mpich
  #- upcxx@2022.3.0 +cuda                                  # requires driver

  # BUILD FAILED - CPU
  #- catalyst@5.6.0                                        # https://github.com/spack/spack/issues/30478
  #- dealii@9.3.3
  #- stat@4.1.0

  # BUILD FAILED - GPU
  #- ascent@0.8.0 ~shared +cuda cuda_arch=80               # https://github.com/spack/spack/issues/27954
  #- axom@0.6.1 +cuda cuda_arch=80 ^umpire@6.0.0 ~shared   # https://github.com/spack/spack/issues/29520
  #- dealii@9.3.3 +cuda cuda_arch=80                       # https://github.com/spack/spack/issues/29523
  #- lammps@20220107 +cuda cuda_arch=80                    # https://github.com/spack/spack/issues/30590
